{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 layers model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gathering of all functions needed to train a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from numpy import argmax\n",
    "\n",
    "def read_csv(filename):\n",
    "    dataset = pd.read_csv(filename, encoding='utf-8')\n",
    "    return dataset\n",
    "\n",
    "def one_hot_encode(dataset):\n",
    "    dataset_one_hot_encoded = pd.get_dummies(dataset)  \n",
    "    return dataset_one_hot_encoded\n",
    "\n",
    "def divide_X_y(dataset, index_sep):\n",
    "    X = dataset.iloc[:,:index_sep]\n",
    "    y = dataset.iloc[:,index_sep:]\n",
    "    return X,y\n",
    "\n",
    "def split_train_test(X, y, test_size):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=1)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "def graph_loss_vs_epochs(history, save_image_filename, title):\n",
    "    training_loss = history.history['loss']\n",
    "    test_loss = history.history['val_loss']\n",
    "    epoch_count = range(1, len(training_loss) + 1)\n",
    "    plt.title(title)\n",
    "    plt.plot(epoch_count, training_loss, 'r--')\n",
    "    plt.plot(epoch_count, test_loss, 'b-')\n",
    "    plt.legend(['Training Loss', 'Test Loss'])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss') \n",
    "    plt.axvline(x = epoch_count[test_loss.index(min(test_loss))], color = 'c', linestyle=\"dotted\")\n",
    "    plt.savefig(save_image_filename)\n",
    "    plt.show()\n",
    "    \n",
    "def save_history(filename, model):\n",
    "    # ejemplo de filename:'history1.npy'\n",
    "    np.save(filename,model.history.history)\n",
    "    \n",
    "def load_history(filename):\n",
    "    history=np.load(filename,allow_pickle='TRUE').item()\n",
    "    return history\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    print('\\nEvaluating:')\n",
    "    (test_loss, test_accuracy) = model.evaluate(X_test, y_test)\n",
    "    print(f'\\nTest accuracy: {test_accuracy * 100:>0.1f}%, test loss: {test_loss:>8f}')\n",
    "    \n",
    "def get_label(column):\n",
    "    label = y_test.columns[column]\n",
    "    return label.replace('Nivel de Adaptación_', '')\n",
    "\n",
    "def fill_test_ds_labels(model, test_ds_filename, output_test_filename):\n",
    "    test_ds = read_csv(test_ds_filename)\n",
    "    test_ds = pd.get_dummies(test_ds)\n",
    "    nivel_de_adaptacion_test_ds = []\n",
    "    for index,test in test_ds.iterrows():\n",
    "        test_ds_pred = pd.DataFrame(test).transpose()\n",
    "        test_oh = pd.get_dummies(test_ds_pred)\n",
    "        prediction = model.predict(test_oh)\n",
    "        nivel_de_adaptacion_test_ds.append((index+1,get_label(argmax(prediction))))\n",
    "    print(len(nivel_de_adaptacion_test_ds))\n",
    "    nivel_de_adaptacion_df = pd.DataFrame(nivel_de_adaptacion_test_ds, columns=['id','Nivel de Adaptación']).reset_index(drop=True)\n",
    "    nivel_de_adaptacion_df.to_csv(output_test_filename,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading, preparing and dividing dataset for Experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_sep = 31\n",
    "test_size=0.2\n",
    "dataset = read_csv('../training-ds.csv')\n",
    "dataset = one_hot_encode(dataset)\n",
    "X, y = divide_X_y(dataset, index_sep)\n",
    "X_train, X_test, y_train, y_test = split_train_test(X, y, test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: V1\n",
    "#### Model 4 consists in 4 hidden Dense layers:\n",
    "    learning_rate = 0.001\n",
    "    batch_size = 32\n",
    "    loss_fn = CategoricalCrossentropy\n",
    "    optimizer = Adam\n",
    "    Hidden layers:\n",
    "        1. units = 32, activation = relu\n",
    "        2. units = 32, activation = relu\n",
    "        3. units = 64, activation = relu\n",
    "        4. units = 64, activation = relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4000\n",
      "25/25 - 3s - loss: 1.0071 - accuracy: 0.5045 - val_loss: 0.8849 - val_accuracy: 0.5596\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.88494, saving model to models\\model_4L_v1\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v1\\assets\n",
      "Epoch 2/4000\n",
      "25/25 - 0s - loss: 0.8673 - accuracy: 0.5759 - val_loss: 0.8072 - val_accuracy: 0.6321\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.88494 to 0.80724, saving model to models\\model_4L_v1\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v1\\assets\n",
      "Epoch 3/4000\n",
      "25/25 - 0s - loss: 0.7954 - accuracy: 0.6394 - val_loss: 0.7278 - val_accuracy: 0.6684\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.80724 to 0.72780, saving model to models\\model_4L_v1\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v1\\assets\n",
      "Epoch 4/4000\n",
      "25/25 - 0s - loss: 0.7260 - accuracy: 0.6667 - val_loss: 0.6668 - val_accuracy: 0.7098\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.72780 to 0.66681, saving model to models\\model_4L_v1\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v1\\assets\n",
      "Epoch 5/4000\n",
      "25/25 - 0s - loss: 0.6688 - accuracy: 0.6978 - val_loss: 0.6437 - val_accuracy: 0.7409\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.66681 to 0.64366, saving model to models\\model_4L_v1\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v1\\assets\n",
      "Epoch 6/4000\n",
      "25/25 - 0s - loss: 0.6222 - accuracy: 0.7198 - val_loss: 0.5834 - val_accuracy: 0.7617\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.64366 to 0.58344, saving model to models\\model_4L_v1\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v1\\assets\n",
      "Epoch 7/4000\n",
      "25/25 - 0s - loss: 0.5746 - accuracy: 0.7613 - val_loss: 0.5540 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.58344 to 0.55398, saving model to models\\model_4L_v1\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v1\\assets\n",
      "Epoch 8/4000\n",
      "25/25 - 0s - loss: 0.5342 - accuracy: 0.7873 - val_loss: 0.5497 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.55398 to 0.54975, saving model to models\\model_4L_v1\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v1\\assets\n",
      "Epoch 9/4000\n",
      "25/25 - 0s - loss: 0.5054 - accuracy: 0.7886 - val_loss: 0.5138 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.54975 to 0.51381, saving model to models\\model_4L_v1\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v1\\assets\n",
      "Epoch 10/4000\n",
      "25/25 - 0s - loss: 0.4644 - accuracy: 0.8106 - val_loss: 0.5105 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.51381 to 0.51050, saving model to models\\model_4L_v1\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v1\\assets\n",
      "Epoch 11/4000\n",
      "25/25 - 0s - loss: 0.4328 - accuracy: 0.8262 - val_loss: 0.5075 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.51050 to 0.50754, saving model to models\\model_4L_v1\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v1\\assets\n",
      "Epoch 12/4000\n",
      "25/25 - 0s - loss: 0.4213 - accuracy: 0.8327 - val_loss: 0.4831 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.50754 to 0.48311, saving model to models\\model_4L_v1\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v1\\assets\n",
      "Epoch 13/4000\n",
      "25/25 - 0s - loss: 0.4319 - accuracy: 0.8249 - val_loss: 0.4845 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.48311\n",
      "Epoch 14/4000\n",
      "25/25 - 0s - loss: 0.3896 - accuracy: 0.8457 - val_loss: 0.4666 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.48311 to 0.46655, saving model to models\\model_4L_v1\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v1\\assets\n",
      "Epoch 15/4000\n",
      "25/25 - 0s - loss: 0.3614 - accuracy: 0.8508 - val_loss: 0.4581 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.46655 to 0.45811, saving model to models\\model_4L_v1\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v1\\assets\n",
      "Epoch 16/4000\n",
      "25/25 - 3s - loss: 0.3452 - accuracy: 0.8586 - val_loss: 0.4975 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.45811\n",
      "Epoch 17/4000\n",
      "25/25 - 0s - loss: 0.3559 - accuracy: 0.8560 - val_loss: 0.4566 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.45811 to 0.45664, saving model to models\\model_4L_v1\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v1\\assets\n",
      "Epoch 18/4000\n",
      "25/25 - 0s - loss: 0.3353 - accuracy: 0.8534 - val_loss: 0.4384 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.45664 to 0.43843, saving model to models\\model_4L_v1\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v1\\assets\n",
      "Epoch 19/4000\n",
      "25/25 - 0s - loss: 0.3430 - accuracy: 0.8547 - val_loss: 0.4586 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.43843\n",
      "Epoch 20/4000\n",
      "25/25 - 0s - loss: 0.3206 - accuracy: 0.8534 - val_loss: 0.4768 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.43843\n",
      "Epoch 21/4000\n",
      "25/25 - 0s - loss: 0.3548 - accuracy: 0.8470 - val_loss: 0.5118 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.43843\n",
      "Epoch 22/4000\n",
      "25/25 - 0s - loss: 0.3213 - accuracy: 0.8690 - val_loss: 0.4533 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.43843\n",
      "Epoch 23/4000\n",
      "25/25 - 0s - loss: 0.2917 - accuracy: 0.8755 - val_loss: 0.4365 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.43843 to 0.43651, saving model to models\\model_4L_v1\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v1\\assets\n",
      "Epoch 24/4000\n",
      "25/25 - 0s - loss: 0.2819 - accuracy: 0.8794 - val_loss: 0.4310 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.43651 to 0.43101, saving model to models\\model_4L_v1\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v1\\assets\n",
      "Epoch 25/4000\n",
      "25/25 - 0s - loss: 0.3010 - accuracy: 0.8742 - val_loss: 0.4453 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.43101\n",
      "Epoch 26/4000\n",
      "25/25 - 0s - loss: 0.2813 - accuracy: 0.8859 - val_loss: 0.4523 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.43101\n",
      "Epoch 27/4000\n",
      "25/25 - 0s - loss: 0.2729 - accuracy: 0.8911 - val_loss: 0.4318 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.43101\n",
      "Epoch 28/4000\n",
      "25/25 - 0s - loss: 0.2663 - accuracy: 0.8911 - val_loss: 0.4439 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.43101\n",
      "Epoch 29/4000\n",
      "25/25 - 0s - loss: 0.2641 - accuracy: 0.8859 - val_loss: 0.4999 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.43101\n",
      "Epoch 30/4000\n",
      "25/25 - 0s - loss: 0.2925 - accuracy: 0.8729 - val_loss: 0.4418 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.43101\n",
      "Epoch 31/4000\n",
      "25/25 - 0s - loss: 0.2678 - accuracy: 0.8807 - val_loss: 0.4456 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.43101\n",
      "Epoch 32/4000\n",
      "25/25 - 0s - loss: 0.2651 - accuracy: 0.8859 - val_loss: 0.4460 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.43101\n",
      "Epoch 33/4000\n",
      "25/25 - 0s - loss: 0.2725 - accuracy: 0.8820 - val_loss: 0.4373 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.43101\n",
      "Epoch 34/4000\n",
      "25/25 - 0s - loss: 0.2613 - accuracy: 0.8820 - val_loss: 0.4699 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.43101\n",
      "Epoch 35/4000\n",
      "25/25 - 0s - loss: 0.3270 - accuracy: 0.8651 - val_loss: 0.4816 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.43101\n",
      "Epoch 36/4000\n",
      "25/25 - 0s - loss: 0.2603 - accuracy: 0.8833 - val_loss: 0.4224 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.43101 to 0.42236, saving model to models\\model_4L_v1\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v1\\assets\n",
      "Epoch 37/4000\n",
      "25/25 - 0s - loss: 0.2507 - accuracy: 0.8911 - val_loss: 0.4773 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.42236\n",
      "Epoch 38/4000\n",
      "25/25 - 0s - loss: 0.2484 - accuracy: 0.8949 - val_loss: 0.4307 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.42236\n",
      "Epoch 39/4000\n",
      "25/25 - 0s - loss: 0.2504 - accuracy: 0.8923 - val_loss: 0.4677 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.42236\n",
      "Epoch 40/4000\n",
      "25/25 - 0s - loss: 0.2600 - accuracy: 0.8794 - val_loss: 0.4751 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.42236\n",
      "Epoch 41/4000\n",
      "25/25 - 0s - loss: 0.2502 - accuracy: 0.8975 - val_loss: 0.4426 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.42236\n",
      "Epoch 42/4000\n",
      "25/25 - 0s - loss: 0.2432 - accuracy: 0.9001 - val_loss: 0.4858 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.42236\n",
      "Epoch 43/4000\n",
      "25/25 - 0s - loss: 0.2495 - accuracy: 0.8898 - val_loss: 0.4645 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.42236\n",
      "Epoch 44/4000\n",
      "25/25 - 0s - loss: 0.2391 - accuracy: 0.8975 - val_loss: 0.4685 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.42236\n",
      "Epoch 45/4000\n",
      "25/25 - 0s - loss: 0.2523 - accuracy: 0.8846 - val_loss: 0.4595 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.42236\n",
      "Epoch 46/4000\n",
      "25/25 - 0s - loss: 0.2492 - accuracy: 0.8962 - val_loss: 0.4697 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.42236\n",
      "Epoch 47/4000\n",
      "25/25 - 0s - loss: 0.2706 - accuracy: 0.8923 - val_loss: 0.4661 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.42236\n",
      "Epoch 48/4000\n",
      "25/25 - 0s - loss: 0.2378 - accuracy: 0.8859 - val_loss: 0.4286 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.42236\n",
      "Epoch 49/4000\n",
      "25/25 - 0s - loss: 0.2323 - accuracy: 0.8962 - val_loss: 0.4489 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.42236\n",
      "Epoch 50/4000\n",
      "25/25 - 0s - loss: 0.2508 - accuracy: 0.8833 - val_loss: 0.4616 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.42236\n",
      "Epoch 51/4000\n",
      "25/25 - 0s - loss: 0.2385 - accuracy: 0.8949 - val_loss: 0.4423 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.42236\n",
      "Epoch 52/4000\n",
      "25/25 - 0s - loss: 0.2522 - accuracy: 0.8729 - val_loss: 0.4501 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.42236\n",
      "Epoch 53/4000\n",
      "25/25 - 0s - loss: 0.2378 - accuracy: 0.8872 - val_loss: 0.4424 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.42236\n",
      "Epoch 54/4000\n",
      "25/25 - 0s - loss: 0.2687 - accuracy: 0.8690 - val_loss: 0.4715 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.42236\n",
      "Epoch 55/4000\n",
      "25/25 - 0s - loss: 0.2599 - accuracy: 0.8846 - val_loss: 0.4762 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.42236\n",
      "Epoch 56/4000\n",
      "25/25 - 0s - loss: 0.2637 - accuracy: 0.8885 - val_loss: 0.4322 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.42236\n",
      "Epoch 57/4000\n",
      "25/25 - 0s - loss: 0.2468 - accuracy: 0.8923 - val_loss: 0.4751 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.42236\n",
      "Epoch 58/4000\n",
      "25/25 - 0s - loss: 0.2431 - accuracy: 0.8911 - val_loss: 0.4284 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.42236\n",
      "Epoch 59/4000\n",
      "25/25 - 0s - loss: 0.2350 - accuracy: 0.8872 - val_loss: 0.4460 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.42236\n",
      "Epoch 60/4000\n",
      "25/25 - 0s - loss: 0.2322 - accuracy: 0.8949 - val_loss: 0.4548 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.42236\n",
      "Epoch 61/4000\n",
      "25/25 - 0s - loss: 0.2390 - accuracy: 0.8911 - val_loss: 0.4359 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.42236\n",
      "Epoch 62/4000\n",
      "25/25 - 0s - loss: 0.2311 - accuracy: 0.8911 - val_loss: 0.4974 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.42236\n",
      "Epoch 63/4000\n",
      "25/25 - 0s - loss: 0.2311 - accuracy: 0.8923 - val_loss: 0.4392 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.42236\n",
      "Epoch 64/4000\n",
      "25/25 - 0s - loss: 0.2312 - accuracy: 0.8962 - val_loss: 0.4349 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.42236\n",
      "Epoch 65/4000\n",
      "25/25 - 0s - loss: 0.2403 - accuracy: 0.8898 - val_loss: 0.4361 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.42236\n",
      "Epoch 66/4000\n",
      "25/25 - 0s - loss: 0.2636 - accuracy: 0.8872 - val_loss: 0.4722 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.42236\n",
      "Epoch 67/4000\n",
      "25/25 - 0s - loss: 0.2360 - accuracy: 0.8846 - val_loss: 0.4302 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.42236\n",
      "Epoch 68/4000\n",
      "25/25 - 0s - loss: 0.2299 - accuracy: 0.8859 - val_loss: 0.4416 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.42236\n",
      "Epoch 69/4000\n",
      "25/25 - 0s - loss: 0.2417 - accuracy: 0.8962 - val_loss: 0.4353 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.42236\n",
      "Epoch 70/4000\n",
      "25/25 - 0s - loss: 0.2267 - accuracy: 0.8923 - val_loss: 0.4500 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.42236\n",
      "Epoch 71/4000\n",
      "25/25 - 0s - loss: 0.2548 - accuracy: 0.8690 - val_loss: 0.4397 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.42236\n",
      "Epoch 72/4000\n",
      "25/25 - 0s - loss: 0.2357 - accuracy: 0.8807 - val_loss: 0.4197 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.42236 to 0.41973, saving model to models\\model_4L_v1\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v1\\assets\n",
      "Epoch 73/4000\n",
      "25/25 - 0s - loss: 0.2287 - accuracy: 0.9027 - val_loss: 0.4365 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.41973\n",
      "Epoch 74/4000\n",
      "25/25 - 0s - loss: 0.2372 - accuracy: 0.8923 - val_loss: 0.4430 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.41973\n",
      "Epoch 75/4000\n",
      "25/25 - 0s - loss: 0.2373 - accuracy: 0.8911 - val_loss: 0.4330 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.41973\n",
      "Epoch 76/4000\n",
      "25/25 - 0s - loss: 0.2326 - accuracy: 0.8988 - val_loss: 0.4568 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.41973\n",
      "Epoch 77/4000\n",
      "25/25 - 0s - loss: 0.2221 - accuracy: 0.9027 - val_loss: 0.4441 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.41973\n",
      "Epoch 78/4000\n",
      "25/25 - 0s - loss: 0.2627 - accuracy: 0.8846 - val_loss: 0.4341 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.41973\n",
      "Epoch 79/4000\n",
      "25/25 - 0s - loss: 0.2305 - accuracy: 0.8911 - val_loss: 0.4482 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.41973\n",
      "Epoch 80/4000\n",
      "25/25 - 0s - loss: 0.2371 - accuracy: 0.8898 - val_loss: 0.4464 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.41973\n",
      "Epoch 81/4000\n",
      "25/25 - 0s - loss: 0.2430 - accuracy: 0.8911 - val_loss: 0.4496 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.41973\n",
      "Epoch 82/4000\n",
      "25/25 - 0s - loss: 0.2377 - accuracy: 0.8949 - val_loss: 0.4480 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.41973\n",
      "Epoch 83/4000\n",
      "25/25 - 0s - loss: 0.2339 - accuracy: 0.8859 - val_loss: 0.4205 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.41973\n",
      "Epoch 84/4000\n",
      "25/25 - 0s - loss: 0.2451 - accuracy: 0.8872 - val_loss: 0.4371 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.41973\n",
      "Epoch 85/4000\n",
      "25/25 - 0s - loss: 0.2392 - accuracy: 0.8936 - val_loss: 0.4470 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.41973\n",
      "Epoch 86/4000\n",
      "25/25 - 0s - loss: 0.2365 - accuracy: 0.8898 - val_loss: 0.4473 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.41973\n",
      "Epoch 87/4000\n",
      "25/25 - 0s - loss: 0.2276 - accuracy: 0.8898 - val_loss: 0.4404 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.41973\n",
      "Epoch 88/4000\n",
      "25/25 - 0s - loss: 0.2230 - accuracy: 0.8988 - val_loss: 0.4478 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.41973\n",
      "Epoch 89/4000\n",
      "25/25 - 0s - loss: 0.2388 - accuracy: 0.8923 - val_loss: 0.4638 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.41973\n",
      "Epoch 90/4000\n",
      "25/25 - 0s - loss: 0.2465 - accuracy: 0.8911 - val_loss: 0.4561 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.41973\n",
      "Epoch 91/4000\n",
      "25/25 - 0s - loss: 0.2450 - accuracy: 0.8962 - val_loss: 0.4402 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.41973\n",
      "Epoch 92/4000\n",
      "25/25 - 0s - loss: 0.2230 - accuracy: 0.8949 - val_loss: 0.4437 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.41973\n",
      "Epoch 93/4000\n",
      "25/25 - 0s - loss: 0.2223 - accuracy: 0.8846 - val_loss: 0.4534 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.41973\n",
      "Epoch 94/4000\n",
      "25/25 - 0s - loss: 0.2351 - accuracy: 0.8911 - val_loss: 0.4377 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.41973\n",
      "Epoch 95/4000\n",
      "25/25 - 0s - loss: 0.2215 - accuracy: 0.8911 - val_loss: 0.4593 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.41973\n",
      "Epoch 96/4000\n",
      "25/25 - 0s - loss: 0.2260 - accuracy: 0.8923 - val_loss: 0.4353 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.41973\n",
      "Epoch 97/4000\n",
      "25/25 - 0s - loss: 0.2309 - accuracy: 0.8975 - val_loss: 0.4455 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.41973\n",
      "Epoch 98/4000\n",
      "25/25 - 0s - loss: 0.2301 - accuracy: 0.8898 - val_loss: 0.4560 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.41973\n",
      "Epoch 99/4000\n",
      "25/25 - 0s - loss: 0.2236 - accuracy: 0.8923 - val_loss: 0.4533 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.41973\n",
      "Epoch 100/4000\n",
      "25/25 - 0s - loss: 0.2479 - accuracy: 0.8911 - val_loss: 0.4515 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.41973\n",
      "Epoch 101/4000\n",
      "25/25 - 0s - loss: 0.2282 - accuracy: 0.9014 - val_loss: 0.4610 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.41973\n",
      "Epoch 102/4000\n",
      "25/25 - 0s - loss: 0.2305 - accuracy: 0.8962 - val_loss: 0.4365 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.41973\n",
      "Epoch 103/4000\n",
      "25/25 - 0s - loss: 0.2275 - accuracy: 0.8975 - val_loss: 0.4480 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.41973\n",
      "Epoch 104/4000\n",
      "25/25 - 0s - loss: 0.2232 - accuracy: 0.9014 - val_loss: 0.4517 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.41973\n",
      "Epoch 105/4000\n",
      "25/25 - 0s - loss: 0.2218 - accuracy: 0.9027 - val_loss: 0.4630 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.41973\n",
      "Epoch 106/4000\n",
      "25/25 - 0s - loss: 0.2263 - accuracy: 0.9014 - val_loss: 0.4517 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.41973\n",
      "Epoch 107/4000\n",
      "25/25 - 0s - loss: 0.2198 - accuracy: 0.8949 - val_loss: 0.4548 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.41973\n",
      "Epoch 108/4000\n",
      "25/25 - 0s - loss: 0.2193 - accuracy: 0.8988 - val_loss: 0.4336 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.41973\n",
      "Epoch 109/4000\n",
      "25/25 - 0s - loss: 0.2219 - accuracy: 0.8949 - val_loss: 0.4695 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.41973\n",
      "Epoch 110/4000\n",
      "25/25 - 0s - loss: 0.2192 - accuracy: 0.8923 - val_loss: 0.4518 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.41973\n",
      "Epoch 111/4000\n",
      "25/25 - 0s - loss: 0.2254 - accuracy: 0.8911 - val_loss: 0.4600 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.41973\n",
      "Epoch 112/4000\n",
      "25/25 - 0s - loss: 0.2296 - accuracy: 0.8923 - val_loss: 0.4395 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.41973\n",
      "Epoch 113/4000\n",
      "25/25 - 0s - loss: 0.2352 - accuracy: 0.8820 - val_loss: 0.4815 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.41973\n",
      "Epoch 114/4000\n",
      "25/25 - 0s - loss: 0.2486 - accuracy: 0.8898 - val_loss: 0.4295 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.41973\n",
      "Epoch 115/4000\n",
      "25/25 - 0s - loss: 0.2325 - accuracy: 0.8872 - val_loss: 0.4474 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.41973\n",
      "Epoch 116/4000\n",
      "25/25 - 0s - loss: 0.2244 - accuracy: 0.8949 - val_loss: 0.4617 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.41973\n",
      "Epoch 117/4000\n",
      "25/25 - 0s - loss: 0.2194 - accuracy: 0.8911 - val_loss: 0.4431 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.41973\n",
      "Epoch 118/4000\n",
      "25/25 - 0s - loss: 0.2260 - accuracy: 0.8949 - val_loss: 0.4493 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.41973\n",
      "Epoch 119/4000\n",
      "25/25 - 0s - loss: 0.2224 - accuracy: 0.8872 - val_loss: 0.4556 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.41973\n",
      "Epoch 120/4000\n",
      "25/25 - 0s - loss: 0.2197 - accuracy: 0.8975 - val_loss: 0.4826 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.41973\n",
      "Epoch 121/4000\n",
      "25/25 - 0s - loss: 0.2195 - accuracy: 0.9014 - val_loss: 0.4462 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.41973\n",
      "Epoch 122/4000\n",
      "25/25 - 0s - loss: 0.2169 - accuracy: 0.8911 - val_loss: 0.4548 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.41973\n",
      "Epoch 123/4000\n",
      "25/25 - 0s - loss: 0.2372 - accuracy: 0.8975 - val_loss: 0.5086 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.41973\n",
      "Epoch 124/4000\n",
      "25/25 - 0s - loss: 0.2274 - accuracy: 0.9001 - val_loss: 0.4549 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.41973\n",
      "Epoch 125/4000\n",
      "25/25 - 0s - loss: 0.2211 - accuracy: 0.8949 - val_loss: 0.4361 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.41973\n",
      "Epoch 126/4000\n",
      "25/25 - 0s - loss: 0.2356 - accuracy: 0.8975 - val_loss: 0.4462 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.41973\n",
      "Epoch 127/4000\n",
      "25/25 - 0s - loss: 0.2252 - accuracy: 0.9001 - val_loss: 0.4313 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.41973\n",
      "Epoch 128/4000\n",
      "25/25 - 0s - loss: 0.2180 - accuracy: 0.8898 - val_loss: 0.4276 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.41973\n",
      "Epoch 129/4000\n",
      "25/25 - 0s - loss: 0.2224 - accuracy: 0.8962 - val_loss: 0.4491 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.41973\n",
      "Epoch 130/4000\n",
      "25/25 - 0s - loss: 0.2279 - accuracy: 0.8898 - val_loss: 0.4431 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.41973\n",
      "Epoch 131/4000\n",
      "25/25 - 0s - loss: 0.2263 - accuracy: 0.8988 - val_loss: 0.4357 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.41973\n",
      "Epoch 132/4000\n",
      "25/25 - 0s - loss: 0.2191 - accuracy: 0.8885 - val_loss: 0.4585 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.41973\n",
      "Epoch 133/4000\n",
      "25/25 - 0s - loss: 0.2226 - accuracy: 0.8923 - val_loss: 0.4755 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.41973\n",
      "Epoch 134/4000\n",
      "25/25 - 0s - loss: 0.2311 - accuracy: 0.8962 - val_loss: 0.4771 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.41973\n",
      "Epoch 135/4000\n",
      "25/25 - 0s - loss: 0.2171 - accuracy: 0.9014 - val_loss: 0.4579 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.41973\n",
      "Epoch 136/4000\n",
      "25/25 - 0s - loss: 0.2218 - accuracy: 0.8898 - val_loss: 0.4378 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.41973\n",
      "Epoch 137/4000\n",
      "25/25 - 0s - loss: 0.2250 - accuracy: 0.8936 - val_loss: 0.4586 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.41973\n",
      "Epoch 138/4000\n",
      "25/25 - 0s - loss: 0.2204 - accuracy: 0.8923 - val_loss: 0.4707 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.41973\n",
      "Epoch 139/4000\n",
      "25/25 - 0s - loss: 0.2276 - accuracy: 0.8936 - val_loss: 0.4571 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.41973\n",
      "Epoch 140/4000\n",
      "25/25 - 0s - loss: 0.2230 - accuracy: 0.8923 - val_loss: 0.4446 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.41973\n",
      "Epoch 141/4000\n",
      "25/25 - 0s - loss: 0.2162 - accuracy: 0.8988 - val_loss: 0.4498 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.41973\n",
      "Epoch 142/4000\n",
      "25/25 - 0s - loss: 0.2193 - accuracy: 0.9014 - val_loss: 0.4508 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.41973\n",
      "Epoch 143/4000\n",
      "25/25 - 0s - loss: 0.2210 - accuracy: 0.8885 - val_loss: 0.4601 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.41973\n",
      "Epoch 144/4000\n",
      "25/25 - 0s - loss: 0.2383 - accuracy: 0.8859 - val_loss: 0.4973 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.41973\n",
      "Epoch 145/4000\n",
      "25/25 - 0s - loss: 0.2238 - accuracy: 0.8988 - val_loss: 0.4459 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.41973\n",
      "Epoch 146/4000\n",
      "25/25 - 0s - loss: 0.2367 - accuracy: 0.8923 - val_loss: 0.4826 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.41973\n",
      "Epoch 147/4000\n",
      "25/25 - 0s - loss: 0.2184 - accuracy: 0.8975 - val_loss: 0.4704 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.41973\n",
      "Epoch 148/4000\n",
      "25/25 - 0s - loss: 0.2150 - accuracy: 0.9040 - val_loss: 0.4397 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.41973\n",
      "Epoch 149/4000\n",
      "25/25 - 0s - loss: 0.2161 - accuracy: 0.8962 - val_loss: 0.4774 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.41973\n",
      "Epoch 150/4000\n",
      "25/25 - 0s - loss: 0.2488 - accuracy: 0.8911 - val_loss: 0.4375 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.41973\n",
      "Epoch 151/4000\n",
      "25/25 - 0s - loss: 0.2243 - accuracy: 0.8898 - val_loss: 0.4638 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.41973\n",
      "Epoch 152/4000\n",
      "25/25 - 0s - loss: 0.2243 - accuracy: 0.8885 - val_loss: 0.4462 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.41973\n",
      "Epoch 153/4000\n",
      "25/25 - 0s - loss: 0.2189 - accuracy: 0.8962 - val_loss: 0.4401 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.41973\n",
      "Epoch 154/4000\n",
      "25/25 - 0s - loss: 0.2187 - accuracy: 0.8923 - val_loss: 0.4758 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.41973\n",
      "Epoch 155/4000\n",
      "25/25 - 0s - loss: 0.2170 - accuracy: 0.8872 - val_loss: 0.4462 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.41973\n",
      "Epoch 156/4000\n",
      "25/25 - 0s - loss: 0.2134 - accuracy: 0.8936 - val_loss: 0.4651 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.41973\n",
      "Epoch 157/4000\n",
      "25/25 - 0s - loss: 0.2168 - accuracy: 0.8949 - val_loss: 0.4608 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.41973\n",
      "Epoch 158/4000\n",
      "25/25 - 0s - loss: 0.2154 - accuracy: 0.9014 - val_loss: 0.4534 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.41973\n",
      "Epoch 159/4000\n",
      "25/25 - 0s - loss: 0.2137 - accuracy: 0.8936 - val_loss: 0.4549 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.41973\n",
      "Epoch 160/4000\n",
      "25/25 - 0s - loss: 0.2193 - accuracy: 0.8975 - val_loss: 0.4853 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.41973\n",
      "Epoch 161/4000\n",
      "25/25 - 0s - loss: 0.2211 - accuracy: 0.8949 - val_loss: 0.4462 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.41973\n",
      "Epoch 162/4000\n",
      "25/25 - 0s - loss: 0.2197 - accuracy: 0.8872 - val_loss: 0.4698 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.41973\n",
      "Epoch 163/4000\n",
      "25/25 - 0s - loss: 0.2240 - accuracy: 0.9040 - val_loss: 0.4465 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.41973\n",
      "Epoch 164/4000\n",
      "25/25 - 0s - loss: 0.2249 - accuracy: 0.8949 - val_loss: 0.4841 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.41973\n",
      "Epoch 165/4000\n",
      "25/25 - 0s - loss: 0.2141 - accuracy: 0.8988 - val_loss: 0.4497 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.41973\n",
      "Epoch 166/4000\n",
      "25/25 - 0s - loss: 0.2184 - accuracy: 0.8911 - val_loss: 0.4892 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.41973\n",
      "Epoch 167/4000\n",
      "25/25 - 0s - loss: 0.2207 - accuracy: 0.8911 - val_loss: 0.4493 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.41973\n",
      "Epoch 168/4000\n",
      "25/25 - 0s - loss: 0.2168 - accuracy: 0.8936 - val_loss: 0.4530 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.41973\n",
      "Epoch 169/4000\n",
      "25/25 - 0s - loss: 0.2130 - accuracy: 0.8923 - val_loss: 0.4883 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.41973\n",
      "Epoch 170/4000\n",
      "25/25 - 0s - loss: 0.2199 - accuracy: 0.8962 - val_loss: 0.4595 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.41973\n",
      "Epoch 171/4000\n",
      "25/25 - 0s - loss: 0.2216 - accuracy: 0.8872 - val_loss: 0.4476 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.41973\n",
      "Epoch 172/4000\n",
      "25/25 - 0s - loss: 0.2212 - accuracy: 0.8988 - val_loss: 0.4674 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.41973\n",
      "Epoch 173/4000\n",
      "25/25 - 0s - loss: 0.2165 - accuracy: 0.8975 - val_loss: 0.4509 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.41973\n",
      "Epoch 174/4000\n",
      "25/25 - 0s - loss: 0.2164 - accuracy: 0.8962 - val_loss: 0.4572 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.41973\n",
      "Epoch 175/4000\n",
      "25/25 - 0s - loss: 0.2354 - accuracy: 0.8898 - val_loss: 0.4660 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.41973\n",
      "Epoch 176/4000\n",
      "25/25 - 0s - loss: 0.2203 - accuracy: 0.8923 - val_loss: 0.4212 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.41973\n",
      "Epoch 177/4000\n",
      "25/25 - 0s - loss: 0.2156 - accuracy: 0.8949 - val_loss: 0.4421 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.41973\n",
      "Epoch 178/4000\n",
      "25/25 - 0s - loss: 0.2151 - accuracy: 0.8975 - val_loss: 0.4575 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.41973\n",
      "Epoch 179/4000\n",
      "25/25 - 0s - loss: 0.2148 - accuracy: 0.8988 - val_loss: 0.4366 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.41973\n",
      "Epoch 180/4000\n",
      "25/25 - 0s - loss: 0.2386 - accuracy: 0.8885 - val_loss: 0.4730 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.41973\n",
      "Epoch 181/4000\n",
      "25/25 - 0s - loss: 0.2201 - accuracy: 0.8975 - val_loss: 0.4486 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.41973\n",
      "Epoch 182/4000\n",
      "25/25 - 0s - loss: 0.2192 - accuracy: 0.8949 - val_loss: 0.4669 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.41973\n",
      "Epoch 183/4000\n",
      "25/25 - 0s - loss: 0.2139 - accuracy: 0.8988 - val_loss: 0.4503 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.41973\n",
      "Epoch 184/4000\n",
      "25/25 - 0s - loss: 0.2176 - accuracy: 0.8885 - val_loss: 0.4785 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.41973\n",
      "Epoch 185/4000\n",
      "25/25 - 0s - loss: 0.2153 - accuracy: 0.8962 - val_loss: 0.4635 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.41973\n",
      "Epoch 186/4000\n",
      "25/25 - 0s - loss: 0.2138 - accuracy: 0.9001 - val_loss: 0.4596 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.41973\n",
      "Epoch 187/4000\n",
      "25/25 - 0s - loss: 0.2268 - accuracy: 0.8911 - val_loss: 0.4569 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.41973\n",
      "Epoch 188/4000\n",
      "25/25 - 0s - loss: 0.2163 - accuracy: 0.8936 - val_loss: 0.4521 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.41973\n",
      "Epoch 189/4000\n",
      "25/25 - 0s - loss: 0.2157 - accuracy: 0.8949 - val_loss: 0.4416 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.41973\n",
      "Epoch 190/4000\n",
      "25/25 - 0s - loss: 0.2154 - accuracy: 0.8975 - val_loss: 0.4701 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.41973\n",
      "Epoch 191/4000\n",
      "25/25 - 0s - loss: 0.2131 - accuracy: 0.8962 - val_loss: 0.4988 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.41973\n",
      "Epoch 192/4000\n",
      "25/25 - 0s - loss: 0.2214 - accuracy: 0.8936 - val_loss: 0.4762 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.41973\n",
      "Epoch 193/4000\n",
      "25/25 - 0s - loss: 0.2222 - accuracy: 0.8872 - val_loss: 0.4780 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.41973\n",
      "Epoch 194/4000\n",
      "25/25 - 0s - loss: 0.2168 - accuracy: 0.9014 - val_loss: 0.4663 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.41973\n",
      "Epoch 195/4000\n",
      "25/25 - 0s - loss: 0.2229 - accuracy: 0.8768 - val_loss: 0.4601 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.41973\n",
      "Epoch 196/4000\n",
      "25/25 - 0s - loss: 0.2106 - accuracy: 0.8988 - val_loss: 0.4738 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.41973\n",
      "Epoch 197/4000\n",
      "25/25 - 0s - loss: 0.2117 - accuracy: 0.8975 - val_loss: 0.4802 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.41973\n",
      "Epoch 198/4000\n",
      "25/25 - 0s - loss: 0.2100 - accuracy: 0.8988 - val_loss: 0.4506 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.41973\n",
      "Epoch 199/4000\n",
      "25/25 - 0s - loss: 0.2113 - accuracy: 0.9001 - val_loss: 0.4609 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.41973\n",
      "Epoch 200/4000\n",
      "25/25 - 0s - loss: 0.2138 - accuracy: 0.8949 - val_loss: 0.4627 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.41973\n",
      "Epoch 201/4000\n",
      "25/25 - 0s - loss: 0.2380 - accuracy: 0.8911 - val_loss: 0.4391 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.41973\n",
      "Epoch 202/4000\n",
      "25/25 - 0s - loss: 0.2211 - accuracy: 0.8949 - val_loss: 0.4291 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.41973\n",
      "Epoch 203/4000\n",
      "25/25 - 0s - loss: 0.2137 - accuracy: 0.8885 - val_loss: 0.4716 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.41973\n",
      "Epoch 204/4000\n",
      "25/25 - 0s - loss: 0.2139 - accuracy: 0.8962 - val_loss: 0.4649 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.41973\n",
      "Epoch 205/4000\n",
      "25/25 - 0s - loss: 0.2131 - accuracy: 0.8936 - val_loss: 0.4790 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.41973\n",
      "Epoch 206/4000\n",
      "25/25 - 0s - loss: 0.2124 - accuracy: 0.8975 - val_loss: 0.4749 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.41973\n",
      "Epoch 207/4000\n",
      "25/25 - 0s - loss: 0.2311 - accuracy: 0.8911 - val_loss: 0.4765 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.41973\n",
      "Epoch 208/4000\n",
      "25/25 - 0s - loss: 0.2228 - accuracy: 0.8962 - val_loss: 0.4341 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.41973\n",
      "Epoch 209/4000\n",
      "25/25 - 0s - loss: 0.2197 - accuracy: 0.8949 - val_loss: 0.4372 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.41973\n",
      "Epoch 210/4000\n",
      "25/25 - 0s - loss: 0.2143 - accuracy: 0.8923 - val_loss: 0.4786 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.41973\n",
      "Epoch 211/4000\n",
      "25/25 - 0s - loss: 0.2151 - accuracy: 0.8885 - val_loss: 0.4783 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.41973\n",
      "Epoch 212/4000\n",
      "25/25 - 0s - loss: 0.2227 - accuracy: 0.8911 - val_loss: 0.4861 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.41973\n",
      "Epoch 213/4000\n",
      "25/25 - 0s - loss: 0.2142 - accuracy: 0.9014 - val_loss: 0.4473 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.41973\n",
      "Epoch 214/4000\n",
      "25/25 - 0s - loss: 0.2222 - accuracy: 0.8898 - val_loss: 0.4871 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.41973\n",
      "Epoch 215/4000\n",
      "25/25 - 0s - loss: 0.2221 - accuracy: 0.9001 - val_loss: 0.4514 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.41973\n",
      "Epoch 216/4000\n",
      "25/25 - 0s - loss: 0.2215 - accuracy: 0.8846 - val_loss: 0.4515 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.41973\n",
      "Epoch 217/4000\n",
      "25/25 - 0s - loss: 0.2118 - accuracy: 0.8988 - val_loss: 0.4546 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.41973\n",
      "Epoch 218/4000\n",
      "25/25 - 1s - loss: 0.2122 - accuracy: 0.9014 - val_loss: 0.4835 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.41973\n",
      "Epoch 219/4000\n",
      "25/25 - 0s - loss: 0.2175 - accuracy: 0.8962 - val_loss: 0.4570 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.41973\n",
      "Epoch 220/4000\n",
      "25/25 - 0s - loss: 0.2121 - accuracy: 0.8923 - val_loss: 0.4773 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.41973\n",
      "Epoch 221/4000\n",
      "25/25 - 0s - loss: 0.2113 - accuracy: 0.8936 - val_loss: 0.4816 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.41973\n",
      "Epoch 222/4000\n",
      "25/25 - 0s - loss: 0.2118 - accuracy: 0.9001 - val_loss: 0.4825 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.41973\n",
      "Epoch 223/4000\n",
      "25/25 - 0s - loss: 0.2117 - accuracy: 0.8962 - val_loss: 0.5060 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.41973\n",
      "Epoch 224/4000\n",
      "25/25 - 0s - loss: 0.2153 - accuracy: 0.8975 - val_loss: 0.4794 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.41973\n",
      "Epoch 225/4000\n",
      "25/25 - 0s - loss: 0.2159 - accuracy: 0.8988 - val_loss: 0.4886 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.41973\n",
      "Epoch 226/4000\n",
      "25/25 - 0s - loss: 0.2205 - accuracy: 0.8885 - val_loss: 0.4647 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.41973\n",
      "Epoch 227/4000\n",
      "25/25 - 0s - loss: 0.2100 - accuracy: 0.8962 - val_loss: 0.4908 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.41973\n",
      "Epoch 228/4000\n",
      "25/25 - 0s - loss: 0.2104 - accuracy: 0.9014 - val_loss: 0.4702 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.41973\n",
      "Epoch 229/4000\n",
      "25/25 - 0s - loss: 0.2222 - accuracy: 0.8911 - val_loss: 0.4844 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.41973\n",
      "Epoch 230/4000\n",
      "25/25 - 0s - loss: 0.2270 - accuracy: 0.8742 - val_loss: 0.4976 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.41973\n",
      "Epoch 231/4000\n",
      "25/25 - 0s - loss: 0.2181 - accuracy: 0.8911 - val_loss: 0.4627 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.41973\n",
      "Epoch 232/4000\n",
      "25/25 - 0s - loss: 0.2154 - accuracy: 0.8988 - val_loss: 0.4928 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.41973\n",
      "Epoch 233/4000\n",
      "25/25 - 0s - loss: 0.2133 - accuracy: 0.8975 - val_loss: 0.4940 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.41973\n",
      "Epoch 234/4000\n",
      "25/25 - 0s - loss: 0.2108 - accuracy: 0.9014 - val_loss: 0.4768 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.41973\n",
      "Epoch 235/4000\n",
      "25/25 - 0s - loss: 0.2110 - accuracy: 0.8949 - val_loss: 0.4683 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.41973\n",
      "Epoch 236/4000\n",
      "25/25 - 0s - loss: 0.2082 - accuracy: 0.8975 - val_loss: 0.4896 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.41973\n",
      "Epoch 237/4000\n",
      "25/25 - 0s - loss: 0.2152 - accuracy: 0.9040 - val_loss: 0.4810 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.41973\n",
      "Epoch 238/4000\n",
      "25/25 - 0s - loss: 0.2190 - accuracy: 0.9001 - val_loss: 0.5287 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.41973\n",
      "Epoch 239/4000\n",
      "25/25 - 0s - loss: 0.2178 - accuracy: 0.9027 - val_loss: 0.4558 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.41973\n",
      "Epoch 240/4000\n",
      "25/25 - 0s - loss: 0.2145 - accuracy: 0.8911 - val_loss: 0.5122 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.41973\n",
      "Epoch 241/4000\n",
      "25/25 - 0s - loss: 0.2118 - accuracy: 0.8962 - val_loss: 0.4991 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.41973\n",
      "Epoch 242/4000\n",
      "25/25 - 0s - loss: 0.2115 - accuracy: 0.9014 - val_loss: 0.4901 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.41973\n",
      "Epoch 243/4000\n",
      "25/25 - 0s - loss: 0.2087 - accuracy: 0.9027 - val_loss: 0.5127 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.41973\n",
      "Epoch 244/4000\n",
      "25/25 - 0s - loss: 0.2110 - accuracy: 0.8949 - val_loss: 0.5044 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.41973\n",
      "Epoch 245/4000\n",
      "25/25 - 0s - loss: 0.2111 - accuracy: 0.8923 - val_loss: 0.4913 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.41973\n",
      "Epoch 246/4000\n",
      "25/25 - 0s - loss: 0.2085 - accuracy: 0.8988 - val_loss: 0.5028 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.41973\n",
      "Epoch 247/4000\n",
      "25/25 - 0s - loss: 0.2128 - accuracy: 0.8923 - val_loss: 0.4809 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.41973\n",
      "Epoch 248/4000\n",
      "25/25 - 0s - loss: 0.2111 - accuracy: 0.8962 - val_loss: 0.4777 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.41973\n",
      "Epoch 249/4000\n",
      "25/25 - 0s - loss: 0.2089 - accuracy: 0.9001 - val_loss: 0.4827 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.41973\n",
      "Epoch 250/4000\n",
      "25/25 - 0s - loss: 0.2081 - accuracy: 0.8988 - val_loss: 0.5011 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.41973\n",
      "Epoch 251/4000\n",
      "25/25 - 0s - loss: 0.2099 - accuracy: 0.8962 - val_loss: 0.4990 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.41973\n",
      "Epoch 252/4000\n",
      "25/25 - 0s - loss: 0.2095 - accuracy: 0.8975 - val_loss: 0.4766 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.41973\n",
      "Epoch 253/4000\n",
      "25/25 - 0s - loss: 0.2081 - accuracy: 0.8988 - val_loss: 0.4680 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.41973\n",
      "Epoch 254/4000\n",
      "25/25 - 0s - loss: 0.2103 - accuracy: 0.8962 - val_loss: 0.4868 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.41973\n",
      "Epoch 255/4000\n",
      "25/25 - 0s - loss: 0.2108 - accuracy: 0.8962 - val_loss: 0.5051 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.41973\n",
      "Epoch 256/4000\n",
      "25/25 - 0s - loss: 0.2087 - accuracy: 0.8962 - val_loss: 0.4958 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.41973\n",
      "Epoch 257/4000\n",
      "25/25 - 0s - loss: 0.2175 - accuracy: 0.8975 - val_loss: 0.4895 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.41973\n",
      "Epoch 258/4000\n",
      "25/25 - 0s - loss: 0.2143 - accuracy: 0.8936 - val_loss: 0.4867 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.41973\n",
      "Epoch 259/4000\n",
      "25/25 - 0s - loss: 0.2092 - accuracy: 0.9001 - val_loss: 0.4744 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.41973\n",
      "Epoch 260/4000\n",
      "25/25 - 0s - loss: 0.2174 - accuracy: 0.9040 - val_loss: 0.5176 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.41973\n",
      "Epoch 261/4000\n",
      "25/25 - 0s - loss: 0.2142 - accuracy: 0.8962 - val_loss: 0.4991 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.41973\n",
      "Epoch 262/4000\n",
      "25/25 - 0s - loss: 0.2118 - accuracy: 0.8962 - val_loss: 0.4834 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.41973\n",
      "Epoch 263/4000\n",
      "25/25 - 0s - loss: 0.2116 - accuracy: 0.8911 - val_loss: 0.4985 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.41973\n",
      "Epoch 264/4000\n",
      "25/25 - 0s - loss: 0.2171 - accuracy: 0.8962 - val_loss: 0.4603 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.41973\n",
      "Epoch 265/4000\n",
      "25/25 - 0s - loss: 0.2164 - accuracy: 0.8949 - val_loss: 0.4805 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.41973\n",
      "Epoch 266/4000\n",
      "25/25 - 0s - loss: 0.2093 - accuracy: 0.8975 - val_loss: 0.4836 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.41973\n",
      "Epoch 267/4000\n",
      "25/25 - 0s - loss: 0.2095 - accuracy: 0.8975 - val_loss: 0.4747 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.41973\n",
      "Epoch 268/4000\n",
      "25/25 - 0s - loss: 0.2137 - accuracy: 0.8898 - val_loss: 0.5124 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.41973\n",
      "Epoch 269/4000\n",
      "25/25 - 0s - loss: 0.2093 - accuracy: 0.8975 - val_loss: 0.4872 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.41973\n",
      "Epoch 270/4000\n",
      "25/25 - 0s - loss: 0.2201 - accuracy: 0.8975 - val_loss: 0.5076 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.41973\n",
      "Epoch 271/4000\n",
      "25/25 - 0s - loss: 0.2104 - accuracy: 0.9014 - val_loss: 0.5357 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.41973\n",
      "Epoch 272/4000\n",
      "25/25 - 0s - loss: 0.2122 - accuracy: 0.8936 - val_loss: 0.5012 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.41973\n",
      "Epoch 273/4000\n",
      "25/25 - 0s - loss: 0.2136 - accuracy: 0.8988 - val_loss: 0.5149 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.41973\n",
      "Epoch 274/4000\n",
      "25/25 - 0s - loss: 0.2144 - accuracy: 0.8962 - val_loss: 0.5053 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.41973\n",
      "Epoch 275/4000\n",
      "25/25 - 0s - loss: 0.2141 - accuracy: 0.8975 - val_loss: 0.5633 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.41973\n",
      "Epoch 276/4000\n",
      "25/25 - 0s - loss: 0.2110 - accuracy: 0.8923 - val_loss: 0.5083 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.41973\n",
      "Epoch 277/4000\n",
      "25/25 - 0s - loss: 0.2096 - accuracy: 0.8988 - val_loss: 0.5359 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.41973\n",
      "Epoch 278/4000\n",
      "25/25 - 0s - loss: 0.2112 - accuracy: 0.8988 - val_loss: 0.5190 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.41973\n",
      "Epoch 279/4000\n",
      "25/25 - 0s - loss: 0.2116 - accuracy: 0.9027 - val_loss: 0.5276 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.41973\n",
      "Epoch 280/4000\n",
      "25/25 - 0s - loss: 0.2099 - accuracy: 0.8975 - val_loss: 0.5370 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.41973\n",
      "Epoch 281/4000\n",
      "25/25 - 0s - loss: 0.2092 - accuracy: 0.8975 - val_loss: 0.5254 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.41973\n",
      "Epoch 282/4000\n",
      "25/25 - 0s - loss: 0.2127 - accuracy: 0.8936 - val_loss: 0.5107 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.41973\n",
      "Epoch 283/4000\n",
      "25/25 - 0s - loss: 0.2086 - accuracy: 0.8975 - val_loss: 0.5342 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.41973\n",
      "Epoch 284/4000\n",
      "25/25 - 0s - loss: 0.2069 - accuracy: 0.9014 - val_loss: 0.5190 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.41973\n",
      "Epoch 285/4000\n",
      "25/25 - 0s - loss: 0.2121 - accuracy: 0.8988 - val_loss: 0.5174 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.41973\n",
      "Epoch 286/4000\n",
      "25/25 - 0s - loss: 0.2112 - accuracy: 0.8936 - val_loss: 0.4990 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.41973\n",
      "Epoch 287/4000\n",
      "25/25 - 0s - loss: 0.2100 - accuracy: 0.8936 - val_loss: 0.5159 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.41973\n",
      "Epoch 288/4000\n",
      "25/25 - 0s - loss: 0.2061 - accuracy: 0.9001 - val_loss: 0.5182 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.41973\n",
      "Epoch 289/4000\n",
      "25/25 - 0s - loss: 0.2097 - accuracy: 0.8962 - val_loss: 0.5114 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.41973\n",
      "Epoch 290/4000\n",
      "25/25 - 0s - loss: 0.2081 - accuracy: 0.8988 - val_loss: 0.5178 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.41973\n",
      "Epoch 291/4000\n",
      "25/25 - 0s - loss: 0.2094 - accuracy: 0.9014 - val_loss: 0.5184 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.41973\n",
      "Epoch 292/4000\n",
      "25/25 - 0s - loss: 0.2086 - accuracy: 0.8962 - val_loss: 0.5500 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.41973\n",
      "Epoch 293/4000\n",
      "25/25 - 0s - loss: 0.2083 - accuracy: 0.8988 - val_loss: 0.5333 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.41973\n",
      "Epoch 294/4000\n",
      "25/25 - 0s - loss: 0.2073 - accuracy: 0.9014 - val_loss: 0.5200 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.41973\n",
      "Epoch 295/4000\n",
      "25/25 - 0s - loss: 0.2086 - accuracy: 0.8988 - val_loss: 0.5227 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.41973\n",
      "Epoch 296/4000\n",
      "25/25 - 0s - loss: 0.2079 - accuracy: 0.8975 - val_loss: 0.5188 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.41973\n",
      "Epoch 297/4000\n",
      "25/25 - 0s - loss: 0.2121 - accuracy: 0.8988 - val_loss: 0.5130 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.41973\n",
      "Epoch 298/4000\n",
      "25/25 - 0s - loss: 0.2094 - accuracy: 0.9027 - val_loss: 0.5082 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.41973\n",
      "Epoch 299/4000\n",
      "25/25 - 0s - loss: 0.2107 - accuracy: 0.8898 - val_loss: 0.5258 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.41973\n",
      "Epoch 300/4000\n",
      "25/25 - 0s - loss: 0.2090 - accuracy: 0.8975 - val_loss: 0.5139 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.41973\n",
      "Epoch 301/4000\n",
      "25/25 - 0s - loss: 0.2228 - accuracy: 0.8846 - val_loss: 0.5341 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.41973\n",
      "Epoch 302/4000\n",
      "25/25 - 0s - loss: 0.2088 - accuracy: 0.9001 - val_loss: 0.5341 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.41973\n",
      "Epoch 303/4000\n",
      "25/25 - 0s - loss: 0.2094 - accuracy: 0.9040 - val_loss: 0.5524 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.41973\n",
      "Epoch 304/4000\n",
      "25/25 - 0s - loss: 0.2077 - accuracy: 0.8988 - val_loss: 0.5160 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.41973\n",
      "Epoch 305/4000\n",
      "25/25 - 0s - loss: 0.2127 - accuracy: 0.8988 - val_loss: 0.5427 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.41973\n",
      "Epoch 306/4000\n",
      "25/25 - 0s - loss: 0.2077 - accuracy: 0.8975 - val_loss: 0.5129 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.41973\n",
      "Epoch 307/4000\n",
      "25/25 - 0s - loss: 0.2091 - accuracy: 0.9001 - val_loss: 0.5217 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.41973\n",
      "Epoch 308/4000\n",
      "25/25 - 0s - loss: 0.2057 - accuracy: 0.9014 - val_loss: 0.5397 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.41973\n",
      "Epoch 309/4000\n",
      "25/25 - 0s - loss: 0.2078 - accuracy: 0.9001 - val_loss: 0.5224 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.41973\n",
      "Epoch 310/4000\n",
      "25/25 - 0s - loss: 0.2160 - accuracy: 0.9014 - val_loss: 0.4943 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.41973\n",
      "Epoch 311/4000\n",
      "25/25 - 0s - loss: 0.2095 - accuracy: 0.8975 - val_loss: 0.5350 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.41973\n",
      "Epoch 312/4000\n",
      "25/25 - 0s - loss: 0.2179 - accuracy: 0.8988 - val_loss: 0.5119 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.41973\n",
      "Epoch 313/4000\n",
      "25/25 - 0s - loss: 0.2163 - accuracy: 0.8923 - val_loss: 0.5331 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.41973\n",
      "Epoch 314/4000\n",
      "25/25 - 0s - loss: 0.2077 - accuracy: 0.9040 - val_loss: 0.5125 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.41973\n",
      "Epoch 315/4000\n",
      "25/25 - 0s - loss: 0.2072 - accuracy: 0.8988 - val_loss: 0.5211 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.41973\n",
      "Epoch 316/4000\n",
      "25/25 - 0s - loss: 0.2057 - accuracy: 0.9014 - val_loss: 0.5119 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.41973\n",
      "Epoch 317/4000\n",
      "25/25 - 0s - loss: 0.2086 - accuracy: 0.9001 - val_loss: 0.5212 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.41973\n",
      "Epoch 318/4000\n",
      "25/25 - 0s - loss: 0.2078 - accuracy: 0.8988 - val_loss: 0.5039 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.41973\n",
      "Epoch 319/4000\n",
      "25/25 - 0s - loss: 0.2091 - accuracy: 0.8988 - val_loss: 0.5208 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.41973\n",
      "Epoch 320/4000\n",
      "25/25 - 0s - loss: 0.2098 - accuracy: 0.8911 - val_loss: 0.5262 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.41973\n",
      "Epoch 321/4000\n",
      "25/25 - 0s - loss: 0.2061 - accuracy: 0.9001 - val_loss: 0.5207 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.41973\n",
      "Epoch 322/4000\n",
      "25/25 - 0s - loss: 0.2065 - accuracy: 0.9001 - val_loss: 0.5329 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.41973\n",
      "Epoch 323/4000\n",
      "25/25 - 0s - loss: 0.2116 - accuracy: 0.8975 - val_loss: 0.5030 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.41973\n",
      "Epoch 324/4000\n",
      "25/25 - 0s - loss: 0.2156 - accuracy: 0.8988 - val_loss: 0.5143 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.41973\n",
      "Epoch 325/4000\n",
      "25/25 - 0s - loss: 0.2084 - accuracy: 0.9014 - val_loss: 0.5186 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.41973\n",
      "Epoch 326/4000\n",
      "25/25 - 0s - loss: 0.2097 - accuracy: 0.9001 - val_loss: 0.5190 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.41973\n",
      "Epoch 327/4000\n",
      "25/25 - 0s - loss: 0.2073 - accuracy: 0.8936 - val_loss: 0.5324 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.41973\n",
      "Epoch 328/4000\n",
      "25/25 - 0s - loss: 0.2090 - accuracy: 0.8975 - val_loss: 0.5189 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.41973\n",
      "Epoch 329/4000\n",
      "25/25 - 0s - loss: 0.2077 - accuracy: 0.9014 - val_loss: 0.5221 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.41973\n",
      "Epoch 330/4000\n",
      "25/25 - 0s - loss: 0.2085 - accuracy: 0.9001 - val_loss: 0.5409 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.41973\n",
      "Epoch 331/4000\n",
      "25/25 - 0s - loss: 0.2055 - accuracy: 0.9001 - val_loss: 0.5227 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.41973\n",
      "Epoch 332/4000\n",
      "25/25 - 0s - loss: 0.2082 - accuracy: 0.9027 - val_loss: 0.5205 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.41973\n",
      "Epoch 333/4000\n",
      "25/25 - 0s - loss: 0.2080 - accuracy: 0.8988 - val_loss: 0.5616 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.41973\n",
      "Epoch 334/4000\n",
      "25/25 - 0s - loss: 0.2052 - accuracy: 0.8988 - val_loss: 0.5422 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.41973\n",
      "Epoch 335/4000\n",
      "25/25 - 0s - loss: 0.2094 - accuracy: 0.8962 - val_loss: 0.5556 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.41973\n",
      "Epoch 336/4000\n",
      "25/25 - 0s - loss: 0.2077 - accuracy: 0.8975 - val_loss: 0.5655 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.41973\n",
      "Epoch 337/4000\n",
      "25/25 - 0s - loss: 0.2092 - accuracy: 0.9027 - val_loss: 0.5552 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.41973\n",
      "Epoch 338/4000\n",
      "25/25 - 0s - loss: 0.2082 - accuracy: 0.9001 - val_loss: 0.5266 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.41973\n",
      "Epoch 339/4000\n",
      "25/25 - 0s - loss: 0.2092 - accuracy: 0.8962 - val_loss: 0.5038 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.41973\n",
      "Epoch 340/4000\n",
      "25/25 - 0s - loss: 0.2120 - accuracy: 0.9014 - val_loss: 0.5077 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.41973\n",
      "Epoch 341/4000\n",
      "25/25 - 0s - loss: 0.2077 - accuracy: 0.9027 - val_loss: 0.5073 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.41973\n",
      "Epoch 342/4000\n",
      "25/25 - 0s - loss: 0.2101 - accuracy: 0.9001 - val_loss: 0.5051 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.41973\n",
      "Epoch 343/4000\n",
      "25/25 - 0s - loss: 0.2093 - accuracy: 0.9001 - val_loss: 0.5226 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.41973\n",
      "Epoch 344/4000\n",
      "25/25 - 0s - loss: 0.2119 - accuracy: 0.8962 - val_loss: 0.4853 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.41973\n",
      "Epoch 345/4000\n",
      "25/25 - 0s - loss: 0.2069 - accuracy: 0.8962 - val_loss: 0.5094 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.41973\n",
      "Epoch 346/4000\n",
      "25/25 - 0s - loss: 0.2084 - accuracy: 0.8988 - val_loss: 0.5211 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.41973\n",
      "Epoch 347/4000\n",
      "25/25 - 0s - loss: 0.2068 - accuracy: 0.9001 - val_loss: 0.5115 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.41973\n",
      "Epoch 348/4000\n",
      "25/25 - 0s - loss: 0.2064 - accuracy: 0.9027 - val_loss: 0.5338 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.41973\n",
      "Epoch 349/4000\n",
      "25/25 - 0s - loss: 0.2079 - accuracy: 0.8975 - val_loss: 0.5351 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.41973\n",
      "Epoch 350/4000\n",
      "25/25 - 0s - loss: 0.2133 - accuracy: 0.8988 - val_loss: 0.5194 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.41973\n",
      "Epoch 351/4000\n",
      "25/25 - 0s - loss: 0.2114 - accuracy: 0.8975 - val_loss: 0.5177 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.41973\n",
      "Epoch 352/4000\n",
      "25/25 - 0s - loss: 0.2073 - accuracy: 0.9001 - val_loss: 0.5241 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.41973\n",
      "Epoch 353/4000\n",
      "25/25 - 0s - loss: 0.2060 - accuracy: 0.8988 - val_loss: 0.5082 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.41973\n",
      "Epoch 354/4000\n",
      "25/25 - 0s - loss: 0.2051 - accuracy: 0.9014 - val_loss: 0.5130 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.41973\n",
      "Epoch 355/4000\n",
      "25/25 - 0s - loss: 0.2100 - accuracy: 0.8962 - val_loss: 0.4836 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.41973\n",
      "Epoch 356/4000\n",
      "25/25 - 0s - loss: 0.2076 - accuracy: 0.9014 - val_loss: 0.4919 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.41973\n",
      "Epoch 357/4000\n",
      "25/25 - 0s - loss: 0.2112 - accuracy: 0.8936 - val_loss: 0.4960 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.41973\n",
      "Epoch 358/4000\n",
      "25/25 - 0s - loss: 0.2082 - accuracy: 0.8988 - val_loss: 0.5198 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.41973\n",
      "Epoch 359/4000\n",
      "25/25 - 0s - loss: 0.2082 - accuracy: 0.9001 - val_loss: 0.5059 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.41973\n",
      "Epoch 360/4000\n",
      "25/25 - 0s - loss: 0.2073 - accuracy: 0.8975 - val_loss: 0.5406 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.41973\n",
      "Epoch 361/4000\n",
      "25/25 - 0s - loss: 0.2076 - accuracy: 0.9001 - val_loss: 0.5326 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.41973\n",
      "Epoch 362/4000\n",
      "25/25 - 0s - loss: 0.2125 - accuracy: 0.8898 - val_loss: 0.5321 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.41973\n",
      "Epoch 363/4000\n",
      "25/25 - 0s - loss: 0.2086 - accuracy: 0.8975 - val_loss: 0.5317 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 0.41973\n",
      "Epoch 364/4000\n",
      "25/25 - 0s - loss: 0.2084 - accuracy: 0.8988 - val_loss: 0.5562 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.41973\n",
      "Epoch 365/4000\n",
      "25/25 - 0s - loss: 0.2100 - accuracy: 0.8975 - val_loss: 0.5466 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.41973\n",
      "Epoch 366/4000\n",
      "25/25 - 0s - loss: 0.2067 - accuracy: 0.8936 - val_loss: 0.5294 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.41973\n",
      "Epoch 367/4000\n",
      "25/25 - 0s - loss: 0.2061 - accuracy: 0.8988 - val_loss: 0.5171 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.41973\n",
      "Epoch 368/4000\n",
      "25/25 - 0s - loss: 0.2077 - accuracy: 0.9014 - val_loss: 0.5079 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.41973\n",
      "Epoch 369/4000\n",
      "25/25 - 0s - loss: 0.2056 - accuracy: 0.9001 - val_loss: 0.5242 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.41973\n",
      "Epoch 370/4000\n",
      "25/25 - 0s - loss: 0.2089 - accuracy: 0.8936 - val_loss: 0.5304 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.41973\n",
      "Epoch 371/4000\n",
      "25/25 - 0s - loss: 0.2058 - accuracy: 0.9001 - val_loss: 0.5294 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.41973\n",
      "Epoch 372/4000\n",
      "25/25 - 0s - loss: 0.2065 - accuracy: 0.8936 - val_loss: 0.5310 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.41973\n",
      "Epoch 373/4000\n",
      "25/25 - 0s - loss: 0.2059 - accuracy: 0.8975 - val_loss: 0.5234 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.41973\n",
      "Epoch 374/4000\n",
      "25/25 - 0s - loss: 0.2055 - accuracy: 0.8936 - val_loss: 0.5245 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.41973\n",
      "Epoch 375/4000\n",
      "25/25 - 0s - loss: 0.2046 - accuracy: 0.9001 - val_loss: 0.5377 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.41973\n",
      "Epoch 376/4000\n",
      "25/25 - 0s - loss: 0.2059 - accuracy: 0.9027 - val_loss: 0.5163 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.41973\n",
      "Epoch 377/4000\n",
      "25/25 - 0s - loss: 0.2073 - accuracy: 0.8962 - val_loss: 0.5262 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.41973\n",
      "Epoch 378/4000\n",
      "25/25 - 0s - loss: 0.2078 - accuracy: 0.9001 - val_loss: 0.5623 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.41973\n",
      "Epoch 379/4000\n",
      "25/25 - 0s - loss: 0.2069 - accuracy: 0.8975 - val_loss: 0.5502 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.41973\n",
      "Epoch 380/4000\n",
      "25/25 - 0s - loss: 0.2054 - accuracy: 0.8975 - val_loss: 0.5510 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.41973\n",
      "Epoch 381/4000\n",
      "25/25 - 0s - loss: 0.2078 - accuracy: 0.8975 - val_loss: 0.5359 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 0.41973\n",
      "Epoch 382/4000\n",
      "25/25 - 0s - loss: 0.2072 - accuracy: 0.8898 - val_loss: 0.5687 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 0.41973\n",
      "Epoch 383/4000\n",
      "25/25 - 0s - loss: 0.2055 - accuracy: 0.8988 - val_loss: 0.5759 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 0.41973\n",
      "Epoch 384/4000\n",
      "25/25 - 0s - loss: 0.2126 - accuracy: 0.9001 - val_loss: 0.5361 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 0.41973\n",
      "Epoch 385/4000\n",
      "25/25 - 0s - loss: 0.2102 - accuracy: 0.9001 - val_loss: 0.5427 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 0.41973\n",
      "Epoch 386/4000\n",
      "25/25 - 0s - loss: 0.2075 - accuracy: 0.8962 - val_loss: 0.5585 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.41973\n",
      "Epoch 387/4000\n",
      "25/25 - 0s - loss: 0.2084 - accuracy: 0.8988 - val_loss: 0.5447 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 0.41973\n",
      "Epoch 388/4000\n",
      "25/25 - 0s - loss: 0.2062 - accuracy: 0.9001 - val_loss: 0.5349 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.41973\n",
      "Epoch 389/4000\n",
      "25/25 - 0s - loss: 0.2107 - accuracy: 0.8975 - val_loss: 0.5393 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 0.41973\n",
      "Epoch 390/4000\n",
      "25/25 - 0s - loss: 0.2161 - accuracy: 0.8872 - val_loss: 0.5625 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.41973\n",
      "Epoch 391/4000\n",
      "25/25 - 0s - loss: 0.2073 - accuracy: 0.9001 - val_loss: 0.5253 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.41973\n",
      "Epoch 392/4000\n",
      "25/25 - 0s - loss: 0.2096 - accuracy: 0.8898 - val_loss: 0.5243 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.41973\n",
      "Epoch 393/4000\n",
      "25/25 - 0s - loss: 0.2069 - accuracy: 0.8988 - val_loss: 0.5221 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.41973\n",
      "Epoch 394/4000\n",
      "25/25 - 0s - loss: 0.2070 - accuracy: 0.9027 - val_loss: 0.5168 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 0.41973\n",
      "Epoch 395/4000\n",
      "25/25 - 0s - loss: 0.2046 - accuracy: 0.9040 - val_loss: 0.5248 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 0.41973\n",
      "Epoch 396/4000\n",
      "25/25 - 0s - loss: 0.2058 - accuracy: 0.9014 - val_loss: 0.5219 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 0.41973\n",
      "Epoch 397/4000\n",
      "25/25 - 0s - loss: 0.2055 - accuracy: 0.8898 - val_loss: 0.5291 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.41973\n",
      "Epoch 398/4000\n",
      "25/25 - 0s - loss: 0.2074 - accuracy: 0.9001 - val_loss: 0.5254 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 0.41973\n",
      "Epoch 399/4000\n",
      "25/25 - 0s - loss: 0.2077 - accuracy: 0.8962 - val_loss: 0.5272 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 0.41973\n",
      "Epoch 400/4000\n",
      "25/25 - 0s - loss: 0.2058 - accuracy: 0.8988 - val_loss: 0.5235 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.41973\n",
      "Epoch 401/4000\n",
      "25/25 - 0s - loss: 0.2064 - accuracy: 0.8988 - val_loss: 0.5611 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 0.41973\n",
      "Epoch 402/4000\n",
      "25/25 - 0s - loss: 0.2063 - accuracy: 0.8949 - val_loss: 0.5304 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 0.41973\n",
      "Epoch 403/4000\n",
      "25/25 - 0s - loss: 0.2038 - accuracy: 0.8975 - val_loss: 0.5435 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 0.41973\n",
      "Epoch 404/4000\n",
      "25/25 - 0s - loss: 0.2062 - accuracy: 0.8949 - val_loss: 0.5452 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 0.41973\n",
      "Epoch 405/4000\n",
      "25/25 - 0s - loss: 0.2063 - accuracy: 0.8988 - val_loss: 0.5364 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 0.41973\n",
      "Epoch 406/4000\n",
      "25/25 - 0s - loss: 0.2063 - accuracy: 0.9001 - val_loss: 0.5122 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 0.41973\n",
      "Epoch 407/4000\n",
      "25/25 - 0s - loss: 0.2043 - accuracy: 0.9014 - val_loss: 0.5306 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 0.41973\n",
      "Epoch 408/4000\n",
      "25/25 - 0s - loss: 0.2073 - accuracy: 0.9014 - val_loss: 0.5366 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 0.41973\n",
      "Epoch 409/4000\n",
      "25/25 - 0s - loss: 0.2125 - accuracy: 0.8962 - val_loss: 0.5214 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 0.41973\n",
      "Epoch 410/4000\n",
      "25/25 - 0s - loss: 0.2092 - accuracy: 0.9001 - val_loss: 0.5254 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 0.41973\n",
      "Epoch 411/4000\n",
      "25/25 - 0s - loss: 0.2055 - accuracy: 0.8936 - val_loss: 0.5510 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 0.41973\n",
      "Epoch 412/4000\n",
      "25/25 - 0s - loss: 0.2051 - accuracy: 0.9001 - val_loss: 0.5526 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 0.41973\n",
      "Epoch 413/4000\n",
      "25/25 - 0s - loss: 0.2066 - accuracy: 0.8923 - val_loss: 0.5608 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 0.41973\n",
      "Epoch 414/4000\n",
      "25/25 - 0s - loss: 0.2054 - accuracy: 0.9014 - val_loss: 0.5511 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 0.41973\n",
      "Epoch 415/4000\n",
      "25/25 - 0s - loss: 0.2066 - accuracy: 0.9040 - val_loss: 0.5730 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 0.41973\n",
      "Epoch 416/4000\n",
      "25/25 - 0s - loss: 0.2095 - accuracy: 0.8975 - val_loss: 0.5915 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.41973\n",
      "Epoch 417/4000\n",
      "25/25 - 0s - loss: 0.2069 - accuracy: 0.8988 - val_loss: 0.5495 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.41973\n",
      "Epoch 418/4000\n",
      "25/25 - 0s - loss: 0.2047 - accuracy: 0.8988 - val_loss: 0.5407 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 0.41973\n",
      "Epoch 419/4000\n",
      "25/25 - 0s - loss: 0.2051 - accuracy: 0.9027 - val_loss: 0.5680 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 0.41973\n",
      "Epoch 420/4000\n",
      "25/25 - 0s - loss: 0.2050 - accuracy: 0.8962 - val_loss: 0.5715 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 0.41973\n",
      "Epoch 421/4000\n",
      "25/25 - 0s - loss: 0.2045 - accuracy: 0.8949 - val_loss: 0.5584 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 0.41973\n",
      "Epoch 422/4000\n",
      "25/25 - 0s - loss: 0.2107 - accuracy: 0.8911 - val_loss: 0.5866 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 0.41973\n",
      "Epoch 423/4000\n",
      "25/25 - 0s - loss: 0.2105 - accuracy: 0.9027 - val_loss: 0.4774 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 0.41973\n",
      "Epoch 424/4000\n",
      "25/25 - 0s - loss: 0.2075 - accuracy: 0.9001 - val_loss: 0.5356 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 0.41973\n",
      "Epoch 425/4000\n",
      "25/25 - 0s - loss: 0.2053 - accuracy: 0.9027 - val_loss: 0.5743 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 0.41973\n",
      "Epoch 426/4000\n",
      "25/25 - 0s - loss: 0.2050 - accuracy: 0.9027 - val_loss: 0.5819 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 0.41973\n",
      "Epoch 427/4000\n",
      "25/25 - 0s - loss: 0.2054 - accuracy: 0.9014 - val_loss: 0.5919 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 0.41973\n",
      "Epoch 428/4000\n",
      "25/25 - 0s - loss: 0.2054 - accuracy: 0.9014 - val_loss: 0.5542 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 0.41973\n",
      "Epoch 429/4000\n",
      "25/25 - 0s - loss: 0.2060 - accuracy: 0.8962 - val_loss: 0.5836 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 0.41973\n",
      "Epoch 430/4000\n",
      "25/25 - 0s - loss: 0.2072 - accuracy: 0.9001 - val_loss: 0.5572 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.41973\n",
      "Epoch 431/4000\n",
      "25/25 - 0s - loss: 0.2063 - accuracy: 0.8975 - val_loss: 0.5937 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 0.41973\n",
      "Epoch 432/4000\n",
      "25/25 - 0s - loss: 0.2053 - accuracy: 0.8949 - val_loss: 0.5712 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.41973\n",
      "Epoch 433/4000\n",
      "25/25 - 0s - loss: 0.2086 - accuracy: 0.9001 - val_loss: 0.5714 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.41973\n",
      "Epoch 434/4000\n",
      "25/25 - 0s - loss: 0.2089 - accuracy: 0.8949 - val_loss: 0.5676 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 0.41973\n",
      "Epoch 435/4000\n",
      "25/25 - 0s - loss: 0.2056 - accuracy: 0.9014 - val_loss: 0.5725 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 0.41973\n",
      "Epoch 436/4000\n",
      "25/25 - 0s - loss: 0.2052 - accuracy: 0.9027 - val_loss: 0.5925 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 0.41973\n",
      "Epoch 437/4000\n",
      "25/25 - 0s - loss: 0.2061 - accuracy: 0.8988 - val_loss: 0.5858 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 0.41973\n",
      "Epoch 438/4000\n",
      "25/25 - 0s - loss: 0.2081 - accuracy: 0.8988 - val_loss: 0.6037 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 0.41973\n",
      "Epoch 439/4000\n",
      "25/25 - 0s - loss: 0.2051 - accuracy: 0.8988 - val_loss: 0.5917 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 0.41973\n",
      "Epoch 440/4000\n",
      "25/25 - 0s - loss: 0.2061 - accuracy: 0.8988 - val_loss: 0.5749 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.41973\n",
      "Epoch 441/4000\n",
      "25/25 - 0s - loss: 0.2060 - accuracy: 0.9001 - val_loss: 0.5896 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 0.41973\n",
      "Epoch 442/4000\n",
      "25/25 - 0s - loss: 0.2058 - accuracy: 0.9001 - val_loss: 0.5965 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.41973\n",
      "Epoch 443/4000\n",
      "25/25 - 0s - loss: 0.2099 - accuracy: 0.8975 - val_loss: 0.4915 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.41973\n",
      "Epoch 444/4000\n",
      "25/25 - 0s - loss: 0.2073 - accuracy: 0.8975 - val_loss: 0.5632 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.41973\n",
      "Epoch 445/4000\n",
      "25/25 - 0s - loss: 0.2069 - accuracy: 0.8988 - val_loss: 0.5860 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.41973\n",
      "Epoch 446/4000\n",
      "25/25 - 0s - loss: 0.2069 - accuracy: 0.9027 - val_loss: 0.5941 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.41973\n",
      "Epoch 447/4000\n",
      "25/25 - 0s - loss: 0.2061 - accuracy: 0.9014 - val_loss: 0.5985 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 0.41973\n",
      "Epoch 448/4000\n",
      "25/25 - 0s - loss: 0.2059 - accuracy: 0.8975 - val_loss: 0.6044 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 0.41973\n",
      "Epoch 449/4000\n",
      "25/25 - 0s - loss: 0.2051 - accuracy: 0.9014 - val_loss: 0.6049 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 0.41973\n",
      "Epoch 450/4000\n",
      "25/25 - 0s - loss: 0.2042 - accuracy: 0.9014 - val_loss: 0.5964 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 0.41973\n",
      "Epoch 451/4000\n",
      "25/25 - 0s - loss: 0.2065 - accuracy: 0.8962 - val_loss: 0.5971 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 0.41973\n",
      "Epoch 452/4000\n",
      "25/25 - 0s - loss: 0.2088 - accuracy: 0.9014 - val_loss: 0.5795 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 0.41973\n",
      "Epoch 453/4000\n",
      "25/25 - 0s - loss: 0.2058 - accuracy: 0.9014 - val_loss: 0.5972 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 0.41973\n",
      "Epoch 454/4000\n",
      "25/25 - 0s - loss: 0.2056 - accuracy: 0.8988 - val_loss: 0.6283 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 0.41973\n",
      "Epoch 455/4000\n",
      "25/25 - 0s - loss: 0.2055 - accuracy: 0.9001 - val_loss: 0.5958 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 0.41973\n",
      "Epoch 456/4000\n",
      "25/25 - 0s - loss: 0.2051 - accuracy: 0.8975 - val_loss: 0.6275 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.41973\n",
      "Epoch 457/4000\n",
      "25/25 - 0s - loss: 0.2036 - accuracy: 0.9027 - val_loss: 0.6519 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 0.41973\n",
      "Epoch 458/4000\n",
      "25/25 - 0s - loss: 0.2042 - accuracy: 0.8962 - val_loss: 0.6291 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 0.41973\n",
      "Epoch 459/4000\n",
      "25/25 - 0s - loss: 0.2041 - accuracy: 0.8988 - val_loss: 0.6313 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 0.41973\n",
      "Epoch 460/4000\n",
      "25/25 - 0s - loss: 0.2055 - accuracy: 0.8988 - val_loss: 0.6306 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 0.41973\n",
      "Epoch 461/4000\n",
      "25/25 - 0s - loss: 0.2037 - accuracy: 0.8988 - val_loss: 0.6278 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 0.41973\n",
      "Epoch 462/4000\n",
      "25/25 - 0s - loss: 0.2057 - accuracy: 0.8949 - val_loss: 0.5892 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 0.41973\n",
      "Epoch 463/4000\n",
      "25/25 - 0s - loss: 0.2046 - accuracy: 0.8988 - val_loss: 0.6341 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 0.41973\n",
      "Epoch 464/4000\n",
      "25/25 - 0s - loss: 0.2058 - accuracy: 0.8923 - val_loss: 0.6188 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 0.41973\n",
      "Epoch 465/4000\n",
      "25/25 - 0s - loss: 0.2035 - accuracy: 0.9027 - val_loss: 0.6306 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 0.41973\n",
      "Epoch 466/4000\n",
      "25/25 - 0s - loss: 0.2045 - accuracy: 0.8962 - val_loss: 0.6168 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 0.41973\n",
      "Epoch 467/4000\n",
      "25/25 - 0s - loss: 0.2054 - accuracy: 0.9027 - val_loss: 0.6366 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.41973\n",
      "Epoch 468/4000\n",
      "25/25 - 0s - loss: 0.2062 - accuracy: 0.9027 - val_loss: 0.6359 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 0.41973\n",
      "Epoch 469/4000\n",
      "25/25 - 0s - loss: 0.2038 - accuracy: 0.8988 - val_loss: 0.6083 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 0.41973\n",
      "Epoch 470/4000\n",
      "25/25 - 0s - loss: 0.2061 - accuracy: 0.8975 - val_loss: 0.6251 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.41973\n",
      "Epoch 471/4000\n",
      "25/25 - 0s - loss: 0.2052 - accuracy: 0.8962 - val_loss: 0.6416 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 0.41973\n",
      "Epoch 472/4000\n",
      "25/25 - 0s - loss: 0.2080 - accuracy: 0.9014 - val_loss: 0.5337 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.41973\n",
      "Epoch 473/4000\n",
      "25/25 - 0s - loss: 0.2305 - accuracy: 0.8936 - val_loss: 0.5006 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 0.41973\n",
      "Epoch 474/4000\n",
      "25/25 - 0s - loss: 0.2100 - accuracy: 0.9040 - val_loss: 0.5451 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 0.41973\n",
      "Epoch 475/4000\n",
      "25/25 - 0s - loss: 0.2081 - accuracy: 0.8975 - val_loss: 0.5459 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.41973\n",
      "Epoch 476/4000\n",
      "25/25 - 0s - loss: 0.2047 - accuracy: 0.9014 - val_loss: 0.5578 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 0.41973\n",
      "Epoch 477/4000\n",
      "25/25 - 0s - loss: 0.2096 - accuracy: 0.8975 - val_loss: 0.5340 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 0.41973\n",
      "Epoch 478/4000\n",
      "25/25 - 0s - loss: 0.2087 - accuracy: 0.8975 - val_loss: 0.5767 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 0.41973\n",
      "Epoch 479/4000\n",
      "25/25 - 0s - loss: 0.2093 - accuracy: 0.8988 - val_loss: 0.5565 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 0.41973\n",
      "Epoch 480/4000\n",
      "25/25 - 0s - loss: 0.2091 - accuracy: 0.9014 - val_loss: 0.5158 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.41973\n",
      "Epoch 481/4000\n",
      "25/25 - 0s - loss: 0.2065 - accuracy: 0.8962 - val_loss: 0.5400 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 0.41973\n",
      "Epoch 482/4000\n",
      "25/25 - 0s - loss: 0.2044 - accuracy: 0.9014 - val_loss: 0.5636 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 0.41973\n",
      "Epoch 483/4000\n",
      "25/25 - 0s - loss: 0.2035 - accuracy: 0.9001 - val_loss: 0.5745 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 0.41973\n",
      "Epoch 484/4000\n",
      "25/25 - 0s - loss: 0.2036 - accuracy: 0.9001 - val_loss: 0.5693 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.41973\n",
      "Epoch 485/4000\n",
      "25/25 - 0s - loss: 0.2040 - accuracy: 0.8975 - val_loss: 0.6134 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 0.41973\n",
      "Epoch 486/4000\n",
      "25/25 - 0s - loss: 0.2070 - accuracy: 0.9001 - val_loss: 0.5707 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.41973\n",
      "Epoch 487/4000\n",
      "25/25 - 0s - loss: 0.2060 - accuracy: 0.8988 - val_loss: 0.5833 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.41973\n",
      "Epoch 488/4000\n",
      "25/25 - 0s - loss: 0.2078 - accuracy: 0.8936 - val_loss: 0.5774 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 0.41973\n",
      "Epoch 489/4000\n",
      "25/25 - 0s - loss: 0.2111 - accuracy: 0.8949 - val_loss: 0.5132 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 0.41973\n",
      "Epoch 490/4000\n",
      "25/25 - 0s - loss: 0.2105 - accuracy: 0.8962 - val_loss: 0.4940 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.41973\n",
      "Epoch 491/4000\n",
      "25/25 - 0s - loss: 0.2077 - accuracy: 0.8975 - val_loss: 0.5194 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 0.41973\n",
      "Epoch 492/4000\n",
      "25/25 - 0s - loss: 0.2055 - accuracy: 0.8962 - val_loss: 0.5470 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 0.41973\n",
      "Epoch 493/4000\n",
      "25/25 - 0s - loss: 0.2050 - accuracy: 0.8988 - val_loss: 0.5731 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 0.41973\n",
      "Epoch 494/4000\n",
      "25/25 - 0s - loss: 0.2046 - accuracy: 0.8962 - val_loss: 0.5709 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 0.41973\n",
      "Epoch 495/4000\n",
      "25/25 - 0s - loss: 0.2047 - accuracy: 0.9027 - val_loss: 0.5633 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.41973\n",
      "Epoch 496/4000\n",
      "25/25 - 0s - loss: 0.2034 - accuracy: 0.9014 - val_loss: 0.5578 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.41973\n",
      "Epoch 497/4000\n",
      "25/25 - 0s - loss: 0.2129 - accuracy: 0.8962 - val_loss: 0.5652 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 0.41973\n",
      "Epoch 498/4000\n",
      "25/25 - 0s - loss: 0.2068 - accuracy: 0.9027 - val_loss: 0.4956 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 0.41973\n",
      "Epoch 499/4000\n",
      "25/25 - 0s - loss: 0.2051 - accuracy: 0.8962 - val_loss: 0.5314 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 0.41973\n",
      "Epoch 500/4000\n",
      "25/25 - 0s - loss: 0.2047 - accuracy: 0.8988 - val_loss: 0.5608 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.41973\n",
      "Epoch 501/4000\n",
      "25/25 - 0s - loss: 0.2070 - accuracy: 0.9001 - val_loss: 0.5626 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 0.41973\n",
      "Epoch 502/4000\n",
      "25/25 - 0s - loss: 0.2061 - accuracy: 0.8988 - val_loss: 0.5537 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 0.41973\n",
      "Epoch 503/4000\n",
      "25/25 - 0s - loss: 0.2056 - accuracy: 0.8936 - val_loss: 0.5694 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 0.41973\n",
      "Epoch 504/4000\n",
      "25/25 - 0s - loss: 0.2049 - accuracy: 0.9001 - val_loss: 0.5452 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 0.41973\n",
      "Epoch 505/4000\n",
      "25/25 - 0s - loss: 0.2093 - accuracy: 0.8975 - val_loss: 0.5531 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 0.41973\n",
      "Epoch 506/4000\n",
      "25/25 - 0s - loss: 0.2174 - accuracy: 0.8949 - val_loss: 0.6388 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 0.41973\n",
      "Epoch 507/4000\n",
      "25/25 - 0s - loss: 0.2415 - accuracy: 0.8936 - val_loss: 0.5388 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 0.41973\n",
      "Epoch 508/4000\n",
      "25/25 - 0s - loss: 0.2299 - accuracy: 0.8923 - val_loss: 0.5870 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 0.41973\n",
      "Epoch 509/4000\n",
      "25/25 - 0s - loss: 0.2203 - accuracy: 0.8936 - val_loss: 0.6618 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 0.41973\n",
      "Epoch 510/4000\n",
      "25/25 - 0s - loss: 0.2102 - accuracy: 0.9053 - val_loss: 0.6563 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 0.41973\n",
      "Epoch 511/4000\n",
      "25/25 - 0s - loss: 0.2087 - accuracy: 0.9027 - val_loss: 0.5820 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 0.41973\n",
      "Epoch 512/4000\n",
      "25/25 - 0s - loss: 0.2059 - accuracy: 0.9001 - val_loss: 0.6155 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 0.41973\n",
      "Epoch 513/4000\n",
      "25/25 - 0s - loss: 0.2055 - accuracy: 0.9027 - val_loss: 0.6342 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 0.41973\n",
      "Epoch 514/4000\n",
      "25/25 - 0s - loss: 0.2058 - accuracy: 0.8988 - val_loss: 0.6437 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 0.41973\n",
      "Epoch 515/4000\n",
      "25/25 - 0s - loss: 0.2052 - accuracy: 0.9001 - val_loss: 0.6412 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 0.41973\n",
      "Epoch 516/4000\n",
      "25/25 - 0s - loss: 0.2043 - accuracy: 0.9040 - val_loss: 0.6574 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 0.41973\n",
      "Epoch 517/4000\n",
      "25/25 - 0s - loss: 0.2064 - accuracy: 0.8962 - val_loss: 0.6284 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 0.41973\n",
      "Epoch 518/4000\n",
      "25/25 - 0s - loss: 0.2062 - accuracy: 0.8949 - val_loss: 0.6419 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 0.41973\n",
      "Epoch 519/4000\n",
      "25/25 - 0s - loss: 0.2045 - accuracy: 0.9014 - val_loss: 0.6375 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 0.41973\n",
      "Epoch 520/4000\n",
      "25/25 - 0s - loss: 0.2040 - accuracy: 0.9014 - val_loss: 0.6370 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 0.41973\n",
      "Epoch 521/4000\n",
      "25/25 - 0s - loss: 0.2040 - accuracy: 0.9027 - val_loss: 0.6614 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 0.41973\n",
      "Epoch 522/4000\n",
      "25/25 - 0s - loss: 0.2041 - accuracy: 0.9001 - val_loss: 0.6381 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 0.41973\n",
      "Epoch 523/4000\n",
      "25/25 - 0s - loss: 0.2060 - accuracy: 0.8988 - val_loss: 0.6190 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 0.41973\n",
      "Epoch 524/4000\n",
      "25/25 - 0s - loss: 0.2054 - accuracy: 0.8975 - val_loss: 0.6384 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 0.41973\n",
      "Epoch 525/4000\n",
      "25/25 - 0s - loss: 0.2048 - accuracy: 0.9014 - val_loss: 0.6372 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 0.41973\n",
      "Epoch 526/4000\n",
      "25/25 - 0s - loss: 0.2041 - accuracy: 0.9040 - val_loss: 0.6410 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 0.41973\n",
      "Epoch 527/4000\n",
      "25/25 - 0s - loss: 0.2044 - accuracy: 0.9014 - val_loss: 0.6281 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 0.41973\n",
      "Epoch 528/4000\n",
      "25/25 - 0s - loss: 0.2068 - accuracy: 0.8975 - val_loss: 0.6360 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 0.41973\n",
      "Epoch 529/4000\n",
      "25/25 - 0s - loss: 0.2047 - accuracy: 0.9053 - val_loss: 0.6519 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 0.41973\n",
      "Epoch 530/4000\n",
      "25/25 - 0s - loss: 0.2039 - accuracy: 0.9001 - val_loss: 0.6485 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 0.41973\n",
      "Epoch 531/4000\n",
      "25/25 - 0s - loss: 0.2063 - accuracy: 0.9053 - val_loss: 0.6432 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 0.41973\n",
      "Epoch 532/4000\n",
      "25/25 - 0s - loss: 0.2035 - accuracy: 0.8923 - val_loss: 0.6506 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 0.41973\n",
      "Epoch 533/4000\n",
      "25/25 - 0s - loss: 0.2039 - accuracy: 0.8988 - val_loss: 0.6557 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 0.41973\n",
      "Epoch 534/4000\n",
      "25/25 - 0s - loss: 0.2047 - accuracy: 0.9014 - val_loss: 0.6385 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 0.41973\n",
      "Epoch 535/4000\n",
      "25/25 - 0s - loss: 0.2055 - accuracy: 0.8962 - val_loss: 0.6470 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 0.41973\n",
      "Epoch 536/4000\n",
      "25/25 - 0s - loss: 0.2043 - accuracy: 0.8975 - val_loss: 0.6542 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 0.41973\n",
      "Epoch 537/4000\n",
      "25/25 - 0s - loss: 0.2033 - accuracy: 0.9014 - val_loss: 0.6451 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 0.41973\n",
      "Epoch 538/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.8962 - val_loss: 0.6469 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 0.41973\n",
      "Epoch 539/4000\n",
      "25/25 - 0s - loss: 0.2086 - accuracy: 0.8936 - val_loss: 0.5905 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 0.41973\n",
      "Epoch 540/4000\n",
      "25/25 - 0s - loss: 0.2054 - accuracy: 0.8975 - val_loss: 0.5988 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 0.41973\n",
      "Epoch 541/4000\n",
      "25/25 - 0s - loss: 0.2053 - accuracy: 0.9001 - val_loss: 0.6070 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 0.41973\n",
      "Epoch 542/4000\n",
      "25/25 - 0s - loss: 0.2043 - accuracy: 0.9014 - val_loss: 0.6135 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 0.41973\n",
      "Epoch 543/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.9001 - val_loss: 0.6024 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 0.41973\n",
      "Epoch 544/4000\n",
      "25/25 - 0s - loss: 0.2037 - accuracy: 0.8975 - val_loss: 0.6170 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 0.41973\n",
      "Epoch 545/4000\n",
      "25/25 - 0s - loss: 0.2031 - accuracy: 0.9001 - val_loss: 0.6143 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 0.41973\n",
      "Epoch 546/4000\n",
      "25/25 - 0s - loss: 0.2040 - accuracy: 0.9027 - val_loss: 0.6146 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 0.41973\n",
      "Epoch 547/4000\n",
      "25/25 - 0s - loss: 0.2025 - accuracy: 0.9014 - val_loss: 0.6110 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 0.41973\n",
      "Epoch 548/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.8936 - val_loss: 0.6254 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 0.41973\n",
      "Epoch 549/4000\n",
      "25/25 - 0s - loss: 0.2052 - accuracy: 0.9040 - val_loss: 0.6183 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 0.41973\n",
      "Epoch 550/4000\n",
      "25/25 - 0s - loss: 0.2036 - accuracy: 0.9040 - val_loss: 0.6149 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 0.41973\n",
      "Epoch 551/4000\n",
      "25/25 - 0s - loss: 0.2040 - accuracy: 0.9001 - val_loss: 0.6132 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00551: val_loss did not improve from 0.41973\n",
      "Epoch 552/4000\n",
      "25/25 - 0s - loss: 0.2036 - accuracy: 0.9014 - val_loss: 0.6036 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00552: val_loss did not improve from 0.41973\n",
      "Epoch 553/4000\n",
      "25/25 - 0s - loss: 0.2035 - accuracy: 0.9001 - val_loss: 0.6130 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00553: val_loss did not improve from 0.41973\n",
      "Epoch 554/4000\n",
      "25/25 - 0s - loss: 0.2049 - accuracy: 0.8949 - val_loss: 0.6088 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00554: val_loss did not improve from 0.41973\n",
      "Epoch 555/4000\n",
      "25/25 - 0s - loss: 0.2042 - accuracy: 0.9027 - val_loss: 0.6258 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00555: val_loss did not improve from 0.41973\n",
      "Epoch 556/4000\n",
      "25/25 - 0s - loss: 0.2031 - accuracy: 0.8936 - val_loss: 0.6298 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00556: val_loss did not improve from 0.41973\n",
      "Epoch 557/4000\n",
      "25/25 - 0s - loss: 0.2027 - accuracy: 0.8988 - val_loss: 0.6399 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00557: val_loss did not improve from 0.41973\n",
      "Epoch 558/4000\n",
      "25/25 - 0s - loss: 0.2028 - accuracy: 0.9014 - val_loss: 0.6455 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00558: val_loss did not improve from 0.41973\n",
      "Epoch 559/4000\n",
      "25/25 - 0s - loss: 0.2032 - accuracy: 0.9027 - val_loss: 0.6365 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00559: val_loss did not improve from 0.41973\n",
      "Epoch 560/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9001 - val_loss: 0.6329 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 0.41973\n",
      "Epoch 561/4000\n",
      "25/25 - 0s - loss: 0.2029 - accuracy: 0.9014 - val_loss: 0.6294 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00561: val_loss did not improve from 0.41973\n",
      "Epoch 562/4000\n",
      "25/25 - 0s - loss: 0.2036 - accuracy: 0.9014 - val_loss: 0.6307 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00562: val_loss did not improve from 0.41973\n",
      "Epoch 563/4000\n",
      "25/25 - 0s - loss: 0.2049 - accuracy: 0.9001 - val_loss: 0.6282 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00563: val_loss did not improve from 0.41973\n",
      "Epoch 564/4000\n",
      "25/25 - 0s - loss: 0.2038 - accuracy: 0.8975 - val_loss: 0.6239 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00564: val_loss did not improve from 0.41973\n",
      "Epoch 565/4000\n",
      "25/25 - 0s - loss: 0.2036 - accuracy: 0.9040 - val_loss: 0.6369 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00565: val_loss did not improve from 0.41973\n",
      "Epoch 566/4000\n",
      "25/25 - 0s - loss: 0.2056 - accuracy: 0.9001 - val_loss: 0.6282 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00566: val_loss did not improve from 0.41973\n",
      "Epoch 567/4000\n",
      "25/25 - 0s - loss: 0.2057 - accuracy: 0.8988 - val_loss: 0.6730 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00567: val_loss did not improve from 0.41973\n",
      "Epoch 568/4000\n",
      "25/25 - 0s - loss: 0.2136 - accuracy: 0.8936 - val_loss: 0.6529 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00568: val_loss did not improve from 0.41973\n",
      "Epoch 569/4000\n",
      "25/25 - 0s - loss: 0.2048 - accuracy: 0.8988 - val_loss: 0.6588 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00569: val_loss did not improve from 0.41973\n",
      "Epoch 570/4000\n",
      "25/25 - 0s - loss: 0.2084 - accuracy: 0.9014 - val_loss: 0.6848 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00570: val_loss did not improve from 0.41973\n",
      "Epoch 571/4000\n",
      "25/25 - 0s - loss: 0.2039 - accuracy: 0.9001 - val_loss: 0.6675 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00571: val_loss did not improve from 0.41973\n",
      "Epoch 572/4000\n",
      "25/25 - 0s - loss: 0.2045 - accuracy: 0.9014 - val_loss: 0.6678 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00572: val_loss did not improve from 0.41973\n",
      "Epoch 573/4000\n",
      "25/25 - 0s - loss: 0.2054 - accuracy: 0.8923 - val_loss: 0.6609 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00573: val_loss did not improve from 0.41973\n",
      "Epoch 574/4000\n",
      "25/25 - 0s - loss: 0.2036 - accuracy: 0.9027 - val_loss: 0.6706 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00574: val_loss did not improve from 0.41973\n",
      "Epoch 575/4000\n",
      "25/25 - 0s - loss: 0.2048 - accuracy: 0.8975 - val_loss: 0.6694 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00575: val_loss did not improve from 0.41973\n",
      "Epoch 576/4000\n",
      "25/25 - 0s - loss: 0.2104 - accuracy: 0.8975 - val_loss: 0.6121 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00576: val_loss did not improve from 0.41973\n",
      "Epoch 577/4000\n",
      "25/25 - 0s - loss: 0.2066 - accuracy: 0.9027 - val_loss: 0.6208 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00577: val_loss did not improve from 0.41973\n",
      "Epoch 578/4000\n",
      "25/25 - 0s - loss: 0.2058 - accuracy: 0.9014 - val_loss: 0.6466 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00578: val_loss did not improve from 0.41973\n",
      "Epoch 579/4000\n",
      "25/25 - 0s - loss: 0.2072 - accuracy: 0.9014 - val_loss: 0.6204 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00579: val_loss did not improve from 0.41973\n",
      "Epoch 580/4000\n",
      "25/25 - 0s - loss: 0.2040 - accuracy: 0.9027 - val_loss: 0.6403 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00580: val_loss did not improve from 0.41973\n",
      "Epoch 581/4000\n",
      "25/25 - 0s - loss: 0.2034 - accuracy: 0.9040 - val_loss: 0.6404 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00581: val_loss did not improve from 0.41973\n",
      "Epoch 582/4000\n",
      "25/25 - 0s - loss: 0.2039 - accuracy: 0.8988 - val_loss: 0.6437 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00582: val_loss did not improve from 0.41973\n",
      "Epoch 583/4000\n",
      "25/25 - 0s - loss: 0.2060 - accuracy: 0.9014 - val_loss: 0.6377 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00583: val_loss did not improve from 0.41973\n",
      "Epoch 584/4000\n",
      "25/25 - 0s - loss: 0.2046 - accuracy: 0.9027 - val_loss: 0.6412 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00584: val_loss did not improve from 0.41973\n",
      "Epoch 585/4000\n",
      "25/25 - 0s - loss: 0.2036 - accuracy: 0.9001 - val_loss: 0.6491 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00585: val_loss did not improve from 0.41973\n",
      "Epoch 586/4000\n",
      "25/25 - 0s - loss: 0.2056 - accuracy: 0.8975 - val_loss: 0.6420 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00586: val_loss did not improve from 0.41973\n",
      "Epoch 587/4000\n",
      "25/25 - 0s - loss: 0.2031 - accuracy: 0.8975 - val_loss: 0.6541 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00587: val_loss did not improve from 0.41973\n",
      "Epoch 588/4000\n",
      "25/25 - 0s - loss: 0.2049 - accuracy: 0.9027 - val_loss: 0.6482 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00588: val_loss did not improve from 0.41973\n",
      "Epoch 589/4000\n",
      "25/25 - 0s - loss: 0.2048 - accuracy: 0.9001 - val_loss: 0.6532 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00589: val_loss did not improve from 0.41973\n",
      "Epoch 590/4000\n",
      "25/25 - 0s - loss: 0.2070 - accuracy: 0.8988 - val_loss: 0.6446 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00590: val_loss did not improve from 0.41973\n",
      "Epoch 591/4000\n",
      "25/25 - 0s - loss: 0.2050 - accuracy: 0.8962 - val_loss: 0.6273 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00591: val_loss did not improve from 0.41973\n",
      "Epoch 592/4000\n",
      "25/25 - 0s - loss: 0.2039 - accuracy: 0.8975 - val_loss: 0.6195 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00592: val_loss did not improve from 0.41973\n",
      "Epoch 593/4000\n",
      "25/25 - 0s - loss: 0.2029 - accuracy: 0.9014 - val_loss: 0.6191 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00593: val_loss did not improve from 0.41973\n",
      "Epoch 594/4000\n",
      "25/25 - 0s - loss: 0.2043 - accuracy: 0.9001 - val_loss: 0.6381 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00594: val_loss did not improve from 0.41973\n",
      "Epoch 595/4000\n",
      "25/25 - 0s - loss: 0.2035 - accuracy: 0.8988 - val_loss: 0.6360 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00595: val_loss did not improve from 0.41973\n",
      "Epoch 596/4000\n",
      "25/25 - 0s - loss: 0.2039 - accuracy: 0.9001 - val_loss: 0.6442 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00596: val_loss did not improve from 0.41973\n",
      "Epoch 597/4000\n",
      "25/25 - 0s - loss: 0.2042 - accuracy: 0.8988 - val_loss: 0.6421 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00597: val_loss did not improve from 0.41973\n",
      "Epoch 598/4000\n",
      "25/25 - 0s - loss: 0.2025 - accuracy: 0.9014 - val_loss: 0.6392 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00598: val_loss did not improve from 0.41973\n",
      "Epoch 599/4000\n",
      "25/25 - 0s - loss: 0.2027 - accuracy: 0.9014 - val_loss: 0.6673 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00599: val_loss did not improve from 0.41973\n",
      "Epoch 600/4000\n",
      "25/25 - 0s - loss: 0.2058 - accuracy: 0.8949 - val_loss: 0.6331 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00600: val_loss did not improve from 0.41973\n",
      "Epoch 601/4000\n",
      "25/25 - 0s - loss: 0.2033 - accuracy: 0.8988 - val_loss: 0.6320 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00601: val_loss did not improve from 0.41973\n",
      "Epoch 602/4000\n",
      "25/25 - 0s - loss: 0.2032 - accuracy: 0.9014 - val_loss: 0.6387 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00602: val_loss did not improve from 0.41973\n",
      "Epoch 603/4000\n",
      "25/25 - 0s - loss: 0.2035 - accuracy: 0.9040 - val_loss: 0.6480 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00603: val_loss did not improve from 0.41973\n",
      "Epoch 604/4000\n",
      "25/25 - 0s - loss: 0.2047 - accuracy: 0.9014 - val_loss: 0.6428 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00604: val_loss did not improve from 0.41973\n",
      "Epoch 605/4000\n",
      "25/25 - 0s - loss: 0.2072 - accuracy: 0.9001 - val_loss: 0.6209 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00605: val_loss did not improve from 0.41973\n",
      "Epoch 606/4000\n",
      "25/25 - 0s - loss: 0.2115 - accuracy: 0.8962 - val_loss: 0.6211 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00606: val_loss did not improve from 0.41973\n",
      "Epoch 607/4000\n",
      "25/25 - 0s - loss: 0.2055 - accuracy: 0.8975 - val_loss: 0.6171 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00607: val_loss did not improve from 0.41973\n",
      "Epoch 608/4000\n",
      "25/25 - 0s - loss: 0.2056 - accuracy: 0.9027 - val_loss: 0.6080 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00608: val_loss did not improve from 0.41973\n",
      "Epoch 609/4000\n",
      "25/25 - 0s - loss: 0.2094 - accuracy: 0.9001 - val_loss: 0.5778 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00609: val_loss did not improve from 0.41973\n",
      "Epoch 610/4000\n",
      "25/25 - 0s - loss: 0.2082 - accuracy: 0.9001 - val_loss: 0.5913 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00610: val_loss did not improve from 0.41973\n",
      "Epoch 611/4000\n",
      "25/25 - 0s - loss: 0.2060 - accuracy: 0.9014 - val_loss: 0.5843 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00611: val_loss did not improve from 0.41973\n",
      "Epoch 612/4000\n",
      "25/25 - 0s - loss: 0.2052 - accuracy: 0.9027 - val_loss: 0.5897 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00612: val_loss did not improve from 0.41973\n",
      "Epoch 613/4000\n",
      "25/25 - 0s - loss: 0.2066 - accuracy: 0.8936 - val_loss: 0.6017 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00613: val_loss did not improve from 0.41973\n",
      "Epoch 614/4000\n",
      "25/25 - 0s - loss: 0.2040 - accuracy: 0.9027 - val_loss: 0.6015 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00614: val_loss did not improve from 0.41973\n",
      "Epoch 615/4000\n",
      "25/25 - 0s - loss: 0.2034 - accuracy: 0.9027 - val_loss: 0.5991 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00615: val_loss did not improve from 0.41973\n",
      "Epoch 616/4000\n",
      "25/25 - 0s - loss: 0.2083 - accuracy: 0.9001 - val_loss: 0.5773 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00616: val_loss did not improve from 0.41973\n",
      "Epoch 617/4000\n",
      "25/25 - 0s - loss: 0.2038 - accuracy: 0.9001 - val_loss: 0.5824 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00617: val_loss did not improve from 0.41973\n",
      "Epoch 618/4000\n",
      "25/25 - 0s - loss: 0.2036 - accuracy: 0.8949 - val_loss: 0.5854 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00618: val_loss did not improve from 0.41973\n",
      "Epoch 619/4000\n",
      "25/25 - 0s - loss: 0.2038 - accuracy: 0.8949 - val_loss: 0.5900 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00619: val_loss did not improve from 0.41973\n",
      "Epoch 620/4000\n",
      "25/25 - 0s - loss: 0.2028 - accuracy: 0.8975 - val_loss: 0.6005 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00620: val_loss did not improve from 0.41973\n",
      "Epoch 621/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.8988 - val_loss: 0.6069 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00621: val_loss did not improve from 0.41973\n",
      "Epoch 622/4000\n",
      "25/25 - 0s - loss: 0.2035 - accuracy: 0.9001 - val_loss: 0.6096 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00622: val_loss did not improve from 0.41973\n",
      "Epoch 623/4000\n",
      "25/25 - 0s - loss: 0.2058 - accuracy: 0.9027 - val_loss: 0.6058 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00623: val_loss did not improve from 0.41973\n",
      "Epoch 624/4000\n",
      "25/25 - 0s - loss: 0.2058 - accuracy: 0.9001 - val_loss: 0.5956 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00624: val_loss did not improve from 0.41973\n",
      "Epoch 625/4000\n",
      "25/25 - 0s - loss: 0.2041 - accuracy: 0.9014 - val_loss: 0.5872 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00625: val_loss did not improve from 0.41973\n",
      "Epoch 626/4000\n",
      "25/25 - 0s - loss: 0.2037 - accuracy: 0.8988 - val_loss: 0.5825 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00626: val_loss did not improve from 0.41973\n",
      "Epoch 627/4000\n",
      "25/25 - 0s - loss: 0.2037 - accuracy: 0.9014 - val_loss: 0.5934 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00627: val_loss did not improve from 0.41973\n",
      "Epoch 628/4000\n",
      "25/25 - 0s - loss: 0.2054 - accuracy: 0.9066 - val_loss: 0.6053 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00628: val_loss did not improve from 0.41973\n",
      "Epoch 629/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.8988 - val_loss: 0.6175 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00629: val_loss did not improve from 0.41973\n",
      "Epoch 630/4000\n",
      "25/25 - 0s - loss: 0.2043 - accuracy: 0.8975 - val_loss: 0.6001 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00630: val_loss did not improve from 0.41973\n",
      "Epoch 631/4000\n",
      "25/25 - 0s - loss: 0.2043 - accuracy: 0.9001 - val_loss: 0.6009 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00631: val_loss did not improve from 0.41973\n",
      "Epoch 632/4000\n",
      "25/25 - 0s - loss: 0.2037 - accuracy: 0.9001 - val_loss: 0.6064 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00632: val_loss did not improve from 0.41973\n",
      "Epoch 633/4000\n",
      "25/25 - 0s - loss: 0.2076 - accuracy: 0.8923 - val_loss: 0.5964 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00633: val_loss did not improve from 0.41973\n",
      "Epoch 634/4000\n",
      "25/25 - 0s - loss: 0.2056 - accuracy: 0.9027 - val_loss: 0.5976 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00634: val_loss did not improve from 0.41973\n",
      "Epoch 635/4000\n",
      "25/25 - 0s - loss: 0.2034 - accuracy: 0.9001 - val_loss: 0.6149 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00635: val_loss did not improve from 0.41973\n",
      "Epoch 636/4000\n",
      "25/25 - 0s - loss: 0.2041 - accuracy: 0.9014 - val_loss: 0.6385 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00636: val_loss did not improve from 0.41973\n",
      "Epoch 637/4000\n",
      "25/25 - 0s - loss: 0.2058 - accuracy: 0.8975 - val_loss: 0.6052 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00637: val_loss did not improve from 0.41973\n",
      "Epoch 638/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.9001 - val_loss: 0.5944 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00638: val_loss did not improve from 0.41973\n",
      "Epoch 639/4000\n",
      "25/25 - 0s - loss: 0.2035 - accuracy: 0.9014 - val_loss: 0.6091 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00639: val_loss did not improve from 0.41973\n",
      "Epoch 640/4000\n",
      "25/25 - 0s - loss: 0.2026 - accuracy: 0.9001 - val_loss: 0.6229 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00640: val_loss did not improve from 0.41973\n",
      "Epoch 641/4000\n",
      "25/25 - 0s - loss: 0.2037 - accuracy: 0.8975 - val_loss: 0.6247 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00641: val_loss did not improve from 0.41973\n",
      "Epoch 642/4000\n",
      "25/25 - 0s - loss: 0.2040 - accuracy: 0.8988 - val_loss: 0.6072 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00642: val_loss did not improve from 0.41973\n",
      "Epoch 643/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9001 - val_loss: 0.6078 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00643: val_loss did not improve from 0.41973\n",
      "Epoch 644/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9027 - val_loss: 0.6294 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00644: val_loss did not improve from 0.41973\n",
      "Epoch 645/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.8988 - val_loss: 0.6186 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00645: val_loss did not improve from 0.41973\n",
      "Epoch 646/4000\n",
      "25/25 - 0s - loss: 0.2026 - accuracy: 0.8975 - val_loss: 0.6376 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00646: val_loss did not improve from 0.41973\n",
      "Epoch 647/4000\n",
      "25/25 - 0s - loss: 0.2026 - accuracy: 0.9001 - val_loss: 0.6157 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00647: val_loss did not improve from 0.41973\n",
      "Epoch 648/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.8988 - val_loss: 0.6391 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00648: val_loss did not improve from 0.41973\n",
      "Epoch 649/4000\n",
      "25/25 - 0s - loss: 0.2025 - accuracy: 0.8988 - val_loss: 0.6345 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00649: val_loss did not improve from 0.41973\n",
      "Epoch 650/4000\n",
      "25/25 - 0s - loss: 0.2048 - accuracy: 0.9014 - val_loss: 0.6154 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00650: val_loss did not improve from 0.41973\n",
      "Epoch 651/4000\n",
      "25/25 - 0s - loss: 0.2027 - accuracy: 0.9014 - val_loss: 0.6176 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00651: val_loss did not improve from 0.41973\n",
      "Epoch 652/4000\n",
      "25/25 - 0s - loss: 0.2062 - accuracy: 0.8936 - val_loss: 0.6089 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00652: val_loss did not improve from 0.41973\n",
      "Epoch 653/4000\n",
      "25/25 - 0s - loss: 0.2085 - accuracy: 0.8988 - val_loss: 0.5671 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00653: val_loss did not improve from 0.41973\n",
      "Epoch 654/4000\n",
      "25/25 - 0s - loss: 0.2064 - accuracy: 0.9001 - val_loss: 0.5943 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00654: val_loss did not improve from 0.41973\n",
      "Epoch 655/4000\n",
      "25/25 - 0s - loss: 0.2042 - accuracy: 0.8988 - val_loss: 0.6352 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00655: val_loss did not improve from 0.41973\n",
      "Epoch 656/4000\n",
      "25/25 - 0s - loss: 0.2043 - accuracy: 0.9001 - val_loss: 0.6293 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00656: val_loss did not improve from 0.41973\n",
      "Epoch 657/4000\n",
      "25/25 - 0s - loss: 0.2044 - accuracy: 0.9014 - val_loss: 0.6274 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00657: val_loss did not improve from 0.41973\n",
      "Epoch 658/4000\n",
      "25/25 - 0s - loss: 0.2070 - accuracy: 0.9014 - val_loss: 0.6273 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00658: val_loss did not improve from 0.41973\n",
      "Epoch 659/4000\n",
      "25/25 - 0s - loss: 0.2048 - accuracy: 0.9027 - val_loss: 0.6187 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00659: val_loss did not improve from 0.41973\n",
      "Epoch 660/4000\n",
      "25/25 - 0s - loss: 0.2050 - accuracy: 0.9014 - val_loss: 0.6300 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00660: val_loss did not improve from 0.41973\n",
      "Epoch 661/4000\n",
      "25/25 - 0s - loss: 0.2033 - accuracy: 0.8962 - val_loss: 0.6284 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00661: val_loss did not improve from 0.41973\n",
      "Epoch 662/4000\n",
      "25/25 - 0s - loss: 0.2032 - accuracy: 0.9014 - val_loss: 0.6274 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00662: val_loss did not improve from 0.41973\n",
      "Epoch 663/4000\n",
      "25/25 - 0s - loss: 0.2033 - accuracy: 0.9027 - val_loss: 0.6323 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00663: val_loss did not improve from 0.41973\n",
      "Epoch 664/4000\n",
      "25/25 - 0s - loss: 0.2025 - accuracy: 0.8975 - val_loss: 0.6468 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00664: val_loss did not improve from 0.41973\n",
      "Epoch 665/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.9027 - val_loss: 0.6438 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00665: val_loss did not improve from 0.41973\n",
      "Epoch 666/4000\n",
      "25/25 - 0s - loss: 0.2025 - accuracy: 0.9001 - val_loss: 0.6265 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00666: val_loss did not improve from 0.41973\n",
      "Epoch 667/4000\n",
      "25/25 - 0s - loss: 0.2047 - accuracy: 0.9027 - val_loss: 0.6203 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00667: val_loss did not improve from 0.41973\n",
      "Epoch 668/4000\n",
      "25/25 - 0s - loss: 0.2048 - accuracy: 0.9027 - val_loss: 0.6410 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00668: val_loss did not improve from 0.41973\n",
      "Epoch 669/4000\n",
      "25/25 - 0s - loss: 0.2033 - accuracy: 0.9014 - val_loss: 0.6416 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00669: val_loss did not improve from 0.41973\n",
      "Epoch 670/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.9001 - val_loss: 0.6171 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00670: val_loss did not improve from 0.41973\n",
      "Epoch 671/4000\n",
      "25/25 - 0s - loss: 0.2085 - accuracy: 0.9027 - val_loss: 0.6333 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00671: val_loss did not improve from 0.41973\n",
      "Epoch 672/4000\n",
      "25/25 - 0s - loss: 0.2042 - accuracy: 0.9001 - val_loss: 0.6704 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00672: val_loss did not improve from 0.41973\n",
      "Epoch 673/4000\n",
      "25/25 - 0s - loss: 0.2058 - accuracy: 0.8988 - val_loss: 0.6434 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00673: val_loss did not improve from 0.41973\n",
      "Epoch 674/4000\n",
      "25/25 - 0s - loss: 0.2051 - accuracy: 0.9014 - val_loss: 0.6346 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00674: val_loss did not improve from 0.41973\n",
      "Epoch 675/4000\n",
      "25/25 - 0s - loss: 0.2074 - accuracy: 0.9014 - val_loss: 0.6416 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00675: val_loss did not improve from 0.41973\n",
      "Epoch 676/4000\n",
      "25/25 - 0s - loss: 0.2039 - accuracy: 0.9014 - val_loss: 0.6555 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00676: val_loss did not improve from 0.41973\n",
      "Epoch 677/4000\n",
      "25/25 - 0s - loss: 0.2037 - accuracy: 0.9001 - val_loss: 0.6523 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00677: val_loss did not improve from 0.41973\n",
      "Epoch 678/4000\n",
      "25/25 - 0s - loss: 0.2035 - accuracy: 0.8988 - val_loss: 0.6572 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00678: val_loss did not improve from 0.41973\n",
      "Epoch 679/4000\n",
      "25/25 - 0s - loss: 0.2037 - accuracy: 0.8988 - val_loss: 0.6610 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00679: val_loss did not improve from 0.41973\n",
      "Epoch 680/4000\n",
      "25/25 - 0s - loss: 0.2027 - accuracy: 0.9014 - val_loss: 0.6579 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00680: val_loss did not improve from 0.41973\n",
      "Epoch 681/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.9027 - val_loss: 0.6656 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00681: val_loss did not improve from 0.41973\n",
      "Epoch 682/4000\n",
      "25/25 - 0s - loss: 0.2033 - accuracy: 0.9014 - val_loss: 0.6526 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00682: val_loss did not improve from 0.41973\n",
      "Epoch 683/4000\n",
      "25/25 - 0s - loss: 0.2064 - accuracy: 0.8988 - val_loss: 0.6142 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00683: val_loss did not improve from 0.41973\n",
      "Epoch 684/4000\n",
      "25/25 - 0s - loss: 0.2070 - accuracy: 0.9014 - val_loss: 0.5933 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00684: val_loss did not improve from 0.41973\n",
      "Epoch 685/4000\n",
      "25/25 - 0s - loss: 0.2032 - accuracy: 0.8936 - val_loss: 0.6130 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00685: val_loss did not improve from 0.41973\n",
      "Epoch 686/4000\n",
      "25/25 - 0s - loss: 0.2036 - accuracy: 0.8975 - val_loss: 0.6272 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00686: val_loss did not improve from 0.41973\n",
      "Epoch 687/4000\n",
      "25/25 - 0s - loss: 0.2036 - accuracy: 0.8975 - val_loss: 0.6256 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00687: val_loss did not improve from 0.41973\n",
      "Epoch 688/4000\n",
      "25/25 - 0s - loss: 0.2032 - accuracy: 0.8988 - val_loss: 0.6495 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00688: val_loss did not improve from 0.41973\n",
      "Epoch 689/4000\n",
      "25/25 - 0s - loss: 0.2042 - accuracy: 0.8988 - val_loss: 0.6437 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00689: val_loss did not improve from 0.41973\n",
      "Epoch 690/4000\n",
      "25/25 - 0s - loss: 0.2035 - accuracy: 0.8975 - val_loss: 0.6539 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00690: val_loss did not improve from 0.41973\n",
      "Epoch 691/4000\n",
      "25/25 - 0s - loss: 0.2032 - accuracy: 0.8988 - val_loss: 0.6382 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00691: val_loss did not improve from 0.41973\n",
      "Epoch 692/4000\n",
      "25/25 - 0s - loss: 0.2034 - accuracy: 0.9014 - val_loss: 0.6347 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00692: val_loss did not improve from 0.41973\n",
      "Epoch 693/4000\n",
      "25/25 - 0s - loss: 0.2031 - accuracy: 0.9014 - val_loss: 0.6474 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00693: val_loss did not improve from 0.41973\n",
      "Epoch 694/4000\n",
      "25/25 - 0s - loss: 0.2027 - accuracy: 0.9040 - val_loss: 0.6444 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00694: val_loss did not improve from 0.41973\n",
      "Epoch 695/4000\n",
      "25/25 - 0s - loss: 0.2028 - accuracy: 0.9001 - val_loss: 0.6556 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00695: val_loss did not improve from 0.41973\n",
      "Epoch 696/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.8988 - val_loss: 0.6706 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00696: val_loss did not improve from 0.41973\n",
      "Epoch 697/4000\n",
      "25/25 - 0s - loss: 0.2034 - accuracy: 0.8962 - val_loss: 0.6669 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00697: val_loss did not improve from 0.41973\n",
      "Epoch 698/4000\n",
      "25/25 - 0s - loss: 0.2035 - accuracy: 0.9014 - val_loss: 0.6485 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00698: val_loss did not improve from 0.41973\n",
      "Epoch 699/4000\n",
      "25/25 - 0s - loss: 0.2039 - accuracy: 0.9027 - val_loss: 0.6781 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00699: val_loss did not improve from 0.41973\n",
      "Epoch 700/4000\n",
      "25/25 - 0s - loss: 0.2027 - accuracy: 0.8988 - val_loss: 0.7202 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00700: val_loss did not improve from 0.41973\n",
      "Epoch 701/4000\n",
      "25/25 - 0s - loss: 0.2037 - accuracy: 0.9001 - val_loss: 0.7175 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00701: val_loss did not improve from 0.41973\n",
      "Epoch 702/4000\n",
      "25/25 - 0s - loss: 0.2032 - accuracy: 0.9014 - val_loss: 0.6733 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00702: val_loss did not improve from 0.41973\n",
      "Epoch 703/4000\n",
      "25/25 - 0s - loss: 0.2036 - accuracy: 0.8988 - val_loss: 0.6784 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00703: val_loss did not improve from 0.41973\n",
      "Epoch 704/4000\n",
      "25/25 - 0s - loss: 0.2025 - accuracy: 0.9014 - val_loss: 0.6755 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00704: val_loss did not improve from 0.41973\n",
      "Epoch 705/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.9014 - val_loss: 0.6688 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00705: val_loss did not improve from 0.41973\n",
      "Epoch 706/4000\n",
      "25/25 - 0s - loss: 0.2045 - accuracy: 0.8988 - val_loss: 0.6654 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00706: val_loss did not improve from 0.41973\n",
      "Epoch 707/4000\n",
      "25/25 - 0s - loss: 0.2055 - accuracy: 0.9014 - val_loss: 0.6560 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00707: val_loss did not improve from 0.41973\n",
      "Epoch 708/4000\n",
      "25/25 - 0s - loss: 0.2033 - accuracy: 0.9027 - val_loss: 0.6698 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00708: val_loss did not improve from 0.41973\n",
      "Epoch 709/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.8936 - val_loss: 0.6838 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00709: val_loss did not improve from 0.41973\n",
      "Epoch 710/4000\n",
      "25/25 - 0s - loss: 0.2031 - accuracy: 0.9027 - val_loss: 0.6790 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00710: val_loss did not improve from 0.41973\n",
      "Epoch 711/4000\n",
      "25/25 - 0s - loss: 0.2033 - accuracy: 0.9001 - val_loss: 0.6751 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00711: val_loss did not improve from 0.41973\n",
      "Epoch 712/4000\n",
      "25/25 - 0s - loss: 0.2059 - accuracy: 0.9014 - val_loss: 0.6786 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00712: val_loss did not improve from 0.41973\n",
      "Epoch 713/4000\n",
      "25/25 - 0s - loss: 0.2044 - accuracy: 0.9014 - val_loss: 0.6363 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00713: val_loss did not improve from 0.41973\n",
      "Epoch 714/4000\n",
      "25/25 - 0s - loss: 0.2070 - accuracy: 0.9001 - val_loss: 0.6037 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00714: val_loss did not improve from 0.41973\n",
      "Epoch 715/4000\n",
      "25/25 - 0s - loss: 0.2038 - accuracy: 0.9014 - val_loss: 0.6016 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00715: val_loss did not improve from 0.41973\n",
      "Epoch 716/4000\n",
      "25/25 - 0s - loss: 0.2053 - accuracy: 0.9014 - val_loss: 0.6200 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00716: val_loss did not improve from 0.41973\n",
      "Epoch 717/4000\n",
      "25/25 - 0s - loss: 0.2035 - accuracy: 0.8975 - val_loss: 0.6319 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00717: val_loss did not improve from 0.41973\n",
      "Epoch 718/4000\n",
      "25/25 - 0s - loss: 0.2036 - accuracy: 0.9027 - val_loss: 0.6417 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00718: val_loss did not improve from 0.41973\n",
      "Epoch 719/4000\n",
      "25/25 - 0s - loss: 0.2054 - accuracy: 0.9001 - val_loss: 0.7069 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00719: val_loss did not improve from 0.41973\n",
      "Epoch 720/4000\n",
      "25/25 - 0s - loss: 0.2107 - accuracy: 0.9001 - val_loss: 0.5827 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00720: val_loss did not improve from 0.41973\n",
      "Epoch 721/4000\n",
      "25/25 - 0s - loss: 0.2092 - accuracy: 0.8962 - val_loss: 0.6698 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00721: val_loss did not improve from 0.41973\n",
      "Epoch 722/4000\n",
      "25/25 - 0s - loss: 0.2060 - accuracy: 0.9027 - val_loss: 0.7034 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00722: val_loss did not improve from 0.41973\n",
      "Epoch 723/4000\n",
      "25/25 - 0s - loss: 0.2049 - accuracy: 0.9001 - val_loss: 0.6953 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00723: val_loss did not improve from 0.41973\n",
      "Epoch 724/4000\n",
      "25/25 - 0s - loss: 0.2097 - accuracy: 0.8988 - val_loss: 0.6472 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00724: val_loss did not improve from 0.41973\n",
      "Epoch 725/4000\n",
      "25/25 - 0s - loss: 0.2045 - accuracy: 0.8988 - val_loss: 0.6852 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00725: val_loss did not improve from 0.41973\n",
      "Epoch 726/4000\n",
      "25/25 - 0s - loss: 0.2029 - accuracy: 0.9027 - val_loss: 0.6488 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00726: val_loss did not improve from 0.41973\n",
      "Epoch 727/4000\n",
      "25/25 - 0s - loss: 0.2031 - accuracy: 0.9014 - val_loss: 0.6446 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00727: val_loss did not improve from 0.41973\n",
      "Epoch 728/4000\n",
      "25/25 - 0s - loss: 0.2026 - accuracy: 0.8962 - val_loss: 0.6580 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00728: val_loss did not improve from 0.41973\n",
      "Epoch 729/4000\n",
      "25/25 - 0s - loss: 0.2038 - accuracy: 0.9001 - val_loss: 0.6672 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00729: val_loss did not improve from 0.41973\n",
      "Epoch 730/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.8988 - val_loss: 0.6337 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00730: val_loss did not improve from 0.41973\n",
      "Epoch 731/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.8988 - val_loss: 0.6415 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00731: val_loss did not improve from 0.41973\n",
      "Epoch 732/4000\n",
      "25/25 - 0s - loss: 0.2035 - accuracy: 0.8988 - val_loss: 0.6402 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00732: val_loss did not improve from 0.41973\n",
      "Epoch 733/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.8962 - val_loss: 0.6378 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00733: val_loss did not improve from 0.41973\n",
      "Epoch 734/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.8975 - val_loss: 0.6378 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00734: val_loss did not improve from 0.41973\n",
      "Epoch 735/4000\n",
      "25/25 - 0s - loss: 0.2025 - accuracy: 0.9027 - val_loss: 0.6392 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00735: val_loss did not improve from 0.41973\n",
      "Epoch 736/4000\n",
      "25/25 - 0s - loss: 0.2037 - accuracy: 0.9001 - val_loss: 0.6453 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00736: val_loss did not improve from 0.41973\n",
      "Epoch 737/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.9027 - val_loss: 0.6384 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00737: val_loss did not improve from 0.41973\n",
      "Epoch 738/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.9027 - val_loss: 0.6209 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00738: val_loss did not improve from 0.41973\n",
      "Epoch 739/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.8962 - val_loss: 0.6192 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00739: val_loss did not improve from 0.41973\n",
      "Epoch 740/4000\n",
      "25/25 - 0s - loss: 0.2029 - accuracy: 0.8988 - val_loss: 0.6246 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00740: val_loss did not improve from 0.41973\n",
      "Epoch 741/4000\n",
      "25/25 - 0s - loss: 0.2059 - accuracy: 0.8962 - val_loss: 0.6444 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00741: val_loss did not improve from 0.41973\n",
      "Epoch 742/4000\n",
      "25/25 - 0s - loss: 0.2031 - accuracy: 0.9001 - val_loss: 0.6296 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00742: val_loss did not improve from 0.41973\n",
      "Epoch 743/4000\n",
      "25/25 - 0s - loss: 0.2068 - accuracy: 0.8975 - val_loss: 0.6490 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00743: val_loss did not improve from 0.41973\n",
      "Epoch 744/4000\n",
      "25/25 - 0s - loss: 0.2063 - accuracy: 0.8988 - val_loss: 0.6525 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00744: val_loss did not improve from 0.41973\n",
      "Epoch 745/4000\n",
      "25/25 - 0s - loss: 0.2029 - accuracy: 0.9014 - val_loss: 0.6546 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00745: val_loss did not improve from 0.41973\n",
      "Epoch 746/4000\n",
      "25/25 - 0s - loss: 0.2027 - accuracy: 0.9027 - val_loss: 0.6565 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00746: val_loss did not improve from 0.41973\n",
      "Epoch 747/4000\n",
      "25/25 - 0s - loss: 0.2031 - accuracy: 0.9001 - val_loss: 0.6577 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00747: val_loss did not improve from 0.41973\n",
      "Epoch 748/4000\n",
      "25/25 - 0s - loss: 0.2050 - accuracy: 0.9014 - val_loss: 0.6761 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00748: val_loss did not improve from 0.41973\n",
      "Epoch 749/4000\n",
      "25/25 - 0s - loss: 0.2043 - accuracy: 0.9014 - val_loss: 0.6752 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00749: val_loss did not improve from 0.41973\n",
      "Epoch 750/4000\n",
      "25/25 - 0s - loss: 0.2025 - accuracy: 0.8988 - val_loss: 0.6708 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00750: val_loss did not improve from 0.41973\n",
      "Epoch 751/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.9027 - val_loss: 0.6765 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00751: val_loss did not improve from 0.41973\n",
      "Epoch 752/4000\n",
      "25/25 - 0s - loss: 0.2029 - accuracy: 0.8988 - val_loss: 0.6818 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00752: val_loss did not improve from 0.41973\n",
      "Epoch 753/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.9014 - val_loss: 0.6790 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00753: val_loss did not improve from 0.41973\n",
      "Epoch 754/4000\n",
      "25/25 - 0s - loss: 0.2036 - accuracy: 0.8988 - val_loss: 0.6714 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00754: val_loss did not improve from 0.41973\n",
      "Epoch 755/4000\n",
      "25/25 - 0s - loss: 0.2035 - accuracy: 0.8988 - val_loss: 0.6875 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00755: val_loss did not improve from 0.41973\n",
      "Epoch 756/4000\n",
      "25/25 - 0s - loss: 0.2031 - accuracy: 0.9027 - val_loss: 0.6749 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00756: val_loss did not improve from 0.41973\n",
      "Epoch 757/4000\n",
      "25/25 - 0s - loss: 0.2038 - accuracy: 0.8923 - val_loss: 0.6789 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00757: val_loss did not improve from 0.41973\n",
      "Epoch 758/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9001 - val_loss: 0.6767 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00758: val_loss did not improve from 0.41973\n",
      "Epoch 759/4000\n",
      "25/25 - 0s - loss: 0.2033 - accuracy: 0.8975 - val_loss: 0.6822 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00759: val_loss did not improve from 0.41973\n",
      "Epoch 760/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.8949 - val_loss: 0.6868 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00760: val_loss did not improve from 0.41973\n",
      "Epoch 761/4000\n",
      "25/25 - 0s - loss: 0.2028 - accuracy: 0.9014 - val_loss: 0.6838 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00761: val_loss did not improve from 0.41973\n",
      "Epoch 762/4000\n",
      "25/25 - 0s - loss: 0.2035 - accuracy: 0.9014 - val_loss: 0.6514 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00762: val_loss did not improve from 0.41973\n",
      "Epoch 763/4000\n",
      "25/25 - 0s - loss: 0.2034 - accuracy: 0.9014 - val_loss: 0.6131 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00763: val_loss did not improve from 0.41973\n",
      "Epoch 764/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.8988 - val_loss: 0.6283 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00764: val_loss did not improve from 0.41973\n",
      "Epoch 765/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.8962 - val_loss: 0.6378 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00765: val_loss did not improve from 0.41973\n",
      "Epoch 766/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.9014 - val_loss: 0.6558 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00766: val_loss did not improve from 0.41973\n",
      "Epoch 767/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.8975 - val_loss: 0.6738 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00767: val_loss did not improve from 0.41973\n",
      "Epoch 768/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.8975 - val_loss: 0.6700 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00768: val_loss did not improve from 0.41973\n",
      "Epoch 769/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.8988 - val_loss: 0.6679 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00769: val_loss did not improve from 0.41973\n",
      "Epoch 770/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9001 - val_loss: 0.6616 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00770: val_loss did not improve from 0.41973\n",
      "Epoch 771/4000\n",
      "25/25 - 0s - loss: 0.2026 - accuracy: 0.9027 - val_loss: 0.6595 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00771: val_loss did not improve from 0.41973\n",
      "Epoch 772/4000\n",
      "25/25 - 0s - loss: 0.2029 - accuracy: 0.8988 - val_loss: 0.6827 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00772: val_loss did not improve from 0.41973\n",
      "Epoch 773/4000\n",
      "25/25 - 0s - loss: 0.2025 - accuracy: 0.8988 - val_loss: 0.6795 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00773: val_loss did not improve from 0.41973\n",
      "Epoch 774/4000\n",
      "25/25 - 0s - loss: 0.2029 - accuracy: 0.9014 - val_loss: 0.6826 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00774: val_loss did not improve from 0.41973\n",
      "Epoch 775/4000\n",
      "25/25 - 0s - loss: 0.2027 - accuracy: 0.9027 - val_loss: 0.6838 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00775: val_loss did not improve from 0.41973\n",
      "Epoch 776/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.8962 - val_loss: 0.6791 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00776: val_loss did not improve from 0.41973\n",
      "Epoch 777/4000\n",
      "25/25 - 0s - loss: 0.2033 - accuracy: 0.8988 - val_loss: 0.6679 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00777: val_loss did not improve from 0.41973\n",
      "Epoch 778/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.9014 - val_loss: 0.7078 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00778: val_loss did not improve from 0.41973\n",
      "Epoch 779/4000\n",
      "25/25 - 0s - loss: 0.2033 - accuracy: 0.9001 - val_loss: 0.6913 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00779: val_loss did not improve from 0.41973\n",
      "Epoch 780/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.8949 - val_loss: 0.6994 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00780: val_loss did not improve from 0.41973\n",
      "Epoch 781/4000\n",
      "25/25 - 0s - loss: 0.2040 - accuracy: 0.9001 - val_loss: 0.7023 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00781: val_loss did not improve from 0.41973\n",
      "Epoch 782/4000\n",
      "25/25 - 0s - loss: 0.2032 - accuracy: 0.9027 - val_loss: 0.6932 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00782: val_loss did not improve from 0.41973\n",
      "Epoch 783/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.8962 - val_loss: 0.6670 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00783: val_loss did not improve from 0.41973\n",
      "Epoch 784/4000\n",
      "25/25 - 0s - loss: 0.2026 - accuracy: 0.9001 - val_loss: 0.6680 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00784: val_loss did not improve from 0.41973\n",
      "Epoch 785/4000\n",
      "25/25 - 0s - loss: 0.2032 - accuracy: 0.8988 - val_loss: 0.6798 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00785: val_loss did not improve from 0.41973\n",
      "Epoch 786/4000\n",
      "25/25 - 0s - loss: 0.2031 - accuracy: 0.8975 - val_loss: 0.6804 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00786: val_loss did not improve from 0.41973\n",
      "Epoch 787/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.9027 - val_loss: 0.7020 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00787: val_loss did not improve from 0.41973\n",
      "Epoch 788/4000\n",
      "25/25 - 0s - loss: 0.2028 - accuracy: 0.9027 - val_loss: 0.6924 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00788: val_loss did not improve from 0.41973\n",
      "Epoch 789/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9027 - val_loss: 0.6732 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00789: val_loss did not improve from 0.41973\n",
      "Epoch 790/4000\n",
      "25/25 - 0s - loss: 0.2036 - accuracy: 0.9027 - val_loss: 0.6931 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00790: val_loss did not improve from 0.41973\n",
      "Epoch 791/4000\n",
      "25/25 - 0s - loss: 0.2060 - accuracy: 0.9014 - val_loss: 0.6644 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00791: val_loss did not improve from 0.41973\n",
      "Epoch 792/4000\n",
      "25/25 - 0s - loss: 0.2036 - accuracy: 0.9001 - val_loss: 0.6645 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00792: val_loss did not improve from 0.41973\n",
      "Epoch 793/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.9001 - val_loss: 0.6413 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00793: val_loss did not improve from 0.41973\n",
      "Epoch 794/4000\n",
      "25/25 - 0s - loss: 0.2042 - accuracy: 0.9001 - val_loss: 0.6372 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00794: val_loss did not improve from 0.41973\n",
      "Epoch 795/4000\n",
      "25/25 - 0s - loss: 0.2026 - accuracy: 0.9027 - val_loss: 0.6448 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00795: val_loss did not improve from 0.41973\n",
      "Epoch 796/4000\n",
      "25/25 - 0s - loss: 0.2029 - accuracy: 0.9040 - val_loss: 0.6513 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00796: val_loss did not improve from 0.41973\n",
      "Epoch 797/4000\n",
      "25/25 - 0s - loss: 0.2026 - accuracy: 0.9001 - val_loss: 0.6534 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00797: val_loss did not improve from 0.41973\n",
      "Epoch 798/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9001 - val_loss: 0.6569 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00798: val_loss did not improve from 0.41973\n",
      "Epoch 799/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.8975 - val_loss: 0.6750 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00799: val_loss did not improve from 0.41973\n",
      "Epoch 800/4000\n",
      "25/25 - 0s - loss: 0.2025 - accuracy: 0.9001 - val_loss: 0.7014 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00800: val_loss did not improve from 0.41973\n",
      "Epoch 801/4000\n",
      "25/25 - 0s - loss: 0.2036 - accuracy: 0.9027 - val_loss: 0.7168 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00801: val_loss did not improve from 0.41973\n",
      "Epoch 802/4000\n",
      "25/25 - 0s - loss: 0.2029 - accuracy: 0.9027 - val_loss: 0.7075 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00802: val_loss did not improve from 0.41973\n",
      "Epoch 803/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.9001 - val_loss: 0.6741 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00803: val_loss did not improve from 0.41973\n",
      "Epoch 804/4000\n",
      "25/25 - 0s - loss: 0.2108 - accuracy: 0.9001 - val_loss: 0.6833 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00804: val_loss did not improve from 0.41973\n",
      "Epoch 805/4000\n",
      "25/25 - 0s - loss: 0.2154 - accuracy: 0.8988 - val_loss: 0.5216 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00805: val_loss did not improve from 0.41973\n",
      "Epoch 806/4000\n",
      "25/25 - 0s - loss: 0.2063 - accuracy: 0.8988 - val_loss: 0.5611 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00806: val_loss did not improve from 0.41973\n",
      "Epoch 807/4000\n",
      "25/25 - 0s - loss: 0.2047 - accuracy: 0.9001 - val_loss: 0.5927 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00807: val_loss did not improve from 0.41973\n",
      "Epoch 808/4000\n",
      "25/25 - 0s - loss: 0.2031 - accuracy: 0.8988 - val_loss: 0.6050 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00808: val_loss did not improve from 0.41973\n",
      "Epoch 809/4000\n",
      "25/25 - 0s - loss: 0.2038 - accuracy: 0.9001 - val_loss: 0.6350 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00809: val_loss did not improve from 0.41973\n",
      "Epoch 810/4000\n",
      "25/25 - 0s - loss: 0.2048 - accuracy: 0.9001 - val_loss: 0.6195 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00810: val_loss did not improve from 0.41973\n",
      "Epoch 811/4000\n",
      "25/25 - 0s - loss: 0.2152 - accuracy: 0.8988 - val_loss: 0.6207 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00811: val_loss did not improve from 0.41973\n",
      "Epoch 812/4000\n",
      "25/25 - 0s - loss: 0.2099 - accuracy: 0.9001 - val_loss: 0.5911 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00812: val_loss did not improve from 0.41973\n",
      "Epoch 813/4000\n",
      "25/25 - 0s - loss: 0.2061 - accuracy: 0.8975 - val_loss: 0.5773 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00813: val_loss did not improve from 0.41973\n",
      "Epoch 814/4000\n",
      "25/25 - 0s - loss: 0.2035 - accuracy: 0.9014 - val_loss: 0.6004 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00814: val_loss did not improve from 0.41973\n",
      "Epoch 815/4000\n",
      "25/25 - 0s - loss: 0.2025 - accuracy: 0.9014 - val_loss: 0.5551 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00815: val_loss did not improve from 0.41973\n",
      "Epoch 816/4000\n",
      "25/25 - 0s - loss: 0.2046 - accuracy: 0.8988 - val_loss: 0.5827 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00816: val_loss did not improve from 0.41973\n",
      "Epoch 817/4000\n",
      "25/25 - 0s - loss: 0.2031 - accuracy: 0.9001 - val_loss: 0.5874 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00817: val_loss did not improve from 0.41973\n",
      "Epoch 818/4000\n",
      "25/25 - 0s - loss: 0.2027 - accuracy: 0.9027 - val_loss: 0.5838 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00818: val_loss did not improve from 0.41973\n",
      "Epoch 819/4000\n",
      "25/25 - 0s - loss: 0.2025 - accuracy: 0.9014 - val_loss: 0.6173 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00819: val_loss did not improve from 0.41973\n",
      "Epoch 820/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9027 - val_loss: 0.6203 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00820: val_loss did not improve from 0.41973\n",
      "Epoch 821/4000\n",
      "25/25 - 0s - loss: 0.2036 - accuracy: 0.9053 - val_loss: 0.6352 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00821: val_loss did not improve from 0.41973\n",
      "Epoch 822/4000\n",
      "25/25 - 0s - loss: 0.2047 - accuracy: 0.8975 - val_loss: 0.6293 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00822: val_loss did not improve from 0.41973\n",
      "Epoch 823/4000\n",
      "25/25 - 0s - loss: 0.2047 - accuracy: 0.9014 - val_loss: 0.6281 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00823: val_loss did not improve from 0.41973\n",
      "Epoch 824/4000\n",
      "25/25 - 0s - loss: 0.2029 - accuracy: 0.9001 - val_loss: 0.6376 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00824: val_loss did not improve from 0.41973\n",
      "Epoch 825/4000\n",
      "25/25 - 0s - loss: 0.2026 - accuracy: 0.8962 - val_loss: 0.6142 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00825: val_loss did not improve from 0.41973\n",
      "Epoch 826/4000\n",
      "25/25 - 0s - loss: 0.2029 - accuracy: 0.9014 - val_loss: 0.6191 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00826: val_loss did not improve from 0.41973\n",
      "Epoch 827/4000\n",
      "25/25 - 0s - loss: 0.2031 - accuracy: 0.8988 - val_loss: 0.6334 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00827: val_loss did not improve from 0.41973\n",
      "Epoch 828/4000\n",
      "25/25 - 0s - loss: 0.2089 - accuracy: 0.8975 - val_loss: 0.6065 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00828: val_loss did not improve from 0.41973\n",
      "Epoch 829/4000\n",
      "25/25 - 0s - loss: 0.2070 - accuracy: 0.9027 - val_loss: 0.5958 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00829: val_loss did not improve from 0.41973\n",
      "Epoch 830/4000\n",
      "25/25 - 0s - loss: 0.2059 - accuracy: 0.9027 - val_loss: 0.6351 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00830: val_loss did not improve from 0.41973\n",
      "Epoch 831/4000\n",
      "25/25 - 0s - loss: 0.2046 - accuracy: 0.8975 - val_loss: 0.7066 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00831: val_loss did not improve from 0.41973\n",
      "Epoch 832/4000\n",
      "25/25 - 0s - loss: 0.2055 - accuracy: 0.8988 - val_loss: 0.6522 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00832: val_loss did not improve from 0.41973\n",
      "Epoch 833/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.9001 - val_loss: 0.6416 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00833: val_loss did not improve from 0.41973\n",
      "Epoch 834/4000\n",
      "25/25 - 0s - loss: 0.2029 - accuracy: 0.9027 - val_loss: 0.6421 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00834: val_loss did not improve from 0.41973\n",
      "Epoch 835/4000\n",
      "25/25 - 0s - loss: 0.2029 - accuracy: 0.8975 - val_loss: 0.6537 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00835: val_loss did not improve from 0.41973\n",
      "Epoch 836/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.9027 - val_loss: 0.6498 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00836: val_loss did not improve from 0.41973\n",
      "Epoch 837/4000\n",
      "25/25 - 0s - loss: 0.2025 - accuracy: 0.9014 - val_loss: 0.6556 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00837: val_loss did not improve from 0.41973\n",
      "Epoch 838/4000\n",
      "25/25 - 0s - loss: 0.2029 - accuracy: 0.9014 - val_loss: 0.6661 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00838: val_loss did not improve from 0.41973\n",
      "Epoch 839/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9027 - val_loss: 0.6613 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00839: val_loss did not improve from 0.41973\n",
      "Epoch 840/4000\n",
      "25/25 - 0s - loss: 0.2070 - accuracy: 0.9027 - val_loss: 0.6381 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00840: val_loss did not improve from 0.41973\n",
      "Epoch 841/4000\n",
      "25/25 - 0s - loss: 0.2048 - accuracy: 0.8975 - val_loss: 0.6904 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00841: val_loss did not improve from 0.41973\n",
      "Epoch 842/4000\n",
      "25/25 - 0s - loss: 0.2045 - accuracy: 0.9053 - val_loss: 0.6839 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00842: val_loss did not improve from 0.41973\n",
      "Epoch 843/4000\n",
      "25/25 - 0s - loss: 0.2049 - accuracy: 0.8988 - val_loss: 0.6665 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00843: val_loss did not improve from 0.41973\n",
      "Epoch 844/4000\n",
      "25/25 - 0s - loss: 0.2054 - accuracy: 0.8975 - val_loss: 0.6843 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00844: val_loss did not improve from 0.41973\n",
      "Epoch 845/4000\n",
      "25/25 - 0s - loss: 0.2057 - accuracy: 0.9001 - val_loss: 0.6728 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00845: val_loss did not improve from 0.41973\n",
      "Epoch 846/4000\n",
      "25/25 - 0s - loss: 0.2041 - accuracy: 0.9001 - val_loss: 0.6616 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00846: val_loss did not improve from 0.41973\n",
      "Epoch 847/4000\n",
      "25/25 - 0s - loss: 0.2047 - accuracy: 0.9001 - val_loss: 0.6361 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00847: val_loss did not improve from 0.41973\n",
      "Epoch 848/4000\n",
      "25/25 - 0s - loss: 0.2037 - accuracy: 0.8949 - val_loss: 0.6400 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00848: val_loss did not improve from 0.41973\n",
      "Epoch 849/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9001 - val_loss: 0.6550 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00849: val_loss did not improve from 0.41973\n",
      "Epoch 850/4000\n",
      "25/25 - 0s - loss: 0.2034 - accuracy: 0.9027 - val_loss: 0.6556 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00850: val_loss did not improve from 0.41973\n",
      "Epoch 851/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.9040 - val_loss: 0.6532 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00851: val_loss did not improve from 0.41973\n",
      "Epoch 852/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9027 - val_loss: 0.6553 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00852: val_loss did not improve from 0.41973\n",
      "Epoch 853/4000\n",
      "25/25 - 0s - loss: 0.2038 - accuracy: 0.8962 - val_loss: 0.6462 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00853: val_loss did not improve from 0.41973\n",
      "Epoch 854/4000\n",
      "25/25 - 0s - loss: 0.2039 - accuracy: 0.9001 - val_loss: 0.6423 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00854: val_loss did not improve from 0.41973\n",
      "Epoch 855/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.9014 - val_loss: 0.6465 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00855: val_loss did not improve from 0.41973\n",
      "Epoch 856/4000\n",
      "25/25 - 0s - loss: 0.2032 - accuracy: 0.8936 - val_loss: 0.6457 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00856: val_loss did not improve from 0.41973\n",
      "Epoch 857/4000\n",
      "25/25 - 0s - loss: 0.2042 - accuracy: 0.9014 - val_loss: 0.6612 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00857: val_loss did not improve from 0.41973\n",
      "Epoch 858/4000\n",
      "25/25 - 0s - loss: 0.2032 - accuracy: 0.9027 - val_loss: 0.6569 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00858: val_loss did not improve from 0.41973\n",
      "Epoch 859/4000\n",
      "25/25 - 0s - loss: 0.2028 - accuracy: 0.9014 - val_loss: 0.6625 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00859: val_loss did not improve from 0.41973\n",
      "Epoch 860/4000\n",
      "25/25 - 0s - loss: 0.2040 - accuracy: 0.8962 - val_loss: 0.6599 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00860: val_loss did not improve from 0.41973\n",
      "Epoch 861/4000\n",
      "25/25 - 0s - loss: 0.2035 - accuracy: 0.9014 - val_loss: 0.6689 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00861: val_loss did not improve from 0.41973\n",
      "Epoch 862/4000\n",
      "25/25 - 0s - loss: 0.2035 - accuracy: 0.8975 - val_loss: 0.6697 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00862: val_loss did not improve from 0.41973\n",
      "Epoch 863/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.9014 - val_loss: 0.6622 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00863: val_loss did not improve from 0.41973\n",
      "Epoch 864/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9027 - val_loss: 0.6796 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00864: val_loss did not improve from 0.41973\n",
      "Epoch 865/4000\n",
      "25/25 - 0s - loss: 0.2027 - accuracy: 0.9014 - val_loss: 0.6665 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00865: val_loss did not improve from 0.41973\n",
      "Epoch 866/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.8988 - val_loss: 0.6744 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00866: val_loss did not improve from 0.41973\n",
      "Epoch 867/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9001 - val_loss: 0.6672 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00867: val_loss did not improve from 0.41973\n",
      "Epoch 868/4000\n",
      "25/25 - 0s - loss: 0.2027 - accuracy: 0.8975 - val_loss: 0.6685 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00868: val_loss did not improve from 0.41973\n",
      "Epoch 869/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.8975 - val_loss: 0.6735 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00869: val_loss did not improve from 0.41973\n",
      "Epoch 870/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.8949 - val_loss: 0.6749 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00870: val_loss did not improve from 0.41973\n",
      "Epoch 871/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.8988 - val_loss: 0.6791 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00871: val_loss did not improve from 0.41973\n",
      "Epoch 872/4000\n",
      "25/25 - 0s - loss: 0.2028 - accuracy: 0.8923 - val_loss: 0.6800 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00872: val_loss did not improve from 0.41973\n",
      "Epoch 873/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.8949 - val_loss: 0.6752 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00873: val_loss did not improve from 0.41973\n",
      "Epoch 874/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.8962 - val_loss: 0.6779 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00874: val_loss did not improve from 0.41973\n",
      "Epoch 875/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.8988 - val_loss: 0.6773 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00875: val_loss did not improve from 0.41973\n",
      "Epoch 876/4000\n",
      "25/25 - 0s - loss: 0.2025 - accuracy: 0.8988 - val_loss: 0.6876 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00876: val_loss did not improve from 0.41973\n",
      "Epoch 877/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9001 - val_loss: 0.6810 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00877: val_loss did not improve from 0.41973\n",
      "Epoch 878/4000\n",
      "25/25 - 0s - loss: 0.2028 - accuracy: 0.8988 - val_loss: 0.6675 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00878: val_loss did not improve from 0.41973\n",
      "Epoch 879/4000\n",
      "25/25 - 0s - loss: 0.2047 - accuracy: 0.8962 - val_loss: 0.6533 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00879: val_loss did not improve from 0.41973\n",
      "Epoch 880/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.8962 - val_loss: 0.6501 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00880: val_loss did not improve from 0.41973\n",
      "Epoch 881/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.8975 - val_loss: 0.6391 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00881: val_loss did not improve from 0.41973\n",
      "Epoch 882/4000\n",
      "25/25 - 0s - loss: 0.2035 - accuracy: 0.9027 - val_loss: 0.6429 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00882: val_loss did not improve from 0.41973\n",
      "Epoch 883/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.8988 - val_loss: 0.6545 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00883: val_loss did not improve from 0.41973\n",
      "Epoch 884/4000\n",
      "25/25 - 0s - loss: 0.2032 - accuracy: 0.9014 - val_loss: 0.6544 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00884: val_loss did not improve from 0.41973\n",
      "Epoch 885/4000\n",
      "25/25 - 0s - loss: 0.2028 - accuracy: 0.9014 - val_loss: 0.6548 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00885: val_loss did not improve from 0.41973\n",
      "Epoch 886/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.9014 - val_loss: 0.6647 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00886: val_loss did not improve from 0.41973\n",
      "Epoch 887/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9001 - val_loss: 0.6427 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00887: val_loss did not improve from 0.41973\n",
      "Epoch 888/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.8988 - val_loss: 0.6629 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00888: val_loss did not improve from 0.41973\n",
      "Epoch 889/4000\n",
      "25/25 - 0s - loss: 0.2027 - accuracy: 0.8975 - val_loss: 0.6545 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00889: val_loss did not improve from 0.41973\n",
      "Epoch 890/4000\n",
      "25/25 - 0s - loss: 0.2034 - accuracy: 0.9014 - val_loss: 0.6577 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00890: val_loss did not improve from 0.41973\n",
      "Epoch 891/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9014 - val_loss: 0.6481 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00891: val_loss did not improve from 0.41973\n",
      "Epoch 892/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.8975 - val_loss: 0.6531 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00892: val_loss did not improve from 0.41973\n",
      "Epoch 893/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9001 - val_loss: 0.6684 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00893: val_loss did not improve from 0.41973\n",
      "Epoch 894/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.8988 - val_loss: 0.6770 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00894: val_loss did not improve from 0.41973\n",
      "Epoch 895/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.9001 - val_loss: 0.6591 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00895: val_loss did not improve from 0.41973\n",
      "Epoch 896/4000\n",
      "25/25 - 0s - loss: 0.2027 - accuracy: 0.9001 - val_loss: 0.6729 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00896: val_loss did not improve from 0.41973\n",
      "Epoch 897/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.8988 - val_loss: 0.6655 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00897: val_loss did not improve from 0.41973\n",
      "Epoch 898/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9014 - val_loss: 0.6742 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00898: val_loss did not improve from 0.41973\n",
      "Epoch 899/4000\n",
      "25/25 - 0s - loss: 0.2025 - accuracy: 0.9001 - val_loss: 0.6863 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00899: val_loss did not improve from 0.41973\n",
      "Epoch 900/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.9014 - val_loss: 0.7079 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00900: val_loss did not improve from 0.41973\n",
      "Epoch 901/4000\n",
      "25/25 - 0s - loss: 0.2031 - accuracy: 0.9027 - val_loss: 0.6902 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00901: val_loss did not improve from 0.41973\n",
      "Epoch 902/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9014 - val_loss: 0.6867 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00902: val_loss did not improve from 0.41973\n",
      "Epoch 903/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 0.6878 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00903: val_loss did not improve from 0.41973\n",
      "Epoch 904/4000\n",
      "25/25 - 0s - loss: 0.2026 - accuracy: 0.9027 - val_loss: 0.6963 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00904: val_loss did not improve from 0.41973\n",
      "Epoch 905/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9014 - val_loss: 0.6913 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00905: val_loss did not improve from 0.41973\n",
      "Epoch 906/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9001 - val_loss: 0.7018 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00906: val_loss did not improve from 0.41973\n",
      "Epoch 907/4000\n",
      "25/25 - 0s - loss: 0.2036 - accuracy: 0.9001 - val_loss: 0.6933 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00907: val_loss did not improve from 0.41973\n",
      "Epoch 908/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9027 - val_loss: 0.6989 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00908: val_loss did not improve from 0.41973\n",
      "Epoch 909/4000\n",
      "25/25 - 0s - loss: 0.2025 - accuracy: 0.8988 - val_loss: 0.6777 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00909: val_loss did not improve from 0.41973\n",
      "Epoch 910/4000\n",
      "25/25 - 0s - loss: 0.2028 - accuracy: 0.9014 - val_loss: 0.6636 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00910: val_loss did not improve from 0.41973\n",
      "Epoch 911/4000\n",
      "25/25 - 0s - loss: 0.2027 - accuracy: 0.8975 - val_loss: 0.6947 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00911: val_loss did not improve from 0.41973\n",
      "Epoch 912/4000\n",
      "25/25 - 0s - loss: 0.2053 - accuracy: 0.8988 - val_loss: 0.6850 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00912: val_loss did not improve from 0.41973\n",
      "Epoch 913/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9027 - val_loss: 0.6796 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00913: val_loss did not improve from 0.41973\n",
      "Epoch 914/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.8988 - val_loss: 0.6896 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00914: val_loss did not improve from 0.41973\n",
      "Epoch 915/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.8988 - val_loss: 0.6641 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00915: val_loss did not improve from 0.41973\n",
      "Epoch 916/4000\n",
      "25/25 - 0s - loss: 0.2026 - accuracy: 0.9001 - val_loss: 0.6563 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00916: val_loss did not improve from 0.41973\n",
      "Epoch 917/4000\n",
      "25/25 - 0s - loss: 0.2026 - accuracy: 0.8988 - val_loss: 0.6526 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00917: val_loss did not improve from 0.41973\n",
      "Epoch 918/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9027 - val_loss: 0.6586 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00918: val_loss did not improve from 0.41973\n",
      "Epoch 919/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.9027 - val_loss: 0.6680 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00919: val_loss did not improve from 0.41973\n",
      "Epoch 920/4000\n",
      "25/25 - 0s - loss: 0.2027 - accuracy: 0.9001 - val_loss: 0.6574 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00920: val_loss did not improve from 0.41973\n",
      "Epoch 921/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.8975 - val_loss: 0.6773 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00921: val_loss did not improve from 0.41973\n",
      "Epoch 922/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.8988 - val_loss: 0.6707 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00922: val_loss did not improve from 0.41973\n",
      "Epoch 923/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9001 - val_loss: 0.6582 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00923: val_loss did not improve from 0.41973\n",
      "Epoch 924/4000\n",
      "25/25 - 0s - loss: 0.2034 - accuracy: 0.9027 - val_loss: 0.6445 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00924: val_loss did not improve from 0.41973\n",
      "Epoch 925/4000\n",
      "25/25 - 0s - loss: 0.2063 - accuracy: 0.9001 - val_loss: 0.6370 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00925: val_loss did not improve from 0.41973\n",
      "Epoch 926/4000\n",
      "25/25 - 0s - loss: 0.2025 - accuracy: 0.9040 - val_loss: 0.6366 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00926: val_loss did not improve from 0.41973\n",
      "Epoch 927/4000\n",
      "25/25 - 0s - loss: 0.2076 - accuracy: 0.9027 - val_loss: 0.6831 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00927: val_loss did not improve from 0.41973\n",
      "Epoch 928/4000\n",
      "25/25 - 0s - loss: 0.2058 - accuracy: 0.9001 - val_loss: 0.7263 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00928: val_loss did not improve from 0.41973\n",
      "Epoch 929/4000\n",
      "25/25 - 0s - loss: 0.2037 - accuracy: 0.8975 - val_loss: 0.6471 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00929: val_loss did not improve from 0.41973\n",
      "Epoch 930/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.8936 - val_loss: 0.6836 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00930: val_loss did not improve from 0.41973\n",
      "Epoch 931/4000\n",
      "25/25 - 0s - loss: 0.2033 - accuracy: 0.9001 - val_loss: 0.6855 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00931: val_loss did not improve from 0.41973\n",
      "Epoch 932/4000\n",
      "25/25 - 0s - loss: 0.2025 - accuracy: 0.9014 - val_loss: 0.6976 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00932: val_loss did not improve from 0.41973\n",
      "Epoch 933/4000\n",
      "25/25 - 0s - loss: 0.2027 - accuracy: 0.8975 - val_loss: 0.6827 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00933: val_loss did not improve from 0.41973\n",
      "Epoch 934/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.8988 - val_loss: 0.6763 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00934: val_loss did not improve from 0.41973\n",
      "Epoch 935/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9001 - val_loss: 0.6897 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00935: val_loss did not improve from 0.41973\n",
      "Epoch 936/4000\n",
      "25/25 - 0s - loss: 0.2031 - accuracy: 0.8923 - val_loss: 0.7088 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00936: val_loss did not improve from 0.41973\n",
      "Epoch 937/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9040 - val_loss: 0.6851 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00937: val_loss did not improve from 0.41973\n",
      "Epoch 938/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.9001 - val_loss: 0.6854 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00938: val_loss did not improve from 0.41973\n",
      "Epoch 939/4000\n",
      "25/25 - 0s - loss: 0.2026 - accuracy: 0.8949 - val_loss: 0.6984 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00939: val_loss did not improve from 0.41973\n",
      "Epoch 940/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9014 - val_loss: 0.6885 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00940: val_loss did not improve from 0.41973\n",
      "Epoch 941/4000\n",
      "25/25 - 0s - loss: 0.2036 - accuracy: 0.9014 - val_loss: 0.6973 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00941: val_loss did not improve from 0.41973\n",
      "Epoch 942/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9027 - val_loss: 0.7121 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00942: val_loss did not improve from 0.41973\n",
      "Epoch 943/4000\n",
      "25/25 - 0s - loss: 0.2029 - accuracy: 0.9001 - val_loss: 0.7098 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00943: val_loss did not improve from 0.41973\n",
      "Epoch 944/4000\n",
      "25/25 - 0s - loss: 0.2036 - accuracy: 0.9040 - val_loss: 0.7247 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00944: val_loss did not improve from 0.41973\n",
      "Epoch 945/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.9014 - val_loss: 0.7142 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00945: val_loss did not improve from 0.41973\n",
      "Epoch 946/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9001 - val_loss: 0.7076 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00946: val_loss did not improve from 0.41973\n",
      "Epoch 947/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9027 - val_loss: 0.7150 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00947: val_loss did not improve from 0.41973\n",
      "Epoch 948/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.8988 - val_loss: 0.7223 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00948: val_loss did not improve from 0.41973\n",
      "Epoch 949/4000\n",
      "25/25 - 0s - loss: 0.2058 - accuracy: 0.9027 - val_loss: 0.7097 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00949: val_loss did not improve from 0.41973\n",
      "Epoch 950/4000\n",
      "25/25 - 0s - loss: 0.2040 - accuracy: 0.9001 - val_loss: 0.6827 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00950: val_loss did not improve from 0.41973\n",
      "Epoch 951/4000\n",
      "25/25 - 0s - loss: 0.2057 - accuracy: 0.9014 - val_loss: 0.6822 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00951: val_loss did not improve from 0.41973\n",
      "Epoch 952/4000\n",
      "25/25 - 0s - loss: 0.2033 - accuracy: 0.9014 - val_loss: 0.6948 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00952: val_loss did not improve from 0.41973\n",
      "Epoch 953/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.9027 - val_loss: 0.6946 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00953: val_loss did not improve from 0.41973\n",
      "Epoch 954/4000\n",
      "25/25 - 0s - loss: 0.2033 - accuracy: 0.9014 - val_loss: 0.6871 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00954: val_loss did not improve from 0.41973\n",
      "Epoch 955/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9027 - val_loss: 0.6817 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00955: val_loss did not improve from 0.41973\n",
      "Epoch 956/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9014 - val_loss: 0.7016 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00956: val_loss did not improve from 0.41973\n",
      "Epoch 957/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9001 - val_loss: 0.7100 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00957: val_loss did not improve from 0.41973\n",
      "Epoch 958/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.9001 - val_loss: 0.7243 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00958: val_loss did not improve from 0.41973\n",
      "Epoch 959/4000\n",
      "25/25 - 0s - loss: 0.2029 - accuracy: 0.9014 - val_loss: 0.7280 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00959: val_loss did not improve from 0.41973\n",
      "Epoch 960/4000\n",
      "25/25 - 0s - loss: 0.2062 - accuracy: 0.9027 - val_loss: 0.7347 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00960: val_loss did not improve from 0.41973\n",
      "Epoch 961/4000\n",
      "25/25 - 0s - loss: 0.2057 - accuracy: 0.9014 - val_loss: 0.7298 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00961: val_loss did not improve from 0.41973\n",
      "Epoch 962/4000\n",
      "25/25 - 0s - loss: 0.2045 - accuracy: 0.9027 - val_loss: 0.7088 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00962: val_loss did not improve from 0.41973\n",
      "Epoch 963/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.8988 - val_loss: 0.6944 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00963: val_loss did not improve from 0.41973\n",
      "Epoch 964/4000\n",
      "25/25 - 0s - loss: 0.2043 - accuracy: 0.9027 - val_loss: 0.7249 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00964: val_loss did not improve from 0.41973\n",
      "Epoch 965/4000\n",
      "25/25 - 0s - loss: 0.2046 - accuracy: 0.9040 - val_loss: 0.7441 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00965: val_loss did not improve from 0.41973\n",
      "Epoch 966/4000\n",
      "25/25 - 0s - loss: 0.2034 - accuracy: 0.9001 - val_loss: 0.7316 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00966: val_loss did not improve from 0.41973\n",
      "Epoch 967/4000\n",
      "25/25 - 0s - loss: 0.2027 - accuracy: 0.8988 - val_loss: 0.7373 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00967: val_loss did not improve from 0.41973\n",
      "Epoch 968/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.8962 - val_loss: 0.7450 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00968: val_loss did not improve from 0.41973\n",
      "Epoch 969/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9001 - val_loss: 0.7443 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00969: val_loss did not improve from 0.41973\n",
      "Epoch 970/4000\n",
      "25/25 - 0s - loss: 0.2027 - accuracy: 0.8975 - val_loss: 0.7569 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00970: val_loss did not improve from 0.41973\n",
      "Epoch 971/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9001 - val_loss: 0.7287 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00971: val_loss did not improve from 0.41973\n",
      "Epoch 972/4000\n",
      "25/25 - 0s - loss: 0.2026 - accuracy: 0.8975 - val_loss: 0.7473 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00972: val_loss did not improve from 0.41973\n",
      "Epoch 973/4000\n",
      "25/25 - 0s - loss: 0.2037 - accuracy: 0.8975 - val_loss: 0.7880 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00973: val_loss did not improve from 0.41973\n",
      "Epoch 974/4000\n",
      "25/25 - 0s - loss: 0.2033 - accuracy: 0.9014 - val_loss: 0.7604 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00974: val_loss did not improve from 0.41973\n",
      "Epoch 975/4000\n",
      "25/25 - 0s - loss: 0.2039 - accuracy: 0.9014 - val_loss: 0.7243 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00975: val_loss did not improve from 0.41973\n",
      "Epoch 976/4000\n",
      "25/25 - 0s - loss: 0.2039 - accuracy: 0.8988 - val_loss: 0.7124 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00976: val_loss did not improve from 0.41973\n",
      "Epoch 977/4000\n",
      "25/25 - 0s - loss: 0.2028 - accuracy: 0.9053 - val_loss: 0.7020 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00977: val_loss did not improve from 0.41973\n",
      "Epoch 978/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.8988 - val_loss: 0.7044 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00978: val_loss did not improve from 0.41973\n",
      "Epoch 979/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.8962 - val_loss: 0.7082 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00979: val_loss did not improve from 0.41973\n",
      "Epoch 980/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9014 - val_loss: 0.7139 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00980: val_loss did not improve from 0.41973\n",
      "Epoch 981/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.8988 - val_loss: 0.7210 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00981: val_loss did not improve from 0.41973\n",
      "Epoch 982/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9001 - val_loss: 0.7224 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00982: val_loss did not improve from 0.41973\n",
      "Epoch 983/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9014 - val_loss: 0.7328 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00983: val_loss did not improve from 0.41973\n",
      "Epoch 984/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.9027 - val_loss: 0.7313 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00984: val_loss did not improve from 0.41973\n",
      "Epoch 985/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.8988 - val_loss: 0.7258 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00985: val_loss did not improve from 0.41973\n",
      "Epoch 986/4000\n",
      "25/25 - 0s - loss: 0.2026 - accuracy: 0.9014 - val_loss: 0.6904 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00986: val_loss did not improve from 0.41973\n",
      "Epoch 987/4000\n",
      "25/25 - 0s - loss: 0.2026 - accuracy: 0.8988 - val_loss: 0.7012 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00987: val_loss did not improve from 0.41973\n",
      "Epoch 988/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 0.7103 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00988: val_loss did not improve from 0.41973\n",
      "Epoch 989/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9001 - val_loss: 0.7212 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00989: val_loss did not improve from 0.41973\n",
      "Epoch 990/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9001 - val_loss: 0.7191 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00990: val_loss did not improve from 0.41973\n",
      "Epoch 991/4000\n",
      "25/25 - 0s - loss: 0.2025 - accuracy: 0.8988 - val_loss: 0.7326 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00991: val_loss did not improve from 0.41973\n",
      "Epoch 992/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.9027 - val_loss: 0.7209 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00992: val_loss did not improve from 0.41973\n",
      "Epoch 993/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.8988 - val_loss: 0.7252 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00993: val_loss did not improve from 0.41973\n",
      "Epoch 994/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9001 - val_loss: 0.7104 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00994: val_loss did not improve from 0.41973\n",
      "Epoch 995/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9001 - val_loss: 0.7155 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00995: val_loss did not improve from 0.41973\n",
      "Epoch 996/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.8988 - val_loss: 0.7276 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00996: val_loss did not improve from 0.41973\n",
      "Epoch 997/4000\n",
      "25/25 - 0s - loss: 0.2031 - accuracy: 0.9040 - val_loss: 0.7177 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00997: val_loss did not improve from 0.41973\n",
      "Epoch 998/4000\n",
      "25/25 - 0s - loss: 0.2026 - accuracy: 0.8975 - val_loss: 0.7324 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00998: val_loss did not improve from 0.41973\n",
      "Epoch 999/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9014 - val_loss: 0.7468 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00999: val_loss did not improve from 0.41973\n",
      "Epoch 1000/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.8975 - val_loss: 0.7475 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01000: val_loss did not improve from 0.41973\n",
      "Epoch 1001/4000\n",
      "25/25 - 0s - loss: 0.2029 - accuracy: 0.9027 - val_loss: 0.7170 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01001: val_loss did not improve from 0.41973\n",
      "Epoch 1002/4000\n",
      "25/25 - 0s - loss: 0.2025 - accuracy: 0.9014 - val_loss: 0.7073 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01002: val_loss did not improve from 0.41973\n",
      "Epoch 1003/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.8975 - val_loss: 0.7238 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01003: val_loss did not improve from 0.41973\n",
      "Epoch 1004/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 0.7268 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01004: val_loss did not improve from 0.41973\n",
      "Epoch 1005/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9001 - val_loss: 0.7215 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01005: val_loss did not improve from 0.41973\n",
      "Epoch 1006/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.8988 - val_loss: 0.7404 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01006: val_loss did not improve from 0.41973\n",
      "Epoch 1007/4000\n",
      "25/25 - 0s - loss: 0.2045 - accuracy: 0.9014 - val_loss: 0.7361 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01007: val_loss did not improve from 0.41973\n",
      "Epoch 1008/4000\n",
      "25/25 - 0s - loss: 0.2054 - accuracy: 0.9001 - val_loss: 0.7166 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01008: val_loss did not improve from 0.41973\n",
      "Epoch 1009/4000\n",
      "25/25 - 0s - loss: 0.2036 - accuracy: 0.8949 - val_loss: 0.7017 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01009: val_loss did not improve from 0.41973\n",
      "Epoch 1010/4000\n",
      "25/25 - 0s - loss: 0.2037 - accuracy: 0.8975 - val_loss: 0.6963 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01010: val_loss did not improve from 0.41973\n",
      "Epoch 1011/4000\n",
      "25/25 - 0s - loss: 0.2028 - accuracy: 0.8975 - val_loss: 0.6631 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01011: val_loss did not improve from 0.41973\n",
      "Epoch 1012/4000\n",
      "25/25 - 0s - loss: 0.2036 - accuracy: 0.9027 - val_loss: 0.6894 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01012: val_loss did not improve from 0.41973\n",
      "Epoch 1013/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9001 - val_loss: 0.6913 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01013: val_loss did not improve from 0.41973\n",
      "Epoch 1014/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9001 - val_loss: 0.7011 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01014: val_loss did not improve from 0.41973\n",
      "Epoch 1015/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9014 - val_loss: 0.7056 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01015: val_loss did not improve from 0.41973\n",
      "Epoch 1016/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9001 - val_loss: 0.6936 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01016: val_loss did not improve from 0.41973\n",
      "Epoch 1017/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9014 - val_loss: 0.7123 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01017: val_loss did not improve from 0.41973\n",
      "Epoch 1018/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9014 - val_loss: 0.7053 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01018: val_loss did not improve from 0.41973\n",
      "Epoch 1019/4000\n",
      "25/25 - 0s - loss: 0.2027 - accuracy: 0.9014 - val_loss: 0.7340 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01019: val_loss did not improve from 0.41973\n",
      "Epoch 1020/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9014 - val_loss: 0.7240 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01020: val_loss did not improve from 0.41973\n",
      "Epoch 1021/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.9001 - val_loss: 0.7377 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01021: val_loss did not improve from 0.41973\n",
      "Epoch 1022/4000\n",
      "25/25 - 0s - loss: 0.2027 - accuracy: 0.9027 - val_loss: 0.7393 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01022: val_loss did not improve from 0.41973\n",
      "Epoch 1023/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9027 - val_loss: 0.7510 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01023: val_loss did not improve from 0.41973\n",
      "Epoch 1024/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9027 - val_loss: 0.7851 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01024: val_loss did not improve from 0.41973\n",
      "Epoch 1025/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.8988 - val_loss: 0.7846 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01025: val_loss did not improve from 0.41973\n",
      "Epoch 1026/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.8988 - val_loss: 0.7699 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01026: val_loss did not improve from 0.41973\n",
      "Epoch 1027/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9001 - val_loss: 0.7752 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01027: val_loss did not improve from 0.41973\n",
      "Epoch 1028/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9001 - val_loss: 0.7815 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01028: val_loss did not improve from 0.41973\n",
      "Epoch 1029/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.8975 - val_loss: 0.7709 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01029: val_loss did not improve from 0.41973\n",
      "Epoch 1030/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.8975 - val_loss: 0.7620 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01030: val_loss did not improve from 0.41973\n",
      "Epoch 1031/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9001 - val_loss: 0.7602 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01031: val_loss did not improve from 0.41973\n",
      "Epoch 1032/4000\n",
      "25/25 - 0s - loss: 0.2031 - accuracy: 0.9001 - val_loss: 0.7190 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01032: val_loss did not improve from 0.41973\n",
      "Epoch 1033/4000\n",
      "25/25 - 0s - loss: 0.2025 - accuracy: 0.9014 - val_loss: 0.7373 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01033: val_loss did not improve from 0.41973\n",
      "Epoch 1034/4000\n",
      "25/25 - 0s - loss: 0.2032 - accuracy: 0.9014 - val_loss: 0.6964 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01034: val_loss did not improve from 0.41973\n",
      "Epoch 1035/4000\n",
      "25/25 - 0s - loss: 0.2042 - accuracy: 0.8988 - val_loss: 0.7207 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01035: val_loss did not improve from 0.41973\n",
      "Epoch 1036/4000\n",
      "25/25 - 0s - loss: 0.2039 - accuracy: 0.9014 - val_loss: 0.7512 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01036: val_loss did not improve from 0.41973\n",
      "Epoch 1037/4000\n",
      "25/25 - 0s - loss: 0.2026 - accuracy: 0.8975 - val_loss: 0.7629 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01037: val_loss did not improve from 0.41973\n",
      "Epoch 1038/4000\n",
      "25/25 - 0s - loss: 0.2038 - accuracy: 0.9001 - val_loss: 0.7494 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01038: val_loss did not improve from 0.41973\n",
      "Epoch 1039/4000\n",
      "25/25 - 0s - loss: 0.2031 - accuracy: 0.9014 - val_loss: 0.7584 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01039: val_loss did not improve from 0.41973\n",
      "Epoch 1040/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9027 - val_loss: 0.7671 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01040: val_loss did not improve from 0.41973\n",
      "Epoch 1041/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9014 - val_loss: 0.7490 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01041: val_loss did not improve from 0.41973\n",
      "Epoch 1042/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9001 - val_loss: 0.7649 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01042: val_loss did not improve from 0.41973\n",
      "Epoch 1043/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9027 - val_loss: 0.7480 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01043: val_loss did not improve from 0.41973\n",
      "Epoch 1044/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9001 - val_loss: 0.7485 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01044: val_loss did not improve from 0.41973\n",
      "Epoch 1045/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 0.7678 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01045: val_loss did not improve from 0.41973\n",
      "Epoch 1046/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9027 - val_loss: 0.7634 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01046: val_loss did not improve from 0.41973\n",
      "Epoch 1047/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9001 - val_loss: 0.7803 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01047: val_loss did not improve from 0.41973\n",
      "Epoch 1048/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.9027 - val_loss: 0.7778 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01048: val_loss did not improve from 0.41973\n",
      "Epoch 1049/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 0.7534 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01049: val_loss did not improve from 0.41973\n",
      "Epoch 1050/4000\n",
      "25/25 - 0s - loss: 0.2026 - accuracy: 0.8988 - val_loss: 0.7716 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01050: val_loss did not improve from 0.41973\n",
      "Epoch 1051/4000\n",
      "25/25 - 0s - loss: 0.2028 - accuracy: 0.9014 - val_loss: 0.7628 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01051: val_loss did not improve from 0.41973\n",
      "Epoch 1052/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.9040 - val_loss: 0.7371 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01052: val_loss did not improve from 0.41973\n",
      "Epoch 1053/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9014 - val_loss: 0.7448 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01053: val_loss did not improve from 0.41973\n",
      "Epoch 1054/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9014 - val_loss: 0.7765 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01054: val_loss did not improve from 0.41973\n",
      "Epoch 1055/4000\n",
      "25/25 - 0s - loss: 0.2026 - accuracy: 0.8988 - val_loss: 0.7599 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01055: val_loss did not improve from 0.41973\n",
      "Epoch 1056/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9014 - val_loss: 0.7561 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01056: val_loss did not improve from 0.41973\n",
      "Epoch 1057/4000\n",
      "25/25 - 0s - loss: 0.2026 - accuracy: 0.9014 - val_loss: 0.7853 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01057: val_loss did not improve from 0.41973\n",
      "Epoch 1058/4000\n",
      "25/25 - 0s - loss: 0.2040 - accuracy: 0.9027 - val_loss: 0.8021 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01058: val_loss did not improve from 0.41973\n",
      "Epoch 1059/4000\n",
      "25/25 - 0s - loss: 0.2026 - accuracy: 0.9027 - val_loss: 0.7740 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01059: val_loss did not improve from 0.41973\n",
      "Epoch 1060/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 0.7593 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01060: val_loss did not improve from 0.41973\n",
      "Epoch 1061/4000\n",
      "25/25 - 0s - loss: 0.2028 - accuracy: 0.9014 - val_loss: 0.6569 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01061: val_loss did not improve from 0.41973\n",
      "Epoch 1062/4000\n",
      "25/25 - 0s - loss: 0.2040 - accuracy: 0.9027 - val_loss: 0.7509 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01062: val_loss did not improve from 0.41973\n",
      "Epoch 1063/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.8988 - val_loss: 0.7472 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01063: val_loss did not improve from 0.41973\n",
      "Epoch 1064/4000\n",
      "25/25 - 0s - loss: 0.2031 - accuracy: 0.8988 - val_loss: 0.7482 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01064: val_loss did not improve from 0.41973\n",
      "Epoch 1065/4000\n",
      "25/25 - 0s - loss: 0.2034 - accuracy: 0.8962 - val_loss: 0.7418 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01065: val_loss did not improve from 0.41973\n",
      "Epoch 1066/4000\n",
      "25/25 - 0s - loss: 0.2025 - accuracy: 0.8949 - val_loss: 0.7249 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01066: val_loss did not improve from 0.41973\n",
      "Epoch 1067/4000\n",
      "25/25 - 0s - loss: 0.2033 - accuracy: 0.8988 - val_loss: 0.7346 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01067: val_loss did not improve from 0.41973\n",
      "Epoch 1068/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.9001 - val_loss: 0.7378 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01068: val_loss did not improve from 0.41973\n",
      "Epoch 1069/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9027 - val_loss: 0.7383 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01069: val_loss did not improve from 0.41973\n",
      "Epoch 1070/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.8962 - val_loss: 0.7478 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01070: val_loss did not improve from 0.41973\n",
      "Epoch 1071/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.8962 - val_loss: 0.7641 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01071: val_loss did not improve from 0.41973\n",
      "Epoch 1072/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.8975 - val_loss: 0.7512 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01072: val_loss did not improve from 0.41973\n",
      "Epoch 1073/4000\n",
      "25/25 - 0s - loss: 0.2026 - accuracy: 0.9001 - val_loss: 0.7368 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01073: val_loss did not improve from 0.41973\n",
      "Epoch 1074/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.8988 - val_loss: 0.7225 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01074: val_loss did not improve from 0.41973\n",
      "Epoch 1075/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.9001 - val_loss: 0.7376 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01075: val_loss did not improve from 0.41973\n",
      "Epoch 1076/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.9014 - val_loss: 0.7443 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01076: val_loss did not improve from 0.41973\n",
      "Epoch 1077/4000\n",
      "25/25 - 0s - loss: 0.2037 - accuracy: 0.9014 - val_loss: 0.7480 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01077: val_loss did not improve from 0.41973\n",
      "Epoch 1078/4000\n",
      "25/25 - 0s - loss: 0.2032 - accuracy: 0.9001 - val_loss: 0.7522 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01078: val_loss did not improve from 0.41973\n",
      "Epoch 1079/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.9040 - val_loss: 0.7732 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01079: val_loss did not improve from 0.41973\n",
      "Epoch 1080/4000\n",
      "25/25 - 0s - loss: 0.2034 - accuracy: 0.9027 - val_loss: 0.7674 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01080: val_loss did not improve from 0.41973\n",
      "Epoch 1081/4000\n",
      "25/25 - 0s - loss: 0.2099 - accuracy: 0.9001 - val_loss: 0.6219 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01081: val_loss did not improve from 0.41973\n",
      "Epoch 1082/4000\n",
      "25/25 - 0s - loss: 0.2038 - accuracy: 0.9014 - val_loss: 0.6609 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01082: val_loss did not improve from 0.41973\n",
      "Epoch 1083/4000\n",
      "25/25 - 0s - loss: 0.2035 - accuracy: 0.9001 - val_loss: 0.6908 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01083: val_loss did not improve from 0.41973\n",
      "Epoch 1084/4000\n",
      "25/25 - 0s - loss: 0.2032 - accuracy: 0.8975 - val_loss: 0.6696 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01084: val_loss did not improve from 0.41973\n",
      "Epoch 1085/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8975 - val_loss: 0.6823 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01085: val_loss did not improve from 0.41973\n",
      "Epoch 1086/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.9027 - val_loss: 0.6988 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01086: val_loss did not improve from 0.41973\n",
      "Epoch 1087/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.9027 - val_loss: 0.6892 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01087: val_loss did not improve from 0.41973\n",
      "Epoch 1088/4000\n",
      "25/25 - 0s - loss: 0.2028 - accuracy: 0.9001 - val_loss: 0.6946 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01088: val_loss did not improve from 0.41973\n",
      "Epoch 1089/4000\n",
      "25/25 - 0s - loss: 0.2034 - accuracy: 0.8975 - val_loss: 0.6611 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01089: val_loss did not improve from 0.41973\n",
      "Epoch 1090/4000\n",
      "25/25 - 0s - loss: 0.2029 - accuracy: 0.9014 - val_loss: 0.6703 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01090: val_loss did not improve from 0.41973\n",
      "Epoch 1091/4000\n",
      "25/25 - 0s - loss: 0.2025 - accuracy: 0.9001 - val_loss: 0.7017 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01091: val_loss did not improve from 0.41973\n",
      "Epoch 1092/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.8988 - val_loss: 0.6920 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01092: val_loss did not improve from 0.41973\n",
      "Epoch 1093/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.8988 - val_loss: 0.7275 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01093: val_loss did not improve from 0.41973\n",
      "Epoch 1094/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.8975 - val_loss: 0.7361 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01094: val_loss did not improve from 0.41973\n",
      "Epoch 1095/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.8936 - val_loss: 0.7188 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01095: val_loss did not improve from 0.41973\n",
      "Epoch 1096/4000\n",
      "25/25 - 0s - loss: 0.2028 - accuracy: 0.8975 - val_loss: 0.7297 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01096: val_loss did not improve from 0.41973\n",
      "Epoch 1097/4000\n",
      "25/25 - 0s - loss: 0.2094 - accuracy: 0.9014 - val_loss: 0.8630 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 01097: val_loss did not improve from 0.41973\n",
      "Epoch 1098/4000\n",
      "25/25 - 0s - loss: 0.2350 - accuracy: 0.8988 - val_loss: 0.6224 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01098: val_loss did not improve from 0.41973\n",
      "Epoch 1099/4000\n",
      "25/25 - 0s - loss: 0.2146 - accuracy: 0.8962 - val_loss: 0.7702 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01099: val_loss did not improve from 0.41973\n",
      "Epoch 1100/4000\n",
      "25/25 - 0s - loss: 0.2130 - accuracy: 0.8936 - val_loss: 0.6684 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01100: val_loss did not improve from 0.41973\n",
      "Epoch 1101/4000\n",
      "25/25 - 0s - loss: 0.2120 - accuracy: 0.8962 - val_loss: 0.6834 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01101: val_loss did not improve from 0.41973\n",
      "Epoch 1102/4000\n",
      "25/25 - 0s - loss: 0.2035 - accuracy: 0.9027 - val_loss: 0.6702 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01102: val_loss did not improve from 0.41973\n",
      "Epoch 1103/4000\n",
      "25/25 - 0s - loss: 0.2028 - accuracy: 0.9001 - val_loss: 0.6822 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01103: val_loss did not improve from 0.41973\n",
      "Epoch 1104/4000\n",
      "25/25 - 0s - loss: 0.2035 - accuracy: 0.8975 - val_loss: 0.6636 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01104: val_loss did not improve from 0.41973\n",
      "Epoch 1105/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.8975 - val_loss: 0.6639 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01105: val_loss did not improve from 0.41973\n",
      "Epoch 1106/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9027 - val_loss: 0.6695 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01106: val_loss did not improve from 0.41973\n",
      "Epoch 1107/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9014 - val_loss: 0.6675 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01107: val_loss did not improve from 0.41973\n",
      "Epoch 1108/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9014 - val_loss: 0.6701 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01108: val_loss did not improve from 0.41973\n",
      "Epoch 1109/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9001 - val_loss: 0.6795 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01109: val_loss did not improve from 0.41973\n",
      "Epoch 1110/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9001 - val_loss: 0.6686 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01110: val_loss did not improve from 0.41973\n",
      "Epoch 1111/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9001 - val_loss: 0.6790 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01111: val_loss did not improve from 0.41973\n",
      "Epoch 1112/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.8975 - val_loss: 0.6828 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01112: val_loss did not improve from 0.41973\n",
      "Epoch 1113/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9001 - val_loss: 0.6910 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01113: val_loss did not improve from 0.41973\n",
      "Epoch 1114/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.8988 - val_loss: 0.6528 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01114: val_loss did not improve from 0.41973\n",
      "Epoch 1115/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9040 - val_loss: 0.6597 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01115: val_loss did not improve from 0.41973\n",
      "Epoch 1116/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.8962 - val_loss: 0.6491 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01116: val_loss did not improve from 0.41973\n",
      "Epoch 1117/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.8975 - val_loss: 0.6597 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01117: val_loss did not improve from 0.41973\n",
      "Epoch 1118/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.8988 - val_loss: 0.6656 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01118: val_loss did not improve from 0.41973\n",
      "Epoch 1119/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 0.6749 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01119: val_loss did not improve from 0.41973\n",
      "Epoch 1120/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.8962 - val_loss: 0.6682 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01120: val_loss did not improve from 0.41973\n",
      "Epoch 1121/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.8975 - val_loss: 0.6748 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01121: val_loss did not improve from 0.41973\n",
      "Epoch 1122/4000\n",
      "25/25 - 0s - loss: 0.2029 - accuracy: 0.9001 - val_loss: 0.6520 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01122: val_loss did not improve from 0.41973\n",
      "Epoch 1123/4000\n",
      "25/25 - 0s - loss: 0.2028 - accuracy: 0.9027 - val_loss: 0.6609 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01123: val_loss did not improve from 0.41973\n",
      "Epoch 1124/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.8988 - val_loss: 0.6825 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01124: val_loss did not improve from 0.41973\n",
      "Epoch 1125/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.8949 - val_loss: 0.7025 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01125: val_loss did not improve from 0.41973\n",
      "Epoch 1126/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9014 - val_loss: 0.6808 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01126: val_loss did not improve from 0.41973\n",
      "Epoch 1127/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 0.6895 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01127: val_loss did not improve from 0.41973\n",
      "Epoch 1128/4000\n",
      "25/25 - 0s - loss: 0.2026 - accuracy: 0.9027 - val_loss: 0.6915 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01128: val_loss did not improve from 0.41973\n",
      "Epoch 1129/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.8988 - val_loss: 0.6873 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01129: val_loss did not improve from 0.41973\n",
      "Epoch 1130/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9014 - val_loss: 0.6787 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01130: val_loss did not improve from 0.41973\n",
      "Epoch 1131/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9001 - val_loss: 0.6730 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01131: val_loss did not improve from 0.41973\n",
      "Epoch 1132/4000\n",
      "25/25 - 0s - loss: 0.2026 - accuracy: 0.9001 - val_loss: 0.6935 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01132: val_loss did not improve from 0.41973\n",
      "Epoch 1133/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9027 - val_loss: 0.7224 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01133: val_loss did not improve from 0.41973\n",
      "Epoch 1134/4000\n",
      "25/25 - 0s - loss: 0.2029 - accuracy: 0.8988 - val_loss: 0.6820 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01134: val_loss did not improve from 0.41973\n",
      "Epoch 1135/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.8962 - val_loss: 0.6728 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01135: val_loss did not improve from 0.41973\n",
      "Epoch 1136/4000\n",
      "25/25 - 0s - loss: 0.2027 - accuracy: 0.8988 - val_loss: 0.7026 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01136: val_loss did not improve from 0.41973\n",
      "Epoch 1137/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.9001 - val_loss: 0.6798 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01137: val_loss did not improve from 0.41973\n",
      "Epoch 1138/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.8975 - val_loss: 0.6756 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01138: val_loss did not improve from 0.41973\n",
      "Epoch 1139/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9027 - val_loss: 0.7089 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01139: val_loss did not improve from 0.41973\n",
      "Epoch 1140/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.9027 - val_loss: 0.6904 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01140: val_loss did not improve from 0.41973\n",
      "Epoch 1141/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.8988 - val_loss: 0.7126 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01141: val_loss did not improve from 0.41973\n",
      "Epoch 1142/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.8988 - val_loss: 0.7119 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01142: val_loss did not improve from 0.41973\n",
      "Epoch 1143/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 0.7133 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01143: val_loss did not improve from 0.41973\n",
      "Epoch 1144/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9014 - val_loss: 0.7218 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01144: val_loss did not improve from 0.41973\n",
      "Epoch 1145/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9001 - val_loss: 0.7175 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01145: val_loss did not improve from 0.41973\n",
      "Epoch 1146/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.9001 - val_loss: 0.6959 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01146: val_loss did not improve from 0.41973\n",
      "Epoch 1147/4000\n",
      "25/25 - 0s - loss: 0.2025 - accuracy: 0.9001 - val_loss: 0.7061 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01147: val_loss did not improve from 0.41973\n",
      "Epoch 1148/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.9014 - val_loss: 0.7025 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01148: val_loss did not improve from 0.41973\n",
      "Epoch 1149/4000\n",
      "25/25 - 0s - loss: 0.2028 - accuracy: 0.9001 - val_loss: 0.7078 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01149: val_loss did not improve from 0.41973\n",
      "Epoch 1150/4000\n",
      "25/25 - 0s - loss: 0.2033 - accuracy: 0.8988 - val_loss: 0.7308 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01150: val_loss did not improve from 0.41973\n",
      "Epoch 1151/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.8988 - val_loss: 0.7482 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01151: val_loss did not improve from 0.41973\n",
      "Epoch 1152/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9014 - val_loss: 0.7422 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01152: val_loss did not improve from 0.41973\n",
      "Epoch 1153/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8988 - val_loss: 0.7399 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01153: val_loss did not improve from 0.41973\n",
      "Epoch 1154/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 0.7303 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01154: val_loss did not improve from 0.41973\n",
      "Epoch 1155/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9001 - val_loss: 0.7248 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01155: val_loss did not improve from 0.41973\n",
      "Epoch 1156/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.8988 - val_loss: 0.7038 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01156: val_loss did not improve from 0.41973\n",
      "Epoch 1157/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.8975 - val_loss: 0.6849 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01157: val_loss did not improve from 0.41973\n",
      "Epoch 1158/4000\n",
      "25/25 - 0s - loss: 0.2028 - accuracy: 0.8988 - val_loss: 0.7011 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01158: val_loss did not improve from 0.41973\n",
      "Epoch 1159/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9027 - val_loss: 0.7190 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01159: val_loss did not improve from 0.41973\n",
      "Epoch 1160/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9001 - val_loss: 0.7433 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01160: val_loss did not improve from 0.41973\n",
      "Epoch 1161/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.8988 - val_loss: 0.7330 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01161: val_loss did not improve from 0.41973\n",
      "Epoch 1162/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9001 - val_loss: 0.7308 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01162: val_loss did not improve from 0.41973\n",
      "Epoch 1163/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9001 - val_loss: 0.7356 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01163: val_loss did not improve from 0.41973\n",
      "Epoch 1164/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9014 - val_loss: 0.7229 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01164: val_loss did not improve from 0.41973\n",
      "Epoch 1165/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 0.7205 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01165: val_loss did not improve from 0.41973\n",
      "Epoch 1166/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.8988 - val_loss: 0.7183 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01166: val_loss did not improve from 0.41973\n",
      "Epoch 1167/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9014 - val_loss: 0.7255 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01167: val_loss did not improve from 0.41973\n",
      "Epoch 1168/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9027 - val_loss: 0.7195 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01168: val_loss did not improve from 0.41973\n",
      "Epoch 1169/4000\n",
      "25/25 - 0s - loss: 0.2029 - accuracy: 0.8988 - val_loss: 0.7398 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01169: val_loss did not improve from 0.41973\n",
      "Epoch 1170/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9001 - val_loss: 0.7303 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01170: val_loss did not improve from 0.41973\n",
      "Epoch 1171/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9014 - val_loss: 0.7356 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01171: val_loss did not improve from 0.41973\n",
      "Epoch 1172/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.8988 - val_loss: 0.7185 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01172: val_loss did not improve from 0.41973\n",
      "Epoch 1173/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.9027 - val_loss: 0.7129 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01173: val_loss did not improve from 0.41973\n",
      "Epoch 1174/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9014 - val_loss: 0.7104 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01174: val_loss did not improve from 0.41973\n",
      "Epoch 1175/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.9027 - val_loss: 0.6977 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01175: val_loss did not improve from 0.41973\n",
      "Epoch 1176/4000\n",
      "25/25 - 0s - loss: 0.2025 - accuracy: 0.8975 - val_loss: 0.6878 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01176: val_loss did not improve from 0.41973\n",
      "Epoch 1177/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.8975 - val_loss: 0.7023 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01177: val_loss did not improve from 0.41973\n",
      "Epoch 1178/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9001 - val_loss: 0.7130 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01178: val_loss did not improve from 0.41973\n",
      "Epoch 1179/4000\n",
      "25/25 - 0s - loss: 0.2027 - accuracy: 0.9027 - val_loss: 0.7360 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01179: val_loss did not improve from 0.41973\n",
      "Epoch 1180/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.8962 - val_loss: 0.7353 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01180: val_loss did not improve from 0.41973\n",
      "Epoch 1181/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9027 - val_loss: 0.7495 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01181: val_loss did not improve from 0.41973\n",
      "Epoch 1182/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.8988 - val_loss: 0.7496 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01182: val_loss did not improve from 0.41973\n",
      "Epoch 1183/4000\n",
      "25/25 - 0s - loss: 0.2026 - accuracy: 0.8975 - val_loss: 0.7436 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01183: val_loss did not improve from 0.41973\n",
      "Epoch 1184/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 0.7334 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01184: val_loss did not improve from 0.41973\n",
      "Epoch 1185/4000\n",
      "25/25 - 0s - loss: 0.2043 - accuracy: 0.8988 - val_loss: 0.7115 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01185: val_loss did not improve from 0.41973\n",
      "Epoch 1186/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.8975 - val_loss: 0.6987 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01186: val_loss did not improve from 0.41973\n",
      "Epoch 1187/4000\n",
      "25/25 - 0s - loss: 0.2055 - accuracy: 0.9014 - val_loss: 0.7002 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01187: val_loss did not improve from 0.41973\n",
      "Epoch 1188/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.8936 - val_loss: 0.7008 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01188: val_loss did not improve from 0.41973\n",
      "Epoch 1189/4000\n",
      "25/25 - 0s - loss: 0.2034 - accuracy: 0.8962 - val_loss: 0.6870 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01189: val_loss did not improve from 0.41973\n",
      "Epoch 1190/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.9001 - val_loss: 0.7053 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01190: val_loss did not improve from 0.41973\n",
      "Epoch 1191/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9001 - val_loss: 0.7053 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01191: val_loss did not improve from 0.41973\n",
      "Epoch 1192/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 0.7123 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01192: val_loss did not improve from 0.41973\n",
      "Epoch 1193/4000\n",
      "25/25 - 0s - loss: 0.2027 - accuracy: 0.9014 - val_loss: 0.7015 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01193: val_loss did not improve from 0.41973\n",
      "Epoch 1194/4000\n",
      "25/25 - 0s - loss: 0.2027 - accuracy: 0.8975 - val_loss: 0.6917 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01194: val_loss did not improve from 0.41973\n",
      "Epoch 1195/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.8962 - val_loss: 0.7039 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01195: val_loss did not improve from 0.41973\n",
      "Epoch 1196/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9014 - val_loss: 0.7000 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01196: val_loss did not improve from 0.41973\n",
      "Epoch 1197/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.8975 - val_loss: 0.7006 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01197: val_loss did not improve from 0.41973\n",
      "Epoch 1198/4000\n",
      "25/25 - 0s - loss: 0.2057 - accuracy: 0.8988 - val_loss: 0.6583 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01198: val_loss did not improve from 0.41973\n",
      "Epoch 1199/4000\n",
      "25/25 - 0s - loss: 0.2045 - accuracy: 0.9014 - val_loss: 0.6715 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01199: val_loss did not improve from 0.41973\n",
      "Epoch 1200/4000\n",
      "25/25 - 0s - loss: 0.2027 - accuracy: 0.9027 - val_loss: 0.6906 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01200: val_loss did not improve from 0.41973\n",
      "Epoch 1201/4000\n",
      "25/25 - 0s - loss: 0.2075 - accuracy: 0.9027 - val_loss: 0.6650 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01201: val_loss did not improve from 0.41973\n",
      "Epoch 1202/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.9014 - val_loss: 0.6792 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01202: val_loss did not improve from 0.41973\n",
      "Epoch 1203/4000\n",
      "25/25 - 0s - loss: 0.2029 - accuracy: 0.9001 - val_loss: 0.6982 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01203: val_loss did not improve from 0.41973\n",
      "Epoch 1204/4000\n",
      "25/25 - 0s - loss: 0.2025 - accuracy: 0.9014 - val_loss: 0.7536 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01204: val_loss did not improve from 0.41973\n",
      "Epoch 1205/4000\n",
      "25/25 - 0s - loss: 0.2026 - accuracy: 0.8975 - val_loss: 0.7421 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01205: val_loss did not improve from 0.41973\n",
      "Epoch 1206/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9014 - val_loss: 0.7466 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01206: val_loss did not improve from 0.41973\n",
      "Epoch 1207/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9027 - val_loss: 0.7561 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01207: val_loss did not improve from 0.41973\n",
      "Epoch 1208/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9027 - val_loss: 0.7418 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01208: val_loss did not improve from 0.41973\n",
      "Epoch 1209/4000\n",
      "25/25 - 0s - loss: 0.2026 - accuracy: 0.9014 - val_loss: 0.7694 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01209: val_loss did not improve from 0.41973\n",
      "Epoch 1210/4000\n",
      "25/25 - 0s - loss: 0.2026 - accuracy: 0.8988 - val_loss: 0.7712 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01210: val_loss did not improve from 0.41973\n",
      "Epoch 1211/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9014 - val_loss: 0.7871 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01211: val_loss did not improve from 0.41973\n",
      "Epoch 1212/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.8988 - val_loss: 0.7834 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01212: val_loss did not improve from 0.41973\n",
      "Epoch 1213/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.8988 - val_loss: 0.7907 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01213: val_loss did not improve from 0.41973\n",
      "Epoch 1214/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9027 - val_loss: 0.7814 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01214: val_loss did not improve from 0.41973\n",
      "Epoch 1215/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.9027 - val_loss: 0.7547 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01215: val_loss did not improve from 0.41973\n",
      "Epoch 1216/4000\n",
      "25/25 - 0s - loss: 0.2079 - accuracy: 0.9027 - val_loss: 0.8074 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01216: val_loss did not improve from 0.41973\n",
      "Epoch 1217/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.8988 - val_loss: 0.7802 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01217: val_loss did not improve from 0.41973\n",
      "Epoch 1218/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9014 - val_loss: 0.7742 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01218: val_loss did not improve from 0.41973\n",
      "Epoch 1219/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9001 - val_loss: 0.7859 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01219: val_loss did not improve from 0.41973\n",
      "Epoch 1220/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.8988 - val_loss: 0.7908 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01220: val_loss did not improve from 0.41973\n",
      "Epoch 1221/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.8988 - val_loss: 0.7865 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01221: val_loss did not improve from 0.41973\n",
      "Epoch 1222/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.8988 - val_loss: 0.8015 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01222: val_loss did not improve from 0.41973\n",
      "Epoch 1223/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9014 - val_loss: 0.8019 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01223: val_loss did not improve from 0.41973\n",
      "Epoch 1224/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9014 - val_loss: 0.8050 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01224: val_loss did not improve from 0.41973\n",
      "Epoch 1225/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 0.8064 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01225: val_loss did not improve from 0.41973\n",
      "Epoch 1226/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9001 - val_loss: 0.7838 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01226: val_loss did not improve from 0.41973\n",
      "Epoch 1227/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.8988 - val_loss: 0.7936 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01227: val_loss did not improve from 0.41973\n",
      "Epoch 1228/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 0.7873 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01228: val_loss did not improve from 0.41973\n",
      "Epoch 1229/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.8975 - val_loss: 0.7911 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01229: val_loss did not improve from 0.41973\n",
      "Epoch 1230/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 0.7878 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01230: val_loss did not improve from 0.41973\n",
      "Epoch 1231/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.8988 - val_loss: 0.7953 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01231: val_loss did not improve from 0.41973\n",
      "Epoch 1232/4000\n",
      "25/25 - 0s - loss: 0.2034 - accuracy: 0.9027 - val_loss: 0.7887 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01232: val_loss did not improve from 0.41973\n",
      "Epoch 1233/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9001 - val_loss: 0.8623 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01233: val_loss did not improve from 0.41973\n",
      "Epoch 1234/4000\n",
      "25/25 - 0s - loss: 0.2195 - accuracy: 0.9014 - val_loss: 0.7867 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01234: val_loss did not improve from 0.41973\n",
      "Epoch 1235/4000\n",
      "25/25 - 0s - loss: 0.2027 - accuracy: 0.9014 - val_loss: 0.8209 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01235: val_loss did not improve from 0.41973\n",
      "Epoch 1236/4000\n",
      "25/25 - 0s - loss: 0.2033 - accuracy: 0.9014 - val_loss: 0.7218 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01236: val_loss did not improve from 0.41973\n",
      "Epoch 1237/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.8975 - val_loss: 0.7480 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01237: val_loss did not improve from 0.41973\n",
      "Epoch 1238/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9001 - val_loss: 0.7598 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01238: val_loss did not improve from 0.41973\n",
      "Epoch 1239/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9027 - val_loss: 0.7475 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01239: val_loss did not improve from 0.41973\n",
      "Epoch 1240/4000\n",
      "25/25 - 0s - loss: 0.2025 - accuracy: 0.9027 - val_loss: 0.7333 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01240: val_loss did not improve from 0.41973\n",
      "Epoch 1241/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.8962 - val_loss: 0.7468 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01241: val_loss did not improve from 0.41973\n",
      "Epoch 1242/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9001 - val_loss: 0.7507 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01242: val_loss did not improve from 0.41973\n",
      "Epoch 1243/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9014 - val_loss: 0.7424 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01243: val_loss did not improve from 0.41973\n",
      "Epoch 1244/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 0.7591 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01244: val_loss did not improve from 0.41973\n",
      "Epoch 1245/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9027 - val_loss: 0.7731 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01245: val_loss did not improve from 0.41973\n",
      "Epoch 1246/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9001 - val_loss: 0.7632 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01246: val_loss did not improve from 0.41973\n",
      "Epoch 1247/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9027 - val_loss: 0.7734 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01247: val_loss did not improve from 0.41973\n",
      "Epoch 1248/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 0.7720 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01248: val_loss did not improve from 0.41973\n",
      "Epoch 1249/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.8988 - val_loss: 0.7564 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01249: val_loss did not improve from 0.41973\n",
      "Epoch 1250/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9014 - val_loss: 0.7579 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01250: val_loss did not improve from 0.41973\n",
      "Epoch 1251/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.8988 - val_loss: 0.7478 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01251: val_loss did not improve from 0.41973\n",
      "Epoch 1252/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9001 - val_loss: 0.7316 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01252: val_loss did not improve from 0.41973\n",
      "Epoch 1253/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9001 - val_loss: 0.7360 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01253: val_loss did not improve from 0.41973\n",
      "Epoch 1254/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9027 - val_loss: 0.7163 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01254: val_loss did not improve from 0.41973\n",
      "Epoch 1255/4000\n",
      "25/25 - 0s - loss: 0.2038 - accuracy: 0.9001 - val_loss: 0.7256 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01255: val_loss did not improve from 0.41973\n",
      "Epoch 1256/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.8962 - val_loss: 0.7540 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01256: val_loss did not improve from 0.41973\n",
      "Epoch 1257/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9001 - val_loss: 0.7736 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01257: val_loss did not improve from 0.41973\n",
      "Epoch 1258/4000\n",
      "25/25 - 0s - loss: 0.2025 - accuracy: 0.8975 - val_loss: 0.7731 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01258: val_loss did not improve from 0.41973\n",
      "Epoch 1259/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.8975 - val_loss: 0.7003 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01259: val_loss did not improve from 0.41973\n",
      "Epoch 1260/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.9027 - val_loss: 0.6985 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01260: val_loss did not improve from 0.41973\n",
      "Epoch 1261/4000\n",
      "25/25 - 0s - loss: 0.2036 - accuracy: 0.9014 - val_loss: 0.7068 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01261: val_loss did not improve from 0.41973\n",
      "Epoch 1262/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.8975 - val_loss: 0.7356 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01262: val_loss did not improve from 0.41973\n",
      "Epoch 1263/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9001 - val_loss: 0.7324 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01263: val_loss did not improve from 0.41973\n",
      "Epoch 1264/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9027 - val_loss: 0.7345 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01264: val_loss did not improve from 0.41973\n",
      "Epoch 1265/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9014 - val_loss: 0.7344 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01265: val_loss did not improve from 0.41973\n",
      "Epoch 1266/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.8988 - val_loss: 0.7188 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01266: val_loss did not improve from 0.41973\n",
      "Epoch 1267/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 0.7334 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01267: val_loss did not improve from 0.41973\n",
      "Epoch 1268/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.9014 - val_loss: 0.7502 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01268: val_loss did not improve from 0.41973\n",
      "Epoch 1269/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9014 - val_loss: 0.7957 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01269: val_loss did not improve from 0.41973\n",
      "Epoch 1270/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9001 - val_loss: 0.7962 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01270: val_loss did not improve from 0.41973\n",
      "Epoch 1271/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.8988 - val_loss: 0.7980 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01271: val_loss did not improve from 0.41973\n",
      "Epoch 1272/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.8975 - val_loss: 0.7974 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01272: val_loss did not improve from 0.41973\n",
      "Epoch 1273/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9001 - val_loss: 0.7911 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01273: val_loss did not improve from 0.41973\n",
      "Epoch 1274/4000\n",
      "25/25 - 0s - loss: 0.2052 - accuracy: 0.9040 - val_loss: 0.7820 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01274: val_loss did not improve from 0.41973\n",
      "Epoch 1275/4000\n",
      "25/25 - 0s - loss: 0.2032 - accuracy: 0.9001 - val_loss: 0.7775 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01275: val_loss did not improve from 0.41973\n",
      "Epoch 1276/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9027 - val_loss: 0.7879 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01276: val_loss did not improve from 0.41973\n",
      "Epoch 1277/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9014 - val_loss: 0.7852 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01277: val_loss did not improve from 0.41973\n",
      "Epoch 1278/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9001 - val_loss: 0.7930 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01278: val_loss did not improve from 0.41973\n",
      "Epoch 1279/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8988 - val_loss: 0.7669 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01279: val_loss did not improve from 0.41973\n",
      "Epoch 1280/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 0.7718 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01280: val_loss did not improve from 0.41973\n",
      "Epoch 1281/4000\n",
      "25/25 - 0s - loss: 0.2026 - accuracy: 0.9027 - val_loss: 0.7394 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01281: val_loss did not improve from 0.41973\n",
      "Epoch 1282/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.9027 - val_loss: 0.7445 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01282: val_loss did not improve from 0.41973\n",
      "Epoch 1283/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9027 - val_loss: 0.7463 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01283: val_loss did not improve from 0.41973\n",
      "Epoch 1284/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9001 - val_loss: 0.7636 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01284: val_loss did not improve from 0.41973\n",
      "Epoch 1285/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9014 - val_loss: 0.7761 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01285: val_loss did not improve from 0.41973\n",
      "Epoch 1286/4000\n",
      "25/25 - 0s - loss: 0.2025 - accuracy: 0.9001 - val_loss: 0.7893 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01286: val_loss did not improve from 0.41973\n",
      "Epoch 1287/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8988 - val_loss: 0.7846 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01287: val_loss did not improve from 0.41973\n",
      "Epoch 1288/4000\n",
      "25/25 - 0s - loss: 0.2026 - accuracy: 0.9027 - val_loss: 0.8074 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01288: val_loss did not improve from 0.41973\n",
      "Epoch 1289/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.8975 - val_loss: 0.8530 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01289: val_loss did not improve from 0.41973\n",
      "Epoch 1290/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9027 - val_loss: 0.8540 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01290: val_loss did not improve from 0.41973\n",
      "Epoch 1291/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.8988 - val_loss: 0.8304 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01291: val_loss did not improve from 0.41973\n",
      "Epoch 1292/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.9001 - val_loss: 0.8567 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01292: val_loss did not improve from 0.41973\n",
      "Epoch 1293/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9027 - val_loss: 0.8743 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01293: val_loss did not improve from 0.41973\n",
      "Epoch 1294/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.8988 - val_loss: 0.8809 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01294: val_loss did not improve from 0.41973\n",
      "Epoch 1295/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.8975 - val_loss: 0.8858 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01295: val_loss did not improve from 0.41973\n",
      "Epoch 1296/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 0.8690 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01296: val_loss did not improve from 0.41973\n",
      "Epoch 1297/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.8975 - val_loss: 0.8936 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01297: val_loss did not improve from 0.41973\n",
      "Epoch 1298/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 0.8858 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01298: val_loss did not improve from 0.41973\n",
      "Epoch 1299/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.8975 - val_loss: 0.8685 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01299: val_loss did not improve from 0.41973\n",
      "Epoch 1300/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9001 - val_loss: 0.8701 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01300: val_loss did not improve from 0.41973\n",
      "Epoch 1301/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9001 - val_loss: 0.8542 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01301: val_loss did not improve from 0.41973\n",
      "Epoch 1302/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.8988 - val_loss: 0.8419 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01302: val_loss did not improve from 0.41973\n",
      "Epoch 1303/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9001 - val_loss: 0.7990 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01303: val_loss did not improve from 0.41973\n",
      "Epoch 1304/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9001 - val_loss: 0.8052 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01304: val_loss did not improve from 0.41973\n",
      "Epoch 1305/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.8949 - val_loss: 0.8103 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01305: val_loss did not improve from 0.41973\n",
      "Epoch 1306/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.8975 - val_loss: 0.8166 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01306: val_loss did not improve from 0.41973\n",
      "Epoch 1307/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.8975 - val_loss: 0.8269 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01307: val_loss did not improve from 0.41973\n",
      "Epoch 1308/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.8975 - val_loss: 0.7898 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01308: val_loss did not improve from 0.41973\n",
      "Epoch 1309/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9001 - val_loss: 0.7999 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01309: val_loss did not improve from 0.41973\n",
      "Epoch 1310/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9014 - val_loss: 0.7956 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01310: val_loss did not improve from 0.41973\n",
      "Epoch 1311/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.8975 - val_loss: 0.8011 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01311: val_loss did not improve from 0.41973\n",
      "Epoch 1312/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.9014 - val_loss: 0.7901 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01312: val_loss did not improve from 0.41973\n",
      "Epoch 1313/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9027 - val_loss: 0.7906 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01313: val_loss did not improve from 0.41973\n",
      "Epoch 1314/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.9001 - val_loss: 0.7769 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01314: val_loss did not improve from 0.41973\n",
      "Epoch 1315/4000\n",
      "25/25 - 0s - loss: 0.2025 - accuracy: 0.9027 - val_loss: 0.7938 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01315: val_loss did not improve from 0.41973\n",
      "Epoch 1316/4000\n",
      "25/25 - 0s - loss: 0.2027 - accuracy: 0.8988 - val_loss: 0.8110 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01316: val_loss did not improve from 0.41973\n",
      "Epoch 1317/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9014 - val_loss: 0.8110 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01317: val_loss did not improve from 0.41973\n",
      "Epoch 1318/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.8988 - val_loss: 0.8277 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01318: val_loss did not improve from 0.41973\n",
      "Epoch 1319/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.9040 - val_loss: 0.8439 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01319: val_loss did not improve from 0.41973\n",
      "Epoch 1320/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 0.8454 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01320: val_loss did not improve from 0.41973\n",
      "Epoch 1321/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 0.8335 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01321: val_loss did not improve from 0.41973\n",
      "Epoch 1322/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.8975 - val_loss: 0.8481 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01322: val_loss did not improve from 0.41973\n",
      "Epoch 1323/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 0.8620 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01323: val_loss did not improve from 0.41973\n",
      "Epoch 1324/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 0.7936 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01324: val_loss did not improve from 0.41973\n",
      "Epoch 1325/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 0.8015 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01325: val_loss did not improve from 0.41973\n",
      "Epoch 1326/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9014 - val_loss: 0.8150 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01326: val_loss did not improve from 0.41973\n",
      "Epoch 1327/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9014 - val_loss: 0.8130 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01327: val_loss did not improve from 0.41973\n",
      "Epoch 1328/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 0.8129 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01328: val_loss did not improve from 0.41973\n",
      "Epoch 1329/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9014 - val_loss: 0.8017 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01329: val_loss did not improve from 0.41973\n",
      "Epoch 1330/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8988 - val_loss: 0.8163 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01330: val_loss did not improve from 0.41973\n",
      "Epoch 1331/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.8949 - val_loss: 0.8169 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01331: val_loss did not improve from 0.41973\n",
      "Epoch 1332/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9027 - val_loss: 0.8259 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01332: val_loss did not improve from 0.41973\n",
      "Epoch 1333/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9001 - val_loss: 0.8222 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01333: val_loss did not improve from 0.41973\n",
      "Epoch 1334/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 0.8334 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01334: val_loss did not improve from 0.41973\n",
      "Epoch 1335/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.8988 - val_loss: 0.8292 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01335: val_loss did not improve from 0.41973\n",
      "Epoch 1336/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 0.8102 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01336: val_loss did not improve from 0.41973\n",
      "Epoch 1337/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.8988 - val_loss: 0.8114 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01337: val_loss did not improve from 0.41973\n",
      "Epoch 1338/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.8975 - val_loss: 0.8078 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01338: val_loss did not improve from 0.41973\n",
      "Epoch 1339/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.8975 - val_loss: 0.7814 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01339: val_loss did not improve from 0.41973\n",
      "Epoch 1340/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.8962 - val_loss: 0.7895 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01340: val_loss did not improve from 0.41973\n",
      "Epoch 1341/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.8988 - val_loss: 0.8051 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01341: val_loss did not improve from 0.41973\n",
      "Epoch 1342/4000\n",
      "25/25 - 0s - loss: 0.2027 - accuracy: 0.8975 - val_loss: 0.7725 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01342: val_loss did not improve from 0.41973\n",
      "Epoch 1343/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9001 - val_loss: 0.7874 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01343: val_loss did not improve from 0.41973\n",
      "Epoch 1344/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9014 - val_loss: 0.7656 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01344: val_loss did not improve from 0.41973\n",
      "Epoch 1345/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 0.7659 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01345: val_loss did not improve from 0.41973\n",
      "Epoch 1346/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9014 - val_loss: 0.7599 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01346: val_loss did not improve from 0.41973\n",
      "Epoch 1347/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.8988 - val_loss: 0.7574 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01347: val_loss did not improve from 0.41973\n",
      "Epoch 1348/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.8988 - val_loss: 0.7678 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01348: val_loss did not improve from 0.41973\n",
      "Epoch 1349/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.8988 - val_loss: 0.7822 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01349: val_loss did not improve from 0.41973\n",
      "Epoch 1350/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 0.7413 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01350: val_loss did not improve from 0.41973\n",
      "Epoch 1351/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.8988 - val_loss: 0.7521 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01351: val_loss did not improve from 0.41973\n",
      "Epoch 1352/4000\n",
      "25/25 - 0s - loss: 0.2028 - accuracy: 0.8975 - val_loss: 0.7641 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01352: val_loss did not improve from 0.41973\n",
      "Epoch 1353/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.8988 - val_loss: 0.7877 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01353: val_loss did not improve from 0.41973\n",
      "Epoch 1354/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.8988 - val_loss: 0.7897 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01354: val_loss did not improve from 0.41973\n",
      "Epoch 1355/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.8988 - val_loss: 0.8172 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01355: val_loss did not improve from 0.41973\n",
      "Epoch 1356/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 0.8013 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01356: val_loss did not improve from 0.41973\n",
      "Epoch 1357/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9001 - val_loss: 0.7979 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01357: val_loss did not improve from 0.41973\n",
      "Epoch 1358/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9014 - val_loss: 0.7754 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01358: val_loss did not improve from 0.41973\n",
      "Epoch 1359/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9027 - val_loss: 0.7992 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01359: val_loss did not improve from 0.41973\n",
      "Epoch 1360/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9001 - val_loss: 0.7569 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01360: val_loss did not improve from 0.41973\n",
      "Epoch 1361/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9001 - val_loss: 0.8017 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01361: val_loss did not improve from 0.41973\n",
      "Epoch 1362/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8988 - val_loss: 0.8003 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01362: val_loss did not improve from 0.41973\n",
      "Epoch 1363/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 0.7972 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01363: val_loss did not improve from 0.41973\n",
      "Epoch 1364/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9014 - val_loss: 0.7890 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01364: val_loss did not improve from 0.41973\n",
      "Epoch 1365/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9014 - val_loss: 0.7775 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01365: val_loss did not improve from 0.41973\n",
      "Epoch 1366/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.8923 - val_loss: 0.7329 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01366: val_loss did not improve from 0.41973\n",
      "Epoch 1367/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.8975 - val_loss: 0.7352 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01367: val_loss did not improve from 0.41973\n",
      "Epoch 1368/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.8988 - val_loss: 0.7394 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01368: val_loss did not improve from 0.41973\n",
      "Epoch 1369/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9014 - val_loss: 0.7445 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01369: val_loss did not improve from 0.41973\n",
      "Epoch 1370/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.8988 - val_loss: 0.7209 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01370: val_loss did not improve from 0.41973\n",
      "Epoch 1371/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9001 - val_loss: 0.7225 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01371: val_loss did not improve from 0.41973\n",
      "Epoch 1372/4000\n",
      "25/25 - 0s - loss: 0.2043 - accuracy: 0.8988 - val_loss: 0.7676 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01372: val_loss did not improve from 0.41973\n",
      "Epoch 1373/4000\n",
      "25/25 - 0s - loss: 0.2026 - accuracy: 0.8949 - val_loss: 0.7464 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01373: val_loss did not improve from 0.41973\n",
      "Epoch 1374/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9001 - val_loss: 0.7470 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01374: val_loss did not improve from 0.41973\n",
      "Epoch 1375/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.8975 - val_loss: 0.7381 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01375: val_loss did not improve from 0.41973\n",
      "Epoch 1376/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9014 - val_loss: 0.7316 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01376: val_loss did not improve from 0.41973\n",
      "Epoch 1377/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.8975 - val_loss: 0.7212 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01377: val_loss did not improve from 0.41973\n",
      "Epoch 1378/4000\n",
      "25/25 - 0s - loss: 0.2039 - accuracy: 0.9027 - val_loss: 0.7605 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01378: val_loss did not improve from 0.41973\n",
      "Epoch 1379/4000\n",
      "25/25 - 0s - loss: 0.2035 - accuracy: 0.9027 - val_loss: 0.7094 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01379: val_loss did not improve from 0.41973\n",
      "Epoch 1380/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9014 - val_loss: 0.7205 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01380: val_loss did not improve from 0.41973\n",
      "Epoch 1381/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9014 - val_loss: 0.7173 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01381: val_loss did not improve from 0.41973\n",
      "Epoch 1382/4000\n",
      "25/25 - 0s - loss: 0.2031 - accuracy: 0.9014 - val_loss: 0.7317 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01382: val_loss did not improve from 0.41973\n",
      "Epoch 1383/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.8975 - val_loss: 0.7568 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01383: val_loss did not improve from 0.41973\n",
      "Epoch 1384/4000\n",
      "25/25 - 0s - loss: 0.2029 - accuracy: 0.9014 - val_loss: 0.7334 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01384: val_loss did not improve from 0.41973\n",
      "Epoch 1385/4000\n",
      "25/25 - 0s - loss: 0.2027 - accuracy: 0.9014 - val_loss: 0.7493 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01385: val_loss did not improve from 0.41973\n",
      "Epoch 1386/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.8975 - val_loss: 0.7092 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01386: val_loss did not improve from 0.41973\n",
      "Epoch 1387/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.8988 - val_loss: 0.7227 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01387: val_loss did not improve from 0.41973\n",
      "Epoch 1388/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.8975 - val_loss: 0.7414 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01388: val_loss did not improve from 0.41973\n",
      "Epoch 1389/4000\n",
      "25/25 - 0s - loss: 0.2041 - accuracy: 0.8988 - val_loss: 0.8139 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01389: val_loss did not improve from 0.41973\n",
      "Epoch 1390/4000\n",
      "25/25 - 0s - loss: 0.2078 - accuracy: 0.8975 - val_loss: 0.8004 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01390: val_loss did not improve from 0.41973\n",
      "Epoch 1391/4000\n",
      "25/25 - 0s - loss: 0.2099 - accuracy: 0.8975 - val_loss: 0.6757 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01391: val_loss did not improve from 0.41973\n",
      "Epoch 1392/4000\n",
      "25/25 - 0s - loss: 0.2178 - accuracy: 0.8975 - val_loss: 0.8415 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01392: val_loss did not improve from 0.41973\n",
      "Epoch 1393/4000\n",
      "25/25 - 0s - loss: 0.2366 - accuracy: 0.9001 - val_loss: 0.6850 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01393: val_loss did not improve from 0.41973\n",
      "Epoch 1394/4000\n",
      "25/25 - 0s - loss: 0.2071 - accuracy: 0.9001 - val_loss: 0.6957 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01394: val_loss did not improve from 0.41973\n",
      "Epoch 1395/4000\n",
      "25/25 - 0s - loss: 0.2058 - accuracy: 0.8962 - val_loss: 0.6566 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01395: val_loss did not improve from 0.41973\n",
      "Epoch 1396/4000\n",
      "25/25 - 0s - loss: 0.2032 - accuracy: 0.9001 - val_loss: 0.7058 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01396: val_loss did not improve from 0.41973\n",
      "Epoch 1397/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.9001 - val_loss: 0.7224 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01397: val_loss did not improve from 0.41973\n",
      "Epoch 1398/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.8962 - val_loss: 0.7261 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01398: val_loss did not improve from 0.41973\n",
      "Epoch 1399/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.8975 - val_loss: 0.7345 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01399: val_loss did not improve from 0.41973\n",
      "Epoch 1400/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9001 - val_loss: 0.7467 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01400: val_loss did not improve from 0.41973\n",
      "Epoch 1401/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.8936 - val_loss: 0.7574 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01401: val_loss did not improve from 0.41973\n",
      "Epoch 1402/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9001 - val_loss: 0.7576 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01402: val_loss did not improve from 0.41973\n",
      "Epoch 1403/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8975 - val_loss: 0.7463 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01403: val_loss did not improve from 0.41973\n",
      "Epoch 1404/4000\n",
      "25/25 - 0s - loss: 0.2031 - accuracy: 0.9027 - val_loss: 0.7543 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01404: val_loss did not improve from 0.41973\n",
      "Epoch 1405/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.9014 - val_loss: 0.7511 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01405: val_loss did not improve from 0.41973\n",
      "Epoch 1406/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.8975 - val_loss: 0.7485 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01406: val_loss did not improve from 0.41973\n",
      "Epoch 1407/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9027 - val_loss: 0.7523 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01407: val_loss did not improve from 0.41973\n",
      "Epoch 1408/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8988 - val_loss: 0.7558 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01408: val_loss did not improve from 0.41973\n",
      "Epoch 1409/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.9027 - val_loss: 0.7657 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01409: val_loss did not improve from 0.41973\n",
      "Epoch 1410/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9027 - val_loss: 0.7581 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01410: val_loss did not improve from 0.41973\n",
      "Epoch 1411/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 0.7627 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01411: val_loss did not improve from 0.41973\n",
      "Epoch 1412/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.8988 - val_loss: 0.7622 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01412: val_loss did not improve from 0.41973\n",
      "Epoch 1413/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9014 - val_loss: 0.7604 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01413: val_loss did not improve from 0.41973\n",
      "Epoch 1414/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9027 - val_loss: 0.7543 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01414: val_loss did not improve from 0.41973\n",
      "Epoch 1415/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 0.7572 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01415: val_loss did not improve from 0.41973\n",
      "Epoch 1416/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 0.7560 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01416: val_loss did not improve from 0.41973\n",
      "Epoch 1417/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.8962 - val_loss: 0.7520 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01417: val_loss did not improve from 0.41973\n",
      "Epoch 1418/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8988 - val_loss: 0.7585 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01418: val_loss did not improve from 0.41973\n",
      "Epoch 1419/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 0.7692 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01419: val_loss did not improve from 0.41973\n",
      "Epoch 1420/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9001 - val_loss: 0.7624 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01420: val_loss did not improve from 0.41973\n",
      "Epoch 1421/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9001 - val_loss: 0.7564 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01421: val_loss did not improve from 0.41973\n",
      "Epoch 1422/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.8988 - val_loss: 0.7661 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01422: val_loss did not improve from 0.41973\n",
      "Epoch 1423/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 0.7589 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01423: val_loss did not improve from 0.41973\n",
      "Epoch 1424/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9027 - val_loss: 0.7508 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01424: val_loss did not improve from 0.41973\n",
      "Epoch 1425/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 0.7617 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01425: val_loss did not improve from 0.41973\n",
      "Epoch 1426/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9040 - val_loss: 0.7745 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01426: val_loss did not improve from 0.41973\n",
      "Epoch 1427/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 0.7715 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01427: val_loss did not improve from 0.41973\n",
      "Epoch 1428/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9001 - val_loss: 0.7897 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01428: val_loss did not improve from 0.41973\n",
      "Epoch 1429/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 0.7947 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01429: val_loss did not improve from 0.41973\n",
      "Epoch 1430/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9053 - val_loss: 0.7851 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01430: val_loss did not improve from 0.41973\n",
      "Epoch 1431/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.9001 - val_loss: 0.7566 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01431: val_loss did not improve from 0.41973\n",
      "Epoch 1432/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9027 - val_loss: 0.7345 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01432: val_loss did not improve from 0.41973\n",
      "Epoch 1433/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9027 - val_loss: 0.7426 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01433: val_loss did not improve from 0.41973\n",
      "Epoch 1434/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9027 - val_loss: 0.7460 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01434: val_loss did not improve from 0.41973\n",
      "Epoch 1435/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8962 - val_loss: 0.7496 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01435: val_loss did not improve from 0.41973\n",
      "Epoch 1436/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 0.7550 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01436: val_loss did not improve from 0.41973\n",
      "Epoch 1437/4000\n",
      "25/25 - 0s - loss: 0.2027 - accuracy: 0.9014 - val_loss: 0.7418 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01437: val_loss did not improve from 0.41973\n",
      "Epoch 1438/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.8988 - val_loss: 0.7507 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01438: val_loss did not improve from 0.41973\n",
      "Epoch 1439/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.8988 - val_loss: 0.7558 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01439: val_loss did not improve from 0.41973\n",
      "Epoch 1440/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.8988 - val_loss: 0.7570 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01440: val_loss did not improve from 0.41973\n",
      "Epoch 1441/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.8988 - val_loss: 0.7351 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01441: val_loss did not improve from 0.41973\n",
      "Epoch 1442/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 0.7417 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01442: val_loss did not improve from 0.41973\n",
      "Epoch 1443/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 0.7445 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01443: val_loss did not improve from 0.41973\n",
      "Epoch 1444/4000\n",
      "25/25 - 0s - loss: 0.2027 - accuracy: 0.9001 - val_loss: 0.7576 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01444: val_loss did not improve from 0.41973\n",
      "Epoch 1445/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9001 - val_loss: 0.7621 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01445: val_loss did not improve from 0.41973\n",
      "Epoch 1446/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9014 - val_loss: 0.7430 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01446: val_loss did not improve from 0.41973\n",
      "Epoch 1447/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9001 - val_loss: 0.7468 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01447: val_loss did not improve from 0.41973\n",
      "Epoch 1448/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8988 - val_loss: 0.7378 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01448: val_loss did not improve from 0.41973\n",
      "Epoch 1449/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9001 - val_loss: 0.7593 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01449: val_loss did not improve from 0.41973\n",
      "Epoch 1450/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9001 - val_loss: 0.7668 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01450: val_loss did not improve from 0.41973\n",
      "Epoch 1451/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9014 - val_loss: 0.7723 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01451: val_loss did not improve from 0.41973\n",
      "Epoch 1452/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 0.7791 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01452: val_loss did not improve from 0.41973\n",
      "Epoch 1453/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9014 - val_loss: 0.7783 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01453: val_loss did not improve from 0.41973\n",
      "Epoch 1454/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 0.7766 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01454: val_loss did not improve from 0.41973\n",
      "Epoch 1455/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 0.7759 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01455: val_loss did not improve from 0.41973\n",
      "Epoch 1456/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 0.7756 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01456: val_loss did not improve from 0.41973\n",
      "Epoch 1457/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9014 - val_loss: 0.7774 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01457: val_loss did not improve from 0.41973\n",
      "Epoch 1458/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 0.7885 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01458: val_loss did not improve from 0.41973\n",
      "Epoch 1459/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 0.7831 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01459: val_loss did not improve from 0.41973\n",
      "Epoch 1460/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9001 - val_loss: 0.7709 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01460: val_loss did not improve from 0.41973\n",
      "Epoch 1461/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9001 - val_loss: 0.7757 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01461: val_loss did not improve from 0.41973\n",
      "Epoch 1462/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 0.7727 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01462: val_loss did not improve from 0.41973\n",
      "Epoch 1463/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9014 - val_loss: 0.7965 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01463: val_loss did not improve from 0.41973\n",
      "Epoch 1464/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9014 - val_loss: 0.7903 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01464: val_loss did not improve from 0.41973\n",
      "Epoch 1465/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 0.7914 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01465: val_loss did not improve from 0.41973\n",
      "Epoch 1466/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 0.7858 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01466: val_loss did not improve from 0.41973\n",
      "Epoch 1467/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.8975 - val_loss: 0.7899 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01467: val_loss did not improve from 0.41973\n",
      "Epoch 1468/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9014 - val_loss: 0.7898 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01468: val_loss did not improve from 0.41973\n",
      "Epoch 1469/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 0.7924 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01469: val_loss did not improve from 0.41973\n",
      "Epoch 1470/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 0.7902 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01470: val_loss did not improve from 0.41973\n",
      "Epoch 1471/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8988 - val_loss: 0.7858 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01471: val_loss did not improve from 0.41973\n",
      "Epoch 1472/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 0.7777 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01472: val_loss did not improve from 0.41973\n",
      "Epoch 1473/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 0.7784 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01473: val_loss did not improve from 0.41973\n",
      "Epoch 1474/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.9027 - val_loss: 0.7782 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01474: val_loss did not improve from 0.41973\n",
      "Epoch 1475/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8949 - val_loss: 0.7823 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01475: val_loss did not improve from 0.41973\n",
      "Epoch 1476/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9014 - val_loss: 0.7880 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01476: val_loss did not improve from 0.41973\n",
      "Epoch 1477/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9027 - val_loss: 0.7867 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01477: val_loss did not improve from 0.41973\n",
      "Epoch 1478/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 0.7824 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01478: val_loss did not improve from 0.41973\n",
      "Epoch 1479/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9001 - val_loss: 0.7900 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01479: val_loss did not improve from 0.41973\n",
      "Epoch 1480/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.8975 - val_loss: 0.7757 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01480: val_loss did not improve from 0.41973\n",
      "Epoch 1481/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9014 - val_loss: 0.7852 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01481: val_loss did not improve from 0.41973\n",
      "Epoch 1482/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.9014 - val_loss: 0.7828 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01482: val_loss did not improve from 0.41973\n",
      "Epoch 1483/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.8962 - val_loss: 0.7959 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01483: val_loss did not improve from 0.41973\n",
      "Epoch 1484/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9027 - val_loss: 0.7945 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01484: val_loss did not improve from 0.41973\n",
      "Epoch 1485/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9001 - val_loss: 0.8129 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01485: val_loss did not improve from 0.41973\n",
      "Epoch 1486/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9014 - val_loss: 0.8179 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01486: val_loss did not improve from 0.41973\n",
      "Epoch 1487/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.8988 - val_loss: 0.8178 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01487: val_loss did not improve from 0.41973\n",
      "Epoch 1488/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 0.8242 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01488: val_loss did not improve from 0.41973\n",
      "Epoch 1489/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8988 - val_loss: 0.8147 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01489: val_loss did not improve from 0.41973\n",
      "Epoch 1490/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 0.8048 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01490: val_loss did not improve from 0.41973\n",
      "Epoch 1491/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 0.7994 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01491: val_loss did not improve from 0.41973\n",
      "Epoch 1492/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8975 - val_loss: 0.8026 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01492: val_loss did not improve from 0.41973\n",
      "Epoch 1493/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8975 - val_loss: 0.8033 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01493: val_loss did not improve from 0.41973\n",
      "Epoch 1494/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9014 - val_loss: 0.7931 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01494: val_loss did not improve from 0.41973\n",
      "Epoch 1495/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9027 - val_loss: 0.8057 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01495: val_loss did not improve from 0.41973\n",
      "Epoch 1496/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 0.8005 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01496: val_loss did not improve from 0.41973\n",
      "Epoch 1497/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 0.8113 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01497: val_loss did not improve from 0.41973\n",
      "Epoch 1498/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 0.8291 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01498: val_loss did not improve from 0.41973\n",
      "Epoch 1499/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9014 - val_loss: 0.8346 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01499: val_loss did not improve from 0.41973\n",
      "Epoch 1500/4000\n",
      "25/25 - 0s - loss: 0.2040 - accuracy: 0.8962 - val_loss: 0.8009 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01500: val_loss did not improve from 0.41973\n",
      "Epoch 1501/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9014 - val_loss: 0.8160 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01501: val_loss did not improve from 0.41973\n",
      "Epoch 1502/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.9001 - val_loss: 0.8010 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01502: val_loss did not improve from 0.41973\n",
      "Epoch 1503/4000\n",
      "25/25 - 0s - loss: 0.2027 - accuracy: 0.8949 - val_loss: 0.7958 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01503: val_loss did not improve from 0.41973\n",
      "Epoch 1504/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.8975 - val_loss: 0.8099 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01504: val_loss did not improve from 0.41973\n",
      "Epoch 1505/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9001 - val_loss: 0.8089 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01505: val_loss did not improve from 0.41973\n",
      "Epoch 1506/4000\n",
      "25/25 - 0s - loss: 0.2135 - accuracy: 0.9027 - val_loss: 0.7201 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01506: val_loss did not improve from 0.41973\n",
      "Epoch 1507/4000\n",
      "25/25 - 0s - loss: 0.2052 - accuracy: 0.8975 - val_loss: 0.7041 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01507: val_loss did not improve from 0.41973\n",
      "Epoch 1508/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.8975 - val_loss: 0.7122 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01508: val_loss did not improve from 0.41973\n",
      "Epoch 1509/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.9027 - val_loss: 0.7102 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01509: val_loss did not improve from 0.41973\n",
      "Epoch 1510/4000\n",
      "25/25 - 0s - loss: 0.2190 - accuracy: 0.8975 - val_loss: 0.7879 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01510: val_loss did not improve from 0.41973\n",
      "Epoch 1511/4000\n",
      "25/25 - 0s - loss: 0.2821 - accuracy: 0.8911 - val_loss: 0.7964 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01511: val_loss did not improve from 0.41973\n",
      "Epoch 1512/4000\n",
      "25/25 - 0s - loss: 0.2132 - accuracy: 0.8988 - val_loss: 0.7308 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01512: val_loss did not improve from 0.41973\n",
      "Epoch 1513/4000\n",
      "25/25 - 0s - loss: 0.2063 - accuracy: 0.9027 - val_loss: 0.7761 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01513: val_loss did not improve from 0.41973\n",
      "Epoch 1514/4000\n",
      "25/25 - 0s - loss: 0.2032 - accuracy: 0.8988 - val_loss: 0.8349 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01514: val_loss did not improve from 0.41973\n",
      "Epoch 1515/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.9001 - val_loss: 0.8365 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01515: val_loss did not improve from 0.41973\n",
      "Epoch 1516/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 0.8354 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01516: val_loss did not improve from 0.41973\n",
      "Epoch 1517/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9014 - val_loss: 0.8250 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01517: val_loss did not improve from 0.41973\n",
      "Epoch 1518/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9014 - val_loss: 0.8350 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01518: val_loss did not improve from 0.41973\n",
      "Epoch 1519/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9040 - val_loss: 0.8452 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01519: val_loss did not improve from 0.41973\n",
      "Epoch 1520/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.9027 - val_loss: 0.8482 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01520: val_loss did not improve from 0.41973\n",
      "Epoch 1521/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 0.8299 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01521: val_loss did not improve from 0.41973\n",
      "Epoch 1522/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 0.8166 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01522: val_loss did not improve from 0.41973\n",
      "Epoch 1523/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9014 - val_loss: 0.8177 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01523: val_loss did not improve from 0.41973\n",
      "Epoch 1524/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.8975 - val_loss: 0.8132 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01524: val_loss did not improve from 0.41973\n",
      "Epoch 1525/4000\n",
      "25/25 - 0s - loss: 0.2038 - accuracy: 0.8988 - val_loss: 0.8321 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01525: val_loss did not improve from 0.41973\n",
      "Epoch 1526/4000\n",
      "25/25 - 0s - loss: 0.2037 - accuracy: 0.9014 - val_loss: 0.8213 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01526: val_loss did not improve from 0.41973\n",
      "Epoch 1527/4000\n",
      "25/25 - 0s - loss: 0.2029 - accuracy: 0.9027 - val_loss: 0.8255 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01527: val_loss did not improve from 0.41973\n",
      "Epoch 1528/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.9001 - val_loss: 0.8366 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01528: val_loss did not improve from 0.41973\n",
      "Epoch 1529/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9001 - val_loss: 0.8340 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01529: val_loss did not improve from 0.41973\n",
      "Epoch 1530/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9014 - val_loss: 0.8133 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01530: val_loss did not improve from 0.41973\n",
      "Epoch 1531/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.8988 - val_loss: 0.7961 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01531: val_loss did not improve from 0.41973\n",
      "Epoch 1532/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.8975 - val_loss: 0.8071 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01532: val_loss did not improve from 0.41973\n",
      "Epoch 1533/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 0.8062 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01533: val_loss did not improve from 0.41973\n",
      "Epoch 1534/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8975 - val_loss: 0.8083 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01534: val_loss did not improve from 0.41973\n",
      "Epoch 1535/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 0.8041 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01535: val_loss did not improve from 0.41973\n",
      "Epoch 1536/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9014 - val_loss: 0.8190 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01536: val_loss did not improve from 0.41973\n",
      "Epoch 1537/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9027 - val_loss: 0.8124 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01537: val_loss did not improve from 0.41973\n",
      "Epoch 1538/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9014 - val_loss: 0.8075 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01538: val_loss did not improve from 0.41973\n",
      "Epoch 1539/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 0.8162 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01539: val_loss did not improve from 0.41973\n",
      "Epoch 1540/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 0.8129 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01540: val_loss did not improve from 0.41973\n",
      "Epoch 1541/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 0.8232 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01541: val_loss did not improve from 0.41973\n",
      "Epoch 1542/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8988 - val_loss: 0.8224 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01542: val_loss did not improve from 0.41973\n",
      "Epoch 1543/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.8988 - val_loss: 0.8237 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01543: val_loss did not improve from 0.41973\n",
      "Epoch 1544/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 0.8242 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01544: val_loss did not improve from 0.41973\n",
      "Epoch 1545/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9001 - val_loss: 0.8140 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01545: val_loss did not improve from 0.41973\n",
      "Epoch 1546/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9027 - val_loss: 0.8273 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01546: val_loss did not improve from 0.41973\n",
      "Epoch 1547/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9001 - val_loss: 0.8044 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01547: val_loss did not improve from 0.41973\n",
      "Epoch 1548/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9001 - val_loss: 0.8083 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01548: val_loss did not improve from 0.41973\n",
      "Epoch 1549/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 0.8198 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01549: val_loss did not improve from 0.41973\n",
      "Epoch 1550/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 0.8230 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01550: val_loss did not improve from 0.41973\n",
      "Epoch 1551/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9014 - val_loss: 0.8186 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01551: val_loss did not improve from 0.41973\n",
      "Epoch 1552/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 0.8267 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01552: val_loss did not improve from 0.41973\n",
      "Epoch 1553/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.8988 - val_loss: 0.8250 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01553: val_loss did not improve from 0.41973\n",
      "Epoch 1554/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8988 - val_loss: 0.8304 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01554: val_loss did not improve from 0.41973\n",
      "Epoch 1555/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 0.8313 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01555: val_loss did not improve from 0.41973\n",
      "Epoch 1556/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 0.8268 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01556: val_loss did not improve from 0.41973\n",
      "Epoch 1557/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 0.8363 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01557: val_loss did not improve from 0.41973\n",
      "Epoch 1558/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8988 - val_loss: 0.8306 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01558: val_loss did not improve from 0.41973\n",
      "Epoch 1559/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9001 - val_loss: 0.8354 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01559: val_loss did not improve from 0.41973\n",
      "Epoch 1560/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8975 - val_loss: 0.8435 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01560: val_loss did not improve from 0.41973\n",
      "Epoch 1561/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9001 - val_loss: 0.8604 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01561: val_loss did not improve from 0.41973\n",
      "Epoch 1562/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.8962 - val_loss: 0.8498 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01562: val_loss did not improve from 0.41973\n",
      "Epoch 1563/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9014 - val_loss: 0.8513 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01563: val_loss did not improve from 0.41973\n",
      "Epoch 1564/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 0.8477 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01564: val_loss did not improve from 0.41973\n",
      "Epoch 1565/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8988 - val_loss: 0.8551 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01565: val_loss did not improve from 0.41973\n",
      "Epoch 1566/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.8988 - val_loss: 0.8540 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01566: val_loss did not improve from 0.41973\n",
      "Epoch 1567/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8962 - val_loss: 0.8509 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01567: val_loss did not improve from 0.41973\n",
      "Epoch 1568/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 0.8428 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01568: val_loss did not improve from 0.41973\n",
      "Epoch 1569/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8988 - val_loss: 0.8530 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01569: val_loss did not improve from 0.41973\n",
      "Epoch 1570/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9014 - val_loss: 0.8412 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01570: val_loss did not improve from 0.41973\n",
      "Epoch 1571/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9014 - val_loss: 0.8474 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01571: val_loss did not improve from 0.41973\n",
      "Epoch 1572/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.8988 - val_loss: 0.8504 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01572: val_loss did not improve from 0.41973\n",
      "Epoch 1573/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 0.8529 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01573: val_loss did not improve from 0.41973\n",
      "Epoch 1574/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.8975 - val_loss: 0.8441 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01574: val_loss did not improve from 0.41973\n",
      "Epoch 1575/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 0.8476 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01575: val_loss did not improve from 0.41973\n",
      "Epoch 1576/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9014 - val_loss: 0.8407 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01576: val_loss did not improve from 0.41973\n",
      "Epoch 1577/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 0.8431 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01577: val_loss did not improve from 0.41973\n",
      "Epoch 1578/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.8975 - val_loss: 0.8363 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01578: val_loss did not improve from 0.41973\n",
      "Epoch 1579/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8962 - val_loss: 0.8410 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01579: val_loss did not improve from 0.41973\n",
      "Epoch 1580/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 0.8411 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01580: val_loss did not improve from 0.41973\n",
      "Epoch 1581/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 0.8449 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01581: val_loss did not improve from 0.41973\n",
      "Epoch 1582/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9001 - val_loss: 0.8147 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01582: val_loss did not improve from 0.41973\n",
      "Epoch 1583/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9001 - val_loss: 0.8262 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01583: val_loss did not improve from 0.41973\n",
      "Epoch 1584/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9027 - val_loss: 0.8237 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01584: val_loss did not improve from 0.41973\n",
      "Epoch 1585/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.9014 - val_loss: 0.8429 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01585: val_loss did not improve from 0.41973\n",
      "Epoch 1586/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9027 - val_loss: 0.8435 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01586: val_loss did not improve from 0.41973\n",
      "Epoch 1587/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 0.8432 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01587: val_loss did not improve from 0.41973\n",
      "Epoch 1588/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9053 - val_loss: 0.8458 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01588: val_loss did not improve from 0.41973\n",
      "Epoch 1589/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9014 - val_loss: 0.8383 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01589: val_loss did not improve from 0.41973\n",
      "Epoch 1590/4000\n",
      "25/25 - 0s - loss: 0.2032 - accuracy: 0.9001 - val_loss: 0.8399 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01590: val_loss did not improve from 0.41973\n",
      "Epoch 1591/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.9014 - val_loss: 0.8430 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01591: val_loss did not improve from 0.41973\n",
      "Epoch 1592/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.8988 - val_loss: 0.8470 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01592: val_loss did not improve from 0.41973\n",
      "Epoch 1593/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 0.8522 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01593: val_loss did not improve from 0.41973\n",
      "Epoch 1594/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 0.8567 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01594: val_loss did not improve from 0.41973\n",
      "Epoch 1595/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.8988 - val_loss: 0.8699 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01595: val_loss did not improve from 0.41973\n",
      "Epoch 1596/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9001 - val_loss: 0.8706 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01596: val_loss did not improve from 0.41973\n",
      "Epoch 1597/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 0.8605 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01597: val_loss did not improve from 0.41973\n",
      "Epoch 1598/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9014 - val_loss: 0.8612 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01598: val_loss did not improve from 0.41973\n",
      "Epoch 1599/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9001 - val_loss: 0.8610 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01599: val_loss did not improve from 0.41973\n",
      "Epoch 1600/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9001 - val_loss: 0.8557 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01600: val_loss did not improve from 0.41973\n",
      "Epoch 1601/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 0.8907 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01601: val_loss did not improve from 0.41973\n",
      "Epoch 1602/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 0.9093 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01602: val_loss did not improve from 0.41973\n",
      "Epoch 1603/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 0.9005 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01603: val_loss did not improve from 0.41973\n",
      "Epoch 1604/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 0.8981 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01604: val_loss did not improve from 0.41973\n",
      "Epoch 1605/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 0.9017 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01605: val_loss did not improve from 0.41973\n",
      "Epoch 1606/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9001 - val_loss: 0.9010 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01606: val_loss did not improve from 0.41973\n",
      "Epoch 1607/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 0.8892 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01607: val_loss did not improve from 0.41973\n",
      "Epoch 1608/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 0.8791 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01608: val_loss did not improve from 0.41973\n",
      "Epoch 1609/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.8975 - val_loss: 0.8797 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01609: val_loss did not improve from 0.41973\n",
      "Epoch 1610/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9001 - val_loss: 0.8779 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01610: val_loss did not improve from 0.41973\n",
      "Epoch 1611/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 0.8853 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01611: val_loss did not improve from 0.41973\n",
      "Epoch 1612/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 0.8723 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01612: val_loss did not improve from 0.41973\n",
      "Epoch 1613/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.8988 - val_loss: 0.8596 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01613: val_loss did not improve from 0.41973\n",
      "Epoch 1614/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9014 - val_loss: 0.8621 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01614: val_loss did not improve from 0.41973\n",
      "Epoch 1615/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9027 - val_loss: 0.8642 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01615: val_loss did not improve from 0.41973\n",
      "Epoch 1616/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9014 - val_loss: 0.8421 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01616: val_loss did not improve from 0.41973\n",
      "Epoch 1617/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9014 - val_loss: 0.8328 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01617: val_loss did not improve from 0.41973\n",
      "Epoch 1618/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.8975 - val_loss: 0.8434 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01618: val_loss did not improve from 0.41973\n",
      "Epoch 1619/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 0.8486 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01619: val_loss did not improve from 0.41973\n",
      "Epoch 1620/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9014 - val_loss: 0.8620 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01620: val_loss did not improve from 0.41973\n",
      "Epoch 1621/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9001 - val_loss: 0.8454 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01621: val_loss did not improve from 0.41973\n",
      "Epoch 1622/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9014 - val_loss: 0.8684 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01622: val_loss did not improve from 0.41973\n",
      "Epoch 1623/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.8988 - val_loss: 0.8760 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01623: val_loss did not improve from 0.41973\n",
      "Epoch 1624/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 0.8566 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01624: val_loss did not improve from 0.41973\n",
      "Epoch 1625/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8988 - val_loss: 0.8669 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01625: val_loss did not improve from 0.41973\n",
      "Epoch 1626/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9014 - val_loss: 0.8758 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01626: val_loss did not improve from 0.41973\n",
      "Epoch 1627/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.8988 - val_loss: 0.8746 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01627: val_loss did not improve from 0.41973\n",
      "Epoch 1628/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.8949 - val_loss: 0.8837 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01628: val_loss did not improve from 0.41973\n",
      "Epoch 1629/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9014 - val_loss: 0.8403 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01629: val_loss did not improve from 0.41973\n",
      "Epoch 1630/4000\n",
      "25/25 - 0s - loss: 0.2093 - accuracy: 0.8988 - val_loss: 1.0120 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 01630: val_loss did not improve from 0.41973\n",
      "Epoch 1631/4000\n",
      "25/25 - 0s - loss: 0.2233 - accuracy: 0.8949 - val_loss: 0.8312 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01631: val_loss did not improve from 0.41973\n",
      "Epoch 1632/4000\n",
      "25/25 - 0s - loss: 0.2066 - accuracy: 0.8975 - val_loss: 0.8680 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01632: val_loss did not improve from 0.41973\n",
      "Epoch 1633/4000\n",
      "25/25 - 0s - loss: 0.2044 - accuracy: 0.9014 - val_loss: 0.9003 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01633: val_loss did not improve from 0.41973\n",
      "Epoch 1634/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.8988 - val_loss: 0.9136 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01634: val_loss did not improve from 0.41973\n",
      "Epoch 1635/4000\n",
      "25/25 - 0s - loss: 0.2028 - accuracy: 0.8988 - val_loss: 0.9109 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01635: val_loss did not improve from 0.41973\n",
      "Epoch 1636/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.9027 - val_loss: 0.9200 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01636: val_loss did not improve from 0.41973\n",
      "Epoch 1637/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.8975 - val_loss: 0.9274 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01637: val_loss did not improve from 0.41973\n",
      "Epoch 1638/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9027 - val_loss: 0.9356 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01638: val_loss did not improve from 0.41973\n",
      "Epoch 1639/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9014 - val_loss: 0.9291 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01639: val_loss did not improve from 0.41973\n",
      "Epoch 1640/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9014 - val_loss: 0.9371 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01640: val_loss did not improve from 0.41973\n",
      "Epoch 1641/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.8988 - val_loss: 0.9241 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01641: val_loss did not improve from 0.41973\n",
      "Epoch 1642/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9027 - val_loss: 0.9216 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01642: val_loss did not improve from 0.41973\n",
      "Epoch 1643/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9001 - val_loss: 0.9312 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01643: val_loss did not improve from 0.41973\n",
      "Epoch 1644/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 0.9326 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01644: val_loss did not improve from 0.41973\n",
      "Epoch 1645/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.8962 - val_loss: 0.9482 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01645: val_loss did not improve from 0.41973\n",
      "Epoch 1646/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9001 - val_loss: 0.9408 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01646: val_loss did not improve from 0.41973\n",
      "Epoch 1647/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.8988 - val_loss: 0.9305 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01647: val_loss did not improve from 0.41973\n",
      "Epoch 1648/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.8988 - val_loss: 0.9364 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01648: val_loss did not improve from 0.41973\n",
      "Epoch 1649/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9014 - val_loss: 0.9025 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01649: val_loss did not improve from 0.41973\n",
      "Epoch 1650/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.8962 - val_loss: 0.8841 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01650: val_loss did not improve from 0.41973\n",
      "Epoch 1651/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9001 - val_loss: 0.8868 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01651: val_loss did not improve from 0.41973\n",
      "Epoch 1652/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 0.8742 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01652: val_loss did not improve from 0.41973\n",
      "Epoch 1653/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 0.8905 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01653: val_loss did not improve from 0.41973\n",
      "Epoch 1654/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9027 - val_loss: 0.8776 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01654: val_loss did not improve from 0.41973\n",
      "Epoch 1655/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9027 - val_loss: 0.8819 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01655: val_loss did not improve from 0.41973\n",
      "Epoch 1656/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 0.8499 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01656: val_loss did not improve from 0.41973\n",
      "Epoch 1657/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9027 - val_loss: 0.8567 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01657: val_loss did not improve from 0.41973\n",
      "Epoch 1658/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 0.8580 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01658: val_loss did not improve from 0.41973\n",
      "Epoch 1659/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9014 - val_loss: 0.8638 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01659: val_loss did not improve from 0.41973\n",
      "Epoch 1660/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9040 - val_loss: 0.8683 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01660: val_loss did not improve from 0.41973\n",
      "Epoch 1661/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 0.8714 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01661: val_loss did not improve from 0.41973\n",
      "Epoch 1662/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9014 - val_loss: 0.8794 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01662: val_loss did not improve from 0.41973\n",
      "Epoch 1663/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 0.8739 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01663: val_loss did not improve from 0.41973\n",
      "Epoch 1664/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9027 - val_loss: 0.8724 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01664: val_loss did not improve from 0.41973\n",
      "Epoch 1665/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9014 - val_loss: 0.8814 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01665: val_loss did not improve from 0.41973\n",
      "Epoch 1666/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9014 - val_loss: 0.8739 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01666: val_loss did not improve from 0.41973\n",
      "Epoch 1667/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.8949 - val_loss: 0.8802 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01667: val_loss did not improve from 0.41973\n",
      "Epoch 1668/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9053 - val_loss: 0.8799 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01668: val_loss did not improve from 0.41973\n",
      "Epoch 1669/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 0.8769 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01669: val_loss did not improve from 0.41973\n",
      "Epoch 1670/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8988 - val_loss: 0.8666 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01670: val_loss did not improve from 0.41973\n",
      "Epoch 1671/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 0.8746 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01671: val_loss did not improve from 0.41973\n",
      "Epoch 1672/4000\n",
      "25/25 - 0s - loss: 0.2029 - accuracy: 0.9001 - val_loss: 0.8654 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01672: val_loss did not improve from 0.41973\n",
      "Epoch 1673/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 0.8805 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01673: val_loss did not improve from 0.41973\n",
      "Epoch 1674/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.8988 - val_loss: 0.9019 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01674: val_loss did not improve from 0.41973\n",
      "Epoch 1675/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.8975 - val_loss: 0.8594 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01675: val_loss did not improve from 0.41973\n",
      "Epoch 1676/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.8975 - val_loss: 0.8719 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01676: val_loss did not improve from 0.41973\n",
      "Epoch 1677/4000\n",
      "25/25 - 0s - loss: 0.2034 - accuracy: 0.9027 - val_loss: 0.8785 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01677: val_loss did not improve from 0.41973\n",
      "Epoch 1678/4000\n",
      "25/25 - 0s - loss: 0.2025 - accuracy: 0.9001 - val_loss: 0.9040 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01678: val_loss did not improve from 0.41973\n",
      "Epoch 1679/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9027 - val_loss: 0.9192 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01679: val_loss did not improve from 0.41973\n",
      "Epoch 1680/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9027 - val_loss: 0.9166 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01680: val_loss did not improve from 0.41973\n",
      "Epoch 1681/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9001 - val_loss: 0.9125 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01681: val_loss did not improve from 0.41973\n",
      "Epoch 1682/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9001 - val_loss: 0.9087 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01682: val_loss did not improve from 0.41973\n",
      "Epoch 1683/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9001 - val_loss: 0.9121 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01683: val_loss did not improve from 0.41973\n",
      "Epoch 1684/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 0.9368 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01684: val_loss did not improve from 0.41973\n",
      "Epoch 1685/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 0.9175 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01685: val_loss did not improve from 0.41973\n",
      "Epoch 1686/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9014 - val_loss: 0.9263 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01686: val_loss did not improve from 0.41973\n",
      "Epoch 1687/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9027 - val_loss: 0.9298 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01687: val_loss did not improve from 0.41973\n",
      "Epoch 1688/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9014 - val_loss: 0.9310 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01688: val_loss did not improve from 0.41973\n",
      "Epoch 1689/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 0.9145 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01689: val_loss did not improve from 0.41973\n",
      "Epoch 1690/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 0.9108 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01690: val_loss did not improve from 0.41973\n",
      "Epoch 1691/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.8988 - val_loss: 0.8871 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01691: val_loss did not improve from 0.41973\n",
      "Epoch 1692/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9001 - val_loss: 0.9229 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01692: val_loss did not improve from 0.41973\n",
      "Epoch 1693/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9001 - val_loss: 0.9286 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01693: val_loss did not improve from 0.41973\n",
      "Epoch 1694/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 0.8711 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01694: val_loss did not improve from 0.41973\n",
      "Epoch 1695/4000\n",
      "25/25 - 0s - loss: 0.2027 - accuracy: 0.9001 - val_loss: 0.8499 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01695: val_loss did not improve from 0.41973\n",
      "Epoch 1696/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.9027 - val_loss: 0.8610 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01696: val_loss did not improve from 0.41973\n",
      "Epoch 1697/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9014 - val_loss: 0.8664 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01697: val_loss did not improve from 0.41973\n",
      "Epoch 1698/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9001 - val_loss: 0.8777 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01698: val_loss did not improve from 0.41973\n",
      "Epoch 1699/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 0.8810 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01699: val_loss did not improve from 0.41973\n",
      "Epoch 1700/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8988 - val_loss: 0.8838 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01700: val_loss did not improve from 0.41973\n",
      "Epoch 1701/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8988 - val_loss: 0.8990 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01701: val_loss did not improve from 0.41973\n",
      "Epoch 1702/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9014 - val_loss: 0.8948 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01702: val_loss did not improve from 0.41973\n",
      "Epoch 1703/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 0.9005 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01703: val_loss did not improve from 0.41973\n",
      "Epoch 1704/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9001 - val_loss: 0.9066 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01704: val_loss did not improve from 0.41973\n",
      "Epoch 1705/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9001 - val_loss: 0.9121 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01705: val_loss did not improve from 0.41973\n",
      "Epoch 1706/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9014 - val_loss: 0.9239 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01706: val_loss did not improve from 0.41973\n",
      "Epoch 1707/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9014 - val_loss: 0.9229 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01707: val_loss did not improve from 0.41973\n",
      "Epoch 1708/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9001 - val_loss: 0.9137 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01708: val_loss did not improve from 0.41973\n",
      "Epoch 1709/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9014 - val_loss: 0.9169 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01709: val_loss did not improve from 0.41973\n",
      "Epoch 1710/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8988 - val_loss: 0.9127 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01710: val_loss did not improve from 0.41973\n",
      "Epoch 1711/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8962 - val_loss: 0.9099 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01711: val_loss did not improve from 0.41973\n",
      "Epoch 1712/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 0.9102 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01712: val_loss did not improve from 0.41973\n",
      "Epoch 1713/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9014 - val_loss: 0.9184 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01713: val_loss did not improve from 0.41973\n",
      "Epoch 1714/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 0.9023 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01714: val_loss did not improve from 0.41973\n",
      "Epoch 1715/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 0.9076 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01715: val_loss did not improve from 0.41973\n",
      "Epoch 1716/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9001 - val_loss: 0.8967 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01716: val_loss did not improve from 0.41973\n",
      "Epoch 1717/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 0.9097 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01717: val_loss did not improve from 0.41973\n",
      "Epoch 1718/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9014 - val_loss: 0.9256 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01718: val_loss did not improve from 0.41973\n",
      "Epoch 1719/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.8988 - val_loss: 0.9014 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01719: val_loss did not improve from 0.41973\n",
      "Epoch 1720/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9014 - val_loss: 0.9185 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01720: val_loss did not improve from 0.41973\n",
      "Epoch 1721/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 0.9239 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01721: val_loss did not improve from 0.41973\n",
      "Epoch 1722/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9014 - val_loss: 0.9185 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01722: val_loss did not improve from 0.41973\n",
      "Epoch 1723/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 0.9217 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01723: val_loss did not improve from 0.41973\n",
      "Epoch 1724/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8988 - val_loss: 0.9238 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01724: val_loss did not improve from 0.41973\n",
      "Epoch 1725/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 0.9178 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01725: val_loss did not improve from 0.41973\n",
      "Epoch 1726/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 0.9232 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01726: val_loss did not improve from 0.41973\n",
      "Epoch 1727/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9014 - val_loss: 0.8996 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01727: val_loss did not improve from 0.41973\n",
      "Epoch 1728/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9014 - val_loss: 0.8970 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01728: val_loss did not improve from 0.41973\n",
      "Epoch 1729/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.8988 - val_loss: 0.9036 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01729: val_loss did not improve from 0.41973\n",
      "Epoch 1730/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 0.9001 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01730: val_loss did not improve from 0.41973\n",
      "Epoch 1731/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 0.9113 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01731: val_loss did not improve from 0.41973\n",
      "Epoch 1732/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9001 - val_loss: 0.9043 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01732: val_loss did not improve from 0.41973\n",
      "Epoch 1733/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9001 - val_loss: 0.9047 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01733: val_loss did not improve from 0.41973\n",
      "Epoch 1734/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9027 - val_loss: 0.9133 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01734: val_loss did not improve from 0.41973\n",
      "Epoch 1735/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8988 - val_loss: 0.9099 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01735: val_loss did not improve from 0.41973\n",
      "Epoch 1736/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8988 - val_loss: 0.9059 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01736: val_loss did not improve from 0.41973\n",
      "Epoch 1737/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9001 - val_loss: 0.8932 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01737: val_loss did not improve from 0.41973\n",
      "Epoch 1738/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9001 - val_loss: 0.8873 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01738: val_loss did not improve from 0.41973\n",
      "Epoch 1739/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 0.8803 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01739: val_loss did not improve from 0.41973\n",
      "Epoch 1740/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 0.8825 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01740: val_loss did not improve from 0.41973\n",
      "Epoch 1741/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 0.8954 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01741: val_loss did not improve from 0.41973\n",
      "Epoch 1742/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 0.8949 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01742: val_loss did not improve from 0.41973\n",
      "Epoch 1743/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9014 - val_loss: 0.8674 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01743: val_loss did not improve from 0.41973\n",
      "Epoch 1744/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.8988 - val_loss: 0.8932 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01744: val_loss did not improve from 0.41973\n",
      "Epoch 1745/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8988 - val_loss: 0.9119 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01745: val_loss did not improve from 0.41973\n",
      "Epoch 1746/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9014 - val_loss: 0.9163 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01746: val_loss did not improve from 0.41973\n",
      "Epoch 1747/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9001 - val_loss: 0.9107 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01747: val_loss did not improve from 0.41973\n",
      "Epoch 1748/4000\n",
      "25/25 - 1s - loss: 0.2014 - accuracy: 0.9027 - val_loss: 0.8951 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01748: val_loss did not improve from 0.41973\n",
      "Epoch 1749/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 0.9015 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01749: val_loss did not improve from 0.41973\n",
      "Epoch 1750/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9027 - val_loss: 0.9278 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01750: val_loss did not improve from 0.41973\n",
      "Epoch 1751/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9014 - val_loss: 0.9126 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01751: val_loss did not improve from 0.41973\n",
      "Epoch 1752/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 0.9044 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01752: val_loss did not improve from 0.41973\n",
      "Epoch 1753/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 0.9200 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01753: val_loss did not improve from 0.41973\n",
      "Epoch 1754/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9014 - val_loss: 0.9136 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01754: val_loss did not improve from 0.41973\n",
      "Epoch 1755/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9001 - val_loss: 0.8997 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01755: val_loss did not improve from 0.41973\n",
      "Epoch 1756/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 0.9005 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01756: val_loss did not improve from 0.41973\n",
      "Epoch 1757/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 0.8937 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01757: val_loss did not improve from 0.41973\n",
      "Epoch 1758/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9014 - val_loss: 0.9149 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01758: val_loss did not improve from 0.41973\n",
      "Epoch 1759/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8988 - val_loss: 0.9128 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01759: val_loss did not improve from 0.41973\n",
      "Epoch 1760/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 0.9219 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01760: val_loss did not improve from 0.41973\n",
      "Epoch 1761/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8988 - val_loss: 0.8724 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01761: val_loss did not improve from 0.41973\n",
      "Epoch 1762/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 0.8799 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01762: val_loss did not improve from 0.41973\n",
      "Epoch 1763/4000\n",
      "25/25 - 0s - loss: 0.2037 - accuracy: 0.9001 - val_loss: 0.8864 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01763: val_loss did not improve from 0.41973\n",
      "Epoch 1764/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9040 - val_loss: 0.8975 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01764: val_loss did not improve from 0.41973\n",
      "Epoch 1765/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 0.8938 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01765: val_loss did not improve from 0.41973\n",
      "Epoch 1766/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9001 - val_loss: 0.8664 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01766: val_loss did not improve from 0.41973\n",
      "Epoch 1767/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 0.8809 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01767: val_loss did not improve from 0.41973\n",
      "Epoch 1768/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9014 - val_loss: 0.9192 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01768: val_loss did not improve from 0.41973\n",
      "Epoch 1769/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8988 - val_loss: 0.9175 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01769: val_loss did not improve from 0.41973\n",
      "Epoch 1770/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 0.9081 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01770: val_loss did not improve from 0.41973\n",
      "Epoch 1771/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9014 - val_loss: 0.9381 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01771: val_loss did not improve from 0.41973\n",
      "Epoch 1772/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.8975 - val_loss: 0.8824 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01772: val_loss did not improve from 0.41973\n",
      "Epoch 1773/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.8988 - val_loss: 0.8936 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01773: val_loss did not improve from 0.41973\n",
      "Epoch 1774/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8975 - val_loss: 0.9033 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01774: val_loss did not improve from 0.41973\n",
      "Epoch 1775/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.8975 - val_loss: 0.9026 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01775: val_loss did not improve from 0.41973\n",
      "Epoch 1776/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.8936 - val_loss: 0.8910 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01776: val_loss did not improve from 0.41973\n",
      "Epoch 1777/4000\n",
      "25/25 - 0s - loss: 0.2027 - accuracy: 0.8975 - val_loss: 0.8946 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01777: val_loss did not improve from 0.41973\n",
      "Epoch 1778/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9014 - val_loss: 0.9260 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01778: val_loss did not improve from 0.41973\n",
      "Epoch 1779/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9014 - val_loss: 0.9240 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01779: val_loss did not improve from 0.41973\n",
      "Epoch 1780/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9001 - val_loss: 0.9116 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01780: val_loss did not improve from 0.41973\n",
      "Epoch 1781/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.8988 - val_loss: 0.9155 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01781: val_loss did not improve from 0.41973\n",
      "Epoch 1782/4000\n",
      "25/25 - 0s - loss: 0.2198 - accuracy: 0.9001 - val_loss: 0.9054 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01782: val_loss did not improve from 0.41973\n",
      "Epoch 1783/4000\n",
      "25/25 - 0s - loss: 0.2105 - accuracy: 0.8988 - val_loss: 0.9378 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01783: val_loss did not improve from 0.41973\n",
      "Epoch 1784/4000\n",
      "25/25 - 0s - loss: 0.2261 - accuracy: 0.8988 - val_loss: 1.0917 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01784: val_loss did not improve from 0.41973\n",
      "Epoch 1785/4000\n",
      "25/25 - 0s - loss: 0.2411 - accuracy: 0.8988 - val_loss: 1.1574 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01785: val_loss did not improve from 0.41973\n",
      "Epoch 1786/4000\n",
      "25/25 - 0s - loss: 0.2215 - accuracy: 0.8962 - val_loss: 0.8931 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01786: val_loss did not improve from 0.41973\n",
      "Epoch 1787/4000\n",
      "25/25 - 0s - loss: 0.2172 - accuracy: 0.9001 - val_loss: 0.9227 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01787: val_loss did not improve from 0.41973\n",
      "Epoch 1788/4000\n",
      "25/25 - 0s - loss: 0.2070 - accuracy: 0.9014 - val_loss: 0.8158 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01788: val_loss did not improve from 0.41973\n",
      "Epoch 1789/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9001 - val_loss: 0.8064 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01789: val_loss did not improve from 0.41973\n",
      "Epoch 1790/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9027 - val_loss: 0.8125 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01790: val_loss did not improve from 0.41973\n",
      "Epoch 1791/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.9014 - val_loss: 0.8049 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01791: val_loss did not improve from 0.41973\n",
      "Epoch 1792/4000\n",
      "25/25 - 1s - loss: 0.2036 - accuracy: 0.9014 - val_loss: 0.8309 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01792: val_loss did not improve from 0.41973\n",
      "Epoch 1793/4000\n",
      "25/25 - 0s - loss: 0.2041 - accuracy: 0.9001 - val_loss: 0.8433 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01793: val_loss did not improve from 0.41973\n",
      "Epoch 1794/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9027 - val_loss: 0.8757 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01794: val_loss did not improve from 0.41973\n",
      "Epoch 1795/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9027 - val_loss: 0.8665 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01795: val_loss did not improve from 0.41973\n",
      "Epoch 1796/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9027 - val_loss: 0.8851 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01796: val_loss did not improve from 0.41973\n",
      "Epoch 1797/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9014 - val_loss: 0.8850 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01797: val_loss did not improve from 0.41973\n",
      "Epoch 1798/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 0.8835 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01798: val_loss did not improve from 0.41973\n",
      "Epoch 1799/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8988 - val_loss: 0.8719 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01799: val_loss did not improve from 0.41973\n",
      "Epoch 1800/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9014 - val_loss: 0.8751 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01800: val_loss did not improve from 0.41973\n",
      "Epoch 1801/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9014 - val_loss: 0.8845 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01801: val_loss did not improve from 0.41973\n",
      "Epoch 1802/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9027 - val_loss: 0.8882 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01802: val_loss did not improve from 0.41973\n",
      "Epoch 1803/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 0.8879 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01803: val_loss did not improve from 0.41973\n",
      "Epoch 1804/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 0.8799 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01804: val_loss did not improve from 0.41973\n",
      "Epoch 1805/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 0.8765 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01805: val_loss did not improve from 0.41973\n",
      "Epoch 1806/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 0.8798 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01806: val_loss did not improve from 0.41973\n",
      "Epoch 1807/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 0.8726 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01807: val_loss did not improve from 0.41973\n",
      "Epoch 1808/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.9001 - val_loss: 0.8659 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01808: val_loss did not improve from 0.41973\n",
      "Epoch 1809/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.8988 - val_loss: 0.8416 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01809: val_loss did not improve from 0.41973\n",
      "Epoch 1810/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.8988 - val_loss: 0.8420 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01810: val_loss did not improve from 0.41973\n",
      "Epoch 1811/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 0.8563 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01811: val_loss did not improve from 0.41973\n",
      "Epoch 1812/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9053 - val_loss: 0.8547 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01812: val_loss did not improve from 0.41973\n",
      "Epoch 1813/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 0.8578 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01813: val_loss did not improve from 0.41973\n",
      "Epoch 1814/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9001 - val_loss: 0.8610 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01814: val_loss did not improve from 0.41973\n",
      "Epoch 1815/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.8975 - val_loss: 0.8606 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01815: val_loss did not improve from 0.41973\n",
      "Epoch 1816/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.8975 - val_loss: 0.8675 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01816: val_loss did not improve from 0.41973\n",
      "Epoch 1817/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 0.8871 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01817: val_loss did not improve from 0.41973\n",
      "Epoch 1818/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.8975 - val_loss: 0.8824 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01818: val_loss did not improve from 0.41973\n",
      "Epoch 1819/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9014 - val_loss: 0.8822 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01819: val_loss did not improve from 0.41973\n",
      "Epoch 1820/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 0.8712 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01820: val_loss did not improve from 0.41973\n",
      "Epoch 1821/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9014 - val_loss: 0.8858 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01821: val_loss did not improve from 0.41973\n",
      "Epoch 1822/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9001 - val_loss: 0.8888 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01822: val_loss did not improve from 0.41973\n",
      "Epoch 1823/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9014 - val_loss: 0.8864 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01823: val_loss did not improve from 0.41973\n",
      "Epoch 1824/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 0.9051 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01824: val_loss did not improve from 0.41973\n",
      "Epoch 1825/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9027 - val_loss: 0.9030 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01825: val_loss did not improve from 0.41973\n",
      "Epoch 1826/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 0.9099 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01826: val_loss did not improve from 0.41973\n",
      "Epoch 1827/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 0.9125 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01827: val_loss did not improve from 0.41973\n",
      "Epoch 1828/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 0.9212 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01828: val_loss did not improve from 0.41973\n",
      "Epoch 1829/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9040 - val_loss: 0.9317 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01829: val_loss did not improve from 0.41973\n",
      "Epoch 1830/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8975 - val_loss: 0.9178 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01830: val_loss did not improve from 0.41973\n",
      "Epoch 1831/4000\n",
      "25/25 - 0s - loss: 0.2184 - accuracy: 0.8975 - val_loss: 0.9840 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01831: val_loss did not improve from 0.41973\n",
      "Epoch 1832/4000\n",
      "25/25 - 0s - loss: 0.2148 - accuracy: 0.9014 - val_loss: 1.0322 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01832: val_loss did not improve from 0.41973\n",
      "Epoch 1833/4000\n",
      "25/25 - 0s - loss: 0.2049 - accuracy: 0.9014 - val_loss: 1.0113 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01833: val_loss did not improve from 0.41973\n",
      "Epoch 1834/4000\n",
      "25/25 - 0s - loss: 0.2048 - accuracy: 0.8936 - val_loss: 1.0207 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01834: val_loss did not improve from 0.41973\n",
      "Epoch 1835/4000\n",
      "25/25 - 0s - loss: 0.2037 - accuracy: 0.9027 - val_loss: 1.0146 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01835: val_loss did not improve from 0.41973\n",
      "Epoch 1836/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.9001 - val_loss: 0.9880 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01836: val_loss did not improve from 0.41973\n",
      "Epoch 1837/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9014 - val_loss: 0.9957 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01837: val_loss did not improve from 0.41973\n",
      "Epoch 1838/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9014 - val_loss: 0.9805 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01838: val_loss did not improve from 0.41973\n",
      "Epoch 1839/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9014 - val_loss: 0.9920 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01839: val_loss did not improve from 0.41973\n",
      "Epoch 1840/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 0.9960 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01840: val_loss did not improve from 0.41973\n",
      "Epoch 1841/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9027 - val_loss: 1.0036 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01841: val_loss did not improve from 0.41973\n",
      "Epoch 1842/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 1.0006 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01842: val_loss did not improve from 0.41973\n",
      "Epoch 1843/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9014 - val_loss: 1.0004 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01843: val_loss did not improve from 0.41973\n",
      "Epoch 1844/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8949 - val_loss: 1.0020 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01844: val_loss did not improve from 0.41973\n",
      "Epoch 1845/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.8975 - val_loss: 1.0033 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01845: val_loss did not improve from 0.41973\n",
      "Epoch 1846/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 0.9915 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01846: val_loss did not improve from 0.41973\n",
      "Epoch 1847/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 0.9886 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01847: val_loss did not improve from 0.41973\n",
      "Epoch 1848/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.8988 - val_loss: 0.9988 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01848: val_loss did not improve from 0.41973\n",
      "Epoch 1849/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9001 - val_loss: 0.9958 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01849: val_loss did not improve from 0.41973\n",
      "Epoch 1850/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.8988 - val_loss: 0.9941 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01850: val_loss did not improve from 0.41973\n",
      "Epoch 1851/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 1.0013 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01851: val_loss did not improve from 0.41973\n",
      "Epoch 1852/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8988 - val_loss: 1.0075 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01852: val_loss did not improve from 0.41973\n",
      "Epoch 1853/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9027 - val_loss: 0.9979 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01853: val_loss did not improve from 0.41973\n",
      "Epoch 1854/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9027 - val_loss: 0.9983 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01854: val_loss did not improve from 0.41973\n",
      "Epoch 1855/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9014 - val_loss: 1.0068 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01855: val_loss did not improve from 0.41973\n",
      "Epoch 1856/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 1.0082 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01856: val_loss did not improve from 0.41973\n",
      "Epoch 1857/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 0.9512 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01857: val_loss did not improve from 0.41973\n",
      "Epoch 1858/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9001 - val_loss: 0.9480 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01858: val_loss did not improve from 0.41973\n",
      "Epoch 1859/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9027 - val_loss: 0.9528 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01859: val_loss did not improve from 0.41973\n",
      "Epoch 1860/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9027 - val_loss: 0.9554 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01860: val_loss did not improve from 0.41973\n",
      "Epoch 1861/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 0.9590 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01861: val_loss did not improve from 0.41973\n",
      "Epoch 1862/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9027 - val_loss: 0.9576 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01862: val_loss did not improve from 0.41973\n",
      "Epoch 1863/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 0.9751 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01863: val_loss did not improve from 0.41973\n",
      "Epoch 1864/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8988 - val_loss: 0.9638 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01864: val_loss did not improve from 0.41973\n",
      "Epoch 1865/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 0.9679 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01865: val_loss did not improve from 0.41973\n",
      "Epoch 1866/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.8962 - val_loss: 0.9649 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01866: val_loss did not improve from 0.41973\n",
      "Epoch 1867/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 0.9672 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01867: val_loss did not improve from 0.41973\n",
      "Epoch 1868/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 0.9626 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01868: val_loss did not improve from 0.41973\n",
      "Epoch 1869/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 0.9548 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01869: val_loss did not improve from 0.41973\n",
      "Epoch 1870/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 0.9676 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01870: val_loss did not improve from 0.41973\n",
      "Epoch 1871/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 0.9580 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01871: val_loss did not improve from 0.41973\n",
      "Epoch 1872/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 0.9576 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01872: val_loss did not improve from 0.41973\n",
      "Epoch 1873/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8949 - val_loss: 0.9664 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01873: val_loss did not improve from 0.41973\n",
      "Epoch 1874/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9001 - val_loss: 1.0028 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01874: val_loss did not improve from 0.41973\n",
      "Epoch 1875/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9027 - val_loss: 0.9551 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01875: val_loss did not improve from 0.41973\n",
      "Epoch 1876/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 0.9535 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01876: val_loss did not improve from 0.41973\n",
      "Epoch 1877/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8975 - val_loss: 0.9551 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01877: val_loss did not improve from 0.41973\n",
      "Epoch 1878/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9014 - val_loss: 0.9513 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01878: val_loss did not improve from 0.41973\n",
      "Epoch 1879/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 0.9556 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01879: val_loss did not improve from 0.41973\n",
      "Epoch 1880/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.8988 - val_loss: 0.9611 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01880: val_loss did not improve from 0.41973\n",
      "Epoch 1881/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 0.9403 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01881: val_loss did not improve from 0.41973\n",
      "Epoch 1882/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9001 - val_loss: 0.9257 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01882: val_loss did not improve from 0.41973\n",
      "Epoch 1883/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 0.9202 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01883: val_loss did not improve from 0.41973\n",
      "Epoch 1884/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8988 - val_loss: 0.9331 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01884: val_loss did not improve from 0.41973\n",
      "Epoch 1885/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8975 - val_loss: 0.9410 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01885: val_loss did not improve from 0.41973\n",
      "Epoch 1886/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 0.9311 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01886: val_loss did not improve from 0.41973\n",
      "Epoch 1887/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 0.9408 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01887: val_loss did not improve from 0.41973\n",
      "Epoch 1888/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 0.9618 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01888: val_loss did not improve from 0.41973\n",
      "Epoch 1889/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 0.9501 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01889: val_loss did not improve from 0.41973\n",
      "Epoch 1890/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9040 - val_loss: 0.9273 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01890: val_loss did not improve from 0.41973\n",
      "Epoch 1891/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9014 - val_loss: 0.9454 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01891: val_loss did not improve from 0.41973\n",
      "Epoch 1892/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9001 - val_loss: 0.9490 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01892: val_loss did not improve from 0.41973\n",
      "Epoch 1893/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9040 - val_loss: 0.9367 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01893: val_loss did not improve from 0.41973\n",
      "Epoch 1894/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 0.9357 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01894: val_loss did not improve from 0.41973\n",
      "Epoch 1895/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9014 - val_loss: 0.9391 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01895: val_loss did not improve from 0.41973\n",
      "Epoch 1896/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 0.9341 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01896: val_loss did not improve from 0.41973\n",
      "Epoch 1897/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 0.9281 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01897: val_loss did not improve from 0.41973\n",
      "Epoch 1898/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 0.9405 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01898: val_loss did not improve from 0.41973\n",
      "Epoch 1899/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 0.9572 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01899: val_loss did not improve from 0.41973\n",
      "Epoch 1900/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9001 - val_loss: 0.9474 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01900: val_loss did not improve from 0.41973\n",
      "Epoch 1901/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9014 - val_loss: 0.9537 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01901: val_loss did not improve from 0.41973\n",
      "Epoch 1902/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 0.9637 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01902: val_loss did not improve from 0.41973\n",
      "Epoch 1903/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 0.9546 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01903: val_loss did not improve from 0.41973\n",
      "Epoch 1904/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 0.9503 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01904: val_loss did not improve from 0.41973\n",
      "Epoch 1905/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8988 - val_loss: 0.9580 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01905: val_loss did not improve from 0.41973\n",
      "Epoch 1906/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 0.9635 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01906: val_loss did not improve from 0.41973\n",
      "Epoch 1907/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.8975 - val_loss: 0.9510 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01907: val_loss did not improve from 0.41973\n",
      "Epoch 1908/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9001 - val_loss: 0.9517 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01908: val_loss did not improve from 0.41973\n",
      "Epoch 1909/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 0.9518 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01909: val_loss did not improve from 0.41973\n",
      "Epoch 1910/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9001 - val_loss: 0.9681 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01910: val_loss did not improve from 0.41973\n",
      "Epoch 1911/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 0.9736 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01911: val_loss did not improve from 0.41973\n",
      "Epoch 1912/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8975 - val_loss: 0.9851 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01912: val_loss did not improve from 0.41973\n",
      "Epoch 1913/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.8988 - val_loss: 0.9940 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01913: val_loss did not improve from 0.41973\n",
      "Epoch 1914/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9014 - val_loss: 0.9882 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01914: val_loss did not improve from 0.41973\n",
      "Epoch 1915/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9001 - val_loss: 0.9930 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01915: val_loss did not improve from 0.41973\n",
      "Epoch 1916/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9001 - val_loss: 0.9854 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01916: val_loss did not improve from 0.41973\n",
      "Epoch 1917/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8975 - val_loss: 0.9945 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01917: val_loss did not improve from 0.41973\n",
      "Epoch 1918/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 0.9908 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01918: val_loss did not improve from 0.41973\n",
      "Epoch 1919/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 0.9835 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01919: val_loss did not improve from 0.41973\n",
      "Epoch 1920/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8975 - val_loss: 0.9868 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01920: val_loss did not improve from 0.41973\n",
      "Epoch 1921/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.8988 - val_loss: 0.9994 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01921: val_loss did not improve from 0.41973\n",
      "Epoch 1922/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8975 - val_loss: 0.9967 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01922: val_loss did not improve from 0.41973\n",
      "Epoch 1923/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8975 - val_loss: 0.9905 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01923: val_loss did not improve from 0.41973\n",
      "Epoch 1924/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 1.0145 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01924: val_loss did not improve from 0.41973\n",
      "Epoch 1925/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.0435 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01925: val_loss did not improve from 0.41973\n",
      "Epoch 1926/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.0252 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01926: val_loss did not improve from 0.41973\n",
      "Epoch 1927/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.0192 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01927: val_loss did not improve from 0.41973\n",
      "Epoch 1928/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9027 - val_loss: 1.0162 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01928: val_loss did not improve from 0.41973\n",
      "Epoch 1929/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.0061 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01929: val_loss did not improve from 0.41973\n",
      "Epoch 1930/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 1.0105 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01930: val_loss did not improve from 0.41973\n",
      "Epoch 1931/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 1.0090 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01931: val_loss did not improve from 0.41973\n",
      "Epoch 1932/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9014 - val_loss: 1.0080 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01932: val_loss did not improve from 0.41973\n",
      "Epoch 1933/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.0149 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01933: val_loss did not improve from 0.41973\n",
      "Epoch 1934/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 1.0093 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01934: val_loss did not improve from 0.41973\n",
      "Epoch 1935/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.8988 - val_loss: 1.0267 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01935: val_loss did not improve from 0.41973\n",
      "Epoch 1936/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.0140 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01936: val_loss did not improve from 0.41973\n",
      "Epoch 1937/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9027 - val_loss: 1.0179 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01937: val_loss did not improve from 0.41973\n",
      "Epoch 1938/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.8988 - val_loss: 0.9883 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01938: val_loss did not improve from 0.41973\n",
      "Epoch 1939/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9027 - val_loss: 0.9693 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01939: val_loss did not improve from 0.41973\n",
      "Epoch 1940/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9014 - val_loss: 0.9804 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01940: val_loss did not improve from 0.41973\n",
      "Epoch 1941/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9027 - val_loss: 0.9876 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01941: val_loss did not improve from 0.41973\n",
      "Epoch 1942/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.9027 - val_loss: 0.9830 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01942: val_loss did not improve from 0.41973\n",
      "Epoch 1943/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.9001 - val_loss: 0.9252 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01943: val_loss did not improve from 0.41973\n",
      "Epoch 1944/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.9040 - val_loss: 0.9827 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01944: val_loss did not improve from 0.41973\n",
      "Epoch 1945/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9027 - val_loss: 1.0184 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01945: val_loss did not improve from 0.41973\n",
      "Epoch 1946/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9027 - val_loss: 1.0410 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01946: val_loss did not improve from 0.41973\n",
      "Epoch 1947/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.8988 - val_loss: 1.0333 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01947: val_loss did not improve from 0.41973\n",
      "Epoch 1948/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.8962 - val_loss: 1.0289 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01948: val_loss did not improve from 0.41973\n",
      "Epoch 1949/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.8975 - val_loss: 0.9474 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01949: val_loss did not improve from 0.41973\n",
      "Epoch 1950/4000\n",
      "25/25 - 0s - loss: 0.2070 - accuracy: 0.9027 - val_loss: 1.0025 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01950: val_loss did not improve from 0.41973\n",
      "Epoch 1951/4000\n",
      "25/25 - 0s - loss: 0.2044 - accuracy: 0.9027 - val_loss: 0.9898 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01951: val_loss did not improve from 0.41973\n",
      "Epoch 1952/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9027 - val_loss: 1.0136 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01952: val_loss did not improve from 0.41973\n",
      "Epoch 1953/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.8975 - val_loss: 1.0136 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01953: val_loss did not improve from 0.41973\n",
      "Epoch 1954/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 1.0260 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01954: val_loss did not improve from 0.41973\n",
      "Epoch 1955/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9001 - val_loss: 1.0319 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01955: val_loss did not improve from 0.41973\n",
      "Epoch 1956/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9053 - val_loss: 1.0489 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01956: val_loss did not improve from 0.41973\n",
      "Epoch 1957/4000\n",
      "25/25 - 0s - loss: 0.2025 - accuracy: 0.8949 - val_loss: 1.0734 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01957: val_loss did not improve from 0.41973\n",
      "Epoch 1958/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9014 - val_loss: 1.0355 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01958: val_loss did not improve from 0.41973\n",
      "Epoch 1959/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 1.0244 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01959: val_loss did not improve from 0.41973\n",
      "Epoch 1960/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 1.0409 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01960: val_loss did not improve from 0.41973\n",
      "Epoch 1961/4000\n",
      "25/25 - 0s - loss: 0.2178 - accuracy: 0.9027 - val_loss: 1.1523 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01961: val_loss did not improve from 0.41973\n",
      "Epoch 1962/4000\n",
      "25/25 - 0s - loss: 0.2028 - accuracy: 0.8988 - val_loss: 0.9704 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01962: val_loss did not improve from 0.41973\n",
      "Epoch 1963/4000\n",
      "25/25 - 0s - loss: 0.2028 - accuracy: 0.8962 - val_loss: 1.0555 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01963: val_loss did not improve from 0.41973\n",
      "Epoch 1964/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9001 - val_loss: 1.0159 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01964: val_loss did not improve from 0.41973\n",
      "Epoch 1965/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.8975 - val_loss: 0.9266 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01965: val_loss did not improve from 0.41973\n",
      "Epoch 1966/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9014 - val_loss: 0.9416 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01966: val_loss did not improve from 0.41973\n",
      "Epoch 1967/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9001 - val_loss: 0.9210 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01967: val_loss did not improve from 0.41973\n",
      "Epoch 1968/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.8988 - val_loss: 0.9554 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01968: val_loss did not improve from 0.41973\n",
      "Epoch 1969/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.8988 - val_loss: 0.9919 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01969: val_loss did not improve from 0.41973\n",
      "Epoch 1970/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9014 - val_loss: 0.9975 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01970: val_loss did not improve from 0.41973\n",
      "Epoch 1971/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 0.9976 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01971: val_loss did not improve from 0.41973\n",
      "Epoch 1972/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8988 - val_loss: 0.9918 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01972: val_loss did not improve from 0.41973\n",
      "Epoch 1973/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 1.0110 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01973: val_loss did not improve from 0.41973\n",
      "Epoch 1974/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9014 - val_loss: 0.9900 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01974: val_loss did not improve from 0.41973\n",
      "Epoch 1975/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9001 - val_loss: 1.0082 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01975: val_loss did not improve from 0.41973\n",
      "Epoch 1976/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9001 - val_loss: 0.9991 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01976: val_loss did not improve from 0.41973\n",
      "Epoch 1977/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9001 - val_loss: 0.9970 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01977: val_loss did not improve from 0.41973\n",
      "Epoch 1978/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 0.9722 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01978: val_loss did not improve from 0.41973\n",
      "Epoch 1979/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8988 - val_loss: 0.9719 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01979: val_loss did not improve from 0.41973\n",
      "Epoch 1980/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9027 - val_loss: 0.9738 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01980: val_loss did not improve from 0.41973\n",
      "Epoch 1981/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9001 - val_loss: 0.9941 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01981: val_loss did not improve from 0.41973\n",
      "Epoch 1982/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9001 - val_loss: 1.0092 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01982: val_loss did not improve from 0.41973\n",
      "Epoch 1983/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 1.0046 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01983: val_loss did not improve from 0.41973\n",
      "Epoch 1984/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9001 - val_loss: 0.9925 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01984: val_loss did not improve from 0.41973\n",
      "Epoch 1985/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 0.9863 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01985: val_loss did not improve from 0.41973\n",
      "Epoch 1986/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 0.9442 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01986: val_loss did not improve from 0.41973\n",
      "Epoch 1987/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 0.9710 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01987: val_loss did not improve from 0.41973\n",
      "Epoch 1988/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9014 - val_loss: 0.9653 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01988: val_loss did not improve from 0.41973\n",
      "Epoch 1989/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 0.9954 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01989: val_loss did not improve from 0.41973\n",
      "Epoch 1990/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 0.9966 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01990: val_loss did not improve from 0.41973\n",
      "Epoch 1991/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8988 - val_loss: 0.9984 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01991: val_loss did not improve from 0.41973\n",
      "Epoch 1992/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.0074 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01992: val_loss did not improve from 0.41973\n",
      "Epoch 1993/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 1.0026 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01993: val_loss did not improve from 0.41973\n",
      "Epoch 1994/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 0.9945 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01994: val_loss did not improve from 0.41973\n",
      "Epoch 1995/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9001 - val_loss: 0.9952 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01995: val_loss did not improve from 0.41973\n",
      "Epoch 1996/4000\n",
      "25/25 - 0s - loss: 0.2027 - accuracy: 0.9014 - val_loss: 1.0284 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01996: val_loss did not improve from 0.41973\n",
      "Epoch 1997/4000\n",
      "25/25 - 0s - loss: 0.2025 - accuracy: 0.8988 - val_loss: 1.0355 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01997: val_loss did not improve from 0.41973\n",
      "Epoch 1998/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9027 - val_loss: 1.0167 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01998: val_loss did not improve from 0.41973\n",
      "Epoch 1999/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 1.0960 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01999: val_loss did not improve from 0.41973\n",
      "Epoch 2000/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.8949 - val_loss: 1.0356 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02000: val_loss did not improve from 0.41973\n",
      "Epoch 2001/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.8936 - val_loss: 1.0223 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02001: val_loss did not improve from 0.41973\n",
      "Epoch 2002/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.8988 - val_loss: 1.0717 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02002: val_loss did not improve from 0.41973\n",
      "Epoch 2003/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9001 - val_loss: 1.0899 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02003: val_loss did not improve from 0.41973\n",
      "Epoch 2004/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9014 - val_loss: 1.0823 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02004: val_loss did not improve from 0.41973\n",
      "Epoch 2005/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 1.0756 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02005: val_loss did not improve from 0.41973\n",
      "Epoch 2006/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8988 - val_loss: 1.0662 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02006: val_loss did not improve from 0.41973\n",
      "Epoch 2007/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9027 - val_loss: 1.0919 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02007: val_loss did not improve from 0.41973\n",
      "Epoch 2008/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9014 - val_loss: 1.0909 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02008: val_loss did not improve from 0.41973\n",
      "Epoch 2009/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 1.0808 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02009: val_loss did not improve from 0.41973\n",
      "Epoch 2010/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.0824 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02010: val_loss did not improve from 0.41973\n",
      "Epoch 2011/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 1.0914 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02011: val_loss did not improve from 0.41973\n",
      "Epoch 2012/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 1.0853 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02012: val_loss did not improve from 0.41973\n",
      "Epoch 2013/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8975 - val_loss: 1.1140 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02013: val_loss did not improve from 0.41973\n",
      "Epoch 2014/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.1204 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02014: val_loss did not improve from 0.41973\n",
      "Epoch 2015/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9040 - val_loss: 1.0965 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02015: val_loss did not improve from 0.41973\n",
      "Epoch 2016/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 1.0867 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02016: val_loss did not improve from 0.41973\n",
      "Epoch 2017/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.0850 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02017: val_loss did not improve from 0.41973\n",
      "Epoch 2018/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.0884 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02018: val_loss did not improve from 0.41973\n",
      "Epoch 2019/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9027 - val_loss: 1.0838 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02019: val_loss did not improve from 0.41973\n",
      "Epoch 2020/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 1.0981 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02020: val_loss did not improve from 0.41973\n",
      "Epoch 2021/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 1.1024 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02021: val_loss did not improve from 0.41973\n",
      "Epoch 2022/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8988 - val_loss: 1.1024 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02022: val_loss did not improve from 0.41973\n",
      "Epoch 2023/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9040 - val_loss: 1.1071 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02023: val_loss did not improve from 0.41973\n",
      "Epoch 2024/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9027 - val_loss: 1.1120 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02024: val_loss did not improve from 0.41973\n",
      "Epoch 2025/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.1048 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02025: val_loss did not improve from 0.41973\n",
      "Epoch 2026/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9014 - val_loss: 1.1154 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02026: val_loss did not improve from 0.41973\n",
      "Epoch 2027/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.1188 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02027: val_loss did not improve from 0.41973\n",
      "Epoch 2028/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9053 - val_loss: 1.0983 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02028: val_loss did not improve from 0.41973\n",
      "Epoch 2029/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8988 - val_loss: 1.1242 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02029: val_loss did not improve from 0.41973\n",
      "Epoch 2030/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 1.1251 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02030: val_loss did not improve from 0.41973\n",
      "Epoch 2031/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9014 - val_loss: 1.1292 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02031: val_loss did not improve from 0.41973\n",
      "Epoch 2032/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 1.1293 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02032: val_loss did not improve from 0.41973\n",
      "Epoch 2033/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 1.1202 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02033: val_loss did not improve from 0.41973\n",
      "Epoch 2034/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 1.1234 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02034: val_loss did not improve from 0.41973\n",
      "Epoch 2035/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 1.1136 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02035: val_loss did not improve from 0.41973\n",
      "Epoch 2036/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 1.1060 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02036: val_loss did not improve from 0.41973\n",
      "Epoch 2037/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 1.0865 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02037: val_loss did not improve from 0.41973\n",
      "Epoch 2038/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 1.1053 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02038: val_loss did not improve from 0.41973\n",
      "Epoch 2039/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 1.1170 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02039: val_loss did not improve from 0.41973\n",
      "Epoch 2040/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.1149 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02040: val_loss did not improve from 0.41973\n",
      "Epoch 2041/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.1225 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02041: val_loss did not improve from 0.41973\n",
      "Epoch 2042/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.1412 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02042: val_loss did not improve from 0.41973\n",
      "Epoch 2043/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 1.1468 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02043: val_loss did not improve from 0.41973\n",
      "Epoch 2044/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9014 - val_loss: 1.1286 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02044: val_loss did not improve from 0.41973\n",
      "Epoch 2045/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9014 - val_loss: 1.1255 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02045: val_loss did not improve from 0.41973\n",
      "Epoch 2046/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.1333 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02046: val_loss did not improve from 0.41973\n",
      "Epoch 2047/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9001 - val_loss: 1.1226 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02047: val_loss did not improve from 0.41973\n",
      "Epoch 2048/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 1.1197 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02048: val_loss did not improve from 0.41973\n",
      "Epoch 2049/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 1.1072 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02049: val_loss did not improve from 0.41973\n",
      "Epoch 2050/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.8962 - val_loss: 1.1002 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02050: val_loss did not improve from 0.41973\n",
      "Epoch 2051/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 1.1086 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02051: val_loss did not improve from 0.41973\n",
      "Epoch 2052/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 1.1089 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02052: val_loss did not improve from 0.41973\n",
      "Epoch 2053/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.1170 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02053: val_loss did not improve from 0.41973\n",
      "Epoch 2054/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9027 - val_loss: 1.1089 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02054: val_loss did not improve from 0.41973\n",
      "Epoch 2055/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9014 - val_loss: 1.1055 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02055: val_loss did not improve from 0.41973\n",
      "Epoch 2056/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 1.1081 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02056: val_loss did not improve from 0.41973\n",
      "Epoch 2057/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9001 - val_loss: 1.1078 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02057: val_loss did not improve from 0.41973\n",
      "Epoch 2058/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.9027 - val_loss: 1.1054 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02058: val_loss did not improve from 0.41973\n",
      "Epoch 2059/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9027 - val_loss: 1.1101 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02059: val_loss did not improve from 0.41973\n",
      "Epoch 2060/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 1.0965 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02060: val_loss did not improve from 0.41973\n",
      "Epoch 2061/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 1.1021 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02061: val_loss did not improve from 0.41973\n",
      "Epoch 2062/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9001 - val_loss: 1.0706 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02062: val_loss did not improve from 0.41973\n",
      "Epoch 2063/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.0970 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02063: val_loss did not improve from 0.41973\n",
      "Epoch 2064/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9027 - val_loss: 1.1066 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02064: val_loss did not improve from 0.41973\n",
      "Epoch 2065/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9014 - val_loss: 1.0689 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02065: val_loss did not improve from 0.41973\n",
      "Epoch 2066/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9027 - val_loss: 1.0718 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02066: val_loss did not improve from 0.41973\n",
      "Epoch 2067/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 1.0809 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02067: val_loss did not improve from 0.41973\n",
      "Epoch 2068/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9014 - val_loss: 1.0938 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02068: val_loss did not improve from 0.41973\n",
      "Epoch 2069/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 1.1072 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02069: val_loss did not improve from 0.41973\n",
      "Epoch 2070/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 1.0967 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02070: val_loss did not improve from 0.41973\n",
      "Epoch 2071/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 1.1104 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02071: val_loss did not improve from 0.41973\n",
      "Epoch 2072/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9014 - val_loss: 1.1297 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02072: val_loss did not improve from 0.41973\n",
      "Epoch 2073/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8975 - val_loss: 1.1084 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02073: val_loss did not improve from 0.41973\n",
      "Epoch 2074/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.0804 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02074: val_loss did not improve from 0.41973\n",
      "Epoch 2075/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9014 - val_loss: 1.0830 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02075: val_loss did not improve from 0.41973\n",
      "Epoch 2076/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9027 - val_loss: 1.0436 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02076: val_loss did not improve from 0.41973\n",
      "Epoch 2077/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9014 - val_loss: 1.0629 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02077: val_loss did not improve from 0.41973\n",
      "Epoch 2078/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 1.0216 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02078: val_loss did not improve from 0.41973\n",
      "Epoch 2079/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 1.0346 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02079: val_loss did not improve from 0.41973\n",
      "Epoch 2080/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9001 - val_loss: 0.9749 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02080: val_loss did not improve from 0.41973\n",
      "Epoch 2081/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.8988 - val_loss: 0.9784 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02081: val_loss did not improve from 0.41973\n",
      "Epoch 2082/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.8988 - val_loss: 1.0038 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02082: val_loss did not improve from 0.41973\n",
      "Epoch 2083/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 1.0051 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02083: val_loss did not improve from 0.41973\n",
      "Epoch 2084/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 0.9961 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02084: val_loss did not improve from 0.41973\n",
      "Epoch 2085/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 1.0116 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02085: val_loss did not improve from 0.41973\n",
      "Epoch 2086/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9040 - val_loss: 1.0178 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02086: val_loss did not improve from 0.41973\n",
      "Epoch 2087/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 1.0209 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02087: val_loss did not improve from 0.41973\n",
      "Epoch 2088/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 1.0066 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02088: val_loss did not improve from 0.41973\n",
      "Epoch 2089/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 1.0134 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02089: val_loss did not improve from 0.41973\n",
      "Epoch 2090/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.0083 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02090: val_loss did not improve from 0.41973\n",
      "Epoch 2091/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9014 - val_loss: 1.0241 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02091: val_loss did not improve from 0.41973\n",
      "Epoch 2092/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 1.0194 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02092: val_loss did not improve from 0.41973\n",
      "Epoch 2093/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 1.0045 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02093: val_loss did not improve from 0.41973\n",
      "Epoch 2094/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 0.9944 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02094: val_loss did not improve from 0.41973\n",
      "Epoch 2095/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9014 - val_loss: 1.0252 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02095: val_loss did not improve from 0.41973\n",
      "Epoch 2096/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9001 - val_loss: 1.0091 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02096: val_loss did not improve from 0.41973\n",
      "Epoch 2097/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.8988 - val_loss: 0.9974 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02097: val_loss did not improve from 0.41973\n",
      "Epoch 2098/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 1.0172 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02098: val_loss did not improve from 0.41973\n",
      "Epoch 2099/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 1.0186 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02099: val_loss did not improve from 0.41973\n",
      "Epoch 2100/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8988 - val_loss: 0.9718 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02100: val_loss did not improve from 0.41973\n",
      "Epoch 2101/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9027 - val_loss: 0.9502 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02101: val_loss did not improve from 0.41973\n",
      "Epoch 2102/4000\n",
      "25/25 - 0s - loss: 0.2039 - accuracy: 0.9027 - val_loss: 1.0179 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02102: val_loss did not improve from 0.41973\n",
      "Epoch 2103/4000\n",
      "25/25 - 0s - loss: 0.2162 - accuracy: 0.9001 - val_loss: 0.8897 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02103: val_loss did not improve from 0.41973\n",
      "Epoch 2104/4000\n",
      "25/25 - 0s - loss: 0.2078 - accuracy: 0.8949 - val_loss: 0.9724 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02104: val_loss did not improve from 0.41973\n",
      "Epoch 2105/4000\n",
      "25/25 - 0s - loss: 0.2074 - accuracy: 0.9014 - val_loss: 0.9531 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02105: val_loss did not improve from 0.41973\n",
      "Epoch 2106/4000\n",
      "25/25 - 0s - loss: 0.2084 - accuracy: 0.8962 - val_loss: 1.0585 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02106: val_loss did not improve from 0.41973\n",
      "Epoch 2107/4000\n",
      "25/25 - 0s - loss: 0.2029 - accuracy: 0.9014 - val_loss: 1.0151 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02107: val_loss did not improve from 0.41973\n",
      "Epoch 2108/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 1.0336 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02108: val_loss did not improve from 0.41973\n",
      "Epoch 2109/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.8988 - val_loss: 1.0337 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02109: val_loss did not improve from 0.41973\n",
      "Epoch 2110/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 1.0455 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02110: val_loss did not improve from 0.41973\n",
      "Epoch 2111/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9001 - val_loss: 1.0460 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02111: val_loss did not improve from 0.41973\n",
      "Epoch 2112/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 1.0517 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02112: val_loss did not improve from 0.41973\n",
      "Epoch 2113/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 1.0623 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02113: val_loss did not improve from 0.41973\n",
      "Epoch 2114/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9001 - val_loss: 1.0457 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02114: val_loss did not improve from 0.41973\n",
      "Epoch 2115/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.0408 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02115: val_loss did not improve from 0.41973\n",
      "Epoch 2116/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8988 - val_loss: 1.0351 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02116: val_loss did not improve from 0.41973\n",
      "Epoch 2117/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8988 - val_loss: 1.0450 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02117: val_loss did not improve from 0.41973\n",
      "Epoch 2118/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 1.0666 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02118: val_loss did not improve from 0.41973\n",
      "Epoch 2119/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8962 - val_loss: 1.0690 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02119: val_loss did not improve from 0.41973\n",
      "Epoch 2120/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9040 - val_loss: 1.0604 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02120: val_loss did not improve from 0.41973\n",
      "Epoch 2121/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 1.0558 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02121: val_loss did not improve from 0.41973\n",
      "Epoch 2122/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 1.0772 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02122: val_loss did not improve from 0.41973\n",
      "Epoch 2123/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 1.0695 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02123: val_loss did not improve from 0.41973\n",
      "Epoch 2124/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 1.0750 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02124: val_loss did not improve from 0.41973\n",
      "Epoch 2125/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.8988 - val_loss: 1.0642 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02125: val_loss did not improve from 0.41973\n",
      "Epoch 2126/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9001 - val_loss: 1.0683 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02126: val_loss did not improve from 0.41973\n",
      "Epoch 2127/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 1.0381 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02127: val_loss did not improve from 0.41973\n",
      "Epoch 2128/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 1.0467 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02128: val_loss did not improve from 0.41973\n",
      "Epoch 2129/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 1.0390 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02129: val_loss did not improve from 0.41973\n",
      "Epoch 2130/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 1.0669 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02130: val_loss did not improve from 0.41973\n",
      "Epoch 2131/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 1.0201 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02131: val_loss did not improve from 0.41973\n",
      "Epoch 2132/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8988 - val_loss: 1.0059 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02132: val_loss did not improve from 0.41973\n",
      "Epoch 2133/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9001 - val_loss: 1.0144 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02133: val_loss did not improve from 0.41973\n",
      "Epoch 2134/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.0139 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02134: val_loss did not improve from 0.41973\n",
      "Epoch 2135/4000\n",
      "25/25 - 1s - loss: 0.2010 - accuracy: 0.8988 - val_loss: 1.0097 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02135: val_loss did not improve from 0.41973\n",
      "Epoch 2136/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8988 - val_loss: 1.0221 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02136: val_loss did not improve from 0.41973\n",
      "Epoch 2137/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 1.0262 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02137: val_loss did not improve from 0.41973\n",
      "Epoch 2138/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.0242 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02138: val_loss did not improve from 0.41973\n",
      "Epoch 2139/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9001 - val_loss: 1.0179 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02139: val_loss did not improve from 0.41973\n",
      "Epoch 2140/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9027 - val_loss: 0.9770 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02140: val_loss did not improve from 0.41973\n",
      "Epoch 2141/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9014 - val_loss: 1.0100 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02141: val_loss did not improve from 0.41973\n",
      "Epoch 2142/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9027 - val_loss: 1.0347 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02142: val_loss did not improve from 0.41973\n",
      "Epoch 2143/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 1.0375 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02143: val_loss did not improve from 0.41973\n",
      "Epoch 2144/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 1.0387 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02144: val_loss did not improve from 0.41973\n",
      "Epoch 2145/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 1.0440 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02145: val_loss did not improve from 0.41973\n",
      "Epoch 2146/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8988 - val_loss: 1.0559 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02146: val_loss did not improve from 0.41973\n",
      "Epoch 2147/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9014 - val_loss: 1.0112 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02147: val_loss did not improve from 0.41973\n",
      "Epoch 2148/4000\n",
      "25/25 - 1s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 0.9920 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02148: val_loss did not improve from 0.41973\n",
      "Epoch 2149/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 0.9701 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02149: val_loss did not improve from 0.41973\n",
      "Epoch 2150/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 0.9892 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02150: val_loss did not improve from 0.41973\n",
      "Epoch 2151/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 0.9757 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02151: val_loss did not improve from 0.41973\n",
      "Epoch 2152/4000\n",
      "25/25 - 1s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 0.9860 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02152: val_loss did not improve from 0.41973\n",
      "Epoch 2153/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 0.9896 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02153: val_loss did not improve from 0.41973\n",
      "Epoch 2154/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 0.9867 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02154: val_loss did not improve from 0.41973\n",
      "Epoch 2155/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 0.9873 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02155: val_loss did not improve from 0.41973\n",
      "Epoch 2156/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8962 - val_loss: 0.9773 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02156: val_loss did not improve from 0.41973\n",
      "Epoch 2157/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 0.9446 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02157: val_loss did not improve from 0.41973\n",
      "Epoch 2158/4000\n",
      "25/25 - 0s - loss: 0.2037 - accuracy: 0.9014 - val_loss: 0.9179 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02158: val_loss did not improve from 0.41973\n",
      "Epoch 2159/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9014 - val_loss: 0.9416 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02159: val_loss did not improve from 0.41973\n",
      "Epoch 2160/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.8988 - val_loss: 0.9677 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02160: val_loss did not improve from 0.41973\n",
      "Epoch 2161/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9014 - val_loss: 0.9821 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02161: val_loss did not improve from 0.41973\n",
      "Epoch 2162/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9001 - val_loss: 0.9700 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02162: val_loss did not improve from 0.41973\n",
      "Epoch 2163/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.8962 - val_loss: 1.0186 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02163: val_loss did not improve from 0.41973\n",
      "Epoch 2164/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 1.0285 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02164: val_loss did not improve from 0.41973\n",
      "Epoch 2165/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.8988 - val_loss: 1.0512 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02165: val_loss did not improve from 0.41973\n",
      "Epoch 2166/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 1.0035 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02166: val_loss did not improve from 0.41973\n",
      "Epoch 2167/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.0025 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02167: val_loss did not improve from 0.41973\n",
      "Epoch 2168/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8962 - val_loss: 1.0029 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02168: val_loss did not improve from 0.41973\n",
      "Epoch 2169/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.0063 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02169: val_loss did not improve from 0.41973\n",
      "Epoch 2170/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9014 - val_loss: 1.0067 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02170: val_loss did not improve from 0.41973\n",
      "Epoch 2171/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 0.9856 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02171: val_loss did not improve from 0.41973\n",
      "Epoch 2172/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9001 - val_loss: 0.9775 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02172: val_loss did not improve from 0.41973\n",
      "Epoch 2173/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 0.9879 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02173: val_loss did not improve from 0.41973\n",
      "Epoch 2174/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 0.9774 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02174: val_loss did not improve from 0.41973\n",
      "Epoch 2175/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9027 - val_loss: 0.9830 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02175: val_loss did not improve from 0.41973\n",
      "Epoch 2176/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8988 - val_loss: 0.9825 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02176: val_loss did not improve from 0.41973\n",
      "Epoch 2177/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9001 - val_loss: 0.9510 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02177: val_loss did not improve from 0.41973\n",
      "Epoch 2178/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9001 - val_loss: 0.9694 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02178: val_loss did not improve from 0.41973\n",
      "Epoch 2179/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 0.9743 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02179: val_loss did not improve from 0.41973\n",
      "Epoch 2180/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 0.9779 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02180: val_loss did not improve from 0.41973\n",
      "Epoch 2181/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 0.9804 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02181: val_loss did not improve from 0.41973\n",
      "Epoch 2182/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 0.9930 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02182: val_loss did not improve from 0.41973\n",
      "Epoch 2183/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8962 - val_loss: 0.9967 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02183: val_loss did not improve from 0.41973\n",
      "Epoch 2184/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 0.9739 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02184: val_loss did not improve from 0.41973\n",
      "Epoch 2185/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 0.9596 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02185: val_loss did not improve from 0.41973\n",
      "Epoch 2186/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.0609 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02186: val_loss did not improve from 0.41973\n",
      "Epoch 2187/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.0641 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02187: val_loss did not improve from 0.41973\n",
      "Epoch 2188/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8949 - val_loss: 1.0466 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02188: val_loss did not improve from 0.41973\n",
      "Epoch 2189/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 1.0352 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02189: val_loss did not improve from 0.41973\n",
      "Epoch 2190/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.8988 - val_loss: 1.0458 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02190: val_loss did not improve from 0.41973\n",
      "Epoch 2191/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 1.0334 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02191: val_loss did not improve from 0.41973\n",
      "Epoch 2192/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.0213 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02192: val_loss did not improve from 0.41973\n",
      "Epoch 2193/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.8988 - val_loss: 1.0243 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02193: val_loss did not improve from 0.41973\n",
      "Epoch 2194/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.0010 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02194: val_loss did not improve from 0.41973\n",
      "Epoch 2195/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 0.9893 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02195: val_loss did not improve from 0.41973\n",
      "Epoch 2196/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 0.9795 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02196: val_loss did not improve from 0.41973\n",
      "Epoch 2197/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 0.9792 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02197: val_loss did not improve from 0.41973\n",
      "Epoch 2198/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 0.9695 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02198: val_loss did not improve from 0.41973\n",
      "Epoch 2199/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 0.9809 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02199: val_loss did not improve from 0.41973\n",
      "Epoch 2200/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 0.9751 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02200: val_loss did not improve from 0.41973\n",
      "Epoch 2201/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 0.9621 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02201: val_loss did not improve from 0.41973\n",
      "Epoch 2202/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 0.9744 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02202: val_loss did not improve from 0.41973\n",
      "Epoch 2203/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 0.9766 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02203: val_loss did not improve from 0.41973\n",
      "Epoch 2204/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.8988 - val_loss: 0.9787 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02204: val_loss did not improve from 0.41973\n",
      "Epoch 2205/4000\n",
      "25/25 - 0s - loss: 0.2026 - accuracy: 0.9014 - val_loss: 1.0445 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02205: val_loss did not improve from 0.41973\n",
      "Epoch 2206/4000\n",
      "25/25 - 0s - loss: 0.2046 - accuracy: 0.9014 - val_loss: 0.9983 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02206: val_loss did not improve from 0.41973\n",
      "Epoch 2207/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9014 - val_loss: 0.9079 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02207: val_loss did not improve from 0.41973\n",
      "Epoch 2208/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 0.9014 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02208: val_loss did not improve from 0.41973\n",
      "Epoch 2209/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9014 - val_loss: 0.9168 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02209: val_loss did not improve from 0.41973\n",
      "Epoch 2210/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9014 - val_loss: 0.9385 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02210: val_loss did not improve from 0.41973\n",
      "Epoch 2211/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8988 - val_loss: 0.9517 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02211: val_loss did not improve from 0.41973\n",
      "Epoch 2212/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 0.9512 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02212: val_loss did not improve from 0.41973\n",
      "Epoch 2213/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9014 - val_loss: 0.9670 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02213: val_loss did not improve from 0.41973\n",
      "Epoch 2214/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.8962 - val_loss: 0.9532 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02214: val_loss did not improve from 0.41973\n",
      "Epoch 2215/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 0.9688 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02215: val_loss did not improve from 0.41973\n",
      "Epoch 2216/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 0.9556 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02216: val_loss did not improve from 0.41973\n",
      "Epoch 2217/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9014 - val_loss: 0.9662 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02217: val_loss did not improve from 0.41973\n",
      "Epoch 2218/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.8975 - val_loss: 0.9817 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02218: val_loss did not improve from 0.41973\n",
      "Epoch 2219/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 0.9858 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02219: val_loss did not improve from 0.41973\n",
      "Epoch 2220/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 0.9907 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02220: val_loss did not improve from 0.41973\n",
      "Epoch 2221/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 0.9964 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02221: val_loss did not improve from 0.41973\n",
      "Epoch 2222/4000\n",
      "25/25 - 0s - loss: 0.2028 - accuracy: 0.9001 - val_loss: 0.9860 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02222: val_loss did not improve from 0.41973\n",
      "Epoch 2223/4000\n",
      "25/25 - 0s - loss: 0.2029 - accuracy: 0.8975 - val_loss: 0.9363 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02223: val_loss did not improve from 0.41973\n",
      "Epoch 2224/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.8988 - val_loss: 0.9438 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02224: val_loss did not improve from 0.41973\n",
      "Epoch 2225/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9001 - val_loss: 0.9582 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02225: val_loss did not improve from 0.41973\n",
      "Epoch 2226/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8988 - val_loss: 0.9524 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02226: val_loss did not improve from 0.41973\n",
      "Epoch 2227/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 0.9588 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02227: val_loss did not improve from 0.41973\n",
      "Epoch 2228/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9027 - val_loss: 0.9686 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02228: val_loss did not improve from 0.41973\n",
      "Epoch 2229/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.8975 - val_loss: 0.9536 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02229: val_loss did not improve from 0.41973\n",
      "Epoch 2230/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.8975 - val_loss: 0.9604 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02230: val_loss did not improve from 0.41973\n",
      "Epoch 2231/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9001 - val_loss: 0.9835 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02231: val_loss did not improve from 0.41973\n",
      "Epoch 2232/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 0.9899 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02232: val_loss did not improve from 0.41973\n",
      "Epoch 2233/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 0.9912 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02233: val_loss did not improve from 0.41973\n",
      "Epoch 2234/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 1.0083 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02234: val_loss did not improve from 0.41973\n",
      "Epoch 2235/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9001 - val_loss: 1.0129 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02235: val_loss did not improve from 0.41973\n",
      "Epoch 2236/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8988 - val_loss: 1.0106 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02236: val_loss did not improve from 0.41973\n",
      "Epoch 2237/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 0.9977 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02237: val_loss did not improve from 0.41973\n",
      "Epoch 2238/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8988 - val_loss: 0.9769 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02238: val_loss did not improve from 0.41973\n",
      "Epoch 2239/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9001 - val_loss: 0.9965 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02239: val_loss did not improve from 0.41973\n",
      "Epoch 2240/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 1.0088 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02240: val_loss did not improve from 0.41973\n",
      "Epoch 2241/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 0.9895 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02241: val_loss did not improve from 0.41973\n",
      "Epoch 2242/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8949 - val_loss: 0.9767 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02242: val_loss did not improve from 0.41973\n",
      "Epoch 2243/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 0.9975 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02243: val_loss did not improve from 0.41973\n",
      "Epoch 2244/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9014 - val_loss: 1.0640 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02244: val_loss did not improve from 0.41973\n",
      "Epoch 2245/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9027 - val_loss: 1.0026 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02245: val_loss did not improve from 0.41973\n",
      "Epoch 2246/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9001 - val_loss: 0.9882 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02246: val_loss did not improve from 0.41973\n",
      "Epoch 2247/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 0.9961 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02247: val_loss did not improve from 0.41973\n",
      "Epoch 2248/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 1.0033 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02248: val_loss did not improve from 0.41973\n",
      "Epoch 2249/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8988 - val_loss: 1.0097 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02249: val_loss did not improve from 0.41973\n",
      "Epoch 2250/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9001 - val_loss: 1.0071 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02250: val_loss did not improve from 0.41973\n",
      "Epoch 2251/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9001 - val_loss: 1.0222 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02251: val_loss did not improve from 0.41973\n",
      "Epoch 2252/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.0323 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02252: val_loss did not improve from 0.41973\n",
      "Epoch 2253/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 1.0234 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02253: val_loss did not improve from 0.41973\n",
      "Epoch 2254/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 1.0080 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02254: val_loss did not improve from 0.41973\n",
      "Epoch 2255/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.8975 - val_loss: 1.0034 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02255: val_loss did not improve from 0.41973\n",
      "Epoch 2256/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9001 - val_loss: 1.0095 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02256: val_loss did not improve from 0.41973\n",
      "Epoch 2257/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 1.0166 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02257: val_loss did not improve from 0.41973\n",
      "Epoch 2258/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.8988 - val_loss: 1.0280 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02258: val_loss did not improve from 0.41973\n",
      "Epoch 2259/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 1.0250 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02259: val_loss did not improve from 0.41973\n",
      "Epoch 2260/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9014 - val_loss: 1.0305 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02260: val_loss did not improve from 0.41973\n",
      "Epoch 2261/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9001 - val_loss: 1.0320 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02261: val_loss did not improve from 0.41973\n",
      "Epoch 2262/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 1.0037 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02262: val_loss did not improve from 0.41973\n",
      "Epoch 2263/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 1.0135 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02263: val_loss did not improve from 0.41973\n",
      "Epoch 2264/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9001 - val_loss: 1.0180 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02264: val_loss did not improve from 0.41973\n",
      "Epoch 2265/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8962 - val_loss: 1.0325 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02265: val_loss did not improve from 0.41973\n",
      "Epoch 2266/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9014 - val_loss: 1.0166 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02266: val_loss did not improve from 0.41973\n",
      "Epoch 2267/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 1.0078 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02267: val_loss did not improve from 0.41973\n",
      "Epoch 2268/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 1.0069 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02268: val_loss did not improve from 0.41973\n",
      "Epoch 2269/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8936 - val_loss: 1.0003 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02269: val_loss did not improve from 0.41973\n",
      "Epoch 2270/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 0.9620 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02270: val_loss did not improve from 0.41973\n",
      "Epoch 2271/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8949 - val_loss: 0.9704 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02271: val_loss did not improve from 0.41973\n",
      "Epoch 2272/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 0.9693 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02272: val_loss did not improve from 0.41973\n",
      "Epoch 2273/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8988 - val_loss: 0.9670 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02273: val_loss did not improve from 0.41973\n",
      "Epoch 2274/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 0.9486 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02274: val_loss did not improve from 0.41973\n",
      "Epoch 2275/4000\n",
      "25/25 - 0s - loss: 0.2034 - accuracy: 0.9027 - val_loss: 0.9501 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02275: val_loss did not improve from 0.41973\n",
      "Epoch 2276/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9001 - val_loss: 0.9516 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02276: val_loss did not improve from 0.41973\n",
      "Epoch 2277/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8975 - val_loss: 0.9554 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02277: val_loss did not improve from 0.41973\n",
      "Epoch 2278/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8975 - val_loss: 0.9668 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02278: val_loss did not improve from 0.41973\n",
      "Epoch 2279/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 0.9654 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02279: val_loss did not improve from 0.41973\n",
      "Epoch 2280/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9040 - val_loss: 0.9784 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02280: val_loss did not improve from 0.41973\n",
      "Epoch 2281/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 0.9671 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02281: val_loss did not improve from 0.41973\n",
      "Epoch 2282/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9001 - val_loss: 0.9643 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02282: val_loss did not improve from 0.41973\n",
      "Epoch 2283/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9027 - val_loss: 0.9708 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02283: val_loss did not improve from 0.41973\n",
      "Epoch 2284/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9014 - val_loss: 0.9868 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02284: val_loss did not improve from 0.41973\n",
      "Epoch 2285/4000\n",
      "25/25 - 0s - loss: 0.2085 - accuracy: 0.9014 - val_loss: 0.9924 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02285: val_loss did not improve from 0.41973\n",
      "Epoch 2286/4000\n",
      "25/25 - 0s - loss: 0.2085 - accuracy: 0.9001 - val_loss: 1.0103 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02286: val_loss did not improve from 0.41973\n",
      "Epoch 2287/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9014 - val_loss: 1.0908 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02287: val_loss did not improve from 0.41973\n",
      "Epoch 2288/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9014 - val_loss: 1.0766 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02288: val_loss did not improve from 0.41973\n",
      "Epoch 2289/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 1.0784 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02289: val_loss did not improve from 0.41973\n",
      "Epoch 2290/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 1.0640 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02290: val_loss did not improve from 0.41973\n",
      "Epoch 2291/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9001 - val_loss: 1.0835 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02291: val_loss did not improve from 0.41973\n",
      "Epoch 2292/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9014 - val_loss: 1.0823 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02292: val_loss did not improve from 0.41973\n",
      "Epoch 2293/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9001 - val_loss: 1.0745 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02293: val_loss did not improve from 0.41973\n",
      "Epoch 2294/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.8988 - val_loss: 1.0753 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02294: val_loss did not improve from 0.41973\n",
      "Epoch 2295/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 1.0755 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02295: val_loss did not improve from 0.41973\n",
      "Epoch 2296/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9001 - val_loss: 1.0519 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02296: val_loss did not improve from 0.41973\n",
      "Epoch 2297/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 1.0730 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02297: val_loss did not improve from 0.41973\n",
      "Epoch 2298/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9014 - val_loss: 1.0638 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02298: val_loss did not improve from 0.41973\n",
      "Epoch 2299/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 1.0516 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02299: val_loss did not improve from 0.41973\n",
      "Epoch 2300/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 1.0622 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02300: val_loss did not improve from 0.41973\n",
      "Epoch 2301/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9001 - val_loss: 0.9882 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02301: val_loss did not improve from 0.41973\n",
      "Epoch 2302/4000\n",
      "25/25 - 0s - loss: 0.2082 - accuracy: 0.8988 - val_loss: 0.9628 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02302: val_loss did not improve from 0.41973\n",
      "Epoch 2303/4000\n",
      "25/25 - 0s - loss: 0.2048 - accuracy: 0.9001 - val_loss: 1.1296 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02303: val_loss did not improve from 0.41973\n",
      "Epoch 2304/4000\n",
      "25/25 - 0s - loss: 0.2033 - accuracy: 0.8962 - val_loss: 1.2776 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02304: val_loss did not improve from 0.41973\n",
      "Epoch 2305/4000\n",
      "25/25 - 0s - loss: 0.2036 - accuracy: 0.9027 - val_loss: 1.1828 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02305: val_loss did not improve from 0.41973\n",
      "Epoch 2306/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9027 - val_loss: 1.1814 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02306: val_loss did not improve from 0.41973\n",
      "Epoch 2307/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 1.2085 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02307: val_loss did not improve from 0.41973\n",
      "Epoch 2308/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 1.2130 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02308: val_loss did not improve from 0.41973\n",
      "Epoch 2309/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.8988 - val_loss: 1.1939 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02309: val_loss did not improve from 0.41973\n",
      "Epoch 2310/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9001 - val_loss: 1.2043 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02310: val_loss did not improve from 0.41973\n",
      "Epoch 2311/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 1.2237 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02311: val_loss did not improve from 0.41973\n",
      "Epoch 2312/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 1.2304 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02312: val_loss did not improve from 0.41973\n",
      "Epoch 2313/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 1.2375 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02313: val_loss did not improve from 0.41973\n",
      "Epoch 2314/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.8988 - val_loss: 1.2271 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02314: val_loss did not improve from 0.41973\n",
      "Epoch 2315/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9001 - val_loss: 1.2471 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02315: val_loss did not improve from 0.41973\n",
      "Epoch 2316/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.8975 - val_loss: 1.2485 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02316: val_loss did not improve from 0.41973\n",
      "Epoch 2317/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9001 - val_loss: 1.2261 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02317: val_loss did not improve from 0.41973\n",
      "Epoch 2318/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 1.2445 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02318: val_loss did not improve from 0.41973\n",
      "Epoch 2319/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9001 - val_loss: 1.2458 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02319: val_loss did not improve from 0.41973\n",
      "Epoch 2320/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8975 - val_loss: 1.2478 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02320: val_loss did not improve from 0.41973\n",
      "Epoch 2321/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 1.2522 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02321: val_loss did not improve from 0.41973\n",
      "Epoch 2322/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.2560 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02322: val_loss did not improve from 0.41973\n",
      "Epoch 2323/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8988 - val_loss: 1.2380 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02323: val_loss did not improve from 0.41973\n",
      "Epoch 2324/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9040 - val_loss: 1.2472 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02324: val_loss did not improve from 0.41973\n",
      "Epoch 2325/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8988 - val_loss: 1.2467 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02325: val_loss did not improve from 0.41973\n",
      "Epoch 2326/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8911 - val_loss: 1.2464 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02326: val_loss did not improve from 0.41973\n",
      "Epoch 2327/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9027 - val_loss: 1.2284 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02327: val_loss did not improve from 0.41973\n",
      "Epoch 2328/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 1.2219 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02328: val_loss did not improve from 0.41973\n",
      "Epoch 2329/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 1.2623 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02329: val_loss did not improve from 0.41973\n",
      "Epoch 2330/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9040 - val_loss: 1.2882 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02330: val_loss did not improve from 0.41973\n",
      "Epoch 2331/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.2618 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02331: val_loss did not improve from 0.41973\n",
      "Epoch 2332/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 1.2748 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02332: val_loss did not improve from 0.41973\n",
      "Epoch 2333/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8988 - val_loss: 1.2568 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02333: val_loss did not improve from 0.41973\n",
      "Epoch 2334/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 1.2467 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02334: val_loss did not improve from 0.41973\n",
      "Epoch 2335/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 1.2444 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02335: val_loss did not improve from 0.41973\n",
      "Epoch 2336/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9001 - val_loss: 1.2272 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02336: val_loss did not improve from 0.41973\n",
      "Epoch 2337/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9001 - val_loss: 1.2553 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02337: val_loss did not improve from 0.41973\n",
      "Epoch 2338/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.8988 - val_loss: 1.2491 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02338: val_loss did not improve from 0.41973\n",
      "Epoch 2339/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.8975 - val_loss: 1.2491 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02339: val_loss did not improve from 0.41973\n",
      "Epoch 2340/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 1.2536 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02340: val_loss did not improve from 0.41973\n",
      "Epoch 2341/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 1.2494 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02341: val_loss did not improve from 0.41973\n",
      "Epoch 2342/4000\n",
      "25/25 - 0s - loss: 0.2028 - accuracy: 0.9027 - val_loss: 1.2471 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02342: val_loss did not improve from 0.41973\n",
      "Epoch 2343/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 1.2734 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02343: val_loss did not improve from 0.41973\n",
      "Epoch 2344/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 1.2937 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02344: val_loss did not improve from 0.41973\n",
      "Epoch 2345/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9040 - val_loss: 1.3084 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02345: val_loss did not improve from 0.41973\n",
      "Epoch 2346/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9001 - val_loss: 1.3357 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02346: val_loss did not improve from 0.41973\n",
      "Epoch 2347/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 1.3447 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02347: val_loss did not improve from 0.41973\n",
      "Epoch 2348/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9014 - val_loss: 1.3845 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02348: val_loss did not improve from 0.41973\n",
      "Epoch 2349/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9001 - val_loss: 1.3508 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02349: val_loss did not improve from 0.41973\n",
      "Epoch 2350/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9014 - val_loss: 1.3365 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02350: val_loss did not improve from 0.41973\n",
      "Epoch 2351/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9014 - val_loss: 1.3265 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02351: val_loss did not improve from 0.41973\n",
      "Epoch 2352/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8988 - val_loss: 1.3263 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02352: val_loss did not improve from 0.41973\n",
      "Epoch 2353/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9001 - val_loss: 1.3810 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02353: val_loss did not improve from 0.41973\n",
      "Epoch 2354/4000\n",
      "25/25 - 0s - loss: 0.2100 - accuracy: 0.9001 - val_loss: 1.2244 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02354: val_loss did not improve from 0.41973\n",
      "Epoch 2355/4000\n",
      "25/25 - 0s - loss: 0.2026 - accuracy: 0.9014 - val_loss: 1.1264 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02355: val_loss did not improve from 0.41973\n",
      "Epoch 2356/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.1812 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02356: val_loss did not improve from 0.41973\n",
      "Epoch 2357/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9014 - val_loss: 1.1900 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02357: val_loss did not improve from 0.41973\n",
      "Epoch 2358/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8988 - val_loss: 1.2379 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02358: val_loss did not improve from 0.41973\n",
      "Epoch 2359/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.2221 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02359: val_loss did not improve from 0.41973\n",
      "Epoch 2360/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.2254 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02360: val_loss did not improve from 0.41973\n",
      "Epoch 2361/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 1.2352 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02361: val_loss did not improve from 0.41973\n",
      "Epoch 2362/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9027 - val_loss: 1.1967 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02362: val_loss did not improve from 0.41973\n",
      "Epoch 2363/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.2424 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02363: val_loss did not improve from 0.41973\n",
      "Epoch 2364/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.8988 - val_loss: 1.2628 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02364: val_loss did not improve from 0.41973\n",
      "Epoch 2365/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9040 - val_loss: 1.0686 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02365: val_loss did not improve from 0.41973\n",
      "Epoch 2366/4000\n",
      "25/25 - 0s - loss: 0.2034 - accuracy: 0.9001 - val_loss: 1.0937 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02366: val_loss did not improve from 0.41973\n",
      "Epoch 2367/4000\n",
      "25/25 - 0s - loss: 0.2086 - accuracy: 0.9014 - val_loss: 1.0546 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02367: val_loss did not improve from 0.41973\n",
      "Epoch 2368/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 0.9577 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02368: val_loss did not improve from 0.41973\n",
      "Epoch 2369/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.8975 - val_loss: 0.9702 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02369: val_loss did not improve from 0.41973\n",
      "Epoch 2370/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9040 - val_loss: 0.9527 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02370: val_loss did not improve from 0.41973\n",
      "Epoch 2371/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 0.9488 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02371: val_loss did not improve from 0.41973\n",
      "Epoch 2372/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9014 - val_loss: 0.9897 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02372: val_loss did not improve from 0.41973\n",
      "Epoch 2373/4000\n",
      "25/25 - 0s - loss: 0.2080 - accuracy: 0.9014 - val_loss: 0.9460 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02373: val_loss did not improve from 0.41973\n",
      "Epoch 2374/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9027 - val_loss: 0.9414 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02374: val_loss did not improve from 0.41973\n",
      "Epoch 2375/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9001 - val_loss: 0.9712 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02375: val_loss did not improve from 0.41973\n",
      "Epoch 2376/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9040 - val_loss: 0.9926 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02376: val_loss did not improve from 0.41973\n",
      "Epoch 2377/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8962 - val_loss: 1.0166 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02377: val_loss did not improve from 0.41973\n",
      "Epoch 2378/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.0111 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02378: val_loss did not improve from 0.41973\n",
      "Epoch 2379/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 1.0167 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02379: val_loss did not improve from 0.41973\n",
      "Epoch 2380/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 1.0089 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02380: val_loss did not improve from 0.41973\n",
      "Epoch 2381/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.8988 - val_loss: 1.0208 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02381: val_loss did not improve from 0.41973\n",
      "Epoch 2382/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 1.0189 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02382: val_loss did not improve from 0.41973\n",
      "Epoch 2383/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 1.0214 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02383: val_loss did not improve from 0.41973\n",
      "Epoch 2384/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.8988 - val_loss: 1.0112 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02384: val_loss did not improve from 0.41973\n",
      "Epoch 2385/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 1.0141 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02385: val_loss did not improve from 0.41973\n",
      "Epoch 2386/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9001 - val_loss: 0.9998 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02386: val_loss did not improve from 0.41973\n",
      "Epoch 2387/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 0.9530 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02387: val_loss did not improve from 0.41973\n",
      "Epoch 2388/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9014 - val_loss: 0.9640 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02388: val_loss did not improve from 0.41973\n",
      "Epoch 2389/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9014 - val_loss: 0.9624 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02389: val_loss did not improve from 0.41973\n",
      "Epoch 2390/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 0.9669 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02390: val_loss did not improve from 0.41973\n",
      "Epoch 2391/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 0.9760 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02391: val_loss did not improve from 0.41973\n",
      "Epoch 2392/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9014 - val_loss: 0.9656 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02392: val_loss did not improve from 0.41973\n",
      "Epoch 2393/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9014 - val_loss: 0.9740 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02393: val_loss did not improve from 0.41973\n",
      "Epoch 2394/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8988 - val_loss: 0.9654 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02394: val_loss did not improve from 0.41973\n",
      "Epoch 2395/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9001 - val_loss: 0.9718 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02395: val_loss did not improve from 0.41973\n",
      "Epoch 2396/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 0.9768 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02396: val_loss did not improve from 0.41973\n",
      "Epoch 2397/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9014 - val_loss: 0.9997 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02397: val_loss did not improve from 0.41973\n",
      "Epoch 2398/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8988 - val_loss: 0.9439 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02398: val_loss did not improve from 0.41973\n",
      "Epoch 2399/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.8975 - val_loss: 0.9358 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02399: val_loss did not improve from 0.41973\n",
      "Epoch 2400/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 0.9416 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02400: val_loss did not improve from 0.41973\n",
      "Epoch 2401/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 0.9387 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02401: val_loss did not improve from 0.41973\n",
      "Epoch 2402/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8988 - val_loss: 0.9516 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02402: val_loss did not improve from 0.41973\n",
      "Epoch 2403/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 0.9531 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02403: val_loss did not improve from 0.41973\n",
      "Epoch 2404/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 0.9535 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02404: val_loss did not improve from 0.41973\n",
      "Epoch 2405/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 0.9486 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02405: val_loss did not improve from 0.41973\n",
      "Epoch 2406/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8988 - val_loss: 0.9452 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02406: val_loss did not improve from 0.41973\n",
      "Epoch 2407/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.9027 - val_loss: 0.9371 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02407: val_loss did not improve from 0.41973\n",
      "Epoch 2408/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8988 - val_loss: 0.9534 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02408: val_loss did not improve from 0.41973\n",
      "Epoch 2409/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9014 - val_loss: 0.9570 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02409: val_loss did not improve from 0.41973\n",
      "Epoch 2410/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 0.9462 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02410: val_loss did not improve from 0.41973\n",
      "Epoch 2411/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 0.9417 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02411: val_loss did not improve from 0.41973\n",
      "Epoch 2412/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 0.9277 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02412: val_loss did not improve from 0.41973\n",
      "Epoch 2413/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 0.9273 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02413: val_loss did not improve from 0.41973\n",
      "Epoch 2414/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9014 - val_loss: 0.9265 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02414: val_loss did not improve from 0.41973\n",
      "Epoch 2415/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 0.9210 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02415: val_loss did not improve from 0.41973\n",
      "Epoch 2416/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 0.9092 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02416: val_loss did not improve from 0.41973\n",
      "Epoch 2417/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 0.9175 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02417: val_loss did not improve from 0.41973\n",
      "Epoch 2418/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9040 - val_loss: 0.9291 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02418: val_loss did not improve from 0.41973\n",
      "Epoch 2419/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 0.9353 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02419: val_loss did not improve from 0.41973\n",
      "Epoch 2420/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9014 - val_loss: 0.9387 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02420: val_loss did not improve from 0.41973\n",
      "Epoch 2421/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 0.9273 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02421: val_loss did not improve from 0.41973\n",
      "Epoch 2422/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8988 - val_loss: 0.9459 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02422: val_loss did not improve from 0.41973\n",
      "Epoch 2423/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 0.9329 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02423: val_loss did not improve from 0.41973\n",
      "Epoch 2424/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 0.9339 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02424: val_loss did not improve from 0.41973\n",
      "Epoch 2425/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.8988 - val_loss: 0.9395 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02425: val_loss did not improve from 0.41973\n",
      "Epoch 2426/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 0.9374 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02426: val_loss did not improve from 0.41973\n",
      "Epoch 2427/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9001 - val_loss: 0.9420 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02427: val_loss did not improve from 0.41973\n",
      "Epoch 2428/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 0.9341 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02428: val_loss did not improve from 0.41973\n",
      "Epoch 2429/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.8975 - val_loss: 0.9376 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02429: val_loss did not improve from 0.41973\n",
      "Epoch 2430/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9001 - val_loss: 0.9386 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02430: val_loss did not improve from 0.41973\n",
      "Epoch 2431/4000\n",
      "25/25 - 0s - loss: 0.1999 - accuracy: 0.8988 - val_loss: 0.9297 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02431: val_loss did not improve from 0.41973\n",
      "Epoch 2432/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 0.9219 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02432: val_loss did not improve from 0.41973\n",
      "Epoch 2433/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.8988 - val_loss: 0.9271 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02433: val_loss did not improve from 0.41973\n",
      "Epoch 2434/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 0.9113 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02434: val_loss did not improve from 0.41973\n",
      "Epoch 2435/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 0.9224 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02435: val_loss did not improve from 0.41973\n",
      "Epoch 2436/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 0.9234 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02436: val_loss did not improve from 0.41973\n",
      "Epoch 2437/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 0.9364 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02437: val_loss did not improve from 0.41973\n",
      "Epoch 2438/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 0.9430 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02438: val_loss did not improve from 0.41973\n",
      "Epoch 2439/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 0.9485 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02439: val_loss did not improve from 0.41973\n",
      "Epoch 2440/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8988 - val_loss: 0.9545 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02440: val_loss did not improve from 0.41973\n",
      "Epoch 2441/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.8988 - val_loss: 0.9516 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02441: val_loss did not improve from 0.41973\n",
      "Epoch 2442/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9014 - val_loss: 0.9469 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02442: val_loss did not improve from 0.41973\n",
      "Epoch 2443/4000\n",
      "25/25 - 0s - loss: 0.2122 - accuracy: 0.8988 - val_loss: 1.0462 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02443: val_loss did not improve from 0.41973\n",
      "Epoch 2444/4000\n",
      "25/25 - 0s - loss: 0.2045 - accuracy: 0.9027 - val_loss: 1.2104 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02444: val_loss did not improve from 0.41973\n",
      "Epoch 2445/4000\n",
      "25/25 - 0s - loss: 0.2045 - accuracy: 0.9027 - val_loss: 1.2615 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02445: val_loss did not improve from 0.41973\n",
      "Epoch 2446/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.8975 - val_loss: 1.3106 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02446: val_loss did not improve from 0.41973\n",
      "Epoch 2447/4000\n",
      "25/25 - 0s - loss: 0.2096 - accuracy: 0.9001 - val_loss: 1.1566 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02447: val_loss did not improve from 0.41973\n",
      "Epoch 2448/4000\n",
      "25/25 - 0s - loss: 0.2035 - accuracy: 0.9014 - val_loss: 1.2680 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02448: val_loss did not improve from 0.41973\n",
      "Epoch 2449/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9027 - val_loss: 1.3184 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02449: val_loss did not improve from 0.41973\n",
      "Epoch 2450/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9027 - val_loss: 1.3428 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02450: val_loss did not improve from 0.41973\n",
      "Epoch 2451/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9027 - val_loss: 1.3170 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02451: val_loss did not improve from 0.41973\n",
      "Epoch 2452/4000\n",
      "25/25 - 0s - loss: 0.2077 - accuracy: 0.9027 - val_loss: 1.1969 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02452: val_loss did not improve from 0.41973\n",
      "Epoch 2453/4000\n",
      "25/25 - 0s - loss: 0.2034 - accuracy: 0.9014 - val_loss: 1.2280 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02453: val_loss did not improve from 0.41973\n",
      "Epoch 2454/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9027 - val_loss: 1.2366 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02454: val_loss did not improve from 0.41973\n",
      "Epoch 2455/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9014 - val_loss: 1.2468 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02455: val_loss did not improve from 0.41973\n",
      "Epoch 2456/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9001 - val_loss: 1.2311 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02456: val_loss did not improve from 0.41973\n",
      "Epoch 2457/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 1.2212 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02457: val_loss did not improve from 0.41973\n",
      "Epoch 2458/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 1.2141 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02458: val_loss did not improve from 0.41973\n",
      "Epoch 2459/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.2144 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02459: val_loss did not improve from 0.41973\n",
      "Epoch 2460/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.2182 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02460: val_loss did not improve from 0.41973\n",
      "Epoch 2461/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 1.2193 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02461: val_loss did not improve from 0.41973\n",
      "Epoch 2462/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9001 - val_loss: 1.2134 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02462: val_loss did not improve from 0.41973\n",
      "Epoch 2463/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.2056 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02463: val_loss did not improve from 0.41973\n",
      "Epoch 2464/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.8988 - val_loss: 1.2101 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02464: val_loss did not improve from 0.41973\n",
      "Epoch 2465/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9001 - val_loss: 1.2011 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02465: val_loss did not improve from 0.41973\n",
      "Epoch 2466/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 1.2014 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02466: val_loss did not improve from 0.41973\n",
      "Epoch 2467/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 1.2077 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02467: val_loss did not improve from 0.41973\n",
      "Epoch 2468/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9040 - val_loss: 1.2068 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02468: val_loss did not improve from 0.41973\n",
      "Epoch 2469/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 1.2048 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02469: val_loss did not improve from 0.41973\n",
      "Epoch 2470/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8988 - val_loss: 1.2151 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02470: val_loss did not improve from 0.41973\n",
      "Epoch 2471/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8988 - val_loss: 1.2257 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02471: val_loss did not improve from 0.41973\n",
      "Epoch 2472/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9001 - val_loss: 1.2112 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02472: val_loss did not improve from 0.41973\n",
      "Epoch 2473/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8975 - val_loss: 1.2185 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02473: val_loss did not improve from 0.41973\n",
      "Epoch 2474/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8988 - val_loss: 1.2036 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02474: val_loss did not improve from 0.41973\n",
      "Epoch 2475/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8988 - val_loss: 1.1831 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02475: val_loss did not improve from 0.41973\n",
      "Epoch 2476/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.8975 - val_loss: 1.1896 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02476: val_loss did not improve from 0.41973\n",
      "Epoch 2477/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.1872 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02477: val_loss did not improve from 0.41973\n",
      "Epoch 2478/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 1.1961 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02478: val_loss did not improve from 0.41973\n",
      "Epoch 2479/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8988 - val_loss: 1.2056 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02479: val_loss did not improve from 0.41973\n",
      "Epoch 2480/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8988 - val_loss: 1.1979 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02480: val_loss did not improve from 0.41973\n",
      "Epoch 2481/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.1876 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02481: val_loss did not improve from 0.41973\n",
      "Epoch 2482/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9014 - val_loss: 1.1683 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02482: val_loss did not improve from 0.41973\n",
      "Epoch 2483/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9014 - val_loss: 1.1492 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02483: val_loss did not improve from 0.41973\n",
      "Epoch 2484/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.1591 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02484: val_loss did not improve from 0.41973\n",
      "Epoch 2485/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 1.1590 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02485: val_loss did not improve from 0.41973\n",
      "Epoch 2486/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9001 - val_loss: 1.1689 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02486: val_loss did not improve from 0.41973\n",
      "Epoch 2487/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 1.1702 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02487: val_loss did not improve from 0.41973\n",
      "Epoch 2488/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9053 - val_loss: 1.1902 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02488: val_loss did not improve from 0.41973\n",
      "Epoch 2489/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 1.1691 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02489: val_loss did not improve from 0.41973\n",
      "Epoch 2490/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 1.1628 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02490: val_loss did not improve from 0.41973\n",
      "Epoch 2491/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 1.1564 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02491: val_loss did not improve from 0.41973\n",
      "Epoch 2492/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 1.1539 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02492: val_loss did not improve from 0.41973\n",
      "Epoch 2493/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 1.1316 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02493: val_loss did not improve from 0.41973\n",
      "Epoch 2494/4000\n",
      "25/25 - 0s - loss: 0.2025 - accuracy: 0.8988 - val_loss: 1.0756 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02494: val_loss did not improve from 0.41973\n",
      "Epoch 2495/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 1.0252 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02495: val_loss did not improve from 0.41973\n",
      "Epoch 2496/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 1.0205 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02496: val_loss did not improve from 0.41973\n",
      "Epoch 2497/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.0041 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02497: val_loss did not improve from 0.41973\n",
      "Epoch 2498/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 0.9725 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02498: val_loss did not improve from 0.41973\n",
      "Epoch 2499/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 0.9651 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02499: val_loss did not improve from 0.41973\n",
      "Epoch 2500/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 0.9650 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02500: val_loss did not improve from 0.41973\n",
      "Epoch 2501/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 0.9668 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02501: val_loss did not improve from 0.41973\n",
      "Epoch 2502/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 0.9626 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02502: val_loss did not improve from 0.41973\n",
      "Epoch 2503/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9001 - val_loss: 0.9458 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02503: val_loss did not improve from 0.41973\n",
      "Epoch 2504/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 0.9585 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02504: val_loss did not improve from 0.41973\n",
      "Epoch 2505/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 0.9740 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02505: val_loss did not improve from 0.41973\n",
      "Epoch 2506/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 0.9928 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02506: val_loss did not improve from 0.41973\n",
      "Epoch 2507/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8988 - val_loss: 1.0069 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02507: val_loss did not improve from 0.41973\n",
      "Epoch 2508/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9001 - val_loss: 0.9716 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02508: val_loss did not improve from 0.41973\n",
      "Epoch 2509/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 1.0062 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02509: val_loss did not improve from 0.41973\n",
      "Epoch 2510/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8975 - val_loss: 0.9976 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02510: val_loss did not improve from 0.41973\n",
      "Epoch 2511/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8988 - val_loss: 0.9895 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02511: val_loss did not improve from 0.41973\n",
      "Epoch 2512/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 0.9922 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02512: val_loss did not improve from 0.41973\n",
      "Epoch 2513/4000\n",
      "25/25 - 1s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 0.9930 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02513: val_loss did not improve from 0.41973\n",
      "Epoch 2514/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.0018 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02514: val_loss did not improve from 0.41973\n",
      "Epoch 2515/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 1.0012 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02515: val_loss did not improve from 0.41973\n",
      "Epoch 2516/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.8975 - val_loss: 0.9912 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02516: val_loss did not improve from 0.41973\n",
      "Epoch 2517/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 0.9925 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02517: val_loss did not improve from 0.41973\n",
      "Epoch 2518/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.0116 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02518: val_loss did not improve from 0.41973\n",
      "Epoch 2519/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 0.9900 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02519: val_loss did not improve from 0.41973\n",
      "Epoch 2520/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8988 - val_loss: 1.0264 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02520: val_loss did not improve from 0.41973\n",
      "Epoch 2521/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9014 - val_loss: 1.0292 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02521: val_loss did not improve from 0.41973\n",
      "Epoch 2522/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9027 - val_loss: 1.0023 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02522: val_loss did not improve from 0.41973\n",
      "Epoch 2523/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9014 - val_loss: 1.0283 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02523: val_loss did not improve from 0.41973\n",
      "Epoch 2524/4000\n",
      "25/25 - 1s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 1.0165 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02524: val_loss did not improve from 0.41973\n",
      "Epoch 2525/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.8988 - val_loss: 1.0169 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02525: val_loss did not improve from 0.41973\n",
      "Epoch 2526/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8988 - val_loss: 1.0228 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02526: val_loss did not improve from 0.41973\n",
      "Epoch 2527/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8975 - val_loss: 1.0459 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02527: val_loss did not improve from 0.41973\n",
      "Epoch 2528/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 1.0397 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02528: val_loss did not improve from 0.41973\n",
      "Epoch 2529/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.8988 - val_loss: 1.0247 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02529: val_loss did not improve from 0.41973\n",
      "Epoch 2530/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.8988 - val_loss: 1.0349 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02530: val_loss did not improve from 0.41973\n",
      "Epoch 2531/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 1.0319 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02531: val_loss did not improve from 0.41973\n",
      "Epoch 2532/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.8975 - val_loss: 0.9848 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02532: val_loss did not improve from 0.41973\n",
      "Epoch 2533/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9027 - val_loss: 1.0437 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02533: val_loss did not improve from 0.41973\n",
      "Epoch 2534/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9027 - val_loss: 1.0529 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02534: val_loss did not improve from 0.41973\n",
      "Epoch 2535/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8988 - val_loss: 1.0487 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02535: val_loss did not improve from 0.41973\n",
      "Epoch 2536/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8975 - val_loss: 1.0506 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02536: val_loss did not improve from 0.41973\n",
      "Epoch 2537/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9014 - val_loss: 1.0516 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02537: val_loss did not improve from 0.41973\n",
      "Epoch 2538/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9001 - val_loss: 1.0347 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02538: val_loss did not improve from 0.41973\n",
      "Epoch 2539/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 1.0377 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02539: val_loss did not improve from 0.41973\n",
      "Epoch 2540/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9040 - val_loss: 1.0326 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02540: val_loss did not improve from 0.41973\n",
      "Epoch 2541/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 1.0256 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02541: val_loss did not improve from 0.41973\n",
      "Epoch 2542/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9014 - val_loss: 1.0390 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02542: val_loss did not improve from 0.41973\n",
      "Epoch 2543/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 1.0433 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02543: val_loss did not improve from 0.41973\n",
      "Epoch 2544/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 1.0002 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02544: val_loss did not improve from 0.41973\n",
      "Epoch 2545/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 0.9973 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02545: val_loss did not improve from 0.41973\n",
      "Epoch 2546/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.0030 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02546: val_loss did not improve from 0.41973\n",
      "Epoch 2547/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.8988 - val_loss: 0.9382 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02547: val_loss did not improve from 0.41973\n",
      "Epoch 2548/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9014 - val_loss: 0.9606 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02548: val_loss did not improve from 0.41973\n",
      "Epoch 2549/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9014 - val_loss: 0.9589 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02549: val_loss did not improve from 0.41973\n",
      "Epoch 2550/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 0.9646 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02550: val_loss did not improve from 0.41973\n",
      "Epoch 2551/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.8988 - val_loss: 0.9700 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02551: val_loss did not improve from 0.41973\n",
      "Epoch 2552/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8988 - val_loss: 0.9728 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02552: val_loss did not improve from 0.41973\n",
      "Epoch 2553/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 0.9709 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02553: val_loss did not improve from 0.41973\n",
      "Epoch 2554/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8962 - val_loss: 0.9805 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02554: val_loss did not improve from 0.41973\n",
      "Epoch 2555/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 0.9874 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02555: val_loss did not improve from 0.41973\n",
      "Epoch 2556/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9014 - val_loss: 0.9587 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02556: val_loss did not improve from 0.41973\n",
      "Epoch 2557/4000\n",
      "25/25 - 0s - loss: 0.2043 - accuracy: 0.8975 - val_loss: 1.0022 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02557: val_loss did not improve from 0.41973\n",
      "Epoch 2558/4000\n",
      "25/25 - 0s - loss: 0.2196 - accuracy: 0.8988 - val_loss: 1.3143 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02558: val_loss did not improve from 0.41973\n",
      "Epoch 2559/4000\n",
      "25/25 - 0s - loss: 0.2116 - accuracy: 0.8962 - val_loss: 1.0612 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02559: val_loss did not improve from 0.41973\n",
      "Epoch 2560/4000\n",
      "25/25 - 0s - loss: 0.2360 - accuracy: 0.8898 - val_loss: 1.0558 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02560: val_loss did not improve from 0.41973\n",
      "Epoch 2561/4000\n",
      "25/25 - 0s - loss: 0.2141 - accuracy: 0.8949 - val_loss: 1.1382 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02561: val_loss did not improve from 0.41973\n",
      "Epoch 2562/4000\n",
      "25/25 - 0s - loss: 0.2117 - accuracy: 0.9027 - val_loss: 1.0579 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02562: val_loss did not improve from 0.41973\n",
      "Epoch 2563/4000\n",
      "25/25 - 0s - loss: 0.2072 - accuracy: 0.8988 - val_loss: 0.9655 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02563: val_loss did not improve from 0.41973\n",
      "Epoch 2564/4000\n",
      "25/25 - 0s - loss: 0.2053 - accuracy: 0.8962 - val_loss: 1.0596 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02564: val_loss did not improve from 0.41973\n",
      "Epoch 2565/4000\n",
      "25/25 - 0s - loss: 0.2031 - accuracy: 0.8975 - val_loss: 1.0715 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02565: val_loss did not improve from 0.41973\n",
      "Epoch 2566/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.9027 - val_loss: 1.0836 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02566: val_loss did not improve from 0.41973\n",
      "Epoch 2567/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9001 - val_loss: 1.0756 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02567: val_loss did not improve from 0.41973\n",
      "Epoch 2568/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.8988 - val_loss: 1.0897 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02568: val_loss did not improve from 0.41973\n",
      "Epoch 2569/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 1.0905 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02569: val_loss did not improve from 0.41973\n",
      "Epoch 2570/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9014 - val_loss: 1.0981 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02570: val_loss did not improve from 0.41973\n",
      "Epoch 2571/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.8988 - val_loss: 1.1069 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02571: val_loss did not improve from 0.41973\n",
      "Epoch 2572/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9014 - val_loss: 1.1294 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02572: val_loss did not improve from 0.41973\n",
      "Epoch 2573/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9014 - val_loss: 1.1424 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02573: val_loss did not improve from 0.41973\n",
      "Epoch 2574/4000\n",
      "25/25 - 0s - loss: 0.2057 - accuracy: 0.9001 - val_loss: 1.1343 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02574: val_loss did not improve from 0.41973\n",
      "Epoch 2575/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.8988 - val_loss: 1.1626 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02575: val_loss did not improve from 0.41973\n",
      "Epoch 2576/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.8988 - val_loss: 1.1664 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02576: val_loss did not improve from 0.41973\n",
      "Epoch 2577/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9001 - val_loss: 1.1602 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02577: val_loss did not improve from 0.41973\n",
      "Epoch 2578/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 1.1578 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02578: val_loss did not improve from 0.41973\n",
      "Epoch 2579/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 1.1554 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02579: val_loss did not improve from 0.41973\n",
      "Epoch 2580/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.8949 - val_loss: 1.1473 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02580: val_loss did not improve from 0.41973\n",
      "Epoch 2581/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 1.1318 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02581: val_loss did not improve from 0.41973\n",
      "Epoch 2582/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 1.1305 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02582: val_loss did not improve from 0.41973\n",
      "Epoch 2583/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.8988 - val_loss: 1.1429 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02583: val_loss did not improve from 0.41973\n",
      "Epoch 2584/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8949 - val_loss: 1.1412 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02584: val_loss did not improve from 0.41973\n",
      "Epoch 2585/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9001 - val_loss: 1.1511 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02585: val_loss did not improve from 0.41973\n",
      "Epoch 2586/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8988 - val_loss: 1.1426 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02586: val_loss did not improve from 0.41973\n",
      "Epoch 2587/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 1.1360 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02587: val_loss did not improve from 0.41973\n",
      "Epoch 2588/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 1.1332 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02588: val_loss did not improve from 0.41973\n",
      "Epoch 2589/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 1.1310 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02589: val_loss did not improve from 0.41973\n",
      "Epoch 2590/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.1256 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02590: val_loss did not improve from 0.41973\n",
      "Epoch 2591/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9014 - val_loss: 1.1312 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02591: val_loss did not improve from 0.41973\n",
      "Epoch 2592/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9014 - val_loss: 1.1347 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02592: val_loss did not improve from 0.41973\n",
      "Epoch 2593/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 1.1295 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02593: val_loss did not improve from 0.41973\n",
      "Epoch 2594/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9001 - val_loss: 1.1365 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02594: val_loss did not improve from 0.41973\n",
      "Epoch 2595/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.1263 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02595: val_loss did not improve from 0.41973\n",
      "Epoch 2596/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 1.1296 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02596: val_loss did not improve from 0.41973\n",
      "Epoch 2597/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8988 - val_loss: 1.1297 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02597: val_loss did not improve from 0.41973\n",
      "Epoch 2598/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9001 - val_loss: 1.1231 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02598: val_loss did not improve from 0.41973\n",
      "Epoch 2599/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 1.1146 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02599: val_loss did not improve from 0.41973\n",
      "Epoch 2600/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.1170 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02600: val_loss did not improve from 0.41973\n",
      "Epoch 2601/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8988 - val_loss: 1.1157 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02601: val_loss did not improve from 0.41973\n",
      "Epoch 2602/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.1269 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02602: val_loss did not improve from 0.41973\n",
      "Epoch 2603/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.1294 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02603: val_loss did not improve from 0.41973\n",
      "Epoch 2604/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 1.1194 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02604: val_loss did not improve from 0.41973\n",
      "Epoch 2605/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9001 - val_loss: 1.1046 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02605: val_loss did not improve from 0.41973\n",
      "Epoch 2606/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9001 - val_loss: 1.1121 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02606: val_loss did not improve from 0.41973\n",
      "Epoch 2607/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.1096 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02607: val_loss did not improve from 0.41973\n",
      "Epoch 2608/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8988 - val_loss: 1.1173 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02608: val_loss did not improve from 0.41973\n",
      "Epoch 2609/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.8988 - val_loss: 1.0982 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02609: val_loss did not improve from 0.41973\n",
      "Epoch 2610/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8988 - val_loss: 1.0967 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02610: val_loss did not improve from 0.41973\n",
      "Epoch 2611/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.8988 - val_loss: 1.0920 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02611: val_loss did not improve from 0.41973\n",
      "Epoch 2612/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.8988 - val_loss: 1.0995 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02612: val_loss did not improve from 0.41973\n",
      "Epoch 2613/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8962 - val_loss: 1.0946 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02613: val_loss did not improve from 0.41973\n",
      "Epoch 2614/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 1.1001 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02614: val_loss did not improve from 0.41973\n",
      "Epoch 2615/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.0908 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02615: val_loss did not improve from 0.41973\n",
      "Epoch 2616/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.0885 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02616: val_loss did not improve from 0.41973\n",
      "Epoch 2617/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8975 - val_loss: 1.0984 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02617: val_loss did not improve from 0.41973\n",
      "Epoch 2618/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9001 - val_loss: 1.0866 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02618: val_loss did not improve from 0.41973\n",
      "Epoch 2619/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 1.0867 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02619: val_loss did not improve from 0.41973\n",
      "Epoch 2620/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.0767 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02620: val_loss did not improve from 0.41973\n",
      "Epoch 2621/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.0821 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02621: val_loss did not improve from 0.41973\n",
      "Epoch 2622/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9014 - val_loss: 1.0858 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02622: val_loss did not improve from 0.41973\n",
      "Epoch 2623/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 1.0799 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02623: val_loss did not improve from 0.41973\n",
      "Epoch 2624/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.0823 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02624: val_loss did not improve from 0.41973\n",
      "Epoch 2625/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.8988 - val_loss: 1.0974 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02625: val_loss did not improve from 0.41973\n",
      "Epoch 2626/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 1.0911 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02626: val_loss did not improve from 0.41973\n",
      "Epoch 2627/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9001 - val_loss: 1.0827 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02627: val_loss did not improve from 0.41973\n",
      "Epoch 2628/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 1.0954 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02628: val_loss did not improve from 0.41973\n",
      "Epoch 2629/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8975 - val_loss: 1.1002 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02629: val_loss did not improve from 0.41973\n",
      "Epoch 2630/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.8975 - val_loss: 1.0936 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02630: val_loss did not improve from 0.41973\n",
      "Epoch 2631/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8988 - val_loss: 1.0839 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02631: val_loss did not improve from 0.41973\n",
      "Epoch 2632/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9001 - val_loss: 1.0885 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02632: val_loss did not improve from 0.41973\n",
      "Epoch 2633/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.0847 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02633: val_loss did not improve from 0.41973\n",
      "Epoch 2634/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.0930 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02634: val_loss did not improve from 0.41973\n",
      "Epoch 2635/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 1.0774 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02635: val_loss did not improve from 0.41973\n",
      "Epoch 2636/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.0733 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02636: val_loss did not improve from 0.41973\n",
      "Epoch 2637/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8962 - val_loss: 1.0860 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02637: val_loss did not improve from 0.41973\n",
      "Epoch 2638/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 1.0920 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02638: val_loss did not improve from 0.41973\n",
      "Epoch 2639/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 1.0755 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02639: val_loss did not improve from 0.41973\n",
      "Epoch 2640/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.8988 - val_loss: 1.0776 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02640: val_loss did not improve from 0.41973\n",
      "Epoch 2641/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 1.0785 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02641: val_loss did not improve from 0.41973\n",
      "Epoch 2642/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.0847 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02642: val_loss did not improve from 0.41973\n",
      "Epoch 2643/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8988 - val_loss: 1.0905 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02643: val_loss did not improve from 0.41973\n",
      "Epoch 2644/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.8988 - val_loss: 1.0939 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02644: val_loss did not improve from 0.41973\n",
      "Epoch 2645/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9014 - val_loss: 1.0823 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02645: val_loss did not improve from 0.41973\n",
      "Epoch 2646/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8988 - val_loss: 1.0848 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02646: val_loss did not improve from 0.41973\n",
      "Epoch 2647/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8988 - val_loss: 1.0887 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02647: val_loss did not improve from 0.41973\n",
      "Epoch 2648/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.8988 - val_loss: 1.0849 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02648: val_loss did not improve from 0.41973\n",
      "Epoch 2649/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.8975 - val_loss: 1.0635 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02649: val_loss did not improve from 0.41973\n",
      "Epoch 2650/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.0412 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02650: val_loss did not improve from 0.41973\n",
      "Epoch 2651/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 1.0524 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02651: val_loss did not improve from 0.41973\n",
      "Epoch 2652/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.0400 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02652: val_loss did not improve from 0.41973\n",
      "Epoch 2653/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 1.0360 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02653: val_loss did not improve from 0.41973\n",
      "Epoch 2654/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 1.0014 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02654: val_loss did not improve from 0.41973\n",
      "Epoch 2655/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 1.0210 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02655: val_loss did not improve from 0.41973\n",
      "Epoch 2656/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 1.0204 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02656: val_loss did not improve from 0.41973\n",
      "Epoch 2657/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 1.0372 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02657: val_loss did not improve from 0.41973\n",
      "Epoch 2658/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 1.0439 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02658: val_loss did not improve from 0.41973\n",
      "Epoch 2659/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.0473 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02659: val_loss did not improve from 0.41973\n",
      "Epoch 2660/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 1.0580 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02660: val_loss did not improve from 0.41973\n",
      "Epoch 2661/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.8988 - val_loss: 1.0716 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02661: val_loss did not improve from 0.41973\n",
      "Epoch 2662/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8975 - val_loss: 1.0785 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02662: val_loss did not improve from 0.41973\n",
      "Epoch 2663/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.0599 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02663: val_loss did not improve from 0.41973\n",
      "Epoch 2664/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 1.0605 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02664: val_loss did not improve from 0.41973\n",
      "Epoch 2665/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.8988 - val_loss: 1.0470 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02665: val_loss did not improve from 0.41973\n",
      "Epoch 2666/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 1.0432 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02666: val_loss did not improve from 0.41973\n",
      "Epoch 2667/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 1.0486 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02667: val_loss did not improve from 0.41973\n",
      "Epoch 2668/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8975 - val_loss: 1.0432 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02668: val_loss did not improve from 0.41973\n",
      "Epoch 2669/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.0563 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02669: val_loss did not improve from 0.41973\n",
      "Epoch 2670/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.8988 - val_loss: 1.0401 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02670: val_loss did not improve from 0.41973\n",
      "Epoch 2671/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.0405 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02671: val_loss did not improve from 0.41973\n",
      "Epoch 2672/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 1.0572 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02672: val_loss did not improve from 0.41973\n",
      "Epoch 2673/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9027 - val_loss: 1.0441 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02673: val_loss did not improve from 0.41973\n",
      "Epoch 2674/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8988 - val_loss: 1.0673 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02674: val_loss did not improve from 0.41973\n",
      "Epoch 2675/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 1.0754 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02675: val_loss did not improve from 0.41973\n",
      "Epoch 2676/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.0609 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02676: val_loss did not improve from 0.41973\n",
      "Epoch 2677/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9001 - val_loss: 1.0407 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02677: val_loss did not improve from 0.41973\n",
      "Epoch 2678/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.0479 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02678: val_loss did not improve from 0.41973\n",
      "Epoch 2679/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.0408 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02679: val_loss did not improve from 0.41973\n",
      "Epoch 2680/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.0371 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02680: val_loss did not improve from 0.41973\n",
      "Epoch 2681/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9040 - val_loss: 1.0400 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02681: val_loss did not improve from 0.41973\n",
      "Epoch 2682/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.0383 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02682: val_loss did not improve from 0.41973\n",
      "Epoch 2683/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 1.0327 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02683: val_loss did not improve from 0.41973\n",
      "Epoch 2684/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9001 - val_loss: 1.0446 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02684: val_loss did not improve from 0.41973\n",
      "Epoch 2685/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.0389 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02685: val_loss did not improve from 0.41973\n",
      "Epoch 2686/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 1.0277 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02686: val_loss did not improve from 0.41973\n",
      "Epoch 2687/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.8988 - val_loss: 1.0297 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02687: val_loss did not improve from 0.41973\n",
      "Epoch 2688/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 1.0686 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02688: val_loss did not improve from 0.41973\n",
      "Epoch 2689/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.0635 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02689: val_loss did not improve from 0.41973\n",
      "Epoch 2690/4000\n",
      "25/25 - 0s - loss: 0.2041 - accuracy: 0.9014 - val_loss: 1.1573 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02690: val_loss did not improve from 0.41973\n",
      "Epoch 2691/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 1.1819 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02691: val_loss did not improve from 0.41973\n",
      "Epoch 2692/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9001 - val_loss: 1.1724 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02692: val_loss did not improve from 0.41973\n",
      "Epoch 2693/4000\n",
      "25/25 - 0s - loss: 0.2034 - accuracy: 0.9001 - val_loss: 1.1591 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02693: val_loss did not improve from 0.41973\n",
      "Epoch 2694/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9001 - val_loss: 1.1294 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02694: val_loss did not improve from 0.41973\n",
      "Epoch 2695/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9001 - val_loss: 1.1643 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02695: val_loss did not improve from 0.41973\n",
      "Epoch 2696/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.8988 - val_loss: 1.1455 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02696: val_loss did not improve from 0.41973\n",
      "Epoch 2697/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 1.1905 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02697: val_loss did not improve from 0.41973\n",
      "Epoch 2698/4000\n",
      "25/25 - 0s - loss: 0.2084 - accuracy: 0.9027 - val_loss: 1.2107 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02698: val_loss did not improve from 0.41973\n",
      "Epoch 2699/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.8975 - val_loss: 1.1919 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02699: val_loss did not improve from 0.41973\n",
      "Epoch 2700/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9027 - val_loss: 1.2100 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02700: val_loss did not improve from 0.41973\n",
      "Epoch 2701/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 1.1949 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02701: val_loss did not improve from 0.41973\n",
      "Epoch 2702/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.1988 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02702: val_loss did not improve from 0.41973\n",
      "Epoch 2703/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 1.2014 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02703: val_loss did not improve from 0.41973\n",
      "Epoch 2704/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 1.2155 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02704: val_loss did not improve from 0.41973\n",
      "Epoch 2705/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 1.2094 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02705: val_loss did not improve from 0.41973\n",
      "Epoch 2706/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.2053 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02706: val_loss did not improve from 0.41973\n",
      "Epoch 2707/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.2021 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02707: val_loss did not improve from 0.41973\n",
      "Epoch 2708/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 1.2188 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02708: val_loss did not improve from 0.41973\n",
      "Epoch 2709/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.2232 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02709: val_loss did not improve from 0.41973\n",
      "Epoch 2710/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9027 - val_loss: 1.2223 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02710: val_loss did not improve from 0.41973\n",
      "Epoch 2711/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 1.2234 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02711: val_loss did not improve from 0.41973\n",
      "Epoch 2712/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8975 - val_loss: 1.2026 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02712: val_loss did not improve from 0.41973\n",
      "Epoch 2713/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.1915 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02713: val_loss did not improve from 0.41973\n",
      "Epoch 2714/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.8988 - val_loss: 1.1882 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02714: val_loss did not improve from 0.41973\n",
      "Epoch 2715/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 1.1793 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02715: val_loss did not improve from 0.41973\n",
      "Epoch 2716/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 1.1603 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02716: val_loss did not improve from 0.41973\n",
      "Epoch 2717/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.1543 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02717: val_loss did not improve from 0.41973\n",
      "Epoch 2718/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 1.1592 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02718: val_loss did not improve from 0.41973\n",
      "Epoch 2719/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.1864 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02719: val_loss did not improve from 0.41973\n",
      "Epoch 2720/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9014 - val_loss: 1.1708 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02720: val_loss did not improve from 0.41973\n",
      "Epoch 2721/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 1.1773 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02721: val_loss did not improve from 0.41973\n",
      "Epoch 2722/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9014 - val_loss: 1.1779 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02722: val_loss did not improve from 0.41973\n",
      "Epoch 2723/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 1.2171 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02723: val_loss did not improve from 0.41973\n",
      "Epoch 2724/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9014 - val_loss: 1.2480 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02724: val_loss did not improve from 0.41973\n",
      "Epoch 2725/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.8962 - val_loss: 1.2299 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02725: val_loss did not improve from 0.41973\n",
      "Epoch 2726/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.2193 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02726: val_loss did not improve from 0.41973\n",
      "Epoch 2727/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9001 - val_loss: 1.2185 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02727: val_loss did not improve from 0.41973\n",
      "Epoch 2728/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9001 - val_loss: 1.2220 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02728: val_loss did not improve from 0.41973\n",
      "Epoch 2729/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 1.2121 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02729: val_loss did not improve from 0.41973\n",
      "Epoch 2730/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8975 - val_loss: 1.2139 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02730: val_loss did not improve from 0.41973\n",
      "Epoch 2731/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8988 - val_loss: 1.1864 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02731: val_loss did not improve from 0.41973\n",
      "Epoch 2732/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 1.1851 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02732: val_loss did not improve from 0.41973\n",
      "Epoch 2733/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9001 - val_loss: 1.1530 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02733: val_loss did not improve from 0.41973\n",
      "Epoch 2734/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9040 - val_loss: 1.1567 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02734: val_loss did not improve from 0.41973\n",
      "Epoch 2735/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 1.1497 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02735: val_loss did not improve from 0.41973\n",
      "Epoch 2736/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.8975 - val_loss: 1.1640 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02736: val_loss did not improve from 0.41973\n",
      "Epoch 2737/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8975 - val_loss: 1.1608 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02737: val_loss did not improve from 0.41973\n",
      "Epoch 2738/4000\n",
      "25/25 - 1s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 1.1769 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02738: val_loss did not improve from 0.41973\n",
      "Epoch 2739/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 1.1601 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02739: val_loss did not improve from 0.41973\n",
      "Epoch 2740/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9014 - val_loss: 1.1679 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02740: val_loss did not improve from 0.41973\n",
      "Epoch 2741/4000\n",
      "25/25 - 0s - loss: 0.2036 - accuracy: 0.8988 - val_loss: 1.1802 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02741: val_loss did not improve from 0.41973\n",
      "Epoch 2742/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9040 - val_loss: 1.1607 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02742: val_loss did not improve from 0.41973\n",
      "Epoch 2743/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9027 - val_loss: 1.1494 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02743: val_loss did not improve from 0.41973\n",
      "Epoch 2744/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9014 - val_loss: 1.1347 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02744: val_loss did not improve from 0.41973\n",
      "Epoch 2745/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 1.1466 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02745: val_loss did not improve from 0.41973\n",
      "Epoch 2746/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.1510 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02746: val_loss did not improve from 0.41973\n",
      "Epoch 2747/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 1.1597 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02747: val_loss did not improve from 0.41973\n",
      "Epoch 2748/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9040 - val_loss: 1.1690 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02748: val_loss did not improve from 0.41973\n",
      "Epoch 2749/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9014 - val_loss: 1.1590 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02749: val_loss did not improve from 0.41973\n",
      "Epoch 2750/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9027 - val_loss: 1.1770 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02750: val_loss did not improve from 0.41973\n",
      "Epoch 2751/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 1.1804 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02751: val_loss did not improve from 0.41973\n",
      "Epoch 2752/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 1.1728 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02752: val_loss did not improve from 0.41973\n",
      "Epoch 2753/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 1.1726 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02753: val_loss did not improve from 0.41973\n",
      "Epoch 2754/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9014 - val_loss: 1.1619 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02754: val_loss did not improve from 0.41973\n",
      "Epoch 2755/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.1686 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02755: val_loss did not improve from 0.41973\n",
      "Epoch 2756/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9001 - val_loss: 1.1611 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02756: val_loss did not improve from 0.41973\n",
      "Epoch 2757/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 1.1722 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02757: val_loss did not improve from 0.41973\n",
      "Epoch 2758/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 1.1638 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02758: val_loss did not improve from 0.41973\n",
      "Epoch 2759/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9027 - val_loss: 1.1651 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02759: val_loss did not improve from 0.41973\n",
      "Epoch 2760/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.1348 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02760: val_loss did not improve from 0.41973\n",
      "Epoch 2761/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9014 - val_loss: 1.1334 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02761: val_loss did not improve from 0.41973\n",
      "Epoch 2762/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9040 - val_loss: 1.0833 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02762: val_loss did not improve from 0.41973\n",
      "Epoch 2763/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 1.0757 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02763: val_loss did not improve from 0.41973\n",
      "Epoch 2764/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8962 - val_loss: 1.0787 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02764: val_loss did not improve from 0.41973\n",
      "Epoch 2765/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9014 - val_loss: 1.0831 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02765: val_loss did not improve from 0.41973\n",
      "Epoch 2766/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 1.0654 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02766: val_loss did not improve from 0.41973\n",
      "Epoch 2767/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.9027 - val_loss: 1.0808 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02767: val_loss did not improve from 0.41973\n",
      "Epoch 2768/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9040 - val_loss: 1.0489 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02768: val_loss did not improve from 0.41973\n",
      "Epoch 2769/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 1.0509 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02769: val_loss did not improve from 0.41973\n",
      "Epoch 2770/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8988 - val_loss: 1.0351 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02770: val_loss did not improve from 0.41973\n",
      "Epoch 2771/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8975 - val_loss: 1.0369 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02771: val_loss did not improve from 0.41973\n",
      "Epoch 2772/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9027 - val_loss: 0.9828 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02772: val_loss did not improve from 0.41973\n",
      "Epoch 2773/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9027 - val_loss: 0.9898 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02773: val_loss did not improve from 0.41973\n",
      "Epoch 2774/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8975 - val_loss: 1.0037 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02774: val_loss did not improve from 0.41973\n",
      "Epoch 2775/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9001 - val_loss: 1.0168 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02775: val_loss did not improve from 0.41973\n",
      "Epoch 2776/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9014 - val_loss: 1.0135 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02776: val_loss did not improve from 0.41973\n",
      "Epoch 2777/4000\n",
      "25/25 - 0s - loss: 0.2036 - accuracy: 0.9027 - val_loss: 1.0209 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02777: val_loss did not improve from 0.41973\n",
      "Epoch 2778/4000\n",
      "25/25 - 0s - loss: 0.2027 - accuracy: 0.9027 - val_loss: 1.0359 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02778: val_loss did not improve from 0.41973\n",
      "Epoch 2779/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 1.0505 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02779: val_loss did not improve from 0.41973\n",
      "Epoch 2780/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 1.0612 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02780: val_loss did not improve from 0.41973\n",
      "Epoch 2781/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 1.0552 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02781: val_loss did not improve from 0.41973\n",
      "Epoch 2782/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8988 - val_loss: 1.0494 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02782: val_loss did not improve from 0.41973\n",
      "Epoch 2783/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 1.0721 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02783: val_loss did not improve from 0.41973\n",
      "Epoch 2784/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9027 - val_loss: 1.1034 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02784: val_loss did not improve from 0.41973\n",
      "Epoch 2785/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 1.1113 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02785: val_loss did not improve from 0.41973\n",
      "Epoch 2786/4000\n",
      "25/25 - 1s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 1.0979 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02786: val_loss did not improve from 0.41973\n",
      "Epoch 2787/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 1.1024 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02787: val_loss did not improve from 0.41973\n",
      "Epoch 2788/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 1.1021 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02788: val_loss did not improve from 0.41973\n",
      "Epoch 2789/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.0832 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02789: val_loss did not improve from 0.41973\n",
      "Epoch 2790/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.0830 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02790: val_loss did not improve from 0.41973\n",
      "Epoch 2791/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 1.0853 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02791: val_loss did not improve from 0.41973\n",
      "Epoch 2792/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.0871 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02792: val_loss did not improve from 0.41973\n",
      "Epoch 2793/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.0725 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02793: val_loss did not improve from 0.41973\n",
      "Epoch 2794/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 1.0021 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02794: val_loss did not improve from 0.41973\n",
      "Epoch 2795/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.0281 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02795: val_loss did not improve from 0.41973\n",
      "Epoch 2796/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9014 - val_loss: 1.0235 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02796: val_loss did not improve from 0.41973\n",
      "Epoch 2797/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.8988 - val_loss: 1.0336 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02797: val_loss did not improve from 0.41973\n",
      "Epoch 2798/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 1.0495 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02798: val_loss did not improve from 0.41973\n",
      "Epoch 2799/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9014 - val_loss: 1.0427 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02799: val_loss did not improve from 0.41973\n",
      "Epoch 2800/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 1.0481 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02800: val_loss did not improve from 0.41973\n",
      "Epoch 2801/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.0467 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02801: val_loss did not improve from 0.41973\n",
      "Epoch 2802/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 1.0406 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02802: val_loss did not improve from 0.41973\n",
      "Epoch 2803/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 1.0112 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02803: val_loss did not improve from 0.41973\n",
      "Epoch 2804/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 1.0057 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02804: val_loss did not improve from 0.41973\n",
      "Epoch 2805/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 1.0619 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02805: val_loss did not improve from 0.41973\n",
      "Epoch 2806/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9014 - val_loss: 1.0907 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02806: val_loss did not improve from 0.41973\n",
      "Epoch 2807/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 1.0749 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02807: val_loss did not improve from 0.41973\n",
      "Epoch 2808/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9014 - val_loss: 1.0986 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02808: val_loss did not improve from 0.41973\n",
      "Epoch 2809/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 1.1041 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02809: val_loss did not improve from 0.41973\n",
      "Epoch 2810/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9027 - val_loss: 1.1188 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02810: val_loss did not improve from 0.41973\n",
      "Epoch 2811/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.1458 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02811: val_loss did not improve from 0.41973\n",
      "Epoch 2812/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.1367 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02812: val_loss did not improve from 0.41973\n",
      "Epoch 2813/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9014 - val_loss: 1.1259 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02813: val_loss did not improve from 0.41973\n",
      "Epoch 2814/4000\n",
      "25/25 - 0s - loss: 0.2029 - accuracy: 0.8988 - val_loss: 1.1168 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02814: val_loss did not improve from 0.41973\n",
      "Epoch 2815/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.9027 - val_loss: 1.1175 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02815: val_loss did not improve from 0.41973\n",
      "Epoch 2816/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9014 - val_loss: 1.1503 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02816: val_loss did not improve from 0.41973\n",
      "Epoch 2817/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 1.1720 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02817: val_loss did not improve from 0.41973\n",
      "Epoch 2818/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9027 - val_loss: 1.1582 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02818: val_loss did not improve from 0.41973\n",
      "Epoch 2819/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 1.1530 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02819: val_loss did not improve from 0.41973\n",
      "Epoch 2820/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.8975 - val_loss: 1.1980 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02820: val_loss did not improve from 0.41973\n",
      "Epoch 2821/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9014 - val_loss: 1.2306 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02821: val_loss did not improve from 0.41973\n",
      "Epoch 2822/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9014 - val_loss: 1.1699 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02822: val_loss did not improve from 0.41973\n",
      "Epoch 2823/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 1.1511 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02823: val_loss did not improve from 0.41973\n",
      "Epoch 2824/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8975 - val_loss: 1.1776 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02824: val_loss did not improve from 0.41973\n",
      "Epoch 2825/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.1970 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02825: val_loss did not improve from 0.41973\n",
      "Epoch 2826/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9001 - val_loss: 1.1869 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02826: val_loss did not improve from 0.41973\n",
      "Epoch 2827/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9001 - val_loss: 1.1723 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02827: val_loss did not improve from 0.41973\n",
      "Epoch 2828/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 1.1638 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02828: val_loss did not improve from 0.41973\n",
      "Epoch 2829/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 1.1561 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02829: val_loss did not improve from 0.41973\n",
      "Epoch 2830/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 1.1470 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02830: val_loss did not improve from 0.41973\n",
      "Epoch 2831/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 1.1180 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02831: val_loss did not improve from 0.41973\n",
      "Epoch 2832/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9027 - val_loss: 1.1283 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02832: val_loss did not improve from 0.41973\n",
      "Epoch 2833/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 1.1265 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02833: val_loss did not improve from 0.41973\n",
      "Epoch 2834/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 1.1536 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02834: val_loss did not improve from 0.41973\n",
      "Epoch 2835/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8988 - val_loss: 1.1881 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02835: val_loss did not improve from 0.41973\n",
      "Epoch 2836/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9001 - val_loss: 1.2015 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02836: val_loss did not improve from 0.41973\n",
      "Epoch 2837/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8962 - val_loss: 1.1980 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02837: val_loss did not improve from 0.41973\n",
      "Epoch 2838/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.1901 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02838: val_loss did not improve from 0.41973\n",
      "Epoch 2839/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9001 - val_loss: 1.2102 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02839: val_loss did not improve from 0.41973\n",
      "Epoch 2840/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 1.2174 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02840: val_loss did not improve from 0.41973\n",
      "Epoch 2841/4000\n",
      "25/25 - 0s - loss: 0.2029 - accuracy: 0.9014 - val_loss: 1.1933 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02841: val_loss did not improve from 0.41973\n",
      "Epoch 2842/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9014 - val_loss: 1.2016 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02842: val_loss did not improve from 0.41973\n",
      "Epoch 2843/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.2086 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02843: val_loss did not improve from 0.41973\n",
      "Epoch 2844/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.1969 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02844: val_loss did not improve from 0.41973\n",
      "Epoch 2845/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.1906 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02845: val_loss did not improve from 0.41973\n",
      "Epoch 2846/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9001 - val_loss: 1.2108 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02846: val_loss did not improve from 0.41973\n",
      "Epoch 2847/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9001 - val_loss: 1.1843 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02847: val_loss did not improve from 0.41973\n",
      "Epoch 2848/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.1737 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02848: val_loss did not improve from 0.41973\n",
      "Epoch 2849/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 1.1656 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02849: val_loss did not improve from 0.41973\n",
      "Epoch 2850/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8962 - val_loss: 1.1586 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02850: val_loss did not improve from 0.41973\n",
      "Epoch 2851/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9014 - val_loss: 1.1611 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02851: val_loss did not improve from 0.41973\n",
      "Epoch 2852/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 1.1812 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02852: val_loss did not improve from 0.41973\n",
      "Epoch 2853/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.1854 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02853: val_loss did not improve from 0.41973\n",
      "Epoch 2854/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9001 - val_loss: 1.1801 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02854: val_loss did not improve from 0.41973\n",
      "Epoch 2855/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 1.1919 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02855: val_loss did not improve from 0.41973\n",
      "Epoch 2856/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9001 - val_loss: 1.1870 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02856: val_loss did not improve from 0.41973\n",
      "Epoch 2857/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8988 - val_loss: 1.1907 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02857: val_loss did not improve from 0.41973\n",
      "Epoch 2858/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9001 - val_loss: 1.1972 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02858: val_loss did not improve from 0.41973\n",
      "Epoch 2859/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9027 - val_loss: 1.1985 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02859: val_loss did not improve from 0.41973\n",
      "Epoch 2860/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9001 - val_loss: 1.2102 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02860: val_loss did not improve from 0.41973\n",
      "Epoch 2861/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9001 - val_loss: 1.2248 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02861: val_loss did not improve from 0.41973\n",
      "Epoch 2862/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9001 - val_loss: 1.2219 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02862: val_loss did not improve from 0.41973\n",
      "Epoch 2863/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9001 - val_loss: 1.2063 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02863: val_loss did not improve from 0.41973\n",
      "Epoch 2864/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 1.2118 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02864: val_loss did not improve from 0.41973\n",
      "Epoch 2865/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 1.2219 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02865: val_loss did not improve from 0.41973\n",
      "Epoch 2866/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 1.2328 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02866: val_loss did not improve from 0.41973\n",
      "Epoch 2867/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 1.2200 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02867: val_loss did not improve from 0.41973\n",
      "Epoch 2868/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.2221 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02868: val_loss did not improve from 0.41973\n",
      "Epoch 2869/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 1.2229 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02869: val_loss did not improve from 0.41973\n",
      "Epoch 2870/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.2385 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02870: val_loss did not improve from 0.41973\n",
      "Epoch 2871/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.2242 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02871: val_loss did not improve from 0.41973\n",
      "Epoch 2872/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.2178 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02872: val_loss did not improve from 0.41973\n",
      "Epoch 2873/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.2203 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02873: val_loss did not improve from 0.41973\n",
      "Epoch 2874/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 1.2165 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02874: val_loss did not improve from 0.41973\n",
      "Epoch 2875/4000\n",
      "25/25 - 0s - loss: 0.2192 - accuracy: 0.8975 - val_loss: 1.1472 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02875: val_loss did not improve from 0.41973\n",
      "Epoch 2876/4000\n",
      "25/25 - 0s - loss: 0.2845 - accuracy: 0.8898 - val_loss: 0.9759 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02876: val_loss did not improve from 0.41973\n",
      "Epoch 2877/4000\n",
      "25/25 - 0s - loss: 0.2132 - accuracy: 0.8975 - val_loss: 0.9940 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02877: val_loss did not improve from 0.41973\n",
      "Epoch 2878/4000\n",
      "25/25 - 0s - loss: 0.2039 - accuracy: 0.9001 - val_loss: 1.0142 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02878: val_loss did not improve from 0.41973\n",
      "Epoch 2879/4000\n",
      "25/25 - 0s - loss: 0.2029 - accuracy: 0.9014 - val_loss: 1.0237 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02879: val_loss did not improve from 0.41973\n",
      "Epoch 2880/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.8988 - val_loss: 1.0096 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02880: val_loss did not improve from 0.41973\n",
      "Epoch 2881/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9040 - val_loss: 1.0134 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02881: val_loss did not improve from 0.41973\n",
      "Epoch 2882/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.9027 - val_loss: 1.0070 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02882: val_loss did not improve from 0.41973\n",
      "Epoch 2883/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9027 - val_loss: 1.0056 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02883: val_loss did not improve from 0.41973\n",
      "Epoch 2884/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9001 - val_loss: 0.9998 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02884: val_loss did not improve from 0.41973\n",
      "Epoch 2885/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9001 - val_loss: 1.0067 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02885: val_loss did not improve from 0.41973\n",
      "Epoch 2886/4000\n",
      "25/25 - 0s - loss: 0.2031 - accuracy: 0.9014 - val_loss: 1.0056 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02886: val_loss did not improve from 0.41973\n",
      "Epoch 2887/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9001 - val_loss: 0.9953 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02887: val_loss did not improve from 0.41973\n",
      "Epoch 2888/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.8988 - val_loss: 0.9823 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02888: val_loss did not improve from 0.41973\n",
      "Epoch 2889/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 0.9691 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02889: val_loss did not improve from 0.41973\n",
      "Epoch 2890/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9001 - val_loss: 0.9659 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02890: val_loss did not improve from 0.41973\n",
      "Epoch 2891/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.8988 - val_loss: 0.9552 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02891: val_loss did not improve from 0.41973\n",
      "Epoch 2892/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 0.9502 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02892: val_loss did not improve from 0.41973\n",
      "Epoch 2893/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9014 - val_loss: 0.9546 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02893: val_loss did not improve from 0.41973\n",
      "Epoch 2894/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 0.9917 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02894: val_loss did not improve from 0.41973\n",
      "Epoch 2895/4000\n",
      "25/25 - 0s - loss: 0.2028 - accuracy: 0.8988 - val_loss: 0.9914 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02895: val_loss did not improve from 0.41973\n",
      "Epoch 2896/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.8988 - val_loss: 0.9769 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02896: val_loss did not improve from 0.41973\n",
      "Epoch 2897/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9014 - val_loss: 0.9728 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02897: val_loss did not improve from 0.41973\n",
      "Epoch 2898/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 0.9745 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02898: val_loss did not improve from 0.41973\n",
      "Epoch 2899/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 0.9661 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02899: val_loss did not improve from 0.41973\n",
      "Epoch 2900/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9014 - val_loss: 0.9630 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02900: val_loss did not improve from 0.41973\n",
      "Epoch 2901/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 0.9494 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02901: val_loss did not improve from 0.41973\n",
      "Epoch 2902/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 0.9509 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02902: val_loss did not improve from 0.41973\n",
      "Epoch 2903/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9027 - val_loss: 0.9451 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02903: val_loss did not improve from 0.41973\n",
      "Epoch 2904/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9027 - val_loss: 0.9482 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02904: val_loss did not improve from 0.41973\n",
      "Epoch 2905/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9040 - val_loss: 0.9394 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02905: val_loss did not improve from 0.41973\n",
      "Epoch 2906/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 0.9563 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02906: val_loss did not improve from 0.41973\n",
      "Epoch 2907/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 0.9709 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02907: val_loss did not improve from 0.41973\n",
      "Epoch 2908/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 0.9669 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02908: val_loss did not improve from 0.41973\n",
      "Epoch 2909/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 0.9458 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02909: val_loss did not improve from 0.41973\n",
      "Epoch 2910/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 0.9402 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02910: val_loss did not improve from 0.41973\n",
      "Epoch 2911/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 0.9390 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02911: val_loss did not improve from 0.41973\n",
      "Epoch 2912/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.8988 - val_loss: 0.9380 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02912: val_loss did not improve from 0.41973\n",
      "Epoch 2913/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8975 - val_loss: 0.9409 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02913: val_loss did not improve from 0.41973\n",
      "Epoch 2914/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9014 - val_loss: 0.9325 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02914: val_loss did not improve from 0.41973\n",
      "Epoch 2915/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.8988 - val_loss: 0.9199 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02915: val_loss did not improve from 0.41973\n",
      "Epoch 2916/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.8988 - val_loss: 0.9194 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02916: val_loss did not improve from 0.41973\n",
      "Epoch 2917/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 0.9304 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02917: val_loss did not improve from 0.41973\n",
      "Epoch 2918/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 0.9152 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02918: val_loss did not improve from 0.41973\n",
      "Epoch 2919/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 0.9052 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02919: val_loss did not improve from 0.41973\n",
      "Epoch 2920/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8988 - val_loss: 0.9040 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02920: val_loss did not improve from 0.41973\n",
      "Epoch 2921/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 0.9068 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02921: val_loss did not improve from 0.41973\n",
      "Epoch 2922/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 0.8766 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02922: val_loss did not improve from 0.41973\n",
      "Epoch 2923/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8988 - val_loss: 0.8805 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02923: val_loss did not improve from 0.41973\n",
      "Epoch 2924/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 0.8902 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02924: val_loss did not improve from 0.41973\n",
      "Epoch 2925/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 0.8885 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02925: val_loss did not improve from 0.41973\n",
      "Epoch 2926/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9001 - val_loss: 0.8780 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02926: val_loss did not improve from 0.41973\n",
      "Epoch 2927/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 0.8815 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02927: val_loss did not improve from 0.41973\n",
      "Epoch 2928/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9014 - val_loss: 0.8739 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02928: val_loss did not improve from 0.41973\n",
      "Epoch 2929/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9001 - val_loss: 0.8913 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02929: val_loss did not improve from 0.41973\n",
      "Epoch 2930/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 0.9074 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02930: val_loss did not improve from 0.41973\n",
      "Epoch 2931/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 0.9236 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02931: val_loss did not improve from 0.41973\n",
      "Epoch 2932/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9014 - val_loss: 0.9216 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02932: val_loss did not improve from 0.41973\n",
      "Epoch 2933/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 0.9382 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02933: val_loss did not improve from 0.41973\n",
      "Epoch 2934/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 0.9233 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02934: val_loss did not improve from 0.41973\n",
      "Epoch 2935/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 0.9381 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02935: val_loss did not improve from 0.41973\n",
      "Epoch 2936/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 0.9381 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02936: val_loss did not improve from 0.41973\n",
      "Epoch 2937/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 0.9394 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02937: val_loss did not improve from 0.41973\n",
      "Epoch 2938/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 0.9407 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02938: val_loss did not improve from 0.41973\n",
      "Epoch 2939/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 0.9372 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02939: val_loss did not improve from 0.41973\n",
      "Epoch 2940/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 0.9340 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02940: val_loss did not improve from 0.41973\n",
      "Epoch 2941/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 0.9288 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02941: val_loss did not improve from 0.41973\n",
      "Epoch 2942/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 0.9279 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02942: val_loss did not improve from 0.41973\n",
      "Epoch 2943/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8975 - val_loss: 0.9326 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02943: val_loss did not improve from 0.41973\n",
      "Epoch 2944/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 0.9381 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02944: val_loss did not improve from 0.41973\n",
      "Epoch 2945/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 0.9383 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02945: val_loss did not improve from 0.41973\n",
      "Epoch 2946/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8988 - val_loss: 0.9497 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02946: val_loss did not improve from 0.41973\n",
      "Epoch 2947/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9040 - val_loss: 0.9458 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02947: val_loss did not improve from 0.41973\n",
      "Epoch 2948/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 0.9548 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02948: val_loss did not improve from 0.41973\n",
      "Epoch 2949/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9027 - val_loss: 0.9756 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02949: val_loss did not improve from 0.41973\n",
      "Epoch 2950/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 0.8693 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02950: val_loss did not improve from 0.41973\n",
      "Epoch 2951/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 0.9025 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02951: val_loss did not improve from 0.41973\n",
      "Epoch 2952/4000\n",
      "25/25 - 0s - loss: 0.2063 - accuracy: 0.9014 - val_loss: 0.9204 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02952: val_loss did not improve from 0.41973\n",
      "Epoch 2953/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 0.9155 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02953: val_loss did not improve from 0.41973\n",
      "Epoch 2954/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 0.9152 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02954: val_loss did not improve from 0.41973\n",
      "Epoch 2955/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 0.9103 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02955: val_loss did not improve from 0.41973\n",
      "Epoch 2956/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 0.9178 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02956: val_loss did not improve from 0.41973\n",
      "Epoch 2957/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 0.9143 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02957: val_loss did not improve from 0.41973\n",
      "Epoch 2958/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 0.9230 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02958: val_loss did not improve from 0.41973\n",
      "Epoch 2959/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9027 - val_loss: 0.9241 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02959: val_loss did not improve from 0.41973\n",
      "Epoch 2960/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9040 - val_loss: 0.9309 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02960: val_loss did not improve from 0.41973\n",
      "Epoch 2961/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8975 - val_loss: 0.9308 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02961: val_loss did not improve from 0.41973\n",
      "Epoch 2962/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 0.9271 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02962: val_loss did not improve from 0.41973\n",
      "Epoch 2963/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9014 - val_loss: 0.9261 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02963: val_loss did not improve from 0.41973\n",
      "Epoch 2964/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 0.9341 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02964: val_loss did not improve from 0.41973\n",
      "Epoch 2965/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9001 - val_loss: 0.9362 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02965: val_loss did not improve from 0.41973\n",
      "Epoch 2966/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 0.9402 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02966: val_loss did not improve from 0.41973\n",
      "Epoch 2967/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 0.9310 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02967: val_loss did not improve from 0.41973\n",
      "Epoch 2968/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9014 - val_loss: 0.9284 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02968: val_loss did not improve from 0.41973\n",
      "Epoch 2969/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 0.9356 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02969: val_loss did not improve from 0.41973\n",
      "Epoch 2970/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8988 - val_loss: 0.9159 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02970: val_loss did not improve from 0.41973\n",
      "Epoch 2971/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8988 - val_loss: 0.9258 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02971: val_loss did not improve from 0.41973\n",
      "Epoch 2972/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9014 - val_loss: 0.9213 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02972: val_loss did not improve from 0.41973\n",
      "Epoch 2973/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 0.9297 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02973: val_loss did not improve from 0.41973\n",
      "Epoch 2974/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8975 - val_loss: 0.9329 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02974: val_loss did not improve from 0.41973\n",
      "Epoch 2975/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9001 - val_loss: 0.9415 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02975: val_loss did not improve from 0.41973\n",
      "Epoch 2976/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 0.9406 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02976: val_loss did not improve from 0.41973\n",
      "Epoch 2977/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 0.9475 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02977: val_loss did not improve from 0.41973\n",
      "Epoch 2978/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 0.9439 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02978: val_loss did not improve from 0.41973\n",
      "Epoch 2979/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9001 - val_loss: 0.9394 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02979: val_loss did not improve from 0.41973\n",
      "Epoch 2980/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 0.9427 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02980: val_loss did not improve from 0.41973\n",
      "Epoch 2981/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 0.9476 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02981: val_loss did not improve from 0.41973\n",
      "Epoch 2982/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8949 - val_loss: 0.9377 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02982: val_loss did not improve from 0.41973\n",
      "Epoch 2983/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9040 - val_loss: 0.9411 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02983: val_loss did not improve from 0.41973\n",
      "Epoch 2984/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 0.9350 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02984: val_loss did not improve from 0.41973\n",
      "Epoch 2985/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9001 - val_loss: 0.9383 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02985: val_loss did not improve from 0.41973\n",
      "Epoch 2986/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9001 - val_loss: 0.9432 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02986: val_loss did not improve from 0.41973\n",
      "Epoch 2987/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8988 - val_loss: 0.9383 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02987: val_loss did not improve from 0.41973\n",
      "Epoch 2988/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 0.9361 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02988: val_loss did not improve from 0.41973\n",
      "Epoch 2989/4000\n",
      "25/25 - 1s - loss: 0.2006 - accuracy: 0.9001 - val_loss: 0.9372 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02989: val_loss did not improve from 0.41973\n",
      "Epoch 2990/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 0.9388 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02990: val_loss did not improve from 0.41973\n",
      "Epoch 2991/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 0.9343 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02991: val_loss did not improve from 0.41973\n",
      "Epoch 2992/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 0.9331 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02992: val_loss did not improve from 0.41973\n",
      "Epoch 2993/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 0.9333 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02993: val_loss did not improve from 0.41973\n",
      "Epoch 2994/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 0.9296 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02994: val_loss did not improve from 0.41973\n",
      "Epoch 2995/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 0.9437 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02995: val_loss did not improve from 0.41973\n",
      "Epoch 2996/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9027 - val_loss: 0.9404 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02996: val_loss did not improve from 0.41973\n",
      "Epoch 2997/4000\n",
      "25/25 - 1s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 0.9445 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02997: val_loss did not improve from 0.41973\n",
      "Epoch 2998/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9027 - val_loss: 0.9410 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02998: val_loss did not improve from 0.41973\n",
      "Epoch 2999/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 0.9382 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02999: val_loss did not improve from 0.41973\n",
      "Epoch 3000/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 0.9402 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03000: val_loss did not improve from 0.41973\n",
      "Epoch 3001/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9040 - val_loss: 0.9518 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03001: val_loss did not improve from 0.41973\n",
      "Epoch 3002/4000\n",
      "25/25 - 0s - loss: 0.2002 - accuracy: 0.9027 - val_loss: 0.9550 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03002: val_loss did not improve from 0.41973\n",
      "Epoch 3003/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 0.9613 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03003: val_loss did not improve from 0.41973\n",
      "Epoch 3004/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.8988 - val_loss: 0.9397 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03004: val_loss did not improve from 0.41973\n",
      "Epoch 3005/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.8975 - val_loss: 0.9342 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03005: val_loss did not improve from 0.41973\n",
      "Epoch 3006/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 0.9415 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03006: val_loss did not improve from 0.41973\n",
      "Epoch 3007/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9001 - val_loss: 0.9433 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03007: val_loss did not improve from 0.41973\n",
      "Epoch 3008/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9001 - val_loss: 0.9468 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03008: val_loss did not improve from 0.41973\n",
      "Epoch 3009/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.8962 - val_loss: 0.9557 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03009: val_loss did not improve from 0.41973\n",
      "Epoch 3010/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9014 - val_loss: 0.9594 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03010: val_loss did not improve from 0.41973\n",
      "Epoch 3011/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.8988 - val_loss: 0.9533 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03011: val_loss did not improve from 0.41973\n",
      "Epoch 3012/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9027 - val_loss: 0.8947 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03012: val_loss did not improve from 0.41973\n",
      "Epoch 3013/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 0.9221 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03013: val_loss did not improve from 0.41973\n",
      "Epoch 3014/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 0.9176 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03014: val_loss did not improve from 0.41973\n",
      "Epoch 3015/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 0.9139 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03015: val_loss did not improve from 0.41973\n",
      "Epoch 3016/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 0.9188 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03016: val_loss did not improve from 0.41973\n",
      "Epoch 3017/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.8962 - val_loss: 0.9240 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03017: val_loss did not improve from 0.41973\n",
      "Epoch 3018/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9040 - val_loss: 0.9296 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03018: val_loss did not improve from 0.41973\n",
      "Epoch 3019/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 0.9108 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03019: val_loss did not improve from 0.41973\n",
      "Epoch 3020/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 0.9036 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03020: val_loss did not improve from 0.41973\n",
      "Epoch 3021/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 0.9030 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03021: val_loss did not improve from 0.41973\n",
      "Epoch 3022/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 0.9115 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03022: val_loss did not improve from 0.41973\n",
      "Epoch 3023/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 0.8991 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03023: val_loss did not improve from 0.41973\n",
      "Epoch 3024/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 0.8971 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03024: val_loss did not improve from 0.41973\n",
      "Epoch 3025/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8988 - val_loss: 0.9026 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03025: val_loss did not improve from 0.41973\n",
      "Epoch 3026/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 0.9185 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03026: val_loss did not improve from 0.41973\n",
      "Epoch 3027/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 0.9205 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03027: val_loss did not improve from 0.41973\n",
      "Epoch 3028/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 0.9019 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03028: val_loss did not improve from 0.41973\n",
      "Epoch 3029/4000\n",
      "25/25 - 0s - loss: 0.2036 - accuracy: 0.9027 - val_loss: 0.9295 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03029: val_loss did not improve from 0.41973\n",
      "Epoch 3030/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 0.9228 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03030: val_loss did not improve from 0.41973\n",
      "Epoch 3031/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 0.9456 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03031: val_loss did not improve from 0.41973\n",
      "Epoch 3032/4000\n",
      "25/25 - 0s - loss: 0.1999 - accuracy: 0.9027 - val_loss: 1.0166 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03032: val_loss did not improve from 0.41973\n",
      "Epoch 3033/4000\n",
      "25/25 - 0s - loss: 0.2079 - accuracy: 0.9027 - val_loss: 0.8491 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03033: val_loss did not improve from 0.41973\n",
      "Epoch 3034/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 0.8669 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03034: val_loss did not improve from 0.41973\n",
      "Epoch 3035/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 0.8627 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03035: val_loss did not improve from 0.41973\n",
      "Epoch 3036/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 0.8791 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03036: val_loss did not improve from 0.41973\n",
      "Epoch 3037/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 0.8714 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03037: val_loss did not improve from 0.41973\n",
      "Epoch 3038/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 0.8755 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03038: val_loss did not improve from 0.41973\n",
      "Epoch 3039/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8988 - val_loss: 0.8790 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03039: val_loss did not improve from 0.41973\n",
      "Epoch 3040/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.9040 - val_loss: 0.8672 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03040: val_loss did not improve from 0.41973\n",
      "Epoch 3041/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9001 - val_loss: 0.9130 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03041: val_loss did not improve from 0.41973\n",
      "Epoch 3042/4000\n",
      "25/25 - 0s - loss: 0.2032 - accuracy: 0.8936 - val_loss: 0.9163 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03042: val_loss did not improve from 0.41973\n",
      "Epoch 3043/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8988 - val_loss: 0.9211 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03043: val_loss did not improve from 0.41973\n",
      "Epoch 3044/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9014 - val_loss: 0.9088 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03044: val_loss did not improve from 0.41973\n",
      "Epoch 3045/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9001 - val_loss: 0.9493 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03045: val_loss did not improve from 0.41973\n",
      "Epoch 3046/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 0.9510 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03046: val_loss did not improve from 0.41973\n",
      "Epoch 3047/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 0.9250 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03047: val_loss did not improve from 0.41973\n",
      "Epoch 3048/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 0.9411 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03048: val_loss did not improve from 0.41973\n",
      "Epoch 3049/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9014 - val_loss: 0.9456 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03049: val_loss did not improve from 0.41973\n",
      "Epoch 3050/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 0.9503 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03050: val_loss did not improve from 0.41973\n",
      "Epoch 3051/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8988 - val_loss: 0.9385 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03051: val_loss did not improve from 0.41973\n",
      "Epoch 3052/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9040 - val_loss: 0.9400 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03052: val_loss did not improve from 0.41973\n",
      "Epoch 3053/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9014 - val_loss: 0.9495 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03053: val_loss did not improve from 0.41973\n",
      "Epoch 3054/4000\n",
      "25/25 - 0s - loss: 0.2095 - accuracy: 0.9027 - val_loss: 1.0039 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03054: val_loss did not improve from 0.41973\n",
      "Epoch 3055/4000\n",
      "25/25 - 0s - loss: 0.2056 - accuracy: 0.9027 - val_loss: 1.1244 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03055: val_loss did not improve from 0.41973\n",
      "Epoch 3056/4000\n",
      "25/25 - 0s - loss: 0.2039 - accuracy: 0.9001 - val_loss: 1.1270 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03056: val_loss did not improve from 0.41973\n",
      "Epoch 3057/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.9027 - val_loss: 1.1898 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03057: val_loss did not improve from 0.41973\n",
      "Epoch 3058/4000\n",
      "25/25 - 0s - loss: 0.2993 - accuracy: 0.8872 - val_loss: 0.8105 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03058: val_loss did not improve from 0.41973\n",
      "Epoch 3059/4000\n",
      "25/25 - 0s - loss: 0.2235 - accuracy: 0.8975 - val_loss: 1.0042 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03059: val_loss did not improve from 0.41973\n",
      "Epoch 3060/4000\n",
      "25/25 - 0s - loss: 0.2135 - accuracy: 0.8988 - val_loss: 0.8228 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03060: val_loss did not improve from 0.41973\n",
      "Epoch 3061/4000\n",
      "25/25 - 0s - loss: 0.2137 - accuracy: 0.8988 - val_loss: 0.8477 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03061: val_loss did not improve from 0.41973\n",
      "Epoch 3062/4000\n",
      "25/25 - 0s - loss: 0.2061 - accuracy: 0.9040 - val_loss: 0.8625 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03062: val_loss did not improve from 0.41973\n",
      "Epoch 3063/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9001 - val_loss: 0.8738 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03063: val_loss did not improve from 0.41973\n",
      "Epoch 3064/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 0.8734 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03064: val_loss did not improve from 0.41973\n",
      "Epoch 3065/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 0.8810 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03065: val_loss did not improve from 0.41973\n",
      "Epoch 3066/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 0.8825 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03066: val_loss did not improve from 0.41973\n",
      "Epoch 3067/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 0.8917 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03067: val_loss did not improve from 0.41973\n",
      "Epoch 3068/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 0.8883 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03068: val_loss did not improve from 0.41973\n",
      "Epoch 3069/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9040 - val_loss: 0.8778 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03069: val_loss did not improve from 0.41973\n",
      "Epoch 3070/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8988 - val_loss: 0.8774 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03070: val_loss did not improve from 0.41973\n",
      "Epoch 3071/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 0.8804 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03071: val_loss did not improve from 0.41973\n",
      "Epoch 3072/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 0.8753 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03072: val_loss did not improve from 0.41973\n",
      "Epoch 3073/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 0.8801 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03073: val_loss did not improve from 0.41973\n",
      "Epoch 3074/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 0.8781 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03074: val_loss did not improve from 0.41973\n",
      "Epoch 3075/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 0.8765 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03075: val_loss did not improve from 0.41973\n",
      "Epoch 3076/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 0.8747 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03076: val_loss did not improve from 0.41973\n",
      "Epoch 3077/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 0.8788 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03077: val_loss did not improve from 0.41973\n",
      "Epoch 3078/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.8988 - val_loss: 0.8736 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03078: val_loss did not improve from 0.41973\n",
      "Epoch 3079/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 0.8745 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03079: val_loss did not improve from 0.41973\n",
      "Epoch 3080/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 0.8824 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03080: val_loss did not improve from 0.41973\n",
      "Epoch 3081/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 0.8868 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03081: val_loss did not improve from 0.41973\n",
      "Epoch 3082/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9001 - val_loss: 0.8863 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03082: val_loss did not improve from 0.41973\n",
      "Epoch 3083/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9040 - val_loss: 0.8854 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03083: val_loss did not improve from 0.41973\n",
      "Epoch 3084/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9001 - val_loss: 0.8838 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03084: val_loss did not improve from 0.41973\n",
      "Epoch 3085/4000\n",
      "25/25 - 0s - loss: 0.2002 - accuracy: 0.9014 - val_loss: 0.8898 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03085: val_loss did not improve from 0.41973\n",
      "Epoch 3086/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.8988 - val_loss: 0.8906 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03086: val_loss did not improve from 0.41973\n",
      "Epoch 3087/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 0.8959 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03087: val_loss did not improve from 0.41973\n",
      "Epoch 3088/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9027 - val_loss: 0.8884 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03088: val_loss did not improve from 0.41973\n",
      "Epoch 3089/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.8988 - val_loss: 0.8859 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03089: val_loss did not improve from 0.41973\n",
      "Epoch 3090/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 0.8857 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03090: val_loss did not improve from 0.41973\n",
      "Epoch 3091/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9027 - val_loss: 0.8739 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03091: val_loss did not improve from 0.41973\n",
      "Epoch 3092/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 0.8720 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03092: val_loss did not improve from 0.41973\n",
      "Epoch 3093/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 0.8792 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03093: val_loss did not improve from 0.41973\n",
      "Epoch 3094/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9001 - val_loss: 0.8817 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03094: val_loss did not improve from 0.41973\n",
      "Epoch 3095/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9014 - val_loss: 0.8843 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03095: val_loss did not improve from 0.41973\n",
      "Epoch 3096/4000\n",
      "25/25 - 0s - loss: 0.2001 - accuracy: 0.9014 - val_loss: 0.8871 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03096: val_loss did not improve from 0.41973\n",
      "Epoch 3097/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 0.8872 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03097: val_loss did not improve from 0.41973\n",
      "Epoch 3098/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 0.8952 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03098: val_loss did not improve from 0.41973\n",
      "Epoch 3099/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 0.8901 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03099: val_loss did not improve from 0.41973\n",
      "Epoch 3100/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 0.8886 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03100: val_loss did not improve from 0.41973\n",
      "Epoch 3101/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 0.8908 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03101: val_loss did not improve from 0.41973\n",
      "Epoch 3102/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 0.8924 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03102: val_loss did not improve from 0.41973\n",
      "Epoch 3103/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9001 - val_loss: 0.8980 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03103: val_loss did not improve from 0.41973\n",
      "Epoch 3104/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 0.8953 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03104: val_loss did not improve from 0.41973\n",
      "Epoch 3105/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 0.9020 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03105: val_loss did not improve from 0.41973\n",
      "Epoch 3106/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 0.8996 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03106: val_loss did not improve from 0.41973\n",
      "Epoch 3107/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 0.8926 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03107: val_loss did not improve from 0.41973\n",
      "Epoch 3108/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 0.8903 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03108: val_loss did not improve from 0.41973\n",
      "Epoch 3109/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 0.9063 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03109: val_loss did not improve from 0.41973\n",
      "Epoch 3110/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 0.9044 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03110: val_loss did not improve from 0.41973\n",
      "Epoch 3111/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 0.9042 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03111: val_loss did not improve from 0.41973\n",
      "Epoch 3112/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 0.9005 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03112: val_loss did not improve from 0.41973\n",
      "Epoch 3113/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 0.8992 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03113: val_loss did not improve from 0.41973\n",
      "Epoch 3114/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 0.9022 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03114: val_loss did not improve from 0.41973\n",
      "Epoch 3115/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 0.9052 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03115: val_loss did not improve from 0.41973\n",
      "Epoch 3116/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.8988 - val_loss: 0.9064 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03116: val_loss did not improve from 0.41973\n",
      "Epoch 3117/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9001 - val_loss: 0.9064 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03117: val_loss did not improve from 0.41973\n",
      "Epoch 3118/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 0.9007 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03118: val_loss did not improve from 0.41973\n",
      "Epoch 3119/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8988 - val_loss: 0.9105 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03119: val_loss did not improve from 0.41973\n",
      "Epoch 3120/4000\n",
      "25/25 - 0s - loss: 0.2001 - accuracy: 0.8988 - val_loss: 0.9138 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03120: val_loss did not improve from 0.41973\n",
      "Epoch 3121/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 0.9128 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03121: val_loss did not improve from 0.41973\n",
      "Epoch 3122/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 0.9148 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03122: val_loss did not improve from 0.41973\n",
      "Epoch 3123/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9014 - val_loss: 0.9158 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03123: val_loss did not improve from 0.41973\n",
      "Epoch 3124/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 0.9146 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03124: val_loss did not improve from 0.41973\n",
      "Epoch 3125/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8936 - val_loss: 0.9194 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03125: val_loss did not improve from 0.41973\n",
      "Epoch 3126/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 0.9255 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03126: val_loss did not improve from 0.41973\n",
      "Epoch 3127/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 0.9194 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03127: val_loss did not improve from 0.41973\n",
      "Epoch 3128/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9027 - val_loss: 0.9244 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03128: val_loss did not improve from 0.41973\n",
      "Epoch 3129/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 0.9299 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03129: val_loss did not improve from 0.41973\n",
      "Epoch 3130/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8988 - val_loss: 0.9272 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03130: val_loss did not improve from 0.41973\n",
      "Epoch 3131/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9001 - val_loss: 0.9314 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03131: val_loss did not improve from 0.41973\n",
      "Epoch 3132/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.8988 - val_loss: 0.9309 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03132: val_loss did not improve from 0.41973\n",
      "Epoch 3133/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.8988 - val_loss: 0.9329 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03133: val_loss did not improve from 0.41973\n",
      "Epoch 3134/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 0.9341 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03134: val_loss did not improve from 0.41973\n",
      "Epoch 3135/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9001 - val_loss: 0.9374 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03135: val_loss did not improve from 0.41973\n",
      "Epoch 3136/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 0.9375 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03136: val_loss did not improve from 0.41973\n",
      "Epoch 3137/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9001 - val_loss: 0.9388 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03137: val_loss did not improve from 0.41973\n",
      "Epoch 3138/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9001 - val_loss: 0.9346 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03138: val_loss did not improve from 0.41973\n",
      "Epoch 3139/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.8988 - val_loss: 0.9364 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03139: val_loss did not improve from 0.41973\n",
      "Epoch 3140/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.8975 - val_loss: 0.9328 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03140: val_loss did not improve from 0.41973\n",
      "Epoch 3141/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 0.9377 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03141: val_loss did not improve from 0.41973\n",
      "Epoch 3142/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9001 - val_loss: 0.9329 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03142: val_loss did not improve from 0.41973\n",
      "Epoch 3143/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8988 - val_loss: 0.9390 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03143: val_loss did not improve from 0.41973\n",
      "Epoch 3144/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8962 - val_loss: 0.9383 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03144: val_loss did not improve from 0.41973\n",
      "Epoch 3145/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.8962 - val_loss: 0.9373 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03145: val_loss did not improve from 0.41973\n",
      "Epoch 3146/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 0.9354 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03146: val_loss did not improve from 0.41973\n",
      "Epoch 3147/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9001 - val_loss: 0.9375 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03147: val_loss did not improve from 0.41973\n",
      "Epoch 3148/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9001 - val_loss: 0.9321 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03148: val_loss did not improve from 0.41973\n",
      "Epoch 3149/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8988 - val_loss: 0.9297 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03149: val_loss did not improve from 0.41973\n",
      "Epoch 3150/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9014 - val_loss: 0.9361 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03150: val_loss did not improve from 0.41973\n",
      "Epoch 3151/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 0.9222 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03151: val_loss did not improve from 0.41973\n",
      "Epoch 3152/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 0.9269 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03152: val_loss did not improve from 0.41973\n",
      "Epoch 3153/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.8988 - val_loss: 0.9334 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03153: val_loss did not improve from 0.41973\n",
      "Epoch 3154/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.8962 - val_loss: 0.9402 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03154: val_loss did not improve from 0.41973\n",
      "Epoch 3155/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.8975 - val_loss: 0.9355 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03155: val_loss did not improve from 0.41973\n",
      "Epoch 3156/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9027 - val_loss: 0.9445 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03156: val_loss did not improve from 0.41973\n",
      "Epoch 3157/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9001 - val_loss: 0.9302 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03157: val_loss did not improve from 0.41973\n",
      "Epoch 3158/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 0.9331 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03158: val_loss did not improve from 0.41973\n",
      "Epoch 3159/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 0.9335 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03159: val_loss did not improve from 0.41973\n",
      "Epoch 3160/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.8962 - val_loss: 0.9301 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03160: val_loss did not improve from 0.41973\n",
      "Epoch 3161/4000\n",
      "25/25 - 0s - loss: 0.2002 - accuracy: 0.8988 - val_loss: 0.8959 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03161: val_loss did not improve from 0.41973\n",
      "Epoch 3162/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.9027 - val_loss: 0.9035 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03162: val_loss did not improve from 0.41973\n",
      "Epoch 3163/4000\n",
      "25/25 - 0s - loss: 0.2044 - accuracy: 0.9014 - val_loss: 0.9547 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03163: val_loss did not improve from 0.41973\n",
      "Epoch 3164/4000\n",
      "25/25 - 0s - loss: 0.2028 - accuracy: 0.9027 - val_loss: 0.9519 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03164: val_loss did not improve from 0.41973\n",
      "Epoch 3165/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 0.9612 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03165: val_loss did not improve from 0.41973\n",
      "Epoch 3166/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9027 - val_loss: 0.9664 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03166: val_loss did not improve from 0.41973\n",
      "Epoch 3167/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 0.9921 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03167: val_loss did not improve from 0.41973\n",
      "Epoch 3168/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 0.9983 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03168: val_loss did not improve from 0.41973\n",
      "Epoch 3169/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 0.9911 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03169: val_loss did not improve from 0.41973\n",
      "Epoch 3170/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8962 - val_loss: 0.9899 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03170: val_loss did not improve from 0.41973\n",
      "Epoch 3171/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9001 - val_loss: 0.9928 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03171: val_loss did not improve from 0.41973\n",
      "Epoch 3172/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 0.9759 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03172: val_loss did not improve from 0.41973\n",
      "Epoch 3173/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 0.9733 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03173: val_loss did not improve from 0.41973\n",
      "Epoch 3174/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9040 - val_loss: 0.9797 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03174: val_loss did not improve from 0.41973\n",
      "Epoch 3175/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 0.9767 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03175: val_loss did not improve from 0.41973\n",
      "Epoch 3176/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 0.9756 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03176: val_loss did not improve from 0.41973\n",
      "Epoch 3177/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9001 - val_loss: 0.9724 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03177: val_loss did not improve from 0.41973\n",
      "Epoch 3178/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9001 - val_loss: 0.9643 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03178: val_loss did not improve from 0.41973\n",
      "Epoch 3179/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 0.9789 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03179: val_loss did not improve from 0.41973\n",
      "Epoch 3180/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 0.9737 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03180: val_loss did not improve from 0.41973\n",
      "Epoch 3181/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 0.9670 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03181: val_loss did not improve from 0.41973\n",
      "Epoch 3182/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 0.9608 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03182: val_loss did not improve from 0.41973\n",
      "Epoch 3183/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 0.9618 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03183: val_loss did not improve from 0.41973\n",
      "Epoch 3184/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9014 - val_loss: 0.9509 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03184: val_loss did not improve from 0.41973\n",
      "Epoch 3185/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.8988 - val_loss: 0.9611 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03185: val_loss did not improve from 0.41973\n",
      "Epoch 3186/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 0.9700 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03186: val_loss did not improve from 0.41973\n",
      "Epoch 3187/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9001 - val_loss: 0.9680 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03187: val_loss did not improve from 0.41973\n",
      "Epoch 3188/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 0.9639 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03188: val_loss did not improve from 0.41973\n",
      "Epoch 3189/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 0.9598 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03189: val_loss did not improve from 0.41973\n",
      "Epoch 3190/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 0.9561 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03190: val_loss did not improve from 0.41973\n",
      "Epoch 3191/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 0.9531 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03191: val_loss did not improve from 0.41973\n",
      "Epoch 3192/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9001 - val_loss: 0.9612 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03192: val_loss did not improve from 0.41973\n",
      "Epoch 3193/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 0.9675 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03193: val_loss did not improve from 0.41973\n",
      "Epoch 3194/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9001 - val_loss: 0.9713 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03194: val_loss did not improve from 0.41973\n",
      "Epoch 3195/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 0.9630 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03195: val_loss did not improve from 0.41973\n",
      "Epoch 3196/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 0.9692 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03196: val_loss did not improve from 0.41973\n",
      "Epoch 3197/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.8988 - val_loss: 0.9667 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03197: val_loss did not improve from 0.41973\n",
      "Epoch 3198/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9001 - val_loss: 0.9562 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03198: val_loss did not improve from 0.41973\n",
      "Epoch 3199/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 0.9618 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03199: val_loss did not improve from 0.41973\n",
      "Epoch 3200/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 0.9682 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03200: val_loss did not improve from 0.41973\n",
      "Epoch 3201/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8975 - val_loss: 0.9581 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03201: val_loss did not improve from 0.41973\n",
      "Epoch 3202/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 0.9555 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03202: val_loss did not improve from 0.41973\n",
      "Epoch 3203/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 0.9523 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03203: val_loss did not improve from 0.41973\n",
      "Epoch 3204/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9014 - val_loss: 0.9555 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03204: val_loss did not improve from 0.41973\n",
      "Epoch 3205/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.8988 - val_loss: 0.9707 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03205: val_loss did not improve from 0.41973\n",
      "Epoch 3206/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9001 - val_loss: 0.9675 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03206: val_loss did not improve from 0.41973\n",
      "Epoch 3207/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 0.9579 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03207: val_loss did not improve from 0.41973\n",
      "Epoch 3208/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.8988 - val_loss: 0.9511 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03208: val_loss did not improve from 0.41973\n",
      "Epoch 3209/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 0.9527 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03209: val_loss did not improve from 0.41973\n",
      "Epoch 3210/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.8988 - val_loss: 0.9526 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03210: val_loss did not improve from 0.41973\n",
      "Epoch 3211/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 0.9568 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03211: val_loss did not improve from 0.41973\n",
      "Epoch 3212/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 0.9561 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03212: val_loss did not improve from 0.41973\n",
      "Epoch 3213/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 0.9587 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03213: val_loss did not improve from 0.41973\n",
      "Epoch 3214/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9014 - val_loss: 0.9615 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03214: val_loss did not improve from 0.41973\n",
      "Epoch 3215/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 0.9590 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03215: val_loss did not improve from 0.41973\n",
      "Epoch 3216/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 0.9636 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03216: val_loss did not improve from 0.41973\n",
      "Epoch 3217/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9001 - val_loss: 0.9673 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03217: val_loss did not improve from 0.41973\n",
      "Epoch 3218/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 0.9617 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03218: val_loss did not improve from 0.41973\n",
      "Epoch 3219/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9001 - val_loss: 0.9656 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03219: val_loss did not improve from 0.41973\n",
      "Epoch 3220/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9001 - val_loss: 0.9622 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03220: val_loss did not improve from 0.41973\n",
      "Epoch 3221/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.8988 - val_loss: 0.9621 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03221: val_loss did not improve from 0.41973\n",
      "Epoch 3222/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8988 - val_loss: 0.9493 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03222: val_loss did not improve from 0.41973\n",
      "Epoch 3223/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 0.9598 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03223: val_loss did not improve from 0.41973\n",
      "Epoch 3224/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 0.9581 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03224: val_loss did not improve from 0.41973\n",
      "Epoch 3225/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 0.9737 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03225: val_loss did not improve from 0.41973\n",
      "Epoch 3226/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9001 - val_loss: 0.9929 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03226: val_loss did not improve from 0.41973\n",
      "Epoch 3227/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9001 - val_loss: 0.9720 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03227: val_loss did not improve from 0.41973\n",
      "Epoch 3228/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.8962 - val_loss: 0.9734 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03228: val_loss did not improve from 0.41973\n",
      "Epoch 3229/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.8962 - val_loss: 0.9731 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03229: val_loss did not improve from 0.41973\n",
      "Epoch 3230/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9001 - val_loss: 0.9688 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03230: val_loss did not improve from 0.41973\n",
      "Epoch 3231/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9001 - val_loss: 0.9680 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03231: val_loss did not improve from 0.41973\n",
      "Epoch 3232/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.8975 - val_loss: 0.9635 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03232: val_loss did not improve from 0.41973\n",
      "Epoch 3233/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.8962 - val_loss: 0.9645 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03233: val_loss did not improve from 0.41973\n",
      "Epoch 3234/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 0.9701 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03234: val_loss did not improve from 0.41973\n",
      "Epoch 3235/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8988 - val_loss: 0.9706 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03235: val_loss did not improve from 0.41973\n",
      "Epoch 3236/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.8962 - val_loss: 0.9781 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03236: val_loss did not improve from 0.41973\n",
      "Epoch 3237/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8988 - val_loss: 0.9775 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03237: val_loss did not improve from 0.41973\n",
      "Epoch 3238/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.8936 - val_loss: 0.9800 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03238: val_loss did not improve from 0.41973\n",
      "Epoch 3239/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9001 - val_loss: 0.9758 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03239: val_loss did not improve from 0.41973\n",
      "Epoch 3240/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 0.9833 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03240: val_loss did not improve from 0.41973\n",
      "Epoch 3241/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.8962 - val_loss: 0.9856 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03241: val_loss did not improve from 0.41973\n",
      "Epoch 3242/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 0.9910 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03242: val_loss did not improve from 0.41973\n",
      "Epoch 3243/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 1.0276 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03243: val_loss did not improve from 0.41973\n",
      "Epoch 3244/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9001 - val_loss: 0.9840 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03244: val_loss did not improve from 0.41973\n",
      "Epoch 3245/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 0.9757 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03245: val_loss did not improve from 0.41973\n",
      "Epoch 3246/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9014 - val_loss: 0.9670 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03246: val_loss did not improve from 0.41973\n",
      "Epoch 3247/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 0.9659 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03247: val_loss did not improve from 0.41973\n",
      "Epoch 3248/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8975 - val_loss: 0.9751 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03248: val_loss did not improve from 0.41973\n",
      "Epoch 3249/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 0.9760 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03249: val_loss did not improve from 0.41973\n",
      "Epoch 3250/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.8975 - val_loss: 0.9720 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03250: val_loss did not improve from 0.41973\n",
      "Epoch 3251/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 0.9715 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03251: val_loss did not improve from 0.41973\n",
      "Epoch 3252/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.9040 - val_loss: 0.9520 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03252: val_loss did not improve from 0.41973\n",
      "Epoch 3253/4000\n",
      "25/25 - 0s - loss: 0.2020 - accuracy: 0.9027 - val_loss: 0.9364 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03253: val_loss did not improve from 0.41973\n",
      "Epoch 3254/4000\n",
      "25/25 - 0s - loss: 0.2033 - accuracy: 0.9027 - val_loss: 0.9330 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03254: val_loss did not improve from 0.41973\n",
      "Epoch 3255/4000\n",
      "25/25 - 0s - loss: 0.2026 - accuracy: 0.8962 - val_loss: 0.8822 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03255: val_loss did not improve from 0.41973\n",
      "Epoch 3256/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 0.8950 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03256: val_loss did not improve from 0.41973\n",
      "Epoch 3257/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9014 - val_loss: 0.8993 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03257: val_loss did not improve from 0.41973\n",
      "Epoch 3258/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 0.8887 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03258: val_loss did not improve from 0.41973\n",
      "Epoch 3259/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 0.8995 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03259: val_loss did not improve from 0.41973\n",
      "Epoch 3260/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 0.9020 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03260: val_loss did not improve from 0.41973\n",
      "Epoch 3261/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8988 - val_loss: 0.8867 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03261: val_loss did not improve from 0.41973\n",
      "Epoch 3262/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8975 - val_loss: 0.8791 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03262: val_loss did not improve from 0.41973\n",
      "Epoch 3263/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 0.8935 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03263: val_loss did not improve from 0.41973\n",
      "Epoch 3264/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 0.9049 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03264: val_loss did not improve from 0.41973\n",
      "Epoch 3265/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 0.9073 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03265: val_loss did not improve from 0.41973\n",
      "Epoch 3266/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.8988 - val_loss: 0.9064 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03266: val_loss did not improve from 0.41973\n",
      "Epoch 3267/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8988 - val_loss: 0.9144 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03267: val_loss did not improve from 0.41973\n",
      "Epoch 3268/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8988 - val_loss: 0.8954 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03268: val_loss did not improve from 0.41973\n",
      "Epoch 3269/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 0.9116 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03269: val_loss did not improve from 0.41973\n",
      "Epoch 3270/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 0.9173 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03270: val_loss did not improve from 0.41973\n",
      "Epoch 3271/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8975 - val_loss: 0.9217 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03271: val_loss did not improve from 0.41973\n",
      "Epoch 3272/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9014 - val_loss: 0.9249 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03272: val_loss did not improve from 0.41973\n",
      "Epoch 3273/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 0.9261 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03273: val_loss did not improve from 0.41973\n",
      "Epoch 3274/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9001 - val_loss: 0.9247 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03274: val_loss did not improve from 0.41973\n",
      "Epoch 3275/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9014 - val_loss: 0.9342 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03275: val_loss did not improve from 0.41973\n",
      "Epoch 3276/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9001 - val_loss: 0.9350 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03276: val_loss did not improve from 0.41973\n",
      "Epoch 3277/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 0.9161 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03277: val_loss did not improve from 0.41973\n",
      "Epoch 3278/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9014 - val_loss: 0.9235 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03278: val_loss did not improve from 0.41973\n",
      "Epoch 3279/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8988 - val_loss: 0.9298 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03279: val_loss did not improve from 0.41973\n",
      "Epoch 3280/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8988 - val_loss: 0.9445 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03280: val_loss did not improve from 0.41973\n",
      "Epoch 3281/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 0.9679 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03281: val_loss did not improve from 0.41973\n",
      "Epoch 3282/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 0.9987 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03282: val_loss did not improve from 0.41973\n",
      "Epoch 3283/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8988 - val_loss: 0.9728 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03283: val_loss did not improve from 0.41973\n",
      "Epoch 3284/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 0.9564 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03284: val_loss did not improve from 0.41973\n",
      "Epoch 3285/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 0.9532 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03285: val_loss did not improve from 0.41973\n",
      "Epoch 3286/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 0.9490 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03286: val_loss did not improve from 0.41973\n",
      "Epoch 3287/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 0.9450 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03287: val_loss did not improve from 0.41973\n",
      "Epoch 3288/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 0.9640 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03288: val_loss did not improve from 0.41973\n",
      "Epoch 3289/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9001 - val_loss: 0.9723 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03289: val_loss did not improve from 0.41973\n",
      "Epoch 3290/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8975 - val_loss: 0.9724 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03290: val_loss did not improve from 0.41973\n",
      "Epoch 3291/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 0.9502 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03291: val_loss did not improve from 0.41973\n",
      "Epoch 3292/4000\n",
      "25/25 - 0s - loss: 0.2027 - accuracy: 0.8975 - val_loss: 0.9424 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03292: val_loss did not improve from 0.41973\n",
      "Epoch 3293/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.8975 - val_loss: 0.9637 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03293: val_loss did not improve from 0.41973\n",
      "Epoch 3294/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 0.9954 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03294: val_loss did not improve from 0.41973\n",
      "Epoch 3295/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8975 - val_loss: 1.0177 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03295: val_loss did not improve from 0.41973\n",
      "Epoch 3296/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9040 - val_loss: 1.0155 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03296: val_loss did not improve from 0.41973\n",
      "Epoch 3297/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8962 - val_loss: 1.0560 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03297: val_loss did not improve from 0.41973\n",
      "Epoch 3298/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 1.0650 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03298: val_loss did not improve from 0.41973\n",
      "Epoch 3299/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.8988 - val_loss: 1.0677 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03299: val_loss did not improve from 0.41973\n",
      "Epoch 3300/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.0646 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03300: val_loss did not improve from 0.41973\n",
      "Epoch 3301/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 1.0730 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03301: val_loss did not improve from 0.41973\n",
      "Epoch 3302/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.0649 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03302: val_loss did not improve from 0.41973\n",
      "Epoch 3303/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.8988 - val_loss: 0.9870 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03303: val_loss did not improve from 0.41973\n",
      "Epoch 3304/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 0.9772 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03304: val_loss did not improve from 0.41973\n",
      "Epoch 3305/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.8975 - val_loss: 0.9868 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03305: val_loss did not improve from 0.41973\n",
      "Epoch 3306/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9001 - val_loss: 0.9828 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03306: val_loss did not improve from 0.41973\n",
      "Epoch 3307/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 0.9727 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03307: val_loss did not improve from 0.41973\n",
      "Epoch 3308/4000\n",
      "25/25 - 0s - loss: 0.2219 - accuracy: 0.9001 - val_loss: 1.2075 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03308: val_loss did not improve from 0.41973\n",
      "Epoch 3309/4000\n",
      "25/25 - 0s - loss: 0.2721 - accuracy: 0.8872 - val_loss: 0.7159 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03309: val_loss did not improve from 0.41973\n",
      "Epoch 3310/4000\n",
      "25/25 - 0s - loss: 0.2232 - accuracy: 0.8988 - val_loss: 1.0348 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03310: val_loss did not improve from 0.41973\n",
      "Epoch 3311/4000\n",
      "25/25 - 0s - loss: 0.2048 - accuracy: 0.9001 - val_loss: 1.1302 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03311: val_loss did not improve from 0.41973\n",
      "Epoch 3312/4000\n",
      "25/25 - 0s - loss: 0.2026 - accuracy: 0.9014 - val_loss: 1.1146 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03312: val_loss did not improve from 0.41973\n",
      "Epoch 3313/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9014 - val_loss: 1.1092 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03313: val_loss did not improve from 0.41973\n",
      "Epoch 3314/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9014 - val_loss: 1.1028 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03314: val_loss did not improve from 0.41973\n",
      "Epoch 3315/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9001 - val_loss: 1.1110 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03315: val_loss did not improve from 0.41973\n",
      "Epoch 3316/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 1.1146 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03316: val_loss did not improve from 0.41973\n",
      "Epoch 3317/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.1110 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03317: val_loss did not improve from 0.41973\n",
      "Epoch 3318/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9001 - val_loss: 1.1145 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03318: val_loss did not improve from 0.41973\n",
      "Epoch 3319/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 1.1129 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03319: val_loss did not improve from 0.41973\n",
      "Epoch 3320/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.1208 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03320: val_loss did not improve from 0.41973\n",
      "Epoch 3321/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 1.1205 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03321: val_loss did not improve from 0.41973\n",
      "Epoch 3322/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9001 - val_loss: 1.1146 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03322: val_loss did not improve from 0.41973\n",
      "Epoch 3323/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9001 - val_loss: 1.1073 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03323: val_loss did not improve from 0.41973\n",
      "Epoch 3324/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.8988 - val_loss: 1.1111 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03324: val_loss did not improve from 0.41973\n",
      "Epoch 3325/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 1.1074 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03325: val_loss did not improve from 0.41973\n",
      "Epoch 3326/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 1.1111 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03326: val_loss did not improve from 0.41973\n",
      "Epoch 3327/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9014 - val_loss: 1.1128 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03327: val_loss did not improve from 0.41973\n",
      "Epoch 3328/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9001 - val_loss: 1.1228 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03328: val_loss did not improve from 0.41973\n",
      "Epoch 3329/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9014 - val_loss: 1.1329 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03329: val_loss did not improve from 0.41973\n",
      "Epoch 3330/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 1.1382 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03330: val_loss did not improve from 0.41973\n",
      "Epoch 3331/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9001 - val_loss: 1.1451 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03331: val_loss did not improve from 0.41973\n",
      "Epoch 3332/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 1.1434 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03332: val_loss did not improve from 0.41973\n",
      "Epoch 3333/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 1.1348 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03333: val_loss did not improve from 0.41973\n",
      "Epoch 3334/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.1333 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03334: val_loss did not improve from 0.41973\n",
      "Epoch 3335/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.1339 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03335: val_loss did not improve from 0.41973\n",
      "Epoch 3336/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9014 - val_loss: 1.1390 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03336: val_loss did not improve from 0.41973\n",
      "Epoch 3337/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.1416 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03337: val_loss did not improve from 0.41973\n",
      "Epoch 3338/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9001 - val_loss: 1.1376 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03338: val_loss did not improve from 0.41973\n",
      "Epoch 3339/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.1426 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03339: val_loss did not improve from 0.41973\n",
      "Epoch 3340/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9001 - val_loss: 1.1325 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03340: val_loss did not improve from 0.41973\n",
      "Epoch 3341/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 1.1357 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03341: val_loss did not improve from 0.41973\n",
      "Epoch 3342/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9001 - val_loss: 1.1436 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03342: val_loss did not improve from 0.41973\n",
      "Epoch 3343/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9001 - val_loss: 1.1389 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03343: val_loss did not improve from 0.41973\n",
      "Epoch 3344/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 1.1226 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03344: val_loss did not improve from 0.41973\n",
      "Epoch 3345/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 1.1211 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03345: val_loss did not improve from 0.41973\n",
      "Epoch 3346/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.8988 - val_loss: 1.1264 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03346: val_loss did not improve from 0.41973\n",
      "Epoch 3347/4000\n",
      "25/25 - 0s - loss: 0.2027 - accuracy: 0.8988 - val_loss: 1.1613 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03347: val_loss did not improve from 0.41973\n",
      "Epoch 3348/4000\n",
      "25/25 - 0s - loss: 0.2147 - accuracy: 0.8975 - val_loss: 1.2639 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03348: val_loss did not improve from 0.41973\n",
      "Epoch 3349/4000\n",
      "25/25 - 0s - loss: 0.2078 - accuracy: 0.8962 - val_loss: 0.9935 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03349: val_loss did not improve from 0.41973\n",
      "Epoch 3350/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9027 - val_loss: 0.9872 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03350: val_loss did not improve from 0.41973\n",
      "Epoch 3351/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 0.9949 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03351: val_loss did not improve from 0.41973\n",
      "Epoch 3352/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9001 - val_loss: 1.0242 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03352: val_loss did not improve from 0.41973\n",
      "Epoch 3353/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9053 - val_loss: 1.0250 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03353: val_loss did not improve from 0.41973\n",
      "Epoch 3354/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 0.9891 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03354: val_loss did not improve from 0.41973\n",
      "Epoch 3355/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8988 - val_loss: 0.9936 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03355: val_loss did not improve from 0.41973\n",
      "Epoch 3356/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 0.9969 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03356: val_loss did not improve from 0.41973\n",
      "Epoch 3357/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8975 - val_loss: 1.0076 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03357: val_loss did not improve from 0.41973\n",
      "Epoch 3358/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.0053 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03358: val_loss did not improve from 0.41973\n",
      "Epoch 3359/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8975 - val_loss: 1.0044 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03359: val_loss did not improve from 0.41973\n",
      "Epoch 3360/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.8962 - val_loss: 1.0081 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03360: val_loss did not improve from 0.41973\n",
      "Epoch 3361/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.8923 - val_loss: 1.0083 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03361: val_loss did not improve from 0.41973\n",
      "Epoch 3362/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8988 - val_loss: 1.0118 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03362: val_loss did not improve from 0.41973\n",
      "Epoch 3363/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.8988 - val_loss: 1.0137 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03363: val_loss did not improve from 0.41973\n",
      "Epoch 3364/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.0092 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03364: val_loss did not improve from 0.41973\n",
      "Epoch 3365/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.0109 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03365: val_loss did not improve from 0.41973\n",
      "Epoch 3366/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 1.0080 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03366: val_loss did not improve from 0.41973\n",
      "Epoch 3367/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 1.0171 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03367: val_loss did not improve from 0.41973\n",
      "Epoch 3368/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.0147 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03368: val_loss did not improve from 0.41973\n",
      "Epoch 3369/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 1.0178 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03369: val_loss did not improve from 0.41973\n",
      "Epoch 3370/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.0242 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03370: val_loss did not improve from 0.41973\n",
      "Epoch 3371/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.0221 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03371: val_loss did not improve from 0.41973\n",
      "Epoch 3372/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9014 - val_loss: 1.0238 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03372: val_loss did not improve from 0.41973\n",
      "Epoch 3373/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.0317 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03373: val_loss did not improve from 0.41973\n",
      "Epoch 3374/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.8988 - val_loss: 1.0339 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03374: val_loss did not improve from 0.41973\n",
      "Epoch 3375/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9014 - val_loss: 1.0116 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03375: val_loss did not improve from 0.41973\n",
      "Epoch 3376/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.0059 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03376: val_loss did not improve from 0.41973\n",
      "Epoch 3377/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 1.0060 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03377: val_loss did not improve from 0.41973\n",
      "Epoch 3378/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 0.9850 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03378: val_loss did not improve from 0.41973\n",
      "Epoch 3379/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9001 - val_loss: 0.9908 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03379: val_loss did not improve from 0.41973\n",
      "Epoch 3380/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9001 - val_loss: 0.9905 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03380: val_loss did not improve from 0.41973\n",
      "Epoch 3381/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 0.9992 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03381: val_loss did not improve from 0.41973\n",
      "Epoch 3382/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 0.9975 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03382: val_loss did not improve from 0.41973\n",
      "Epoch 3383/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8975 - val_loss: 1.0036 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03383: val_loss did not improve from 0.41973\n",
      "Epoch 3384/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.0009 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03384: val_loss did not improve from 0.41973\n",
      "Epoch 3385/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.0073 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03385: val_loss did not improve from 0.41973\n",
      "Epoch 3386/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.8975 - val_loss: 1.0036 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03386: val_loss did not improve from 0.41973\n",
      "Epoch 3387/4000\n",
      "25/25 - 0s - loss: 0.2029 - accuracy: 0.9001 - val_loss: 1.0067 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03387: val_loss did not improve from 0.41973\n",
      "Epoch 3388/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9014 - val_loss: 1.0195 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03388: val_loss did not improve from 0.41973\n",
      "Epoch 3389/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9001 - val_loss: 1.0125 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03389: val_loss did not improve from 0.41973\n",
      "Epoch 3390/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.8962 - val_loss: 1.0061 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03390: val_loss did not improve from 0.41973\n",
      "Epoch 3391/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 1.0026 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03391: val_loss did not improve from 0.41973\n",
      "Epoch 3392/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 1.0069 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03392: val_loss did not improve from 0.41973\n",
      "Epoch 3393/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 1.0050 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03393: val_loss did not improve from 0.41973\n",
      "Epoch 3394/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.0172 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03394: val_loss did not improve from 0.41973\n",
      "Epoch 3395/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.8988 - val_loss: 1.0218 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03395: val_loss did not improve from 0.41973\n",
      "Epoch 3396/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 1.0188 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03396: val_loss did not improve from 0.41973\n",
      "Epoch 3397/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.0186 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03397: val_loss did not improve from 0.41973\n",
      "Epoch 3398/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9001 - val_loss: 1.0170 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03398: val_loss did not improve from 0.41973\n",
      "Epoch 3399/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.0132 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03399: val_loss did not improve from 0.41973\n",
      "Epoch 3400/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.0157 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03400: val_loss did not improve from 0.41973\n",
      "Epoch 3401/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.0156 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03401: val_loss did not improve from 0.41973\n",
      "Epoch 3402/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9001 - val_loss: 1.0204 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03402: val_loss did not improve from 0.41973\n",
      "Epoch 3403/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.0239 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03403: val_loss did not improve from 0.41973\n",
      "Epoch 3404/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.0392 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03404: val_loss did not improve from 0.41973\n",
      "Epoch 3405/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 1.0414 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03405: val_loss did not improve from 0.41973\n",
      "Epoch 3406/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.0439 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03406: val_loss did not improve from 0.41973\n",
      "Epoch 3407/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 1.0503 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03407: val_loss did not improve from 0.41973\n",
      "Epoch 3408/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9040 - val_loss: 1.0485 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03408: val_loss did not improve from 0.41973\n",
      "Epoch 3409/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 1.0504 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03409: val_loss did not improve from 0.41973\n",
      "Epoch 3410/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9001 - val_loss: 1.0391 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03410: val_loss did not improve from 0.41973\n",
      "Epoch 3411/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.0497 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03411: val_loss did not improve from 0.41973\n",
      "Epoch 3412/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 1.0546 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03412: val_loss did not improve from 0.41973\n",
      "Epoch 3413/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.0555 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03413: val_loss did not improve from 0.41973\n",
      "Epoch 3414/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9014 - val_loss: 1.0445 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03414: val_loss did not improve from 0.41973\n",
      "Epoch 3415/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 1.0572 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03415: val_loss did not improve from 0.41973\n",
      "Epoch 3416/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.0533 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03416: val_loss did not improve from 0.41973\n",
      "Epoch 3417/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9014 - val_loss: 1.0530 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03417: val_loss did not improve from 0.41973\n",
      "Epoch 3418/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.0559 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03418: val_loss did not improve from 0.41973\n",
      "Epoch 3419/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9014 - val_loss: 1.0569 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03419: val_loss did not improve from 0.41973\n",
      "Epoch 3420/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 1.0570 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03420: val_loss did not improve from 0.41973\n",
      "Epoch 3421/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9014 - val_loss: 1.0736 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03421: val_loss did not improve from 0.41973\n",
      "Epoch 3422/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 1.0686 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03422: val_loss did not improve from 0.41973\n",
      "Epoch 3423/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.0716 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03423: val_loss did not improve from 0.41973\n",
      "Epoch 3424/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.0655 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03424: val_loss did not improve from 0.41973\n",
      "Epoch 3425/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.8988 - val_loss: 1.0644 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03425: val_loss did not improve from 0.41973\n",
      "Epoch 3426/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.0698 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03426: val_loss did not improve from 0.41973\n",
      "Epoch 3427/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9001 - val_loss: 1.0622 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03427: val_loss did not improve from 0.41973\n",
      "Epoch 3428/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 1.0583 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03428: val_loss did not improve from 0.41973\n",
      "Epoch 3429/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8988 - val_loss: 1.0557 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03429: val_loss did not improve from 0.41973\n",
      "Epoch 3430/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 1.0649 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03430: val_loss did not improve from 0.41973\n",
      "Epoch 3431/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9014 - val_loss: 1.0578 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03431: val_loss did not improve from 0.41973\n",
      "Epoch 3432/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 1.0741 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03432: val_loss did not improve from 0.41973\n",
      "Epoch 3433/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.8988 - val_loss: 1.0878 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03433: val_loss did not improve from 0.41973\n",
      "Epoch 3434/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.8936 - val_loss: 1.0939 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03434: val_loss did not improve from 0.41973\n",
      "Epoch 3435/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9001 - val_loss: 1.0930 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03435: val_loss did not improve from 0.41973\n",
      "Epoch 3436/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8962 - val_loss: 1.1112 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03436: val_loss did not improve from 0.41973\n",
      "Epoch 3437/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9001 - val_loss: 1.1035 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03437: val_loss did not improve from 0.41973\n",
      "Epoch 3438/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9027 - val_loss: 1.0953 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03438: val_loss did not improve from 0.41973\n",
      "Epoch 3439/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9014 - val_loss: 1.0929 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03439: val_loss did not improve from 0.41973\n",
      "Epoch 3440/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.0849 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03440: val_loss did not improve from 0.41973\n",
      "Epoch 3441/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 1.0925 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03441: val_loss did not improve from 0.41973\n",
      "Epoch 3442/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.0885 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03442: val_loss did not improve from 0.41973\n",
      "Epoch 3443/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.0908 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03443: val_loss did not improve from 0.41973\n",
      "Epoch 3444/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.0845 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03444: val_loss did not improve from 0.41973\n",
      "Epoch 3445/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.0852 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03445: val_loss did not improve from 0.41973\n",
      "Epoch 3446/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.0916 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03446: val_loss did not improve from 0.41973\n",
      "Epoch 3447/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 1.0933 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03447: val_loss did not improve from 0.41973\n",
      "Epoch 3448/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 1.0993 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03448: val_loss did not improve from 0.41973\n",
      "Epoch 3449/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.0938 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03449: val_loss did not improve from 0.41973\n",
      "Epoch 3450/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 1.0929 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03450: val_loss did not improve from 0.41973\n",
      "Epoch 3451/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.0826 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03451: val_loss did not improve from 0.41973\n",
      "Epoch 3452/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 1.0869 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03452: val_loss did not improve from 0.41973\n",
      "Epoch 3453/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 1.0883 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03453: val_loss did not improve from 0.41973\n",
      "Epoch 3454/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.8975 - val_loss: 1.0897 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03454: val_loss did not improve from 0.41973\n",
      "Epoch 3455/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9001 - val_loss: 1.0870 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03455: val_loss did not improve from 0.41973\n",
      "Epoch 3456/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 1.0788 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03456: val_loss did not improve from 0.41973\n",
      "Epoch 3457/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.0778 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03457: val_loss did not improve from 0.41973\n",
      "Epoch 3458/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.0796 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03458: val_loss did not improve from 0.41973\n",
      "Epoch 3459/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.0698 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03459: val_loss did not improve from 0.41973\n",
      "Epoch 3460/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.0612 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03460: val_loss did not improve from 0.41973\n",
      "Epoch 3461/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.0656 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03461: val_loss did not improve from 0.41973\n",
      "Epoch 3462/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 1.0568 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03462: val_loss did not improve from 0.41973\n",
      "Epoch 3463/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.0666 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03463: val_loss did not improve from 0.41973\n",
      "Epoch 3464/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9027 - val_loss: 1.0665 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03464: val_loss did not improve from 0.41973\n",
      "Epoch 3465/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9014 - val_loss: 1.0563 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03465: val_loss did not improve from 0.41973\n",
      "Epoch 3466/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.0610 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03466: val_loss did not improve from 0.41973\n",
      "Epoch 3467/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.0572 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03467: val_loss did not improve from 0.41973\n",
      "Epoch 3468/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.8988 - val_loss: 1.0574 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03468: val_loss did not improve from 0.41973\n",
      "Epoch 3469/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.0472 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03469: val_loss did not improve from 0.41973\n",
      "Epoch 3470/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9027 - val_loss: 1.0512 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03470: val_loss did not improve from 0.41973\n",
      "Epoch 3471/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9001 - val_loss: 1.0604 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03471: val_loss did not improve from 0.41973\n",
      "Epoch 3472/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9014 - val_loss: 1.0282 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03472: val_loss did not improve from 0.41973\n",
      "Epoch 3473/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8962 - val_loss: 1.0435 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03473: val_loss did not improve from 0.41973\n",
      "Epoch 3474/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 1.0526 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03474: val_loss did not improve from 0.41973\n",
      "Epoch 3475/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 1.0471 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03475: val_loss did not improve from 0.41973\n",
      "Epoch 3476/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9014 - val_loss: 1.0555 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03476: val_loss did not improve from 0.41973\n",
      "Epoch 3477/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 1.0555 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03477: val_loss did not improve from 0.41973\n",
      "Epoch 3478/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.0555 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03478: val_loss did not improve from 0.41973\n",
      "Epoch 3479/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 1.0598 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03479: val_loss did not improve from 0.41973\n",
      "Epoch 3480/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.8975 - val_loss: 1.0560 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03480: val_loss did not improve from 0.41973\n",
      "Epoch 3481/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 1.0538 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03481: val_loss did not improve from 0.41973\n",
      "Epoch 3482/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 1.0513 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03482: val_loss did not improve from 0.41973\n",
      "Epoch 3483/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.0598 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03483: val_loss did not improve from 0.41973\n",
      "Epoch 3484/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 1.0493 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03484: val_loss did not improve from 0.41973\n",
      "Epoch 3485/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 1.0522 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03485: val_loss did not improve from 0.41973\n",
      "Epoch 3486/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.8988 - val_loss: 1.0599 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03486: val_loss did not improve from 0.41973\n",
      "Epoch 3487/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.8988 - val_loss: 1.0518 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03487: val_loss did not improve from 0.41973\n",
      "Epoch 3488/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8988 - val_loss: 1.0418 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03488: val_loss did not improve from 0.41973\n",
      "Epoch 3489/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 1.0411 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03489: val_loss did not improve from 0.41973\n",
      "Epoch 3490/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9001 - val_loss: 1.0409 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03490: val_loss did not improve from 0.41973\n",
      "Epoch 3491/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.0521 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03491: val_loss did not improve from 0.41973\n",
      "Epoch 3492/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.0472 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03492: val_loss did not improve from 0.41973\n",
      "Epoch 3493/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9014 - val_loss: 1.0378 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03493: val_loss did not improve from 0.41973\n",
      "Epoch 3494/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.8988 - val_loss: 1.0032 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03494: val_loss did not improve from 0.41973\n",
      "Epoch 3495/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9001 - val_loss: 1.0140 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03495: val_loss did not improve from 0.41973\n",
      "Epoch 3496/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 1.0386 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03496: val_loss did not improve from 0.41973\n",
      "Epoch 3497/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 1.0408 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03497: val_loss did not improve from 0.41973\n",
      "Epoch 3498/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.0515 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03498: val_loss did not improve from 0.41973\n",
      "Epoch 3499/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.0659 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03499: val_loss did not improve from 0.41973\n",
      "Epoch 3500/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.0730 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03500: val_loss did not improve from 0.41973\n",
      "Epoch 3501/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9001 - val_loss: 1.0731 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03501: val_loss did not improve from 0.41973\n",
      "Epoch 3502/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9001 - val_loss: 1.0835 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03502: val_loss did not improve from 0.41973\n",
      "Epoch 3503/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 1.0810 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03503: val_loss did not improve from 0.41973\n",
      "Epoch 3504/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9001 - val_loss: 1.0684 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03504: val_loss did not improve from 0.41973\n",
      "Epoch 3505/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 1.0829 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03505: val_loss did not improve from 0.41973\n",
      "Epoch 3506/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 1.0705 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03506: val_loss did not improve from 0.41973\n",
      "Epoch 3507/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.0661 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03507: val_loss did not improve from 0.41973\n",
      "Epoch 3508/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.0717 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03508: val_loss did not improve from 0.41973\n",
      "Epoch 3509/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.0558 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03509: val_loss did not improve from 0.41973\n",
      "Epoch 3510/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 1.0921 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03510: val_loss did not improve from 0.41973\n",
      "Epoch 3511/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8988 - val_loss: 1.0845 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03511: val_loss did not improve from 0.41973\n",
      "Epoch 3512/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.1026 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03512: val_loss did not improve from 0.41973\n",
      "Epoch 3513/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.8988 - val_loss: 1.1087 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03513: val_loss did not improve from 0.41973\n",
      "Epoch 3514/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.1040 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03514: val_loss did not improve from 0.41973\n",
      "Epoch 3515/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.1017 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03515: val_loss did not improve from 0.41973\n",
      "Epoch 3516/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 1.0965 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03516: val_loss did not improve from 0.41973\n",
      "Epoch 3517/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.0910 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03517: val_loss did not improve from 0.41973\n",
      "Epoch 3518/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.0927 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03518: val_loss did not improve from 0.41973\n",
      "Epoch 3519/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.0951 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03519: val_loss did not improve from 0.41973\n",
      "Epoch 3520/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.1000 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03520: val_loss did not improve from 0.41973\n",
      "Epoch 3521/4000\n",
      "25/25 - 0s - loss: 0.2035 - accuracy: 0.9014 - val_loss: 0.9578 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03521: val_loss did not improve from 0.41973\n",
      "Epoch 3522/4000\n",
      "25/25 - 0s - loss: 0.2088 - accuracy: 0.8988 - val_loss: 0.8959 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03522: val_loss did not improve from 0.41973\n",
      "Epoch 3523/4000\n",
      "25/25 - 0s - loss: 0.2030 - accuracy: 0.9014 - val_loss: 0.9445 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03523: val_loss did not improve from 0.41973\n",
      "Epoch 3524/4000\n",
      "25/25 - 0s - loss: 0.2034 - accuracy: 0.9014 - val_loss: 1.1816 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03524: val_loss did not improve from 0.41973\n",
      "Epoch 3525/4000\n",
      "25/25 - 0s - loss: 0.2065 - accuracy: 0.9014 - val_loss: 1.0775 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03525: val_loss did not improve from 0.41973\n",
      "Epoch 3526/4000\n",
      "25/25 - 0s - loss: 0.2041 - accuracy: 0.9001 - val_loss: 1.1313 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03526: val_loss did not improve from 0.41973\n",
      "Epoch 3527/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9014 - val_loss: 1.1708 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03527: val_loss did not improve from 0.41973\n",
      "Epoch 3528/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8988 - val_loss: 1.1783 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03528: val_loss did not improve from 0.41973\n",
      "Epoch 3529/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.1732 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03529: val_loss did not improve from 0.41973\n",
      "Epoch 3530/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 1.1766 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03530: val_loss did not improve from 0.41973\n",
      "Epoch 3531/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.1725 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03531: val_loss did not improve from 0.41973\n",
      "Epoch 3532/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.1688 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03532: val_loss did not improve from 0.41973\n",
      "Epoch 3533/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 1.1885 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03533: val_loss did not improve from 0.41973\n",
      "Epoch 3534/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 1.1903 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03534: val_loss did not improve from 0.41973\n",
      "Epoch 3535/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 1.2003 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03535: val_loss did not improve from 0.41973\n",
      "Epoch 3536/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.2011 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03536: val_loss did not improve from 0.41973\n",
      "Epoch 3537/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 1.1920 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03537: val_loss did not improve from 0.41973\n",
      "Epoch 3538/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 1.1903 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03538: val_loss did not improve from 0.41973\n",
      "Epoch 3539/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.1831 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03539: val_loss did not improve from 0.41973\n",
      "Epoch 3540/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.1831 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03540: val_loss did not improve from 0.41973\n",
      "Epoch 3541/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9014 - val_loss: 1.1893 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03541: val_loss did not improve from 0.41973\n",
      "Epoch 3542/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 1.1830 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03542: val_loss did not improve from 0.41973\n",
      "Epoch 3543/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.8975 - val_loss: 1.1910 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03543: val_loss did not improve from 0.41973\n",
      "Epoch 3544/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.8962 - val_loss: 1.2109 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03544: val_loss did not improve from 0.41973\n",
      "Epoch 3545/4000\n",
      "25/25 - 0s - loss: 0.2040 - accuracy: 0.9027 - val_loss: 1.2002 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03545: val_loss did not improve from 0.41973\n",
      "Epoch 3546/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9053 - val_loss: 1.1975 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03546: val_loss did not improve from 0.41973\n",
      "Epoch 3547/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9001 - val_loss: 1.2114 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03547: val_loss did not improve from 0.41973\n",
      "Epoch 3548/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 1.2039 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03548: val_loss did not improve from 0.41973\n",
      "Epoch 3549/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 1.2094 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03549: val_loss did not improve from 0.41973\n",
      "Epoch 3550/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9040 - val_loss: 1.1999 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03550: val_loss did not improve from 0.41973\n",
      "Epoch 3551/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9001 - val_loss: 1.1967 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03551: val_loss did not improve from 0.41973\n",
      "Epoch 3552/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9014 - val_loss: 1.2136 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03552: val_loss did not improve from 0.41973\n",
      "Epoch 3553/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 1.2081 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03553: val_loss did not improve from 0.41973\n",
      "Epoch 3554/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9001 - val_loss: 1.2120 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03554: val_loss did not improve from 0.41973\n",
      "Epoch 3555/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9001 - val_loss: 1.2130 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03555: val_loss did not improve from 0.41973\n",
      "Epoch 3556/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 1.2099 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03556: val_loss did not improve from 0.41973\n",
      "Epoch 3557/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 1.2165 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03557: val_loss did not improve from 0.41973\n",
      "Epoch 3558/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 1.2224 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03558: val_loss did not improve from 0.41973\n",
      "Epoch 3559/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.8949 - val_loss: 1.2436 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03559: val_loss did not improve from 0.41973\n",
      "Epoch 3560/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 1.2299 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03560: val_loss did not improve from 0.41973\n",
      "Epoch 3561/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.8988 - val_loss: 1.2299 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03561: val_loss did not improve from 0.41973\n",
      "Epoch 3562/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 1.2371 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03562: val_loss did not improve from 0.41973\n",
      "Epoch 3563/4000\n",
      "25/25 - 0s - loss: 0.2002 - accuracy: 0.9001 - val_loss: 1.2438 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03563: val_loss did not improve from 0.41973\n",
      "Epoch 3564/4000\n",
      "25/25 - 0s - loss: 0.2002 - accuracy: 0.8975 - val_loss: 1.2403 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03564: val_loss did not improve from 0.41973\n",
      "Epoch 3565/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9014 - val_loss: 1.2427 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03565: val_loss did not improve from 0.41973\n",
      "Epoch 3566/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 1.2299 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03566: val_loss did not improve from 0.41973\n",
      "Epoch 3567/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 1.2332 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03567: val_loss did not improve from 0.41973\n",
      "Epoch 3568/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9001 - val_loss: 1.2427 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03568: val_loss did not improve from 0.41973\n",
      "Epoch 3569/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 1.2411 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03569: val_loss did not improve from 0.41973\n",
      "Epoch 3570/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9014 - val_loss: 1.2332 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03570: val_loss did not improve from 0.41973\n",
      "Epoch 3571/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9001 - val_loss: 1.2267 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03571: val_loss did not improve from 0.41973\n",
      "Epoch 3572/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 1.2252 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03572: val_loss did not improve from 0.41973\n",
      "Epoch 3573/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 1.2321 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03573: val_loss did not improve from 0.41973\n",
      "Epoch 3574/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 1.2543 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03574: val_loss did not improve from 0.41973\n",
      "Epoch 3575/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9014 - val_loss: 1.2503 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03575: val_loss did not improve from 0.41973\n",
      "Epoch 3576/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.2331 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03576: val_loss did not improve from 0.41973\n",
      "Epoch 3577/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 1.2300 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03577: val_loss did not improve from 0.41973\n",
      "Epoch 3578/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.2231 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03578: val_loss did not improve from 0.41973\n",
      "Epoch 3579/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9001 - val_loss: 1.2296 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03579: val_loss did not improve from 0.41973\n",
      "Epoch 3580/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9027 - val_loss: 1.2238 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03580: val_loss did not improve from 0.41973\n",
      "Epoch 3581/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.2203 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03581: val_loss did not improve from 0.41973\n",
      "Epoch 3582/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.8975 - val_loss: 1.2175 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03582: val_loss did not improve from 0.41973\n",
      "Epoch 3583/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9001 - val_loss: 1.2301 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03583: val_loss did not improve from 0.41973\n",
      "Epoch 3584/4000\n",
      "25/25 - 0s - loss: 0.2002 - accuracy: 0.8988 - val_loss: 1.2314 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03584: val_loss did not improve from 0.41973\n",
      "Epoch 3585/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9001 - val_loss: 1.2461 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03585: val_loss did not improve from 0.41973\n",
      "Epoch 3586/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9027 - val_loss: 1.2220 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03586: val_loss did not improve from 0.41973\n",
      "Epoch 3587/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.2467 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03587: val_loss did not improve from 0.41973\n",
      "Epoch 3588/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 1.2513 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03588: val_loss did not improve from 0.41973\n",
      "Epoch 3589/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.2542 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03589: val_loss did not improve from 0.41973\n",
      "Epoch 3590/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.2370 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03590: val_loss did not improve from 0.41973\n",
      "Epoch 3591/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 1.2371 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03591: val_loss did not improve from 0.41973\n",
      "Epoch 3592/4000\n",
      "25/25 - 0s - loss: 0.2021 - accuracy: 0.9014 - val_loss: 1.2381 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03592: val_loss did not improve from 0.41973\n",
      "Epoch 3593/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.8949 - val_loss: 1.2347 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03593: val_loss did not improve from 0.41973\n",
      "Epoch 3594/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.9027 - val_loss: 1.2381 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03594: val_loss did not improve from 0.41973\n",
      "Epoch 3595/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.2368 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03595: val_loss did not improve from 0.41973\n",
      "Epoch 3596/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9001 - val_loss: 1.2354 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03596: val_loss did not improve from 0.41973\n",
      "Epoch 3597/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 1.2287 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03597: val_loss did not improve from 0.41973\n",
      "Epoch 3598/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 1.2368 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03598: val_loss did not improve from 0.41973\n",
      "Epoch 3599/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 1.2418 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03599: val_loss did not improve from 0.41973\n",
      "Epoch 3600/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 1.2432 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03600: val_loss did not improve from 0.41973\n",
      "Epoch 3601/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9040 - val_loss: 1.2511 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03601: val_loss did not improve from 0.41973\n",
      "Epoch 3602/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.2283 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03602: val_loss did not improve from 0.41973\n",
      "Epoch 3603/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9014 - val_loss: 1.2344 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03603: val_loss did not improve from 0.41973\n",
      "Epoch 3604/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.2245 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03604: val_loss did not improve from 0.41973\n",
      "Epoch 3605/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.2402 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03605: val_loss did not improve from 0.41973\n",
      "Epoch 3606/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9001 - val_loss: 1.2391 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03606: val_loss did not improve from 0.41973\n",
      "Epoch 3607/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.2521 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03607: val_loss did not improve from 0.41973\n",
      "Epoch 3608/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.2724 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03608: val_loss did not improve from 0.41973\n",
      "Epoch 3609/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 1.2592 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03609: val_loss did not improve from 0.41973\n",
      "Epoch 3610/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9014 - val_loss: 1.2691 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03610: val_loss did not improve from 0.41973\n",
      "Epoch 3611/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.2871 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03611: val_loss did not improve from 0.41973\n",
      "Epoch 3612/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 1.2706 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03612: val_loss did not improve from 0.41973\n",
      "Epoch 3613/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.2644 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03613: val_loss did not improve from 0.41973\n",
      "Epoch 3614/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8988 - val_loss: 1.2461 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03614: val_loss did not improve from 0.41973\n",
      "Epoch 3615/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 1.2829 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03615: val_loss did not improve from 0.41973\n",
      "Epoch 3616/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 1.2854 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03616: val_loss did not improve from 0.41973\n",
      "Epoch 3617/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 1.2878 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03617: val_loss did not improve from 0.41973\n",
      "Epoch 3618/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9001 - val_loss: 1.3043 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03618: val_loss did not improve from 0.41973\n",
      "Epoch 3619/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.3295 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03619: val_loss did not improve from 0.41973\n",
      "Epoch 3620/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9027 - val_loss: 1.3424 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03620: val_loss did not improve from 0.41973\n",
      "Epoch 3621/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.3363 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03621: val_loss did not improve from 0.41973\n",
      "Epoch 3622/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 1.3106 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03622: val_loss did not improve from 0.41973\n",
      "Epoch 3623/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9001 - val_loss: 1.2974 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03623: val_loss did not improve from 0.41973\n",
      "Epoch 3624/4000\n",
      "25/25 - 0s - loss: 0.2002 - accuracy: 0.9027 - val_loss: 1.3938 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03624: val_loss did not improve from 0.41973\n",
      "Epoch 3625/4000\n",
      "25/25 - 0s - loss: 0.2153 - accuracy: 0.9027 - val_loss: 1.1865 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03625: val_loss did not improve from 0.41973\n",
      "Epoch 3626/4000\n",
      "25/25 - 0s - loss: 0.2088 - accuracy: 0.9027 - val_loss: 0.8010 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03626: val_loss did not improve from 0.41973\n",
      "Epoch 3627/4000\n",
      "25/25 - 0s - loss: 0.2165 - accuracy: 0.9014 - val_loss: 0.8461 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03627: val_loss did not improve from 0.41973\n",
      "Epoch 3628/4000\n",
      "25/25 - 0s - loss: 0.2069 - accuracy: 0.8988 - val_loss: 1.0173 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03628: val_loss did not improve from 0.41973\n",
      "Epoch 3629/4000\n",
      "25/25 - 0s - loss: 0.2060 - accuracy: 0.8962 - val_loss: 1.0455 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03629: val_loss did not improve from 0.41973\n",
      "Epoch 3630/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.8988 - val_loss: 1.0810 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03630: val_loss did not improve from 0.41973\n",
      "Epoch 3631/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.8988 - val_loss: 1.0992 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03631: val_loss did not improve from 0.41973\n",
      "Epoch 3632/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 1.1088 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03632: val_loss did not improve from 0.41973\n",
      "Epoch 3633/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 1.0845 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03633: val_loss did not improve from 0.41973\n",
      "Epoch 3634/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9014 - val_loss: 1.0821 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03634: val_loss did not improve from 0.41973\n",
      "Epoch 3635/4000\n",
      "25/25 - 0s - loss: 0.2023 - accuracy: 0.9040 - val_loss: 1.0661 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03635: val_loss did not improve from 0.41973\n",
      "Epoch 3636/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 1.0601 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03636: val_loss did not improve from 0.41973\n",
      "Epoch 3637/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 1.0585 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03637: val_loss did not improve from 0.41973\n",
      "Epoch 3638/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8988 - val_loss: 1.0684 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03638: val_loss did not improve from 0.41973\n",
      "Epoch 3639/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 1.0638 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03639: val_loss did not improve from 0.41973\n",
      "Epoch 3640/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 1.0551 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03640: val_loss did not improve from 0.41973\n",
      "Epoch 3641/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 1.0601 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03641: val_loss did not improve from 0.41973\n",
      "Epoch 3642/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 1.0588 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03642: val_loss did not improve from 0.41973\n",
      "Epoch 3643/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 1.0603 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03643: val_loss did not improve from 0.41973\n",
      "Epoch 3644/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.0628 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03644: val_loss did not improve from 0.41973\n",
      "Epoch 3645/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.0631 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03645: val_loss did not improve from 0.41973\n",
      "Epoch 3646/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9027 - val_loss: 1.0686 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03646: val_loss did not improve from 0.41973\n",
      "Epoch 3647/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.0758 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03647: val_loss did not improve from 0.41973\n",
      "Epoch 3648/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.0640 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03648: val_loss did not improve from 0.41973\n",
      "Epoch 3649/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 1.0780 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03649: val_loss did not improve from 0.41973\n",
      "Epoch 3650/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.0742 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03650: val_loss did not improve from 0.41973\n",
      "Epoch 3651/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.0727 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03651: val_loss did not improve from 0.41973\n",
      "Epoch 3652/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.0725 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03652: val_loss did not improve from 0.41973\n",
      "Epoch 3653/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.0750 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03653: val_loss did not improve from 0.41973\n",
      "Epoch 3654/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.0870 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03654: val_loss did not improve from 0.41973\n",
      "Epoch 3655/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.0768 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03655: val_loss did not improve from 0.41973\n",
      "Epoch 3656/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 1.0782 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03656: val_loss did not improve from 0.41973\n",
      "Epoch 3657/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.0812 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03657: val_loss did not improve from 0.41973\n",
      "Epoch 3658/4000\n",
      "25/25 - 0s - loss: 0.2002 - accuracy: 0.9040 - val_loss: 1.0759 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03658: val_loss did not improve from 0.41973\n",
      "Epoch 3659/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9040 - val_loss: 1.0624 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03659: val_loss did not improve from 0.41973\n",
      "Epoch 3660/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.0757 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03660: val_loss did not improve from 0.41973\n",
      "Epoch 3661/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 1.0876 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03661: val_loss did not improve from 0.41973\n",
      "Epoch 3662/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9001 - val_loss: 1.0828 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03662: val_loss did not improve from 0.41973\n",
      "Epoch 3663/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.0714 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03663: val_loss did not improve from 0.41973\n",
      "Epoch 3664/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8988 - val_loss: 1.0710 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03664: val_loss did not improve from 0.41973\n",
      "Epoch 3665/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9014 - val_loss: 1.0767 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03665: val_loss did not improve from 0.41973\n",
      "Epoch 3666/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 1.0979 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03666: val_loss did not improve from 0.41973\n",
      "Epoch 3667/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.1055 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03667: val_loss did not improve from 0.41973\n",
      "Epoch 3668/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.8988 - val_loss: 1.1056 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03668: val_loss did not improve from 0.41973\n",
      "Epoch 3669/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.1128 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03669: val_loss did not improve from 0.41973\n",
      "Epoch 3670/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9001 - val_loss: 1.1127 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03670: val_loss did not improve from 0.41973\n",
      "Epoch 3671/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.8988 - val_loss: 1.1161 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03671: val_loss did not improve from 0.41973\n",
      "Epoch 3672/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.1253 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03672: val_loss did not improve from 0.41973\n",
      "Epoch 3673/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.8988 - val_loss: 1.1288 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03673: val_loss did not improve from 0.41973\n",
      "Epoch 3674/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9014 - val_loss: 1.1247 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03674: val_loss did not improve from 0.41973\n",
      "Epoch 3675/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 1.1294 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03675: val_loss did not improve from 0.41973\n",
      "Epoch 3676/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9014 - val_loss: 1.1231 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03676: val_loss did not improve from 0.41973\n",
      "Epoch 3677/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9027 - val_loss: 1.1248 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03677: val_loss did not improve from 0.41973\n",
      "Epoch 3678/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9014 - val_loss: 1.1326 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03678: val_loss did not improve from 0.41973\n",
      "Epoch 3679/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 1.1245 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03679: val_loss did not improve from 0.41973\n",
      "Epoch 3680/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9014 - val_loss: 1.1246 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03680: val_loss did not improve from 0.41973\n",
      "Epoch 3681/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 1.1182 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03681: val_loss did not improve from 0.41973\n",
      "Epoch 3682/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 1.1121 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03682: val_loss did not improve from 0.41973\n",
      "Epoch 3683/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 1.1192 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03683: val_loss did not improve from 0.41973\n",
      "Epoch 3684/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.8988 - val_loss: 1.1205 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03684: val_loss did not improve from 0.41973\n",
      "Epoch 3685/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9001 - val_loss: 1.1041 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03685: val_loss did not improve from 0.41973\n",
      "Epoch 3686/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.8988 - val_loss: 1.1076 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03686: val_loss did not improve from 0.41973\n",
      "Epoch 3687/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9014 - val_loss: 1.1113 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03687: val_loss did not improve from 0.41973\n",
      "Epoch 3688/4000\n",
      "25/25 - 0s - loss: 0.2002 - accuracy: 0.9014 - val_loss: 1.1182 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03688: val_loss did not improve from 0.41973\n",
      "Epoch 3689/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9001 - val_loss: 1.1108 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03689: val_loss did not improve from 0.41973\n",
      "Epoch 3690/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9001 - val_loss: 1.1200 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03690: val_loss did not improve from 0.41973\n",
      "Epoch 3691/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 1.1228 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03691: val_loss did not improve from 0.41973\n",
      "Epoch 3692/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9014 - val_loss: 1.1091 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03692: val_loss did not improve from 0.41973\n",
      "Epoch 3693/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9014 - val_loss: 1.1130 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03693: val_loss did not improve from 0.41973\n",
      "Epoch 3694/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9001 - val_loss: 1.1160 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03694: val_loss did not improve from 0.41973\n",
      "Epoch 3695/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 1.1164 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03695: val_loss did not improve from 0.41973\n",
      "Epoch 3696/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.1139 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03696: val_loss did not improve from 0.41973\n",
      "Epoch 3697/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 1.1147 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03697: val_loss did not improve from 0.41973\n",
      "Epoch 3698/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8988 - val_loss: 1.1164 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03698: val_loss did not improve from 0.41973\n",
      "Epoch 3699/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9001 - val_loss: 1.1291 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03699: val_loss did not improve from 0.41973\n",
      "Epoch 3700/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9040 - val_loss: 1.1284 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03700: val_loss did not improve from 0.41973\n",
      "Epoch 3701/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9001 - val_loss: 1.1202 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03701: val_loss did not improve from 0.41973\n",
      "Epoch 3702/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.1224 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03702: val_loss did not improve from 0.41973\n",
      "Epoch 3703/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.1250 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03703: val_loss did not improve from 0.41973\n",
      "Epoch 3704/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9040 - val_loss: 1.1189 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03704: val_loss did not improve from 0.41973\n",
      "Epoch 3705/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9001 - val_loss: 1.1219 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03705: val_loss did not improve from 0.41973\n",
      "Epoch 3706/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.8988 - val_loss: 1.0814 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03706: val_loss did not improve from 0.41973\n",
      "Epoch 3707/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.0956 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03707: val_loss did not improve from 0.41973\n",
      "Epoch 3708/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 1.0939 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03708: val_loss did not improve from 0.41973\n",
      "Epoch 3709/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9027 - val_loss: 1.0934 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03709: val_loss did not improve from 0.41973\n",
      "Epoch 3710/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.0886 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03710: val_loss did not improve from 0.41973\n",
      "Epoch 3711/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.0922 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03711: val_loss did not improve from 0.41973\n",
      "Epoch 3712/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.1012 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03712: val_loss did not improve from 0.41973\n",
      "Epoch 3713/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.1061 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03713: val_loss did not improve from 0.41973\n",
      "Epoch 3714/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 1.1291 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03714: val_loss did not improve from 0.41973\n",
      "Epoch 3715/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.1393 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03715: val_loss did not improve from 0.41973\n",
      "Epoch 3716/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 1.0946 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03716: val_loss did not improve from 0.41973\n",
      "Epoch 3717/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9001 - val_loss: 1.1033 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03717: val_loss did not improve from 0.41973\n",
      "Epoch 3718/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9014 - val_loss: 1.1047 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03718: val_loss did not improve from 0.41973\n",
      "Epoch 3719/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 1.1025 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03719: val_loss did not improve from 0.41973\n",
      "Epoch 3720/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.0952 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03720: val_loss did not improve from 0.41973\n",
      "Epoch 3721/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 1.0954 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03721: val_loss did not improve from 0.41973\n",
      "Epoch 3722/4000\n",
      "25/25 - 0s - loss: 0.2002 - accuracy: 0.9014 - val_loss: 1.0904 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03722: val_loss did not improve from 0.41973\n",
      "Epoch 3723/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.0838 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03723: val_loss did not improve from 0.41973\n",
      "Epoch 3724/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9001 - val_loss: 1.0847 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03724: val_loss did not improve from 0.41973\n",
      "Epoch 3725/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.0839 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03725: val_loss did not improve from 0.41973\n",
      "Epoch 3726/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.0911 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03726: val_loss did not improve from 0.41973\n",
      "Epoch 3727/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 1.0861 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03727: val_loss did not improve from 0.41973\n",
      "Epoch 3728/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.1065 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03728: val_loss did not improve from 0.41973\n",
      "Epoch 3729/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9014 - val_loss: 1.1248 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03729: val_loss did not improve from 0.41973\n",
      "Epoch 3730/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.1336 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03730: val_loss did not improve from 0.41973\n",
      "Epoch 3731/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 1.1566 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03731: val_loss did not improve from 0.41973\n",
      "Epoch 3732/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.1169 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03732: val_loss did not improve from 0.41973\n",
      "Epoch 3733/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.1125 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03733: val_loss did not improve from 0.41973\n",
      "Epoch 3734/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9001 - val_loss: 1.1230 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03734: val_loss did not improve from 0.41973\n",
      "Epoch 3735/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 1.1147 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03735: val_loss did not improve from 0.41973\n",
      "Epoch 3736/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.1290 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03736: val_loss did not improve from 0.41973\n",
      "Epoch 3737/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.8988 - val_loss: 1.1615 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03737: val_loss did not improve from 0.41973\n",
      "Epoch 3738/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9014 - val_loss: 1.1512 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03738: val_loss did not improve from 0.41973\n",
      "Epoch 3739/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 1.1456 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03739: val_loss did not improve from 0.41973\n",
      "Epoch 3740/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.8975 - val_loss: 1.1570 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03740: val_loss did not improve from 0.41973\n",
      "Epoch 3741/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.8988 - val_loss: 1.1638 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03741: val_loss did not improve from 0.41973\n",
      "Epoch 3742/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9001 - val_loss: 1.1214 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03742: val_loss did not improve from 0.41973\n",
      "Epoch 3743/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.1286 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03743: val_loss did not improve from 0.41973\n",
      "Epoch 3744/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.8975 - val_loss: 1.1269 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03744: val_loss did not improve from 0.41973\n",
      "Epoch 3745/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9001 - val_loss: 1.1125 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03745: val_loss did not improve from 0.41973\n",
      "Epoch 3746/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.8975 - val_loss: 1.1232 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03746: val_loss did not improve from 0.41973\n",
      "Epoch 3747/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.8962 - val_loss: 1.1292 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03747: val_loss did not improve from 0.41973\n",
      "Epoch 3748/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.8988 - val_loss: 1.1187 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03748: val_loss did not improve from 0.41973\n",
      "Epoch 3749/4000\n",
      "25/25 - 0s - loss: 0.2002 - accuracy: 0.9001 - val_loss: 1.1330 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03749: val_loss did not improve from 0.41973\n",
      "Epoch 3750/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.8988 - val_loss: 1.1251 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03750: val_loss did not improve from 0.41973\n",
      "Epoch 3751/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8962 - val_loss: 1.1264 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03751: val_loss did not improve from 0.41973\n",
      "Epoch 3752/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.8975 - val_loss: 1.1446 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03752: val_loss did not improve from 0.41973\n",
      "Epoch 3753/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.8975 - val_loss: 1.1498 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03753: val_loss did not improve from 0.41973\n",
      "Epoch 3754/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.8988 - val_loss: 1.1427 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03754: val_loss did not improve from 0.41973\n",
      "Epoch 3755/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.8988 - val_loss: 1.1528 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03755: val_loss did not improve from 0.41973\n",
      "Epoch 3756/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9001 - val_loss: 1.1768 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03756: val_loss did not improve from 0.41973\n",
      "Epoch 3757/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 1.1831 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03757: val_loss did not improve from 0.41973\n",
      "Epoch 3758/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.1450 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03758: val_loss did not improve from 0.41973\n",
      "Epoch 3759/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.1496 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03759: val_loss did not improve from 0.41973\n",
      "Epoch 3760/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 1.1573 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03760: val_loss did not improve from 0.41973\n",
      "Epoch 3761/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9014 - val_loss: 1.1575 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03761: val_loss did not improve from 0.41973\n",
      "Epoch 3762/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.8975 - val_loss: 1.1582 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03762: val_loss did not improve from 0.41973\n",
      "Epoch 3763/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9001 - val_loss: 1.1645 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03763: val_loss did not improve from 0.41973\n",
      "Epoch 3764/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9001 - val_loss: 1.1613 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03764: val_loss did not improve from 0.41973\n",
      "Epoch 3765/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9014 - val_loss: 1.1646 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03765: val_loss did not improve from 0.41973\n",
      "Epoch 3766/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.8949 - val_loss: 1.1629 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03766: val_loss did not improve from 0.41973\n",
      "Epoch 3767/4000\n",
      "25/25 - 0s - loss: 0.2002 - accuracy: 0.9014 - val_loss: 1.1684 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03767: val_loss did not improve from 0.41973\n",
      "Epoch 3768/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.8988 - val_loss: 1.1723 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03768: val_loss did not improve from 0.41973\n",
      "Epoch 3769/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.8949 - val_loss: 1.1714 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03769: val_loss did not improve from 0.41973\n",
      "Epoch 3770/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.8988 - val_loss: 1.1679 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03770: val_loss did not improve from 0.41973\n",
      "Epoch 3771/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9014 - val_loss: 1.1614 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03771: val_loss did not improve from 0.41973\n",
      "Epoch 3772/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.8988 - val_loss: 1.1644 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03772: val_loss did not improve from 0.41973\n",
      "Epoch 3773/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 1.1516 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03773: val_loss did not improve from 0.41973\n",
      "Epoch 3774/4000\n",
      "25/25 - 0s - loss: 0.2002 - accuracy: 0.9014 - val_loss: 1.1509 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03774: val_loss did not improve from 0.41973\n",
      "Epoch 3775/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9014 - val_loss: 1.1494 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03775: val_loss did not improve from 0.41973\n",
      "Epoch 3776/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.1623 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03776: val_loss did not improve from 0.41973\n",
      "Epoch 3777/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.1407 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03777: val_loss did not improve from 0.41973\n",
      "Epoch 3778/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 1.1327 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03778: val_loss did not improve from 0.41973\n",
      "Epoch 3779/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.1094 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03779: val_loss did not improve from 0.41973\n",
      "Epoch 3780/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 1.1222 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03780: val_loss did not improve from 0.41973\n",
      "Epoch 3781/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.1407 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03781: val_loss did not improve from 0.41973\n",
      "Epoch 3782/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 1.1758 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03782: val_loss did not improve from 0.41973\n",
      "Epoch 3783/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.1870 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03783: val_loss did not improve from 0.41973\n",
      "Epoch 3784/4000\n",
      "25/25 - 0s - loss: 0.2024 - accuracy: 0.9001 - val_loss: 1.1836 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03784: val_loss did not improve from 0.41973\n",
      "Epoch 3785/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8988 - val_loss: 1.1684 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03785: val_loss did not improve from 0.41973\n",
      "Epoch 3786/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.1511 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03786: val_loss did not improve from 0.41973\n",
      "Epoch 3787/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 1.1358 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03787: val_loss did not improve from 0.41973\n",
      "Epoch 3788/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.1296 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03788: val_loss did not improve from 0.41973\n",
      "Epoch 3789/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.1393 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03789: val_loss did not improve from 0.41973\n",
      "Epoch 3790/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.1283 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03790: val_loss did not improve from 0.41973\n",
      "Epoch 3791/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9014 - val_loss: 1.1013 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03791: val_loss did not improve from 0.41973\n",
      "Epoch 3792/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9001 - val_loss: 1.1249 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03792: val_loss did not improve from 0.41973\n",
      "Epoch 3793/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.1427 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03793: val_loss did not improve from 0.41973\n",
      "Epoch 3794/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9001 - val_loss: 1.1684 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03794: val_loss did not improve from 0.41973\n",
      "Epoch 3795/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 1.1744 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03795: val_loss did not improve from 0.41973\n",
      "Epoch 3796/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.1505 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03796: val_loss did not improve from 0.41973\n",
      "Epoch 3797/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9001 - val_loss: 1.1441 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03797: val_loss did not improve from 0.41973\n",
      "Epoch 3798/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.8988 - val_loss: 1.1554 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03798: val_loss did not improve from 0.41973\n",
      "Epoch 3799/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.8988 - val_loss: 1.1521 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03799: val_loss did not improve from 0.41973\n",
      "Epoch 3800/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9014 - val_loss: 1.1588 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03800: val_loss did not improve from 0.41973\n",
      "Epoch 3801/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.1529 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03801: val_loss did not improve from 0.41973\n",
      "Epoch 3802/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.1714 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03802: val_loss did not improve from 0.41973\n",
      "Epoch 3803/4000\n",
      "25/25 - 0s - loss: 0.2022 - accuracy: 0.9040 - val_loss: 1.1455 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03803: val_loss did not improve from 0.41973\n",
      "Epoch 3804/4000\n",
      "25/25 - 0s - loss: 0.2017 - accuracy: 0.8988 - val_loss: 1.1374 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03804: val_loss did not improve from 0.41973\n",
      "Epoch 3805/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.8988 - val_loss: 1.1800 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03805: val_loss did not improve from 0.41973\n",
      "Epoch 3806/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.1522 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03806: val_loss did not improve from 0.41973\n",
      "Epoch 3807/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.1357 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03807: val_loss did not improve from 0.41973\n",
      "Epoch 3808/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9001 - val_loss: 1.1119 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03808: val_loss did not improve from 0.41973\n",
      "Epoch 3809/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.8975 - val_loss: 1.1187 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03809: val_loss did not improve from 0.41973\n",
      "Epoch 3810/4000\n",
      "25/25 - 0s - loss: 0.2019 - accuracy: 0.9001 - val_loss: 1.1197 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03810: val_loss did not improve from 0.41973\n",
      "Epoch 3811/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8975 - val_loss: 1.1373 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03811: val_loss did not improve from 0.41973\n",
      "Epoch 3812/4000\n",
      "25/25 - 0s - loss: 0.2083 - accuracy: 0.9014 - val_loss: 1.1484 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03812: val_loss did not improve from 0.41973\n",
      "Epoch 3813/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9014 - val_loss: 1.0068 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03813: val_loss did not improve from 0.41973\n",
      "Epoch 3814/4000\n",
      "25/25 - 0s - loss: 0.2046 - accuracy: 0.8962 - val_loss: 1.0709 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03814: val_loss did not improve from 0.41973\n",
      "Epoch 3815/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.0969 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03815: val_loss did not improve from 0.41973\n",
      "Epoch 3816/4000\n",
      "25/25 - 0s - loss: 0.2040 - accuracy: 0.8988 - val_loss: 1.0183 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03816: val_loss did not improve from 0.41973\n",
      "Epoch 3817/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9014 - val_loss: 0.9967 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03817: val_loss did not improve from 0.41973\n",
      "Epoch 3818/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 0.9875 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03818: val_loss did not improve from 0.41973\n",
      "Epoch 3819/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9001 - val_loss: 0.9919 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03819: val_loss did not improve from 0.41973\n",
      "Epoch 3820/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 0.9819 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03820: val_loss did not improve from 0.41973\n",
      "Epoch 3821/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 0.9785 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03821: val_loss did not improve from 0.41973\n",
      "Epoch 3822/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 0.9573 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03822: val_loss did not improve from 0.41973\n",
      "Epoch 3823/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 0.9707 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03823: val_loss did not improve from 0.41973\n",
      "Epoch 3824/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 0.9888 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03824: val_loss did not improve from 0.41973\n",
      "Epoch 3825/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 0.9844 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03825: val_loss did not improve from 0.41973\n",
      "Epoch 3826/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 0.9847 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03826: val_loss did not improve from 0.41973\n",
      "Epoch 3827/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 0.9959 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03827: val_loss did not improve from 0.41973\n",
      "Epoch 3828/4000\n",
      "25/25 - 0s - loss: 0.2016 - accuracy: 0.9027 - val_loss: 0.9913 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03828: val_loss did not improve from 0.41973\n",
      "Epoch 3829/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 0.9764 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03829: val_loss did not improve from 0.41973\n",
      "Epoch 3830/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 0.9665 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03830: val_loss did not improve from 0.41973\n",
      "Epoch 3831/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9014 - val_loss: 0.9677 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03831: val_loss did not improve from 0.41973\n",
      "Epoch 3832/4000\n",
      "25/25 - 0s - loss: 0.2002 - accuracy: 0.9027 - val_loss: 0.9677 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03832: val_loss did not improve from 0.41973\n",
      "Epoch 3833/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9014 - val_loss: 0.9494 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03833: val_loss did not improve from 0.41973\n",
      "Epoch 3834/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 0.9477 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03834: val_loss did not improve from 0.41973\n",
      "Epoch 3835/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 0.9263 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03835: val_loss did not improve from 0.41973\n",
      "Epoch 3836/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 0.9290 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03836: val_loss did not improve from 0.41973\n",
      "Epoch 3837/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 0.9427 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03837: val_loss did not improve from 0.41973\n",
      "Epoch 3838/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 0.9541 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03838: val_loss did not improve from 0.41973\n",
      "Epoch 3839/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.8988 - val_loss: 0.9473 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03839: val_loss did not improve from 0.41973\n",
      "Epoch 3840/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 0.9494 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03840: val_loss did not improve from 0.41973\n",
      "Epoch 3841/4000\n",
      "25/25 - 0s - loss: 0.2015 - accuracy: 0.9001 - val_loss: 0.9466 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03841: val_loss did not improve from 0.41973\n",
      "Epoch 3842/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.0900 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03842: val_loss did not improve from 0.41973\n",
      "Epoch 3843/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.8988 - val_loss: 1.0680 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03843: val_loss did not improve from 0.41973\n",
      "Epoch 3844/4000\n",
      "25/25 - 0s - loss: 0.2031 - accuracy: 0.8988 - val_loss: 1.1012 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03844: val_loss did not improve from 0.41973\n",
      "Epoch 3845/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.1059 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03845: val_loss did not improve from 0.41973\n",
      "Epoch 3846/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.9027 - val_loss: 1.1106 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03846: val_loss did not improve from 0.41973\n",
      "Epoch 3847/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 1.0841 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03847: val_loss did not improve from 0.41973\n",
      "Epoch 3848/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9014 - val_loss: 1.0971 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03848: val_loss did not improve from 0.41973\n",
      "Epoch 3849/4000\n",
      "25/25 - 0s - loss: 0.2173 - accuracy: 0.9027 - val_loss: 1.0777 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03849: val_loss did not improve from 0.41973\n",
      "Epoch 3850/4000\n",
      "25/25 - 0s - loss: 0.2667 - accuracy: 0.8949 - val_loss: 1.1311 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 03850: val_loss did not improve from 0.41973\n",
      "Epoch 3851/4000\n",
      "25/25 - 0s - loss: 0.2328 - accuracy: 0.8975 - val_loss: 1.1138 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03851: val_loss did not improve from 0.41973\n",
      "Epoch 3852/4000\n",
      "25/25 - 0s - loss: 0.2041 - accuracy: 0.9027 - val_loss: 1.2101 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03852: val_loss did not improve from 0.41973\n",
      "Epoch 3853/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 1.1989 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03853: val_loss did not improve from 0.41973\n",
      "Epoch 3854/4000\n",
      "25/25 - 0s - loss: 0.2018 - accuracy: 0.8988 - val_loss: 1.1743 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03854: val_loss did not improve from 0.41973\n",
      "Epoch 3855/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8988 - val_loss: 1.1835 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03855: val_loss did not improve from 0.41973\n",
      "Epoch 3856/4000\n",
      "25/25 - 0s - loss: 0.2013 - accuracy: 0.9001 - val_loss: 1.1727 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03856: val_loss did not improve from 0.41973\n",
      "Epoch 3857/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8988 - val_loss: 1.1738 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03857: val_loss did not improve from 0.41973\n",
      "Epoch 3858/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.8975 - val_loss: 1.1668 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03858: val_loss did not improve from 0.41973\n",
      "Epoch 3859/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 1.1628 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03859: val_loss did not improve from 0.41973\n",
      "Epoch 3860/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.8988 - val_loss: 1.1561 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03860: val_loss did not improve from 0.41973\n",
      "Epoch 3861/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 1.1599 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03861: val_loss did not improve from 0.41973\n",
      "Epoch 3862/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.9014 - val_loss: 1.1583 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03862: val_loss did not improve from 0.41973\n",
      "Epoch 3863/4000\n",
      "25/25 - 0s - loss: 0.2012 - accuracy: 0.8988 - val_loss: 1.1645 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03863: val_loss did not improve from 0.41973\n",
      "Epoch 3864/4000\n",
      "25/25 - 0s - loss: 0.2014 - accuracy: 0.8988 - val_loss: 1.1814 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03864: val_loss did not improve from 0.41973\n",
      "Epoch 3865/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.1836 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03865: val_loss did not improve from 0.41973\n",
      "Epoch 3866/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.8988 - val_loss: 1.1922 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03866: val_loss did not improve from 0.41973\n",
      "Epoch 3867/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.1783 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03867: val_loss did not improve from 0.41973\n",
      "Epoch 3868/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 1.1899 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03868: val_loss did not improve from 0.41973\n",
      "Epoch 3869/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.8988 - val_loss: 1.1938 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03869: val_loss did not improve from 0.41973\n",
      "Epoch 3870/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 1.2009 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03870: val_loss did not improve from 0.41973\n",
      "Epoch 3871/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.8962 - val_loss: 1.1955 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03871: val_loss did not improve from 0.41973\n",
      "Epoch 3872/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8988 - val_loss: 1.1849 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03872: val_loss did not improve from 0.41973\n",
      "Epoch 3873/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8988 - val_loss: 1.1931 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03873: val_loss did not improve from 0.41973\n",
      "Epoch 3874/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 1.2008 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03874: val_loss did not improve from 0.41973\n",
      "Epoch 3875/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8988 - val_loss: 1.2002 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03875: val_loss did not improve from 0.41973\n",
      "Epoch 3876/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9040 - val_loss: 1.2028 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03876: val_loss did not improve from 0.41973\n",
      "Epoch 3877/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9001 - val_loss: 1.2002 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03877: val_loss did not improve from 0.41973\n",
      "Epoch 3878/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9027 - val_loss: 1.2092 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03878: val_loss did not improve from 0.41973\n",
      "Epoch 3879/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.8988 - val_loss: 1.2065 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03879: val_loss did not improve from 0.41973\n",
      "Epoch 3880/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.8988 - val_loss: 1.2168 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03880: val_loss did not improve from 0.41973\n",
      "Epoch 3881/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8988 - val_loss: 1.1921 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03881: val_loss did not improve from 0.41973\n",
      "Epoch 3882/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 1.1813 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03882: val_loss did not improve from 0.41973\n",
      "Epoch 3883/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8975 - val_loss: 1.1855 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03883: val_loss did not improve from 0.41973\n",
      "Epoch 3884/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.1852 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03884: val_loss did not improve from 0.41973\n",
      "Epoch 3885/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 1.1840 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03885: val_loss did not improve from 0.41973\n",
      "Epoch 3886/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.1735 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03886: val_loss did not improve from 0.41973\n",
      "Epoch 3887/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.1961 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03887: val_loss did not improve from 0.41973\n",
      "Epoch 3888/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.2034 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03888: val_loss did not improve from 0.41973\n",
      "Epoch 3889/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9014 - val_loss: 1.2111 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03889: val_loss did not improve from 0.41973\n",
      "Epoch 3890/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 1.2086 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03890: val_loss did not improve from 0.41973\n",
      "Epoch 3891/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9014 - val_loss: 1.2266 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03891: val_loss did not improve from 0.41973\n",
      "Epoch 3892/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.8988 - val_loss: 1.2204 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03892: val_loss did not improve from 0.41973\n",
      "Epoch 3893/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9001 - val_loss: 1.2251 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03893: val_loss did not improve from 0.41973\n",
      "Epoch 3894/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9040 - val_loss: 1.2244 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03894: val_loss did not improve from 0.41973\n",
      "Epoch 3895/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.2237 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03895: val_loss did not improve from 0.41973\n",
      "Epoch 3896/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 1.2314 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03896: val_loss did not improve from 0.41973\n",
      "Epoch 3897/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9014 - val_loss: 1.2210 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03897: val_loss did not improve from 0.41973\n",
      "Epoch 3898/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.2295 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03898: val_loss did not improve from 0.41973\n",
      "Epoch 3899/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9001 - val_loss: 1.2204 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03899: val_loss did not improve from 0.41973\n",
      "Epoch 3900/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9014 - val_loss: 1.2257 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03900: val_loss did not improve from 0.41973\n",
      "Epoch 3901/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9001 - val_loss: 1.2261 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03901: val_loss did not improve from 0.41973\n",
      "Epoch 3902/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.2423 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03902: val_loss did not improve from 0.41973\n",
      "Epoch 3903/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 1.2384 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03903: val_loss did not improve from 0.41973\n",
      "Epoch 3904/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9027 - val_loss: 1.2382 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03904: val_loss did not improve from 0.41973\n",
      "Epoch 3905/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9001 - val_loss: 1.2430 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03905: val_loss did not improve from 0.41973\n",
      "Epoch 3906/4000\n",
      "25/25 - 0s - loss: 0.2001 - accuracy: 0.9001 - val_loss: 1.2373 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03906: val_loss did not improve from 0.41973\n",
      "Epoch 3907/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.2255 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03907: val_loss did not improve from 0.41973\n",
      "Epoch 3908/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.2282 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03908: val_loss did not improve from 0.41973\n",
      "Epoch 3909/4000\n",
      "25/25 - 0s - loss: 0.2001 - accuracy: 0.9001 - val_loss: 1.2395 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03909: val_loss did not improve from 0.41973\n",
      "Epoch 3910/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 1.2362 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03910: val_loss did not improve from 0.41973\n",
      "Epoch 3911/4000\n",
      "25/25 - 0s - loss: 0.2002 - accuracy: 0.9027 - val_loss: 1.2388 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03911: val_loss did not improve from 0.41973\n",
      "Epoch 3912/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 1.2469 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03912: val_loss did not improve from 0.41973\n",
      "Epoch 3913/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9001 - val_loss: 1.2516 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03913: val_loss did not improve from 0.41973\n",
      "Epoch 3914/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9014 - val_loss: 1.2497 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03914: val_loss did not improve from 0.41973\n",
      "Epoch 3915/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9001 - val_loss: 1.2535 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03915: val_loss did not improve from 0.41973\n",
      "Epoch 3916/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9027 - val_loss: 1.2324 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03916: val_loss did not improve from 0.41973\n",
      "Epoch 3917/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.2234 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03917: val_loss did not improve from 0.41973\n",
      "Epoch 3918/4000\n",
      "25/25 - 0s - loss: 0.2002 - accuracy: 0.9027 - val_loss: 1.2291 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03918: val_loss did not improve from 0.41973\n",
      "Epoch 3919/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9014 - val_loss: 1.2286 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03919: val_loss did not improve from 0.41973\n",
      "Epoch 3920/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9040 - val_loss: 1.2246 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03920: val_loss did not improve from 0.41973\n",
      "Epoch 3921/4000\n",
      "25/25 - 0s - loss: 0.2002 - accuracy: 0.8988 - val_loss: 1.2264 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03921: val_loss did not improve from 0.41973\n",
      "Epoch 3922/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9040 - val_loss: 1.2155 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03922: val_loss did not improve from 0.41973\n",
      "Epoch 3923/4000\n",
      "25/25 - 0s - loss: 0.2001 - accuracy: 0.9001 - val_loss: 1.2269 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03923: val_loss did not improve from 0.41973\n",
      "Epoch 3924/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9014 - val_loss: 1.2252 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03924: val_loss did not improve from 0.41973\n",
      "Epoch 3925/4000\n",
      "25/25 - 0s - loss: 0.2002 - accuracy: 0.9001 - val_loss: 1.2057 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03925: val_loss did not improve from 0.41973\n",
      "Epoch 3926/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9001 - val_loss: 1.2064 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03926: val_loss did not improve from 0.41973\n",
      "Epoch 3927/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9027 - val_loss: 1.2122 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03927: val_loss did not improve from 0.41973\n",
      "Epoch 3928/4000\n",
      "25/25 - 0s - loss: 0.2002 - accuracy: 0.9027 - val_loss: 1.2297 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03928: val_loss did not improve from 0.41973\n",
      "Epoch 3929/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.2279 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03929: val_loss did not improve from 0.41973\n",
      "Epoch 3930/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9014 - val_loss: 1.2399 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03930: val_loss did not improve from 0.41973\n",
      "Epoch 3931/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 1.2296 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03931: val_loss did not improve from 0.41973\n",
      "Epoch 3932/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.2195 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03932: val_loss did not improve from 0.41973\n",
      "Epoch 3933/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9040 - val_loss: 1.2227 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03933: val_loss did not improve from 0.41973\n",
      "Epoch 3934/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.2144 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03934: val_loss did not improve from 0.41973\n",
      "Epoch 3935/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.2115 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03935: val_loss did not improve from 0.41973\n",
      "Epoch 3936/4000\n",
      "25/25 - 0s - loss: 0.2002 - accuracy: 0.9014 - val_loss: 1.2281 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03936: val_loss did not improve from 0.41973\n",
      "Epoch 3937/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9027 - val_loss: 1.2240 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03937: val_loss did not improve from 0.41973\n",
      "Epoch 3938/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.2193 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03938: val_loss did not improve from 0.41973\n",
      "Epoch 3939/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9027 - val_loss: 1.2202 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03939: val_loss did not improve from 0.41973\n",
      "Epoch 3940/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 1.2193 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03940: val_loss did not improve from 0.41973\n",
      "Epoch 3941/4000\n",
      "25/25 - 0s - loss: 0.2002 - accuracy: 0.9001 - val_loss: 1.2226 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03941: val_loss did not improve from 0.41973\n",
      "Epoch 3942/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9027 - val_loss: 1.2213 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03942: val_loss did not improve from 0.41973\n",
      "Epoch 3943/4000\n",
      "25/25 - 0s - loss: 0.2002 - accuracy: 0.9014 - val_loss: 1.2255 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03943: val_loss did not improve from 0.41973\n",
      "Epoch 3944/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.2272 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03944: val_loss did not improve from 0.41973\n",
      "Epoch 3945/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9014 - val_loss: 1.2299 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03945: val_loss did not improve from 0.41973\n",
      "Epoch 3946/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9001 - val_loss: 1.2352 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03946: val_loss did not improve from 0.41973\n",
      "Epoch 3947/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9001 - val_loss: 1.2278 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03947: val_loss did not improve from 0.41973\n",
      "Epoch 3948/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 1.2135 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03948: val_loss did not improve from 0.41973\n",
      "Epoch 3949/4000\n",
      "25/25 - 0s - loss: 0.2002 - accuracy: 0.9014 - val_loss: 1.2062 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03949: val_loss did not improve from 0.41973\n",
      "Epoch 3950/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.2047 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03950: val_loss did not improve from 0.41973\n",
      "Epoch 3951/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.2084 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03951: val_loss did not improve from 0.41973\n",
      "Epoch 3952/4000\n",
      "25/25 - 0s - loss: 0.2002 - accuracy: 0.9001 - val_loss: 1.2228 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03952: val_loss did not improve from 0.41973\n",
      "Epoch 3953/4000\n",
      "25/25 - 0s - loss: 0.2002 - accuracy: 0.9014 - val_loss: 1.2381 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03953: val_loss did not improve from 0.41973\n",
      "Epoch 3954/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9027 - val_loss: 1.2272 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03954: val_loss did not improve from 0.41973\n",
      "Epoch 3955/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9001 - val_loss: 1.2338 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03955: val_loss did not improve from 0.41973\n",
      "Epoch 3956/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9027 - val_loss: 1.2497 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03956: val_loss did not improve from 0.41973\n",
      "Epoch 3957/4000\n",
      "25/25 - 0s - loss: 0.2001 - accuracy: 0.9027 - val_loss: 1.2276 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03957: val_loss did not improve from 0.41973\n",
      "Epoch 3958/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.8949 - val_loss: 1.2217 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03958: val_loss did not improve from 0.41973\n",
      "Epoch 3959/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.2356 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03959: val_loss did not improve from 0.41973\n",
      "Epoch 3960/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 1.2333 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03960: val_loss did not improve from 0.41973\n",
      "Epoch 3961/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.2528 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03961: val_loss did not improve from 0.41973\n",
      "Epoch 3962/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.2262 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03962: val_loss did not improve from 0.41973\n",
      "Epoch 3963/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.9014 - val_loss: 1.2261 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03963: val_loss did not improve from 0.41973\n",
      "Epoch 3964/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 1.2184 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03964: val_loss did not improve from 0.41973\n",
      "Epoch 3965/4000\n",
      "25/25 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 1.2278 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03965: val_loss did not improve from 0.41973\n",
      "Epoch 3966/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 1.1705 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03966: val_loss did not improve from 0.41973\n",
      "Epoch 3967/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 1.1659 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03967: val_loss did not improve from 0.41973\n",
      "Epoch 3968/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.1874 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03968: val_loss did not improve from 0.41973\n",
      "Epoch 3969/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 1.1771 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03969: val_loss did not improve from 0.41973\n",
      "Epoch 3970/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.1806 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03970: val_loss did not improve from 0.41973\n",
      "Epoch 3971/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9014 - val_loss: 1.1833 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03971: val_loss did not improve from 0.41973\n",
      "Epoch 3972/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9001 - val_loss: 1.1700 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03972: val_loss did not improve from 0.41973\n",
      "Epoch 3973/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 1.1403 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03973: val_loss did not improve from 0.41973\n",
      "Epoch 3974/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.1297 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03974: val_loss did not improve from 0.41973\n",
      "Epoch 3975/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 1.1287 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03975: val_loss did not improve from 0.41973\n",
      "Epoch 3976/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.8975 - val_loss: 1.1558 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03976: val_loss did not improve from 0.41973\n",
      "Epoch 3977/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9027 - val_loss: 1.1413 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03977: val_loss did not improve from 0.41973\n",
      "Epoch 3978/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9027 - val_loss: 1.1510 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03978: val_loss did not improve from 0.41973\n",
      "Epoch 3979/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9027 - val_loss: 1.1533 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03979: val_loss did not improve from 0.41973\n",
      "Epoch 3980/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.8988 - val_loss: 1.1627 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03980: val_loss did not improve from 0.41973\n",
      "Epoch 3981/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9001 - val_loss: 1.1812 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03981: val_loss did not improve from 0.41973\n",
      "Epoch 3982/4000\n",
      "25/25 - 0s - loss: 0.2001 - accuracy: 0.8988 - val_loss: 1.1709 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03982: val_loss did not improve from 0.41973\n",
      "Epoch 3983/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9001 - val_loss: 1.1755 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03983: val_loss did not improve from 0.41973\n",
      "Epoch 3984/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9014 - val_loss: 1.1818 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03984: val_loss did not improve from 0.41973\n",
      "Epoch 3985/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.8988 - val_loss: 1.1840 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03985: val_loss did not improve from 0.41973\n",
      "Epoch 3986/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.1955 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03986: val_loss did not improve from 0.41973\n",
      "Epoch 3987/4000\n",
      "25/25 - 0s - loss: 0.2003 - accuracy: 0.9027 - val_loss: 1.1894 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03987: val_loss did not improve from 0.41973\n",
      "Epoch 3988/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.8988 - val_loss: 1.2016 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03988: val_loss did not improve from 0.41973\n",
      "Epoch 3989/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.1960 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03989: val_loss did not improve from 0.41973\n",
      "Epoch 3990/4000\n",
      "25/25 - 0s - loss: 0.2006 - accuracy: 0.9027 - val_loss: 1.1897 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03990: val_loss did not improve from 0.41973\n",
      "Epoch 3991/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.9014 - val_loss: 1.2275 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03991: val_loss did not improve from 0.41973\n",
      "Epoch 3992/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9001 - val_loss: 1.2054 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03992: val_loss did not improve from 0.41973\n",
      "Epoch 3993/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9014 - val_loss: 1.1900 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03993: val_loss did not improve from 0.41973\n",
      "Epoch 3994/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9027 - val_loss: 1.2097 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03994: val_loss did not improve from 0.41973\n",
      "Epoch 3995/4000\n",
      "25/25 - 0s - loss: 0.2008 - accuracy: 0.8988 - val_loss: 1.2128 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03995: val_loss did not improve from 0.41973\n",
      "Epoch 3996/4000\n",
      "25/25 - 0s - loss: 0.2007 - accuracy: 0.9001 - val_loss: 1.2161 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03996: val_loss did not improve from 0.41973\n",
      "Epoch 3997/4000\n",
      "25/25 - 0s - loss: 0.2005 - accuracy: 0.9027 - val_loss: 1.1742 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03997: val_loss did not improve from 0.41973\n",
      "Epoch 3998/4000\n",
      "25/25 - 0s - loss: 0.2004 - accuracy: 0.9040 - val_loss: 1.1464 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03998: val_loss did not improve from 0.41973\n",
      "Epoch 3999/4000\n",
      "25/25 - 0s - loss: 0.2011 - accuracy: 0.8975 - val_loss: 1.1557 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03999: val_loss did not improve from 0.41973\n",
      "Epoch 4000/4000\n",
      "25/25 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 1.1681 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 04000: val_loss did not improve from 0.41973\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 32)                1024      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 8,547\n",
      "Trainable params: 8,547\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([      \n",
    "      tf.keras.layers.Dense(32, activation='relu'),\n",
    "      tf.keras.layers.Dense(32, activation='relu'),\n",
    "       tf.keras.layers.Dense(64, activation='relu'),\n",
    "      tf.keras.layers.Dense(64, activation='relu'),\n",
    "      tf.keras.layers.Dense(3)\n",
    "    ])\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "metrics = ['accuracy']\n",
    "model_filename = 'models/model_4L_v1'\n",
    "model_l_v_e_filename = 'loss_vs_epochs_images/model_4L_v1_le.png'\n",
    "model_l_v_e_title = 'model_4L_v1'\n",
    "model_history_filename = 'history/history_model_4L_v1'\n",
    "\n",
    "model.compile(optimizer, loss_fn, metrics)\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(model_filename, monitor='val_loss', verbose=1,save_best_only=True, mode='min')\n",
    "model.fit(X_train, y_train, epochs = 4000,  validation_data=(X_test, y_test),batch_size = batch_size,callbacks=[checkpoint], verbose=2)\n",
    "model.summary()\n",
    "graph_loss_vs_epochs(model.history, model_l_v_e_filename, model_l_v_e_title)\n",
    "save_history(model_history_filename, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:\n",
      "7/7 [==============================] - 1s 5ms/step - loss: 0.4197 - accuracy: 0.8187\n",
      "\n",
      "Test accuracy: 81.9%, test loss: 0.419727\n"
     ]
    }
   ],
   "source": [
    "best_m4L_v1 = load_model(model_filename)\n",
    "evaluate_model(best_m4L_v1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241\n"
     ]
    }
   ],
   "source": [
    "test_ds_filename = '../test-ds.csv'\n",
    "output_filename_test_ds_labeled = 'test-ds-m4L_v1.csv'\n",
    "fill_test_ds_labels(model, test_ds_filename, output_filename_test_ds_labeled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: V2\n",
    "#### Model 4 consists in 4 hidden Dense layers:\n",
    "    learning_rate = 0.01\n",
    "    batch_size = 32\n",
    "    loss_fn = CategoricalCrossentropy\n",
    "    optimizer = Adam\n",
    "    Hidden layers:\n",
    "        1. units = 32, activation = relu\n",
    "        2. units = 32, activation = relu\n",
    "        3. units = 64, activation = relu\n",
    "        4. units = 64, activation = relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4000\n",
      "25/25 - 3s - loss: 0.8374 - accuracy: 0.5875 - val_loss: 0.7601 - val_accuracy: 0.6839\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.76014, saving model to models\\model_4L_v2\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v2\\assets\n",
      "Epoch 2/4000\n",
      "25/25 - 0s - loss: 0.6892 - accuracy: 0.6848 - val_loss: 0.6124 - val_accuracy: 0.7565\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.76014 to 0.61238, saving model to models\\model_4L_v2\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v2\\assets\n",
      "Epoch 3/4000\n",
      "25/25 - 0s - loss: 0.6433 - accuracy: 0.7121 - val_loss: 0.6857 - val_accuracy: 0.6736\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.61238\n",
      "Epoch 4/4000\n",
      "25/25 - 0s - loss: 0.5784 - accuracy: 0.7341 - val_loss: 0.6130 - val_accuracy: 0.7409\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.61238\n",
      "Epoch 5/4000\n",
      "25/25 - 0s - loss: 0.5329 - accuracy: 0.7601 - val_loss: 0.5286 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.61238 to 0.52862, saving model to models\\model_4L_v2\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v2\\assets\n",
      "Epoch 6/4000\n",
      "25/25 - 0s - loss: 0.4578 - accuracy: 0.7912 - val_loss: 0.5692 - val_accuracy: 0.7306\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.52862\n",
      "Epoch 7/4000\n",
      "25/25 - 0s - loss: 0.4537 - accuracy: 0.7951 - val_loss: 0.4838 - val_accuracy: 0.7772\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.52862 to 0.48378, saving model to models\\model_4L_v2\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v2\\assets\n",
      "Epoch 8/4000\n",
      "25/25 - 0s - loss: 0.3913 - accuracy: 0.8314 - val_loss: 0.5335 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.48378\n",
      "Epoch 9/4000\n",
      "25/25 - 0s - loss: 0.3994 - accuracy: 0.8249 - val_loss: 0.4681 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.48378 to 0.46811, saving model to models\\model_4L_v2\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v2\\assets\n",
      "Epoch 10/4000\n",
      "25/25 - 0s - loss: 0.3480 - accuracy: 0.8495 - val_loss: 0.6339 - val_accuracy: 0.7047\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.46811\n",
      "Epoch 11/4000\n",
      "25/25 - 0s - loss: 0.3452 - accuracy: 0.8379 - val_loss: 0.4323 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.46811 to 0.43232, saving model to models\\model_4L_v2\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v2\\assets\n",
      "Epoch 12/4000\n",
      "25/25 - 0s - loss: 0.3633 - accuracy: 0.8470 - val_loss: 0.4846 - val_accuracy: 0.7772\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.43232\n",
      "Epoch 13/4000\n",
      "25/25 - 0s - loss: 0.3421 - accuracy: 0.8392 - val_loss: 0.4098 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.43232 to 0.40981, saving model to models\\model_4L_v2\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v2\\assets\n",
      "Epoch 14/4000\n",
      "25/25 - 0s - loss: 0.3348 - accuracy: 0.8534 - val_loss: 0.4008 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.40981 to 0.40080, saving model to models\\model_4L_v2\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v2\\assets\n",
      "Epoch 15/4000\n",
      "25/25 - 0s - loss: 0.3331 - accuracy: 0.8612 - val_loss: 0.4129 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.40080\n",
      "Epoch 16/4000\n",
      "25/25 - 0s - loss: 0.3275 - accuracy: 0.8664 - val_loss: 0.3783 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.40080 to 0.37829, saving model to models\\model_4L_v2\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v2\\assets\n",
      "Epoch 17/4000\n",
      "25/25 - 0s - loss: 0.3127 - accuracy: 0.8677 - val_loss: 0.4021 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.37829\n",
      "Epoch 18/4000\n",
      "25/25 - 0s - loss: 0.3249 - accuracy: 0.8534 - val_loss: 0.4422 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.37829\n",
      "Epoch 19/4000\n",
      "25/25 - 0s - loss: 0.2897 - accuracy: 0.8703 - val_loss: 0.3715 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.37829 to 0.37150, saving model to models\\model_4L_v2\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v2\\assets\n",
      "Epoch 20/4000\n",
      "25/25 - 0s - loss: 0.2756 - accuracy: 0.8729 - val_loss: 0.4760 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.37150\n",
      "Epoch 21/4000\n",
      "25/25 - 0s - loss: 0.2698 - accuracy: 0.8833 - val_loss: 0.4206 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.37150\n",
      "Epoch 22/4000\n",
      "25/25 - 0s - loss: 0.2668 - accuracy: 0.8846 - val_loss: 0.3648 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.37150 to 0.36483, saving model to models\\model_4L_v2\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v2\\assets\n",
      "Epoch 23/4000\n",
      "25/25 - 0s - loss: 0.2497 - accuracy: 0.8833 - val_loss: 0.3359 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.36483 to 0.33590, saving model to models\\model_4L_v2\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v2\\assets\n",
      "Epoch 24/4000\n",
      "25/25 - 0s - loss: 0.2494 - accuracy: 0.8820 - val_loss: 0.3682 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.33590\n",
      "Epoch 25/4000\n",
      "25/25 - 0s - loss: 0.2739 - accuracy: 0.8716 - val_loss: 0.4379 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.33590\n",
      "Epoch 26/4000\n",
      "25/25 - 0s - loss: 0.2684 - accuracy: 0.8781 - val_loss: 0.4083 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.33590\n",
      "Epoch 27/4000\n",
      "25/25 - 0s - loss: 0.2421 - accuracy: 0.8859 - val_loss: 0.4072 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.33590\n",
      "Epoch 28/4000\n",
      "25/25 - 0s - loss: 0.2428 - accuracy: 0.8859 - val_loss: 0.3632 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.33590\n",
      "Epoch 29/4000\n",
      "25/25 - 0s - loss: 0.2859 - accuracy: 0.8716 - val_loss: 0.4668 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.33590\n",
      "Epoch 30/4000\n",
      "25/25 - 0s - loss: 0.3964 - accuracy: 0.8690 - val_loss: 0.5507 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.33590\n",
      "Epoch 31/4000\n",
      "25/25 - 0s - loss: 0.3348 - accuracy: 0.8534 - val_loss: 0.3882 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.33590\n",
      "Epoch 32/4000\n",
      "25/25 - 0s - loss: 0.3079 - accuracy: 0.8586 - val_loss: 0.4874 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.33590\n",
      "Epoch 33/4000\n",
      "25/25 - 0s - loss: 0.2911 - accuracy: 0.8781 - val_loss: 0.3764 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.33590\n",
      "Epoch 34/4000\n",
      "25/25 - 0s - loss: 0.2962 - accuracy: 0.8560 - val_loss: 0.3731 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.33590\n",
      "Epoch 35/4000\n",
      "25/25 - 0s - loss: 0.2873 - accuracy: 0.8690 - val_loss: 0.3530 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.33590\n",
      "Epoch 36/4000\n",
      "25/25 - 0s - loss: 0.2806 - accuracy: 0.8768 - val_loss: 0.3962 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.33590\n",
      "Epoch 37/4000\n",
      "25/25 - 0s - loss: 0.2750 - accuracy: 0.8833 - val_loss: 0.3728 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.33590\n",
      "Epoch 38/4000\n",
      "25/25 - 0s - loss: 0.2779 - accuracy: 0.8846 - val_loss: 0.4014 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.33590\n",
      "Epoch 39/4000\n",
      "25/25 - 0s - loss: 0.2516 - accuracy: 0.8911 - val_loss: 0.4077 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.33590\n",
      "Epoch 40/4000\n",
      "25/25 - 0s - loss: 0.2405 - accuracy: 0.8846 - val_loss: 0.3770 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.33590\n",
      "Epoch 41/4000\n",
      "25/25 - 0s - loss: 0.2305 - accuracy: 0.8975 - val_loss: 0.3984 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.33590\n",
      "Epoch 42/4000\n",
      "25/25 - 0s - loss: 0.2272 - accuracy: 0.8923 - val_loss: 0.4036 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.33590\n",
      "Epoch 43/4000\n",
      "25/25 - 0s - loss: 0.2428 - accuracy: 0.8962 - val_loss: 0.3728 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.33590\n",
      "Epoch 44/4000\n",
      "25/25 - 0s - loss: 0.2338 - accuracy: 0.8898 - val_loss: 0.4495 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.33590\n",
      "Epoch 45/4000\n",
      "25/25 - 0s - loss: 0.2437 - accuracy: 0.8820 - val_loss: 0.4494 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.33590\n",
      "Epoch 46/4000\n",
      "25/25 - 0s - loss: 0.2492 - accuracy: 0.8898 - val_loss: 0.3807 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.33590\n",
      "Epoch 47/4000\n",
      "25/25 - 0s - loss: 0.2371 - accuracy: 0.8936 - val_loss: 0.4563 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.33590\n",
      "Epoch 48/4000\n",
      "25/25 - 0s - loss: 0.2431 - accuracy: 0.8911 - val_loss: 0.4308 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.33590\n",
      "Epoch 49/4000\n",
      "25/25 - 0s - loss: 0.2386 - accuracy: 0.8820 - val_loss: 0.5487 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.33590\n",
      "Epoch 50/4000\n",
      "25/25 - 0s - loss: 0.2243 - accuracy: 0.8846 - val_loss: 0.5208 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.33590\n",
      "Epoch 51/4000\n",
      "25/25 - 0s - loss: 0.2435 - accuracy: 0.8949 - val_loss: 0.5796 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.33590\n",
      "Epoch 52/4000\n",
      "25/25 - 0s - loss: 0.2470 - accuracy: 0.8923 - val_loss: 0.4834 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.33590\n",
      "Epoch 53/4000\n",
      "25/25 - 0s - loss: 0.2286 - accuracy: 0.8962 - val_loss: 0.4683 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.33590\n",
      "Epoch 54/4000\n",
      "25/25 - 0s - loss: 0.2186 - accuracy: 0.8949 - val_loss: 0.5014 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.33590\n",
      "Epoch 55/4000\n",
      "25/25 - 0s - loss: 0.2145 - accuracy: 0.9014 - val_loss: 0.5184 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.33590\n",
      "Epoch 56/4000\n",
      "25/25 - 0s - loss: 0.2210 - accuracy: 0.8962 - val_loss: 0.4738 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.33590\n",
      "Epoch 57/4000\n",
      "25/25 - 0s - loss: 0.2153 - accuracy: 0.8923 - val_loss: 0.5222 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.33590\n",
      "Epoch 58/4000\n",
      "25/25 - 0s - loss: 0.2134 - accuracy: 0.9014 - val_loss: 0.5834 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33590\n",
      "Epoch 59/4000\n",
      "25/25 - 0s - loss: 0.2218 - accuracy: 0.8975 - val_loss: 0.4939 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.33590\n",
      "Epoch 60/4000\n",
      "25/25 - 0s - loss: 0.2379 - accuracy: 0.8768 - val_loss: 0.5710 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.33590\n",
      "Epoch 61/4000\n",
      "25/25 - 0s - loss: 0.2167 - accuracy: 0.8898 - val_loss: 0.5827 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.33590\n",
      "Epoch 62/4000\n",
      "25/25 - 0s - loss: 0.2283 - accuracy: 0.8911 - val_loss: 0.4680 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33590\n",
      "Epoch 63/4000\n",
      "25/25 - 0s - loss: 0.2155 - accuracy: 0.8949 - val_loss: 0.5927 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.33590\n",
      "Epoch 64/4000\n",
      "25/25 - 0s - loss: 0.2323 - accuracy: 0.8872 - val_loss: 0.4253 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33590\n",
      "Epoch 65/4000\n",
      "25/25 - 0s - loss: 0.2244 - accuracy: 0.8988 - val_loss: 0.4699 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33590\n",
      "Epoch 66/4000\n",
      "25/25 - 0s - loss: 0.2148 - accuracy: 0.8975 - val_loss: 0.5419 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33590\n",
      "Epoch 67/4000\n",
      "25/25 - 0s - loss: 0.2144 - accuracy: 0.8975 - val_loss: 0.5308 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33590\n",
      "Epoch 68/4000\n",
      "25/25 - 0s - loss: 0.2135 - accuracy: 0.8988 - val_loss: 0.5631 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33590\n",
      "Epoch 69/4000\n",
      "25/25 - 0s - loss: 0.2162 - accuracy: 0.8975 - val_loss: 0.6123 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33590\n",
      "Epoch 70/4000\n",
      "25/25 - 0s - loss: 0.2154 - accuracy: 0.9027 - val_loss: 0.6818 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33590\n",
      "Epoch 71/4000\n",
      "25/25 - 0s - loss: 0.2185 - accuracy: 0.8975 - val_loss: 0.5416 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33590\n",
      "Epoch 72/4000\n",
      "25/25 - 0s - loss: 0.2201 - accuracy: 0.8872 - val_loss: 0.5911 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33590\n",
      "Epoch 73/4000\n",
      "25/25 - 0s - loss: 0.2281 - accuracy: 0.8846 - val_loss: 0.5695 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33590\n",
      "Epoch 74/4000\n",
      "25/25 - 0s - loss: 0.2308 - accuracy: 0.8911 - val_loss: 0.5530 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33590\n",
      "Epoch 75/4000\n",
      "25/25 - 0s - loss: 0.2211 - accuracy: 0.8949 - val_loss: 0.5887 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33590\n",
      "Epoch 76/4000\n",
      "25/25 - 0s - loss: 0.2138 - accuracy: 0.8923 - val_loss: 0.5850 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33590\n",
      "Epoch 77/4000\n",
      "25/25 - 0s - loss: 0.2164 - accuracy: 0.8911 - val_loss: 0.5499 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33590\n",
      "Epoch 78/4000\n",
      "25/25 - 0s - loss: 0.2168 - accuracy: 0.9014 - val_loss: 0.5666 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33590\n",
      "Epoch 79/4000\n",
      "25/25 - 0s - loss: 0.3300 - accuracy: 0.8729 - val_loss: 0.6525 - val_accuracy: 0.7306\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33590\n",
      "Epoch 80/4000\n",
      "25/25 - 0s - loss: 0.4415 - accuracy: 0.8042 - val_loss: 0.6144 - val_accuracy: 0.7565\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33590\n",
      "Epoch 81/4000\n",
      "25/25 - 0s - loss: 0.3577 - accuracy: 0.8547 - val_loss: 0.6118 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33590\n",
      "Epoch 82/4000\n",
      "25/25 - 0s - loss: 0.2991 - accuracy: 0.8729 - val_loss: 0.5553 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33590\n",
      "Epoch 83/4000\n",
      "25/25 - 0s - loss: 0.2848 - accuracy: 0.8859 - val_loss: 0.6251 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33590\n",
      "Epoch 84/4000\n",
      "25/25 - 0s - loss: 0.3293 - accuracy: 0.8651 - val_loss: 0.5036 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33590\n",
      "Epoch 85/4000\n",
      "25/25 - 0s - loss: 0.2691 - accuracy: 0.8885 - val_loss: 0.5119 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33590\n",
      "Epoch 86/4000\n",
      "25/25 - 0s - loss: 0.2463 - accuracy: 0.8859 - val_loss: 0.5604 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33590\n",
      "Epoch 87/4000\n",
      "25/25 - 0s - loss: 0.2307 - accuracy: 0.8923 - val_loss: 0.5139 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33590\n",
      "Epoch 88/4000\n",
      "25/25 - 0s - loss: 0.2303 - accuracy: 0.8949 - val_loss: 0.5585 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.33590\n",
      "Epoch 89/4000\n",
      "25/25 - 0s - loss: 0.2185 - accuracy: 0.8949 - val_loss: 0.5754 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33590\n",
      "Epoch 90/4000\n",
      "25/25 - 0s - loss: 0.2279 - accuracy: 0.8911 - val_loss: 0.4999 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33590\n",
      "Epoch 91/4000\n",
      "25/25 - 0s - loss: 0.2226 - accuracy: 0.8949 - val_loss: 0.5867 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33590\n",
      "Epoch 92/4000\n",
      "25/25 - 0s - loss: 0.2248 - accuracy: 0.8859 - val_loss: 0.5430 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33590\n",
      "Epoch 93/4000\n",
      "25/25 - 0s - loss: 0.2138 - accuracy: 0.8975 - val_loss: 0.5927 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33590\n",
      "Epoch 94/4000\n",
      "25/25 - 0s - loss: 0.2227 - accuracy: 0.8988 - val_loss: 0.5252 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33590\n",
      "Epoch 95/4000\n",
      "25/25 - 0s - loss: 0.2206 - accuracy: 0.8962 - val_loss: 0.5078 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33590\n",
      "Epoch 96/4000\n",
      "25/25 - 0s - loss: 0.2262 - accuracy: 0.8885 - val_loss: 0.5481 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33590\n",
      "Epoch 97/4000\n",
      "25/25 - 0s - loss: 0.2182 - accuracy: 0.8975 - val_loss: 0.4805 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33590\n",
      "Epoch 98/4000\n",
      "25/25 - 0s - loss: 0.2468 - accuracy: 0.8923 - val_loss: 0.4512 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33590\n",
      "Epoch 99/4000\n",
      "25/25 - 0s - loss: 0.2322 - accuracy: 0.8923 - val_loss: 0.4949 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33590\n",
      "Epoch 100/4000\n",
      "25/25 - 0s - loss: 0.2290 - accuracy: 0.8820 - val_loss: 0.5338 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33590\n",
      "Epoch 101/4000\n",
      "25/25 - 0s - loss: 0.2218 - accuracy: 0.9014 - val_loss: 0.5214 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.33590\n",
      "Epoch 102/4000\n",
      "25/25 - 0s - loss: 0.2219 - accuracy: 0.8872 - val_loss: 0.5683 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.33590\n",
      "Epoch 103/4000\n",
      "25/25 - 0s - loss: 0.2305 - accuracy: 0.8781 - val_loss: 0.4521 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.33590\n",
      "Epoch 104/4000\n",
      "25/25 - 0s - loss: 0.2218 - accuracy: 0.8846 - val_loss: 0.4716 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.33590\n",
      "Epoch 105/4000\n",
      "25/25 - 0s - loss: 0.2244 - accuracy: 0.8898 - val_loss: 0.5507 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.33590\n",
      "Epoch 106/4000\n",
      "25/25 - 0s - loss: 0.2570 - accuracy: 0.8911 - val_loss: 0.4841 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.33590\n",
      "Epoch 107/4000\n",
      "25/25 - 0s - loss: 0.2570 - accuracy: 0.8898 - val_loss: 0.4668 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.33590\n",
      "Epoch 108/4000\n",
      "25/25 - 0s - loss: 0.2547 - accuracy: 0.8859 - val_loss: 0.4352 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.33590\n",
      "Epoch 109/4000\n",
      "25/25 - 0s - loss: 0.2199 - accuracy: 0.8936 - val_loss: 0.4447 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.33590\n",
      "Epoch 110/4000\n",
      "25/25 - 0s - loss: 0.2176 - accuracy: 0.8988 - val_loss: 0.4397 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.33590\n",
      "Epoch 111/4000\n",
      "25/25 - 0s - loss: 0.2134 - accuracy: 0.8962 - val_loss: 0.4596 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.33590\n",
      "Epoch 112/4000\n",
      "25/25 - 0s - loss: 0.2155 - accuracy: 0.9014 - val_loss: 0.4786 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.33590\n",
      "Epoch 113/4000\n",
      "25/25 - 0s - loss: 0.2106 - accuracy: 0.8962 - val_loss: 0.4639 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.33590\n",
      "Epoch 114/4000\n",
      "25/25 - 0s - loss: 0.2110 - accuracy: 0.8962 - val_loss: 0.4938 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.33590\n",
      "Epoch 115/4000\n",
      "25/25 - 0s - loss: 0.2121 - accuracy: 0.8988 - val_loss: 0.5345 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.33590\n",
      "Epoch 116/4000\n",
      "25/25 - 0s - loss: 0.2139 - accuracy: 0.8988 - val_loss: 0.5054 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.33590\n",
      "Epoch 117/4000\n",
      "25/25 - 0s - loss: 0.2095 - accuracy: 0.8949 - val_loss: 0.5625 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.33590\n",
      "Epoch 118/4000\n",
      "25/25 - 0s - loss: 0.2110 - accuracy: 0.8988 - val_loss: 0.4962 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.33590\n",
      "Epoch 119/4000\n",
      "25/25 - 0s - loss: 0.2105 - accuracy: 0.8949 - val_loss: 0.5283 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.33590\n",
      "Epoch 120/4000\n",
      "25/25 - 0s - loss: 0.2060 - accuracy: 0.8988 - val_loss: 0.5356 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.33590\n",
      "Epoch 121/4000\n",
      "25/25 - 0s - loss: 0.2075 - accuracy: 0.9027 - val_loss: 0.5171 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.33590\n",
      "Epoch 122/4000\n",
      "25/25 - 0s - loss: 0.2079 - accuracy: 0.8962 - val_loss: 0.5196 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.33590\n",
      "Epoch 123/4000\n",
      "25/25 - 0s - loss: 0.2192 - accuracy: 0.8975 - val_loss: 0.5208 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.33590\n",
      "Epoch 124/4000\n",
      "25/25 - 0s - loss: 0.2187 - accuracy: 0.9027 - val_loss: 0.4789 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.33590\n",
      "Epoch 125/4000\n",
      "25/25 - 0s - loss: 0.2157 - accuracy: 0.9014 - val_loss: 0.5086 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.33590\n",
      "Epoch 126/4000\n",
      "25/25 - 0s - loss: 0.2139 - accuracy: 0.8962 - val_loss: 0.5089 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.33590\n",
      "Epoch 127/4000\n",
      "25/25 - 0s - loss: 0.2078 - accuracy: 0.9027 - val_loss: 0.5228 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.33590\n",
      "Epoch 128/4000\n",
      "25/25 - 0s - loss: 0.2074 - accuracy: 0.8975 - val_loss: 0.5328 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.33590\n",
      "Epoch 129/4000\n",
      "25/25 - 0s - loss: 0.2167 - accuracy: 0.8975 - val_loss: 0.4947 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.33590\n",
      "Epoch 130/4000\n",
      "25/25 - 0s - loss: 0.2163 - accuracy: 0.9001 - val_loss: 0.4845 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.33590\n",
      "Epoch 131/4000\n",
      "25/25 - 0s - loss: 0.2279 - accuracy: 0.8962 - val_loss: 0.5364 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.33590\n",
      "Epoch 132/4000\n",
      "25/25 - 0s - loss: 0.2217 - accuracy: 0.8962 - val_loss: 0.5196 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.33590\n",
      "Epoch 133/4000\n",
      "25/25 - 0s - loss: 0.2182 - accuracy: 0.9001 - val_loss: 0.5686 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.33590\n",
      "Epoch 134/4000\n",
      "25/25 - 0s - loss: 0.2174 - accuracy: 0.9014 - val_loss: 0.5398 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.33590\n",
      "Epoch 135/4000\n",
      "25/25 - 0s - loss: 0.2095 - accuracy: 0.9014 - val_loss: 0.5356 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.33590\n",
      "Epoch 136/4000\n",
      "25/25 - 0s - loss: 0.2129 - accuracy: 0.8962 - val_loss: 0.5274 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.33590\n",
      "Epoch 137/4000\n",
      "25/25 - 0s - loss: 0.2224 - accuracy: 0.8988 - val_loss: 0.5783 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.33590\n",
      "Epoch 138/4000\n",
      "25/25 - 0s - loss: 0.2354 - accuracy: 0.8923 - val_loss: 0.7021 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.33590\n",
      "Epoch 139/4000\n",
      "25/25 - 0s - loss: 0.2336 - accuracy: 0.8936 - val_loss: 0.5279 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.33590\n",
      "Epoch 140/4000\n",
      "25/25 - 0s - loss: 0.2329 - accuracy: 0.8975 - val_loss: 0.5219 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.33590\n",
      "Epoch 141/4000\n",
      "25/25 - 0s - loss: 0.2618 - accuracy: 0.8794 - val_loss: 0.4484 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.33590\n",
      "Epoch 142/4000\n",
      "25/25 - 0s - loss: 0.2817 - accuracy: 0.8872 - val_loss: 0.4338 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.33590\n",
      "Epoch 143/4000\n",
      "25/25 - 0s - loss: 0.2813 - accuracy: 0.8807 - val_loss: 0.3286 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.33590 to 0.32861, saving model to models\\model_4L_v2\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v2\\assets\n",
      "Epoch 144/4000\n",
      "25/25 - 0s - loss: 0.3546 - accuracy: 0.8651 - val_loss: 0.4174 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.32861\n",
      "Epoch 145/4000\n",
      "25/25 - 0s - loss: 0.4877 - accuracy: 0.8379 - val_loss: 0.4694 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.32861\n",
      "Epoch 146/4000\n",
      "25/25 - 0s - loss: 0.3082 - accuracy: 0.8664 - val_loss: 0.5107 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.32861\n",
      "Epoch 147/4000\n",
      "25/25 - 0s - loss: 0.4153 - accuracy: 0.8470 - val_loss: 0.4438 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.32861\n",
      "Epoch 148/4000\n",
      "25/25 - 0s - loss: 0.3638 - accuracy: 0.8495 - val_loss: 0.5587 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.32861\n",
      "Epoch 149/4000\n",
      "25/25 - 0s - loss: 0.3611 - accuracy: 0.8534 - val_loss: 0.4490 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.32861\n",
      "Epoch 150/4000\n",
      "25/25 - 0s - loss: 0.3371 - accuracy: 0.8534 - val_loss: 0.5030 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.32861\n",
      "Epoch 151/4000\n",
      "25/25 - 0s - loss: 0.2755 - accuracy: 0.8729 - val_loss: 0.4407 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.32861\n",
      "Epoch 152/4000\n",
      "25/25 - 0s - loss: 0.2604 - accuracy: 0.8833 - val_loss: 0.4656 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.32861\n",
      "Epoch 153/4000\n",
      "25/25 - 0s - loss: 0.2554 - accuracy: 0.8833 - val_loss: 0.4204 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.32861\n",
      "Epoch 154/4000\n",
      "25/25 - 0s - loss: 0.2447 - accuracy: 0.8898 - val_loss: 0.4912 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.32861\n",
      "Epoch 155/4000\n",
      "25/25 - 0s - loss: 0.2586 - accuracy: 0.8820 - val_loss: 0.4689 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.32861\n",
      "Epoch 156/4000\n",
      "25/25 - 0s - loss: 0.2477 - accuracy: 0.8755 - val_loss: 0.4807 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.32861\n",
      "Epoch 157/4000\n",
      "25/25 - 0s - loss: 0.2532 - accuracy: 0.8820 - val_loss: 0.4551 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.32861\n",
      "Epoch 158/4000\n",
      "25/25 - 0s - loss: 0.2652 - accuracy: 0.8923 - val_loss: 0.3929 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.32861\n",
      "Epoch 159/4000\n",
      "25/25 - 0s - loss: 0.2452 - accuracy: 0.8833 - val_loss: 0.3917 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.32861\n",
      "Epoch 160/4000\n",
      "25/25 - 0s - loss: 0.2331 - accuracy: 0.8859 - val_loss: 0.4638 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.32861\n",
      "Epoch 161/4000\n",
      "25/25 - 0s - loss: 0.2278 - accuracy: 0.8949 - val_loss: 0.5230 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.32861\n",
      "Epoch 162/4000\n",
      "25/25 - 0s - loss: 0.2349 - accuracy: 0.8833 - val_loss: 0.5559 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.32861\n",
      "Epoch 163/4000\n",
      "25/25 - 0s - loss: 0.2226 - accuracy: 0.8885 - val_loss: 0.5617 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.32861\n",
      "Epoch 164/4000\n",
      "25/25 - 0s - loss: 0.2197 - accuracy: 0.8911 - val_loss: 0.5427 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.32861\n",
      "Epoch 165/4000\n",
      "25/25 - 0s - loss: 0.2166 - accuracy: 0.8949 - val_loss: 0.5413 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.32861\n",
      "Epoch 166/4000\n",
      "25/25 - 0s - loss: 0.2132 - accuracy: 0.9027 - val_loss: 0.5375 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.32861\n",
      "Epoch 167/4000\n",
      "25/25 - 0s - loss: 0.2169 - accuracy: 0.8962 - val_loss: 0.5276 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.32861\n",
      "Epoch 168/4000\n",
      "25/25 - 0s - loss: 0.2123 - accuracy: 0.8962 - val_loss: 0.5336 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.32861\n",
      "Epoch 169/4000\n",
      "25/25 - 0s - loss: 0.2139 - accuracy: 0.8962 - val_loss: 0.5578 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.32861\n",
      "Epoch 170/4000\n",
      "25/25 - 0s - loss: 0.2121 - accuracy: 0.8962 - val_loss: 0.5918 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.32861\n",
      "Epoch 171/4000\n",
      "25/25 - 0s - loss: 0.2120 - accuracy: 0.9014 - val_loss: 0.5758 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.32861\n",
      "Epoch 172/4000\n",
      "25/25 - 0s - loss: 0.2199 - accuracy: 0.8962 - val_loss: 0.5807 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.32861\n",
      "Epoch 173/4000\n",
      "25/25 - 0s - loss: 0.2175 - accuracy: 0.8988 - val_loss: 0.6139 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.32861\n",
      "Epoch 174/4000\n",
      "25/25 - 0s - loss: 0.2145 - accuracy: 0.8988 - val_loss: 0.6398 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.32861\n",
      "Epoch 175/4000\n",
      "25/25 - 0s - loss: 0.2122 - accuracy: 0.9027 - val_loss: 0.5738 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.32861\n",
      "Epoch 176/4000\n",
      "25/25 - 0s - loss: 0.2075 - accuracy: 0.9001 - val_loss: 0.6200 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.32861\n",
      "Epoch 177/4000\n",
      "25/25 - 0s - loss: 0.2101 - accuracy: 0.8975 - val_loss: 0.6567 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.32861\n",
      "Epoch 178/4000\n",
      "25/25 - 0s - loss: 0.2070 - accuracy: 0.9027 - val_loss: 0.6634 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.32861\n",
      "Epoch 179/4000\n",
      "25/25 - 0s - loss: 0.2106 - accuracy: 0.8975 - val_loss: 0.6722 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.32861\n",
      "Epoch 180/4000\n",
      "25/25 - 0s - loss: 0.2239 - accuracy: 0.8949 - val_loss: 0.5285 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.32861\n",
      "Epoch 181/4000\n",
      "25/25 - 0s - loss: 0.2372 - accuracy: 0.8859 - val_loss: 0.4947 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.32861\n",
      "Epoch 182/4000\n",
      "25/25 - 0s - loss: 0.2314 - accuracy: 0.8872 - val_loss: 0.5771 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.32861\n",
      "Epoch 183/4000\n",
      "25/25 - 0s - loss: 0.2549 - accuracy: 0.8859 - val_loss: 0.4586 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.32861\n",
      "Epoch 184/4000\n",
      "25/25 - 0s - loss: 0.2522 - accuracy: 0.8742 - val_loss: 0.6265 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.32861\n",
      "Epoch 185/4000\n",
      "25/25 - 0s - loss: 0.2358 - accuracy: 0.8846 - val_loss: 0.4740 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.32861\n",
      "Epoch 186/4000\n",
      "25/25 - 0s - loss: 0.2272 - accuracy: 0.8885 - val_loss: 0.5994 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.32861\n",
      "Epoch 187/4000\n",
      "25/25 - 0s - loss: 0.2264 - accuracy: 0.8846 - val_loss: 0.5763 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.32861\n",
      "Epoch 188/4000\n",
      "25/25 - 0s - loss: 0.2195 - accuracy: 0.8833 - val_loss: 0.6005 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.32861\n",
      "Epoch 189/4000\n",
      "25/25 - 0s - loss: 0.2253 - accuracy: 0.8820 - val_loss: 0.6328 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.32861\n",
      "Epoch 190/4000\n",
      "25/25 - 0s - loss: 0.2296 - accuracy: 0.8923 - val_loss: 0.6061 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.32861\n",
      "Epoch 191/4000\n",
      "25/25 - 0s - loss: 0.2516 - accuracy: 0.8898 - val_loss: 0.8365 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.32861\n",
      "Epoch 192/4000\n",
      "25/25 - 0s - loss: 0.3268 - accuracy: 0.8444 - val_loss: 1.0788 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.32861\n",
      "Epoch 193/4000\n",
      "25/25 - 0s - loss: 0.3916 - accuracy: 0.8457 - val_loss: 0.7242 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.32861\n",
      "Epoch 194/4000\n",
      "25/25 - 0s - loss: 0.3303 - accuracy: 0.8353 - val_loss: 1.1122 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.32861\n",
      "Epoch 195/4000\n",
      "25/25 - 0s - loss: 0.3846 - accuracy: 0.8392 - val_loss: 0.7261 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.32861\n",
      "Epoch 196/4000\n",
      "25/25 - 0s - loss: 0.2783 - accuracy: 0.8638 - val_loss: 0.6754 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.32861\n",
      "Epoch 197/4000\n",
      "25/25 - 0s - loss: 0.2731 - accuracy: 0.8677 - val_loss: 0.6372 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.32861\n",
      "Epoch 198/4000\n",
      "25/25 - 0s - loss: 0.2620 - accuracy: 0.8781 - val_loss: 0.6172 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.32861\n",
      "Epoch 199/4000\n",
      "25/25 - 0s - loss: 0.2419 - accuracy: 0.8898 - val_loss: 0.7065 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.32861\n",
      "Epoch 200/4000\n",
      "25/25 - 0s - loss: 0.2508 - accuracy: 0.8911 - val_loss: 0.5826 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.32861\n",
      "Epoch 201/4000\n",
      "25/25 - 0s - loss: 0.2347 - accuracy: 0.8975 - val_loss: 0.6424 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.32861\n",
      "Epoch 202/4000\n",
      "25/25 - 0s - loss: 0.2373 - accuracy: 0.8911 - val_loss: 0.6189 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.32861\n",
      "Epoch 203/4000\n",
      "25/25 - 0s - loss: 0.2274 - accuracy: 0.9014 - val_loss: 0.7496 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.32861\n",
      "Epoch 204/4000\n",
      "25/25 - 0s - loss: 0.2262 - accuracy: 0.8949 - val_loss: 0.7134 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.32861\n",
      "Epoch 205/4000\n",
      "25/25 - 0s - loss: 0.2263 - accuracy: 0.8988 - val_loss: 0.7630 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.32861\n",
      "Epoch 206/4000\n",
      "25/25 - 0s - loss: 0.2307 - accuracy: 0.8962 - val_loss: 0.7200 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.32861\n",
      "Epoch 207/4000\n",
      "25/25 - 0s - loss: 0.2251 - accuracy: 0.8949 - val_loss: 0.7861 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.32861\n",
      "Epoch 208/4000\n",
      "25/25 - 0s - loss: 0.2146 - accuracy: 0.8962 - val_loss: 0.8495 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.32861\n",
      "Epoch 209/4000\n",
      "25/25 - 0s - loss: 0.2117 - accuracy: 0.8988 - val_loss: 0.8168 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.32861\n",
      "Epoch 210/4000\n",
      "25/25 - 0s - loss: 0.2111 - accuracy: 0.9001 - val_loss: 0.7810 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.32861\n",
      "Epoch 211/4000\n",
      "25/25 - 0s - loss: 0.2479 - accuracy: 0.8742 - val_loss: 0.8400 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.32861\n",
      "Epoch 212/4000\n",
      "25/25 - 0s - loss: 0.2213 - accuracy: 0.8923 - val_loss: 1.0011 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.32861\n",
      "Epoch 213/4000\n",
      "25/25 - 0s - loss: 0.2178 - accuracy: 0.8936 - val_loss: 1.0853 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.32861\n",
      "Epoch 214/4000\n",
      "25/25 - 0s - loss: 0.2239 - accuracy: 0.8872 - val_loss: 1.1833 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.32861\n",
      "Epoch 215/4000\n",
      "25/25 - 0s - loss: 0.2291 - accuracy: 0.8885 - val_loss: 1.3652 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.32861\n",
      "Epoch 216/4000\n",
      "25/25 - 0s - loss: 0.2282 - accuracy: 0.8872 - val_loss: 0.9074 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.32861\n",
      "Epoch 217/4000\n",
      "25/25 - 0s - loss: 0.2327 - accuracy: 0.8898 - val_loss: 0.8513 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.32861\n",
      "Epoch 218/4000\n",
      "25/25 - 0s - loss: 0.2224 - accuracy: 0.9001 - val_loss: 0.8553 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.32861\n",
      "Epoch 219/4000\n",
      "25/25 - 0s - loss: 0.2185 - accuracy: 0.8872 - val_loss: 0.9621 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.32861\n",
      "Epoch 220/4000\n",
      "25/25 - 0s - loss: 0.2130 - accuracy: 0.8975 - val_loss: 0.8864 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.32861\n",
      "Epoch 221/4000\n",
      "25/25 - 0s - loss: 0.2203 - accuracy: 0.9001 - val_loss: 0.8834 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.32861\n",
      "Epoch 222/4000\n",
      "25/25 - 0s - loss: 0.2155 - accuracy: 0.8936 - val_loss: 0.9744 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.32861\n",
      "Epoch 223/4000\n",
      "25/25 - 0s - loss: 0.2159 - accuracy: 0.8936 - val_loss: 0.9817 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.32861\n",
      "Epoch 224/4000\n",
      "25/25 - 0s - loss: 0.2125 - accuracy: 0.8988 - val_loss: 1.0125 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.32861\n",
      "Epoch 225/4000\n",
      "25/25 - 0s - loss: 0.2160 - accuracy: 0.9001 - val_loss: 1.0461 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.32861\n",
      "Epoch 226/4000\n",
      "25/25 - 0s - loss: 0.2130 - accuracy: 0.8962 - val_loss: 1.1000 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.32861\n",
      "Epoch 227/4000\n",
      "25/25 - 0s - loss: 0.2075 - accuracy: 0.9027 - val_loss: 1.0651 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.32861\n",
      "Epoch 228/4000\n",
      "25/25 - 0s - loss: 0.2102 - accuracy: 0.8988 - val_loss: 1.1214 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.32861\n",
      "Epoch 229/4000\n",
      "25/25 - 0s - loss: 0.2104 - accuracy: 0.9027 - val_loss: 1.1453 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.32861\n",
      "Epoch 230/4000\n",
      "25/25 - 0s - loss: 0.2107 - accuracy: 0.9027 - val_loss: 1.2238 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.32861\n",
      "Epoch 231/4000\n",
      "25/25 - 0s - loss: 0.2144 - accuracy: 0.9014 - val_loss: 1.2643 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.32861\n",
      "Epoch 232/4000\n",
      "25/25 - 0s - loss: 0.2146 - accuracy: 0.8949 - val_loss: 1.0888 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.32861\n",
      "Epoch 233/4000\n",
      "25/25 - 0s - loss: 0.2112 - accuracy: 0.8923 - val_loss: 1.1999 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.32861\n",
      "Epoch 234/4000\n",
      "25/25 - 0s - loss: 0.2155 - accuracy: 0.8936 - val_loss: 1.0990 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.32861\n",
      "Epoch 235/4000\n",
      "25/25 - 0s - loss: 0.2114 - accuracy: 0.8962 - val_loss: 1.0467 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.32861\n",
      "Epoch 236/4000\n",
      "25/25 - 0s - loss: 0.2140 - accuracy: 0.8975 - val_loss: 1.0196 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.32861\n",
      "Epoch 237/4000\n",
      "25/25 - 0s - loss: 0.2113 - accuracy: 0.9001 - val_loss: 1.1081 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.32861\n",
      "Epoch 238/4000\n",
      "25/25 - 0s - loss: 0.2147 - accuracy: 0.8885 - val_loss: 1.1154 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.32861\n",
      "Epoch 239/4000\n",
      "25/25 - 0s - loss: 0.2089 - accuracy: 0.8988 - val_loss: 1.0450 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.32861\n",
      "Epoch 240/4000\n",
      "25/25 - 0s - loss: 0.2091 - accuracy: 0.9001 - val_loss: 1.1385 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.32861\n",
      "Epoch 241/4000\n",
      "25/25 - 0s - loss: 0.2069 - accuracy: 0.8962 - val_loss: 1.0943 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.32861\n",
      "Epoch 242/4000\n",
      "25/25 - 0s - loss: 0.2052 - accuracy: 0.9001 - val_loss: 1.1486 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.32861\n",
      "Epoch 243/4000\n",
      "25/25 - 0s - loss: 0.2078 - accuracy: 0.8988 - val_loss: 1.1444 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.32861\n",
      "Epoch 244/4000\n",
      "25/25 - 0s - loss: 0.2105 - accuracy: 0.8988 - val_loss: 1.1063 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.32861\n",
      "Epoch 245/4000\n",
      "25/25 - 0s - loss: 0.2095 - accuracy: 0.9001 - val_loss: 1.2502 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.32861\n",
      "Epoch 246/4000\n",
      "25/25 - 0s - loss: 0.2114 - accuracy: 0.8949 - val_loss: 1.0910 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.32861\n",
      "Epoch 247/4000\n",
      "25/25 - 0s - loss: 0.2084 - accuracy: 0.8988 - val_loss: 1.1556 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.32861\n",
      "Epoch 248/4000\n",
      "25/25 - 0s - loss: 0.2052 - accuracy: 0.9014 - val_loss: 1.1451 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.32861\n",
      "Epoch 249/4000\n",
      "25/25 - 0s - loss: 0.2076 - accuracy: 0.8975 - val_loss: 1.1891 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.32861\n",
      "Epoch 250/4000\n",
      "25/25 - 0s - loss: 0.2076 - accuracy: 0.9001 - val_loss: 1.1416 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.32861\n",
      "Epoch 251/4000\n",
      "25/25 - 0s - loss: 0.2057 - accuracy: 0.9001 - val_loss: 1.1543 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.32861\n",
      "Epoch 252/4000\n",
      "25/25 - 0s - loss: 0.2045 - accuracy: 0.8923 - val_loss: 1.1257 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.32861\n",
      "Epoch 253/4000\n",
      "25/25 - 0s - loss: 0.2084 - accuracy: 0.8949 - val_loss: 1.1877 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.32861\n",
      "Epoch 254/4000\n",
      "25/25 - 0s - loss: 0.2090 - accuracy: 0.8923 - val_loss: 1.1887 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.32861\n",
      "Epoch 255/4000\n",
      "25/25 - 0s - loss: 0.2068 - accuracy: 0.8988 - val_loss: 1.2216 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.32861\n",
      "Epoch 256/4000\n",
      "25/25 - 0s - loss: 0.2121 - accuracy: 0.8898 - val_loss: 1.1326 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.32861\n",
      "Epoch 257/4000\n",
      "25/25 - 0s - loss: 0.2100 - accuracy: 0.8923 - val_loss: 1.1364 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.32861\n",
      "Epoch 258/4000\n",
      "25/25 - 0s - loss: 0.2087 - accuracy: 0.8962 - val_loss: 1.1972 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.32861\n",
      "Epoch 259/4000\n",
      "25/25 - 0s - loss: 0.2090 - accuracy: 0.8936 - val_loss: 1.0690 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.32861\n",
      "Epoch 260/4000\n",
      "25/25 - 0s - loss: 0.2115 - accuracy: 0.8962 - val_loss: 1.2029 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.32861\n",
      "Epoch 261/4000\n",
      "25/25 - 0s - loss: 0.2081 - accuracy: 0.8936 - val_loss: 1.3015 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.32861\n",
      "Epoch 262/4000\n",
      "25/25 - 0s - loss: 0.2076 - accuracy: 0.8988 - val_loss: 1.2824 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.32861\n",
      "Epoch 263/4000\n",
      "25/25 - 0s - loss: 0.2086 - accuracy: 0.8923 - val_loss: 1.3247 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.32861\n",
      "Epoch 264/4000\n",
      "25/25 - 0s - loss: 0.2041 - accuracy: 0.9014 - val_loss: 1.2782 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.32861\n",
      "Epoch 265/4000\n",
      "25/25 - 0s - loss: 0.2065 - accuracy: 0.8962 - val_loss: 1.3408 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.32861\n",
      "Epoch 266/4000\n",
      "25/25 - 0s - loss: 0.2069 - accuracy: 0.9001 - val_loss: 1.2139 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.32861\n",
      "Epoch 267/4000\n",
      "25/25 - 0s - loss: 0.2056 - accuracy: 0.9014 - val_loss: 1.1903 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.32861\n",
      "Epoch 268/4000\n",
      "25/25 - 0s - loss: 0.2089 - accuracy: 0.9001 - val_loss: 1.3169 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.32861\n",
      "Epoch 269/4000\n",
      "25/25 - 0s - loss: 0.2078 - accuracy: 0.9001 - val_loss: 1.3505 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.32861\n",
      "Epoch 270/4000\n",
      "25/25 - 0s - loss: 0.2056 - accuracy: 0.8988 - val_loss: 1.2885 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.32861\n",
      "Epoch 271/4000\n",
      "25/25 - 0s - loss: 0.2080 - accuracy: 0.8988 - val_loss: 1.2682 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.32861\n",
      "Epoch 272/4000\n",
      "25/25 - 0s - loss: 0.2074 - accuracy: 0.8975 - val_loss: 1.2892 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.32861\n",
      "Epoch 273/4000\n",
      "25/25 - 0s - loss: 0.2076 - accuracy: 0.9014 - val_loss: 1.1671 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.32861\n",
      "Epoch 274/4000\n",
      "25/25 - 0s - loss: 0.2079 - accuracy: 0.8962 - val_loss: 1.1222 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.32861\n",
      "Epoch 275/4000\n",
      "25/25 - 0s - loss: 0.2199 - accuracy: 0.8859 - val_loss: 0.9664 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.32861\n",
      "Epoch 276/4000\n",
      "25/25 - 0s - loss: 0.2563 - accuracy: 0.8742 - val_loss: 1.0359 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.32861\n",
      "Epoch 277/4000\n",
      "25/25 - 0s - loss: 0.2756 - accuracy: 0.8690 - val_loss: 1.4211 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.32861\n",
      "Epoch 278/4000\n",
      "25/25 - 0s - loss: 0.3437 - accuracy: 0.8651 - val_loss: 0.8151 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.32861\n",
      "Epoch 279/4000\n",
      "25/25 - 0s - loss: 0.4372 - accuracy: 0.8405 - val_loss: 0.5753 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.32861\n",
      "Epoch 280/4000\n",
      "25/25 - 0s - loss: 0.3429 - accuracy: 0.8573 - val_loss: 0.6459 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.32861\n",
      "Epoch 281/4000\n",
      "25/25 - 0s - loss: 0.3020 - accuracy: 0.8820 - val_loss: 0.7205 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.32861\n",
      "Epoch 282/4000\n",
      "25/25 - 0s - loss: 0.2602 - accuracy: 0.8859 - val_loss: 0.7120 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.32861\n",
      "Epoch 283/4000\n",
      "25/25 - 0s - loss: 0.2390 - accuracy: 0.8872 - val_loss: 0.7681 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.32861\n",
      "Epoch 284/4000\n",
      "25/25 - 0s - loss: 0.2433 - accuracy: 0.8949 - val_loss: 0.8098 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.32861\n",
      "Epoch 285/4000\n",
      "25/25 - 0s - loss: 0.2794 - accuracy: 0.8794 - val_loss: 0.5108 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.32861\n",
      "Epoch 286/4000\n",
      "25/25 - 0s - loss: 0.2554 - accuracy: 0.8885 - val_loss: 0.6126 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.32861\n",
      "Epoch 287/4000\n",
      "25/25 - 0s - loss: 0.2383 - accuracy: 0.8936 - val_loss: 0.6263 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.32861\n",
      "Epoch 288/4000\n",
      "25/25 - 0s - loss: 0.2428 - accuracy: 0.8885 - val_loss: 0.8395 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.32861\n",
      "Epoch 289/4000\n",
      "25/25 - 0s - loss: 0.2666 - accuracy: 0.8859 - val_loss: 0.6398 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.32861\n",
      "Epoch 290/4000\n",
      "25/25 - 0s - loss: 0.2577 - accuracy: 0.8820 - val_loss: 0.9542 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.32861\n",
      "Epoch 291/4000\n",
      "25/25 - 0s - loss: 0.3224 - accuracy: 0.8392 - val_loss: 0.7227 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.32861\n",
      "Epoch 292/4000\n",
      "25/25 - 0s - loss: 0.2868 - accuracy: 0.8768 - val_loss: 0.5293 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.32861\n",
      "Epoch 293/4000\n",
      "25/25 - 0s - loss: 0.2557 - accuracy: 0.8768 - val_loss: 0.5899 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.32861\n",
      "Epoch 294/4000\n",
      "25/25 - 0s - loss: 0.2656 - accuracy: 0.8846 - val_loss: 0.6509 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.32861\n",
      "Epoch 295/4000\n",
      "25/25 - 0s - loss: 0.2337 - accuracy: 0.8936 - val_loss: 0.6049 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.32861\n",
      "Epoch 296/4000\n",
      "25/25 - 0s - loss: 0.2563 - accuracy: 0.8936 - val_loss: 0.7299 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.32861\n",
      "Epoch 297/4000\n",
      "25/25 - 0s - loss: 0.2491 - accuracy: 0.8898 - val_loss: 0.5505 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.32861\n",
      "Epoch 298/4000\n",
      "25/25 - 0s - loss: 0.2431 - accuracy: 0.8911 - val_loss: 0.5185 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.32861\n",
      "Epoch 299/4000\n",
      "25/25 - 0s - loss: 0.2189 - accuracy: 0.8936 - val_loss: 0.5754 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.32861\n",
      "Epoch 300/4000\n",
      "25/25 - 0s - loss: 0.2157 - accuracy: 0.8988 - val_loss: 0.5835 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.32861\n",
      "Epoch 301/4000\n",
      "25/25 - 0s - loss: 0.2169 - accuracy: 0.8911 - val_loss: 0.6031 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.32861\n",
      "Epoch 302/4000\n",
      "25/25 - 0s - loss: 0.2124 - accuracy: 0.8988 - val_loss: 0.5735 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.32861\n",
      "Epoch 303/4000\n",
      "25/25 - 0s - loss: 0.2168 - accuracy: 0.8885 - val_loss: 0.6261 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.32861\n",
      "Epoch 304/4000\n",
      "25/25 - 0s - loss: 0.2368 - accuracy: 0.8911 - val_loss: 0.5787 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.32861\n",
      "Epoch 305/4000\n",
      "25/25 - 0s - loss: 0.2222 - accuracy: 0.8962 - val_loss: 0.6323 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.32861\n",
      "Epoch 306/4000\n",
      "25/25 - 0s - loss: 0.2280 - accuracy: 0.8962 - val_loss: 0.5570 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.32861\n",
      "Epoch 307/4000\n",
      "25/25 - 0s - loss: 0.2547 - accuracy: 0.8949 - val_loss: 0.5630 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.32861\n",
      "Epoch 308/4000\n",
      "25/25 - 0s - loss: 0.2245 - accuracy: 0.9014 - val_loss: 0.5168 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.32861\n",
      "Epoch 309/4000\n",
      "25/25 - 0s - loss: 0.2196 - accuracy: 0.8988 - val_loss: 0.5916 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.32861\n",
      "Epoch 310/4000\n",
      "25/25 - 0s - loss: 0.2180 - accuracy: 0.8962 - val_loss: 0.5846 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.32861\n",
      "Epoch 311/4000\n",
      "25/25 - 0s - loss: 0.2169 - accuracy: 0.8988 - val_loss: 0.5872 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.32861\n",
      "Epoch 312/4000\n",
      "25/25 - 0s - loss: 0.2142 - accuracy: 0.9001 - val_loss: 0.5814 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.32861\n",
      "Epoch 313/4000\n",
      "25/25 - 0s - loss: 0.2138 - accuracy: 0.9001 - val_loss: 0.5822 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.32861\n",
      "Epoch 314/4000\n",
      "25/25 - 0s - loss: 0.2136 - accuracy: 0.9001 - val_loss: 0.6122 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.32861\n",
      "Epoch 315/4000\n",
      "25/25 - 0s - loss: 0.2132 - accuracy: 0.9001 - val_loss: 0.6173 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.32861\n",
      "Epoch 316/4000\n",
      "25/25 - 0s - loss: 0.2142 - accuracy: 0.8988 - val_loss: 0.6306 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.32861\n",
      "Epoch 317/4000\n",
      "25/25 - 0s - loss: 0.2179 - accuracy: 0.9027 - val_loss: 0.6211 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.32861\n",
      "Epoch 318/4000\n",
      "25/25 - 0s - loss: 0.2160 - accuracy: 0.9001 - val_loss: 0.6517 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.32861\n",
      "Epoch 319/4000\n",
      "25/25 - 0s - loss: 0.2123 - accuracy: 0.8988 - val_loss: 0.6227 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.32861\n",
      "Epoch 320/4000\n",
      "25/25 - 0s - loss: 0.2244 - accuracy: 0.8911 - val_loss: 0.6319 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.32861\n",
      "Epoch 321/4000\n",
      "25/25 - 0s - loss: 0.2156 - accuracy: 0.9001 - val_loss: 0.6883 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.32861\n",
      "Epoch 322/4000\n",
      "25/25 - 0s - loss: 0.2117 - accuracy: 0.9001 - val_loss: 0.6555 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.32861\n",
      "Epoch 323/4000\n",
      "25/25 - 0s - loss: 0.2116 - accuracy: 0.9001 - val_loss: 0.6695 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.32861\n",
      "Epoch 324/4000\n",
      "25/25 - 0s - loss: 0.2113 - accuracy: 0.8962 - val_loss: 0.6940 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.32861\n",
      "Epoch 325/4000\n",
      "25/25 - 0s - loss: 0.2196 - accuracy: 0.8988 - val_loss: 0.6366 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.32861\n",
      "Epoch 326/4000\n",
      "25/25 - 0s - loss: 0.2147 - accuracy: 0.9001 - val_loss: 0.6399 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.32861\n",
      "Epoch 327/4000\n",
      "25/25 - 0s - loss: 0.2185 - accuracy: 0.8923 - val_loss: 0.6162 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.32861\n",
      "Epoch 328/4000\n",
      "25/25 - 0s - loss: 0.2122 - accuracy: 0.9001 - val_loss: 0.6349 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.32861\n",
      "Epoch 329/4000\n",
      "25/25 - 0s - loss: 0.2114 - accuracy: 0.8962 - val_loss: 0.6420 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.32861\n",
      "Epoch 330/4000\n",
      "25/25 - 0s - loss: 0.2104 - accuracy: 0.9014 - val_loss: 0.6666 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.32861\n",
      "Epoch 331/4000\n",
      "25/25 - 0s - loss: 0.2095 - accuracy: 0.8988 - val_loss: 0.6445 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.32861\n",
      "Epoch 332/4000\n",
      "25/25 - 0s - loss: 0.2099 - accuracy: 0.9014 - val_loss: 0.6752 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.32861\n",
      "Epoch 333/4000\n",
      "25/25 - 0s - loss: 0.2108 - accuracy: 0.8988 - val_loss: 0.6975 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.32861\n",
      "Epoch 334/4000\n",
      "25/25 - 0s - loss: 0.2116 - accuracy: 0.9027 - val_loss: 0.6792 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.32861\n",
      "Epoch 335/4000\n",
      "25/25 - 0s - loss: 0.2121 - accuracy: 0.8975 - val_loss: 0.6588 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.32861\n",
      "Epoch 336/4000\n",
      "25/25 - 0s - loss: 0.2093 - accuracy: 0.9001 - val_loss: 0.6410 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.32861\n",
      "Epoch 337/4000\n",
      "25/25 - 0s - loss: 0.2106 - accuracy: 0.9001 - val_loss: 0.6512 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.32861\n",
      "Epoch 338/4000\n",
      "25/25 - 0s - loss: 0.2086 - accuracy: 0.8988 - val_loss: 0.6464 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.32861\n",
      "Epoch 339/4000\n",
      "25/25 - 0s - loss: 0.2105 - accuracy: 0.9001 - val_loss: 0.6581 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.32861\n",
      "Epoch 340/4000\n",
      "25/25 - 0s - loss: 0.2082 - accuracy: 0.9014 - val_loss: 0.6671 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.32861\n",
      "Epoch 341/4000\n",
      "25/25 - 0s - loss: 0.2087 - accuracy: 0.9001 - val_loss: 0.6659 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.32861\n",
      "Epoch 342/4000\n",
      "25/25 - 0s - loss: 0.2093 - accuracy: 0.9001 - val_loss: 0.6642 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.32861\n",
      "Epoch 343/4000\n",
      "25/25 - 0s - loss: 0.2253 - accuracy: 0.9027 - val_loss: 0.6261 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.32861\n",
      "Epoch 344/4000\n",
      "25/25 - 0s - loss: 0.2621 - accuracy: 0.8949 - val_loss: 0.6029 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.32861\n",
      "Epoch 345/4000\n",
      "25/25 - 0s - loss: 0.2256 - accuracy: 0.8923 - val_loss: 0.7536 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.32861\n",
      "Epoch 346/4000\n",
      "25/25 - 0s - loss: 0.2272 - accuracy: 0.8807 - val_loss: 0.7501 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.32861\n",
      "Epoch 347/4000\n",
      "25/25 - 0s - loss: 0.2144 - accuracy: 0.8988 - val_loss: 0.7569 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.32861\n",
      "Epoch 348/4000\n",
      "25/25 - 0s - loss: 0.2321 - accuracy: 0.8898 - val_loss: 1.1444 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.32861\n",
      "Epoch 349/4000\n",
      "25/25 - 0s - loss: 0.2743 - accuracy: 0.8664 - val_loss: 1.5354 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.32861\n",
      "Epoch 350/4000\n",
      "25/25 - 0s - loss: 0.3903 - accuracy: 0.8755 - val_loss: 1.1009 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.32861\n",
      "Epoch 351/4000\n",
      "25/25 - 0s - loss: 0.2928 - accuracy: 0.8625 - val_loss: 1.1919 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.32861\n",
      "Epoch 352/4000\n",
      "25/25 - 0s - loss: 0.2498 - accuracy: 0.8768 - val_loss: 1.0181 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.32861\n",
      "Epoch 353/4000\n",
      "25/25 - 0s - loss: 0.2683 - accuracy: 0.8768 - val_loss: 1.6532 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.32861\n",
      "Epoch 354/4000\n",
      "25/25 - 0s - loss: 0.4739 - accuracy: 0.7964 - val_loss: 0.6739 - val_accuracy: 0.7409\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.32861\n",
      "Epoch 355/4000\n",
      "25/25 - 0s - loss: 0.3239 - accuracy: 0.8457 - val_loss: 0.7906 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.32861\n",
      "Epoch 356/4000\n",
      "25/25 - 0s - loss: 0.2698 - accuracy: 0.8898 - val_loss: 0.9406 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.32861\n",
      "Epoch 357/4000\n",
      "25/25 - 0s - loss: 0.3238 - accuracy: 0.8729 - val_loss: 0.8981 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.32861\n",
      "Epoch 358/4000\n",
      "25/25 - 0s - loss: 0.2545 - accuracy: 0.8833 - val_loss: 1.1602 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.32861\n",
      "Epoch 359/4000\n",
      "25/25 - 0s - loss: 0.2517 - accuracy: 0.8794 - val_loss: 0.9439 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.32861\n",
      "Epoch 360/4000\n",
      "25/25 - 0s - loss: 0.2618 - accuracy: 0.8859 - val_loss: 0.8957 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.32861\n",
      "Epoch 361/4000\n",
      "25/25 - 0s - loss: 0.2431 - accuracy: 0.8898 - val_loss: 0.9066 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.32861\n",
      "Epoch 362/4000\n",
      "25/25 - 0s - loss: 0.2350 - accuracy: 0.8936 - val_loss: 1.0363 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.32861\n",
      "Epoch 363/4000\n",
      "25/25 - 0s - loss: 0.2375 - accuracy: 0.8898 - val_loss: 1.0261 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 0.32861\n",
      "Epoch 364/4000\n",
      "25/25 - 0s - loss: 0.2280 - accuracy: 0.8885 - val_loss: 1.0627 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.32861\n",
      "Epoch 365/4000\n",
      "25/25 - 0s - loss: 0.2306 - accuracy: 0.8923 - val_loss: 1.0407 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.32861\n",
      "Epoch 366/4000\n",
      "25/25 - 0s - loss: 0.2357 - accuracy: 0.8781 - val_loss: 1.1219 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.32861\n",
      "Epoch 367/4000\n",
      "25/25 - 0s - loss: 0.2395 - accuracy: 0.8820 - val_loss: 1.0219 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.32861\n",
      "Epoch 368/4000\n",
      "25/25 - 0s - loss: 0.2314 - accuracy: 0.8911 - val_loss: 1.0075 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.32861\n",
      "Epoch 369/4000\n",
      "25/25 - 0s - loss: 0.2249 - accuracy: 0.8859 - val_loss: 0.9765 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.32861\n",
      "Epoch 370/4000\n",
      "25/25 - 0s - loss: 0.2246 - accuracy: 0.8911 - val_loss: 0.9510 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.32861\n",
      "Epoch 371/4000\n",
      "25/25 - 0s - loss: 0.2400 - accuracy: 0.8872 - val_loss: 1.0808 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.32861\n",
      "Epoch 372/4000\n",
      "25/25 - 0s - loss: 0.2545 - accuracy: 0.8820 - val_loss: 0.7827 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.32861\n",
      "Epoch 373/4000\n",
      "25/25 - 0s - loss: 0.2293 - accuracy: 0.8911 - val_loss: 0.7891 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.32861\n",
      "Epoch 374/4000\n",
      "25/25 - 0s - loss: 0.2263 - accuracy: 0.8949 - val_loss: 0.7895 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.32861\n",
      "Epoch 375/4000\n",
      "25/25 - 0s - loss: 0.2254 - accuracy: 0.8872 - val_loss: 0.8178 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.32861\n",
      "Epoch 376/4000\n",
      "25/25 - 0s - loss: 0.2257 - accuracy: 0.8898 - val_loss: 0.9299 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.32861\n",
      "Epoch 377/4000\n",
      "25/25 - 0s - loss: 0.2225 - accuracy: 0.8807 - val_loss: 0.9668 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.32861\n",
      "Epoch 378/4000\n",
      "25/25 - 0s - loss: 0.2280 - accuracy: 0.8768 - val_loss: 1.0498 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.32861\n",
      "Epoch 379/4000\n",
      "25/25 - 0s - loss: 0.2217 - accuracy: 0.8820 - val_loss: 1.0950 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.32861\n",
      "Epoch 380/4000\n",
      "25/25 - 0s - loss: 0.2244 - accuracy: 0.8859 - val_loss: 1.1390 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.32861\n",
      "Epoch 381/4000\n",
      "25/25 - 0s - loss: 0.2211 - accuracy: 0.8872 - val_loss: 1.1248 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 0.32861\n",
      "Epoch 382/4000\n",
      "25/25 - 0s - loss: 0.2166 - accuracy: 0.8859 - val_loss: 1.1538 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 0.32861\n",
      "Epoch 383/4000\n",
      "25/25 - 0s - loss: 0.2167 - accuracy: 0.8898 - val_loss: 1.1795 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 0.32861\n",
      "Epoch 384/4000\n",
      "25/25 - 0s - loss: 0.2174 - accuracy: 0.8846 - val_loss: 1.1792 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 0.32861\n",
      "Epoch 385/4000\n",
      "25/25 - 0s - loss: 0.2130 - accuracy: 0.8898 - val_loss: 1.2092 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 0.32861\n",
      "Epoch 386/4000\n",
      "25/25 - 0s - loss: 0.2132 - accuracy: 0.8898 - val_loss: 1.1929 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.32861\n",
      "Epoch 387/4000\n",
      "25/25 - 0s - loss: 0.2168 - accuracy: 0.8898 - val_loss: 1.1751 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 0.32861\n",
      "Epoch 388/4000\n",
      "25/25 - 0s - loss: 0.2136 - accuracy: 0.8859 - val_loss: 1.1525 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.32861\n",
      "Epoch 389/4000\n",
      "25/25 - 0s - loss: 0.2145 - accuracy: 0.8898 - val_loss: 1.1325 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 0.32861\n",
      "Epoch 390/4000\n",
      "25/25 - 0s - loss: 0.2134 - accuracy: 0.8872 - val_loss: 1.1368 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.32861\n",
      "Epoch 391/4000\n",
      "25/25 - 0s - loss: 0.2217 - accuracy: 0.8794 - val_loss: 1.0742 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.32861\n",
      "Epoch 392/4000\n",
      "25/25 - 0s - loss: 0.2200 - accuracy: 0.8833 - val_loss: 1.1509 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.32861\n",
      "Epoch 393/4000\n",
      "25/25 - 0s - loss: 0.2170 - accuracy: 0.8872 - val_loss: 1.1767 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.32861\n",
      "Epoch 394/4000\n",
      "25/25 - 0s - loss: 0.2213 - accuracy: 0.8872 - val_loss: 1.1542 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 0.32861\n",
      "Epoch 395/4000\n",
      "25/25 - 0s - loss: 0.2144 - accuracy: 0.8936 - val_loss: 1.0823 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 0.32861\n",
      "Epoch 396/4000\n",
      "25/25 - 0s - loss: 0.2180 - accuracy: 0.8820 - val_loss: 1.1029 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 0.32861\n",
      "Epoch 397/4000\n",
      "25/25 - 0s - loss: 0.2176 - accuracy: 0.8923 - val_loss: 1.1281 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.32861\n",
      "Epoch 398/4000\n",
      "25/25 - 0s - loss: 0.2161 - accuracy: 0.8923 - val_loss: 1.1264 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 0.32861\n",
      "Epoch 399/4000\n",
      "25/25 - 0s - loss: 0.2173 - accuracy: 0.8962 - val_loss: 1.1169 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 0.32861\n",
      "Epoch 400/4000\n",
      "25/25 - 0s - loss: 0.2152 - accuracy: 0.8923 - val_loss: 1.1086 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.32861\n",
      "Epoch 401/4000\n",
      "25/25 - 0s - loss: 0.2160 - accuracy: 0.8898 - val_loss: 1.2855 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 0.32861\n",
      "Epoch 402/4000\n",
      "25/25 - 0s - loss: 0.2190 - accuracy: 0.8911 - val_loss: 1.2569 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 0.32861\n",
      "Epoch 403/4000\n",
      "25/25 - 0s - loss: 0.2244 - accuracy: 0.8872 - val_loss: 1.2075 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 0.32861\n",
      "Epoch 404/4000\n",
      "25/25 - 0s - loss: 0.2176 - accuracy: 0.8898 - val_loss: 1.2202 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 0.32861\n",
      "Epoch 405/4000\n",
      "25/25 - 0s - loss: 0.2130 - accuracy: 0.8923 - val_loss: 1.2177 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 0.32861\n",
      "Epoch 406/4000\n",
      "25/25 - 0s - loss: 0.2112 - accuracy: 0.8923 - val_loss: 1.2630 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 0.32861\n",
      "Epoch 407/4000\n",
      "25/25 - 0s - loss: 0.2105 - accuracy: 0.8885 - val_loss: 1.2193 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 0.32861\n",
      "Epoch 408/4000\n",
      "25/25 - 0s - loss: 0.2122 - accuracy: 0.8923 - val_loss: 1.2492 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 0.32861\n",
      "Epoch 409/4000\n",
      "25/25 - 0s - loss: 0.2102 - accuracy: 0.8911 - val_loss: 1.2770 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 0.32861\n",
      "Epoch 410/4000\n",
      "25/25 - 0s - loss: 0.2127 - accuracy: 0.8898 - val_loss: 1.3014 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 0.32861\n",
      "Epoch 411/4000\n",
      "25/25 - 0s - loss: 0.2115 - accuracy: 0.8936 - val_loss: 1.2701 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 0.32861\n",
      "Epoch 412/4000\n",
      "25/25 - 0s - loss: 0.2130 - accuracy: 0.8936 - val_loss: 1.3461 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 0.32861\n",
      "Epoch 413/4000\n",
      "25/25 - 0s - loss: 0.2157 - accuracy: 0.8898 - val_loss: 1.3055 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 0.32861\n",
      "Epoch 414/4000\n",
      "25/25 - 0s - loss: 0.2130 - accuracy: 0.8923 - val_loss: 1.2733 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 0.32861\n",
      "Epoch 415/4000\n",
      "25/25 - 0s - loss: 0.2229 - accuracy: 0.8911 - val_loss: 0.9905 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 0.32861\n",
      "Epoch 416/4000\n",
      "25/25 - 0s - loss: 0.2154 - accuracy: 0.8911 - val_loss: 1.1008 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.32861\n",
      "Epoch 417/4000\n",
      "25/25 - 0s - loss: 0.2184 - accuracy: 0.8975 - val_loss: 0.9788 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.32861\n",
      "Epoch 418/4000\n",
      "25/25 - 0s - loss: 0.2156 - accuracy: 0.8923 - val_loss: 1.0066 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 0.32861\n",
      "Epoch 419/4000\n",
      "25/25 - 0s - loss: 0.2127 - accuracy: 0.8936 - val_loss: 1.0245 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 0.32861\n",
      "Epoch 420/4000\n",
      "25/25 - 0s - loss: 0.2171 - accuracy: 0.8962 - val_loss: 1.0487 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 0.32861\n",
      "Epoch 421/4000\n",
      "25/25 - 0s - loss: 0.2249 - accuracy: 0.8794 - val_loss: 0.9312 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 0.32861\n",
      "Epoch 422/4000\n",
      "25/25 - 0s - loss: 0.2204 - accuracy: 0.8898 - val_loss: 1.1416 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 0.32861\n",
      "Epoch 423/4000\n",
      "25/25 - 0s - loss: 0.2191 - accuracy: 0.8975 - val_loss: 1.1418 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 0.32861\n",
      "Epoch 424/4000\n",
      "25/25 - 0s - loss: 0.2158 - accuracy: 0.8923 - val_loss: 1.0831 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 0.32861\n",
      "Epoch 425/4000\n",
      "25/25 - 0s - loss: 0.2441 - accuracy: 0.8846 - val_loss: 1.4479 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 0.32861\n",
      "Epoch 426/4000\n",
      "25/25 - 0s - loss: 0.4689 - accuracy: 0.8444 - val_loss: 0.4776 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 0.32861\n",
      "Epoch 427/4000\n",
      "25/25 - 0s - loss: 0.3625 - accuracy: 0.8431 - val_loss: 0.7096 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 0.32861\n",
      "Epoch 428/4000\n",
      "25/25 - 0s - loss: 0.3075 - accuracy: 0.8690 - val_loss: 0.5315 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 0.32861\n",
      "Epoch 429/4000\n",
      "25/25 - 0s - loss: 0.3393 - accuracy: 0.8392 - val_loss: 0.6360 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 0.32861\n",
      "Epoch 430/4000\n",
      "25/25 - 0s - loss: 0.3098 - accuracy: 0.8482 - val_loss: 0.7543 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.32861\n",
      "Epoch 431/4000\n",
      "25/25 - 0s - loss: 0.2784 - accuracy: 0.8677 - val_loss: 0.6856 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 0.32861\n",
      "Epoch 432/4000\n",
      "25/25 - 0s - loss: 0.2694 - accuracy: 0.8716 - val_loss: 0.6999 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.32861\n",
      "Epoch 433/4000\n",
      "25/25 - 0s - loss: 0.2769 - accuracy: 0.8755 - val_loss: 0.7519 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.32861\n",
      "Epoch 434/4000\n",
      "25/25 - 0s - loss: 0.2668 - accuracy: 0.8638 - val_loss: 0.7875 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 0.32861\n",
      "Epoch 435/4000\n",
      "25/25 - 0s - loss: 0.2688 - accuracy: 0.8742 - val_loss: 0.9792 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 0.32861\n",
      "Epoch 436/4000\n",
      "25/25 - 0s - loss: 0.2729 - accuracy: 0.8664 - val_loss: 0.8363 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 0.32861\n",
      "Epoch 437/4000\n",
      "25/25 - 0s - loss: 0.2598 - accuracy: 0.8729 - val_loss: 0.9282 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 0.32861\n",
      "Epoch 438/4000\n",
      "25/25 - 0s - loss: 0.2631 - accuracy: 0.8742 - val_loss: 0.9408 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 0.32861\n",
      "Epoch 439/4000\n",
      "25/25 - 0s - loss: 0.2565 - accuracy: 0.8742 - val_loss: 0.9539 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 0.32861\n",
      "Epoch 440/4000\n",
      "25/25 - 0s - loss: 0.2432 - accuracy: 0.8768 - val_loss: 0.9139 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.32861\n",
      "Epoch 441/4000\n",
      "25/25 - 0s - loss: 0.2471 - accuracy: 0.8872 - val_loss: 0.9266 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 0.32861\n",
      "Epoch 442/4000\n",
      "25/25 - 0s - loss: 0.2418 - accuracy: 0.8807 - val_loss: 0.9714 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.32861\n",
      "Epoch 443/4000\n",
      "25/25 - 0s - loss: 0.2333 - accuracy: 0.8885 - val_loss: 1.0241 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.32861\n",
      "Epoch 444/4000\n",
      "25/25 - 0s - loss: 0.2419 - accuracy: 0.8833 - val_loss: 0.8947 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.32861\n",
      "Epoch 445/4000\n",
      "25/25 - 0s - loss: 0.2534 - accuracy: 0.8820 - val_loss: 0.8552 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.32861\n",
      "Epoch 446/4000\n",
      "25/25 - 0s - loss: 0.2340 - accuracy: 0.8898 - val_loss: 0.8921 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.32861\n",
      "Epoch 447/4000\n",
      "25/25 - 0s - loss: 0.2279 - accuracy: 0.8949 - val_loss: 0.9689 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 0.32861\n",
      "Epoch 448/4000\n",
      "25/25 - 0s - loss: 0.2561 - accuracy: 0.8859 - val_loss: 0.9618 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 0.32861\n",
      "Epoch 449/4000\n",
      "25/25 - 0s - loss: 0.2500 - accuracy: 0.8885 - val_loss: 0.8546 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 0.32861\n",
      "Epoch 450/4000\n",
      "25/25 - 0s - loss: 0.2369 - accuracy: 0.8898 - val_loss: 0.7179 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 0.32861\n",
      "Epoch 451/4000\n",
      "25/25 - 0s - loss: 0.2344 - accuracy: 0.8911 - val_loss: 0.7949 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 0.32861\n",
      "Epoch 452/4000\n",
      "25/25 - 0s - loss: 0.2326 - accuracy: 0.8911 - val_loss: 0.8351 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 0.32861\n",
      "Epoch 453/4000\n",
      "25/25 - 0s - loss: 0.2319 - accuracy: 0.8898 - val_loss: 0.8026 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 0.32861\n",
      "Epoch 454/4000\n",
      "25/25 - 0s - loss: 0.2323 - accuracy: 0.8911 - val_loss: 0.7946 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 0.32861\n",
      "Epoch 455/4000\n",
      "25/25 - 0s - loss: 0.2301 - accuracy: 0.8911 - val_loss: 0.8341 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 0.32861\n",
      "Epoch 456/4000\n",
      "25/25 - 0s - loss: 0.2326 - accuracy: 0.8911 - val_loss: 0.8812 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.32861\n",
      "Epoch 457/4000\n",
      "25/25 - 0s - loss: 0.2314 - accuracy: 0.8885 - val_loss: 0.8698 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 0.32861\n",
      "Epoch 458/4000\n",
      "25/25 - 0s - loss: 0.2307 - accuracy: 0.8911 - val_loss: 0.9038 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 0.32861\n",
      "Epoch 459/4000\n",
      "25/25 - 0s - loss: 0.2326 - accuracy: 0.8898 - val_loss: 0.8682 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 0.32861\n",
      "Epoch 460/4000\n",
      "25/25 - 0s - loss: 0.2268 - accuracy: 0.8911 - val_loss: 0.8982 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 0.32861\n",
      "Epoch 461/4000\n",
      "25/25 - 0s - loss: 0.2274 - accuracy: 0.8911 - val_loss: 0.9060 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 0.32861\n",
      "Epoch 462/4000\n",
      "25/25 - 0s - loss: 0.2423 - accuracy: 0.8794 - val_loss: 0.8504 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 0.32861\n",
      "Epoch 463/4000\n",
      "25/25 - 0s - loss: 0.2451 - accuracy: 0.8547 - val_loss: 0.9648 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 0.32861\n",
      "Epoch 464/4000\n",
      "25/25 - 0s - loss: 0.2467 - accuracy: 0.8781 - val_loss: 0.8642 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 0.32861\n",
      "Epoch 465/4000\n",
      "25/25 - 0s - loss: 0.2346 - accuracy: 0.8885 - val_loss: 0.8753 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 0.32861\n",
      "Epoch 466/4000\n",
      "25/25 - 0s - loss: 0.2323 - accuracy: 0.8820 - val_loss: 0.8772 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 0.32861\n",
      "Epoch 467/4000\n",
      "25/25 - 0s - loss: 0.2520 - accuracy: 0.8885 - val_loss: 1.0274 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.32861\n",
      "Epoch 468/4000\n",
      "25/25 - 0s - loss: 0.2686 - accuracy: 0.8820 - val_loss: 0.6342 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 0.32861\n",
      "Epoch 469/4000\n",
      "25/25 - 0s - loss: 0.2411 - accuracy: 0.8911 - val_loss: 0.6444 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 0.32861\n",
      "Epoch 470/4000\n",
      "25/25 - 0s - loss: 0.2257 - accuracy: 0.8898 - val_loss: 0.8804 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.32861\n",
      "Epoch 471/4000\n",
      "25/25 - 0s - loss: 0.2221 - accuracy: 0.8949 - val_loss: 0.8305 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 0.32861\n",
      "Epoch 472/4000\n",
      "25/25 - 0s - loss: 0.2247 - accuracy: 0.8936 - val_loss: 0.8343 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.32861\n",
      "Epoch 473/4000\n",
      "25/25 - 0s - loss: 0.2190 - accuracy: 0.8898 - val_loss: 0.8853 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 0.32861\n",
      "Epoch 474/4000\n",
      "25/25 - 0s - loss: 0.2201 - accuracy: 0.8898 - val_loss: 0.8762 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 0.32861\n",
      "Epoch 475/4000\n",
      "25/25 - 0s - loss: 0.2204 - accuracy: 0.8936 - val_loss: 0.9062 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.32861\n",
      "Epoch 476/4000\n",
      "25/25 - 0s - loss: 0.2196 - accuracy: 0.8949 - val_loss: 0.9021 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 0.32861\n",
      "Epoch 477/4000\n",
      "25/25 - 0s - loss: 0.2186 - accuracy: 0.8936 - val_loss: 0.9240 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 0.32861\n",
      "Epoch 478/4000\n",
      "25/25 - 0s - loss: 0.2196 - accuracy: 0.8923 - val_loss: 0.9148 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 0.32861\n",
      "Epoch 479/4000\n",
      "25/25 - 0s - loss: 0.2201 - accuracy: 0.8936 - val_loss: 0.9632 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 0.32861\n",
      "Epoch 480/4000\n",
      "25/25 - 0s - loss: 0.2182 - accuracy: 0.8923 - val_loss: 0.9715 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.32861\n",
      "Epoch 481/4000\n",
      "25/25 - 0s - loss: 0.2199 - accuracy: 0.8923 - val_loss: 0.9762 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 0.32861\n",
      "Epoch 482/4000\n",
      "25/25 - 0s - loss: 0.2230 - accuracy: 0.8936 - val_loss: 0.8971 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 0.32861\n",
      "Epoch 483/4000\n",
      "25/25 - 0s - loss: 0.2543 - accuracy: 0.8820 - val_loss: 1.0217 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 0.32861\n",
      "Epoch 484/4000\n",
      "25/25 - 0s - loss: 0.2656 - accuracy: 0.8781 - val_loss: 0.7215 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.32861\n",
      "Epoch 485/4000\n",
      "25/25 - 0s - loss: 0.3153 - accuracy: 0.8547 - val_loss: 0.6271 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 0.32861\n",
      "Epoch 486/4000\n",
      "25/25 - 0s - loss: 0.2604 - accuracy: 0.8703 - val_loss: 0.7327 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.32861\n",
      "Epoch 487/4000\n",
      "25/25 - 0s - loss: 0.3016 - accuracy: 0.8755 - val_loss: 0.7415 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.32861\n",
      "Epoch 488/4000\n",
      "25/25 - 0s - loss: 0.2708 - accuracy: 0.8755 - val_loss: 0.8054 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 0.32861\n",
      "Epoch 489/4000\n",
      "25/25 - 0s - loss: 0.2646 - accuracy: 0.8651 - val_loss: 0.8682 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 0.32861\n",
      "Epoch 490/4000\n",
      "25/25 - 0s - loss: 0.2389 - accuracy: 0.8755 - val_loss: 0.8943 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.32861\n",
      "Epoch 491/4000\n",
      "25/25 - 0s - loss: 0.2316 - accuracy: 0.8820 - val_loss: 0.7318 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 0.32861\n",
      "Epoch 492/4000\n",
      "25/25 - 0s - loss: 0.2325 - accuracy: 0.8898 - val_loss: 0.7968 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 0.32861\n",
      "Epoch 493/4000\n",
      "25/25 - 0s - loss: 0.2246 - accuracy: 0.8911 - val_loss: 0.8067 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 0.32861\n",
      "Epoch 494/4000\n",
      "25/25 - 0s - loss: 0.2289 - accuracy: 0.8911 - val_loss: 0.8099 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 0.32861\n",
      "Epoch 495/4000\n",
      "25/25 - 0s - loss: 0.2418 - accuracy: 0.8846 - val_loss: 0.7720 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.32861\n",
      "Epoch 496/4000\n",
      "25/25 - 0s - loss: 0.2699 - accuracy: 0.8768 - val_loss: 0.7448 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.32861\n",
      "Epoch 497/4000\n",
      "25/25 - 0s - loss: 0.2507 - accuracy: 0.8833 - val_loss: 0.7782 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 0.32861\n",
      "Epoch 498/4000\n",
      "25/25 - 0s - loss: 0.2401 - accuracy: 0.8807 - val_loss: 0.7714 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 0.32861\n",
      "Epoch 499/4000\n",
      "25/25 - 0s - loss: 0.2350 - accuracy: 0.8833 - val_loss: 0.8062 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 0.32861\n",
      "Epoch 500/4000\n",
      "25/25 - 0s - loss: 0.2317 - accuracy: 0.8820 - val_loss: 0.8243 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.32861\n",
      "Epoch 501/4000\n",
      "25/25 - 0s - loss: 0.2347 - accuracy: 0.8885 - val_loss: 0.8308 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 0.32861\n",
      "Epoch 502/4000\n",
      "25/25 - 0s - loss: 0.2341 - accuracy: 0.8885 - val_loss: 0.8223 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 0.32861\n",
      "Epoch 503/4000\n",
      "25/25 - 0s - loss: 0.2296 - accuracy: 0.8923 - val_loss: 0.8690 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 0.32861\n",
      "Epoch 504/4000\n",
      "25/25 - 0s - loss: 0.2326 - accuracy: 0.8885 - val_loss: 0.8918 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 0.32861\n",
      "Epoch 505/4000\n",
      "25/25 - 0s - loss: 0.2313 - accuracy: 0.8872 - val_loss: 0.8689 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 0.32861\n",
      "Epoch 506/4000\n",
      "25/25 - 0s - loss: 0.2266 - accuracy: 0.8923 - val_loss: 0.8772 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 0.32861\n",
      "Epoch 507/4000\n",
      "25/25 - 0s - loss: 0.2464 - accuracy: 0.8949 - val_loss: 0.8624 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 0.32861\n",
      "Epoch 508/4000\n",
      "25/25 - 0s - loss: 0.2551 - accuracy: 0.8859 - val_loss: 0.8817 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 0.32861\n",
      "Epoch 509/4000\n",
      "25/25 - 0s - loss: 0.2864 - accuracy: 0.8729 - val_loss: 1.0855 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 0.32861\n",
      "Epoch 510/4000\n",
      "25/25 - 0s - loss: 0.2906 - accuracy: 0.8573 - val_loss: 0.8734 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 0.32861\n",
      "Epoch 511/4000\n",
      "25/25 - 0s - loss: 0.3200 - accuracy: 0.8534 - val_loss: 0.7809 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 0.32861\n",
      "Epoch 512/4000\n",
      "25/25 - 0s - loss: 0.2860 - accuracy: 0.8664 - val_loss: 1.0408 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 0.32861\n",
      "Epoch 513/4000\n",
      "25/25 - 0s - loss: 0.2771 - accuracy: 0.8690 - val_loss: 0.7202 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 0.32861\n",
      "Epoch 514/4000\n",
      "25/25 - 0s - loss: 0.2666 - accuracy: 0.8755 - val_loss: 0.5465 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 0.32861\n",
      "Epoch 515/4000\n",
      "25/25 - 0s - loss: 0.2510 - accuracy: 0.8794 - val_loss: 0.5676 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 0.32861\n",
      "Epoch 516/4000\n",
      "25/25 - 0s - loss: 0.2546 - accuracy: 0.8755 - val_loss: 0.6349 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 0.32861\n",
      "Epoch 517/4000\n",
      "25/25 - 0s - loss: 0.2540 - accuracy: 0.8794 - val_loss: 0.6337 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 0.32861\n",
      "Epoch 518/4000\n",
      "25/25 - 0s - loss: 0.2469 - accuracy: 0.8768 - val_loss: 0.6359 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 0.32861\n",
      "Epoch 519/4000\n",
      "25/25 - 0s - loss: 0.2377 - accuracy: 0.8807 - val_loss: 0.6243 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 0.32861\n",
      "Epoch 520/4000\n",
      "25/25 - 0s - loss: 0.2271 - accuracy: 0.8923 - val_loss: 0.6546 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 0.32861\n",
      "Epoch 521/4000\n",
      "25/25 - 0s - loss: 0.2551 - accuracy: 0.8885 - val_loss: 0.8235 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 0.32861\n",
      "Epoch 522/4000\n",
      "25/25 - 0s - loss: 0.2246 - accuracy: 0.8859 - val_loss: 0.7877 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 0.32861\n",
      "Epoch 523/4000\n",
      "25/25 - 0s - loss: 0.2279 - accuracy: 0.8923 - val_loss: 0.7625 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 0.32861\n",
      "Epoch 524/4000\n",
      "25/25 - 0s - loss: 0.2347 - accuracy: 0.8885 - val_loss: 0.7759 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 0.32861\n",
      "Epoch 525/4000\n",
      "25/25 - 0s - loss: 0.2384 - accuracy: 0.8781 - val_loss: 0.6232 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 0.32861\n",
      "Epoch 526/4000\n",
      "25/25 - 0s - loss: 0.2296 - accuracy: 0.8898 - val_loss: 0.6546 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 0.32861\n",
      "Epoch 527/4000\n",
      "25/25 - 0s - loss: 0.2240 - accuracy: 0.8923 - val_loss: 0.7382 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 0.32861\n",
      "Epoch 528/4000\n",
      "25/25 - 0s - loss: 0.2229 - accuracy: 0.8859 - val_loss: 0.7466 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 0.32861\n",
      "Epoch 529/4000\n",
      "25/25 - 0s - loss: 0.2216 - accuracy: 0.8911 - val_loss: 0.7775 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 0.32861\n",
      "Epoch 530/4000\n",
      "25/25 - 0s - loss: 0.2256 - accuracy: 0.8820 - val_loss: 0.7923 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 0.32861\n",
      "Epoch 531/4000\n",
      "25/25 - 0s - loss: 0.2325 - accuracy: 0.8833 - val_loss: 0.5416 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 0.32861\n",
      "Epoch 532/4000\n",
      "25/25 - 0s - loss: 0.2355 - accuracy: 0.8846 - val_loss: 0.6951 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 0.32861\n",
      "Epoch 533/4000\n",
      "25/25 - 0s - loss: 0.2208 - accuracy: 0.8911 - val_loss: 0.7787 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 0.32861\n",
      "Epoch 534/4000\n",
      "25/25 - 0s - loss: 0.2228 - accuracy: 0.8807 - val_loss: 0.7068 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 0.32861\n",
      "Epoch 535/4000\n",
      "25/25 - 0s - loss: 0.2180 - accuracy: 0.8859 - val_loss: 0.7443 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 0.32861\n",
      "Epoch 536/4000\n",
      "25/25 - 0s - loss: 0.2194 - accuracy: 0.8911 - val_loss: 0.7226 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 0.32861\n",
      "Epoch 537/4000\n",
      "25/25 - 0s - loss: 0.2229 - accuracy: 0.8923 - val_loss: 0.7449 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 0.32861\n",
      "Epoch 538/4000\n",
      "25/25 - 0s - loss: 0.2181 - accuracy: 0.8911 - val_loss: 0.7232 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 0.32861\n",
      "Epoch 539/4000\n",
      "25/25 - 0s - loss: 0.2140 - accuracy: 0.8923 - val_loss: 0.7382 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 0.32861\n",
      "Epoch 540/4000\n",
      "25/25 - 0s - loss: 0.2159 - accuracy: 0.8962 - val_loss: 0.7222 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 0.32861\n",
      "Epoch 541/4000\n",
      "25/25 - 0s - loss: 0.2130 - accuracy: 0.8949 - val_loss: 0.7313 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 0.32861\n",
      "Epoch 542/4000\n",
      "25/25 - 0s - loss: 0.2119 - accuracy: 0.8962 - val_loss: 0.6813 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 0.32861\n",
      "Epoch 543/4000\n",
      "25/25 - 0s - loss: 0.2136 - accuracy: 0.8923 - val_loss: 0.7235 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 0.32861\n",
      "Epoch 544/4000\n",
      "25/25 - 0s - loss: 0.2128 - accuracy: 0.8923 - val_loss: 0.6933 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 0.32861\n",
      "Epoch 545/4000\n",
      "25/25 - 0s - loss: 0.2122 - accuracy: 0.8962 - val_loss: 0.7050 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 0.32861\n",
      "Epoch 546/4000\n",
      "25/25 - 0s - loss: 0.2189 - accuracy: 0.8949 - val_loss: 0.6595 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 0.32861\n",
      "Epoch 547/4000\n",
      "25/25 - 0s - loss: 0.2210 - accuracy: 0.8975 - val_loss: 0.6861 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 0.32861\n",
      "Epoch 548/4000\n",
      "25/25 - 0s - loss: 0.2114 - accuracy: 0.9001 - val_loss: 0.7536 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 0.32861\n",
      "Epoch 549/4000\n",
      "25/25 - 0s - loss: 0.2328 - accuracy: 0.8936 - val_loss: 0.6345 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 0.32861\n",
      "Epoch 550/4000\n",
      "25/25 - 0s - loss: 0.2135 - accuracy: 0.8962 - val_loss: 0.6872 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 0.32861\n",
      "Epoch 551/4000\n",
      "25/25 - 0s - loss: 0.2194 - accuracy: 0.8962 - val_loss: 0.6845 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00551: val_loss did not improve from 0.32861\n",
      "Epoch 552/4000\n",
      "25/25 - 0s - loss: 0.2171 - accuracy: 0.8962 - val_loss: 0.6900 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00552: val_loss did not improve from 0.32861\n",
      "Epoch 553/4000\n",
      "25/25 - 0s - loss: 0.2148 - accuracy: 0.8962 - val_loss: 0.6880 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00553: val_loss did not improve from 0.32861\n",
      "Epoch 554/4000\n",
      "25/25 - 0s - loss: 0.2135 - accuracy: 0.8936 - val_loss: 0.6955 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00554: val_loss did not improve from 0.32861\n",
      "Epoch 555/4000\n",
      "25/25 - 0s - loss: 0.2123 - accuracy: 0.8962 - val_loss: 0.7123 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00555: val_loss did not improve from 0.32861\n",
      "Epoch 556/4000\n",
      "25/25 - 0s - loss: 0.2129 - accuracy: 0.8962 - val_loss: 0.7234 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00556: val_loss did not improve from 0.32861\n",
      "Epoch 557/4000\n",
      "25/25 - 0s - loss: 0.2135 - accuracy: 0.8962 - val_loss: 0.6497 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00557: val_loss did not improve from 0.32861\n",
      "Epoch 558/4000\n",
      "25/25 - 0s - loss: 0.2121 - accuracy: 0.8962 - val_loss: 0.6806 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00558: val_loss did not improve from 0.32861\n",
      "Epoch 559/4000\n",
      "25/25 - 0s - loss: 0.2101 - accuracy: 0.8962 - val_loss: 0.6715 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00559: val_loss did not improve from 0.32861\n",
      "Epoch 560/4000\n",
      "25/25 - 0s - loss: 0.2105 - accuracy: 0.8949 - val_loss: 0.7052 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 0.32861\n",
      "Epoch 561/4000\n",
      "25/25 - 0s - loss: 0.2125 - accuracy: 0.8962 - val_loss: 0.7019 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00561: val_loss did not improve from 0.32861\n",
      "Epoch 562/4000\n",
      "25/25 - 0s - loss: 0.2171 - accuracy: 0.8962 - val_loss: 0.7431 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00562: val_loss did not improve from 0.32861\n",
      "Epoch 563/4000\n",
      "25/25 - 0s - loss: 0.2157 - accuracy: 0.8962 - val_loss: 0.6554 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00563: val_loss did not improve from 0.32861\n",
      "Epoch 564/4000\n",
      "25/25 - 0s - loss: 0.2105 - accuracy: 0.8949 - val_loss: 0.7271 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00564: val_loss did not improve from 0.32861\n",
      "Epoch 565/4000\n",
      "25/25 - 0s - loss: 0.2179 - accuracy: 0.8949 - val_loss: 0.6949 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00565: val_loss did not improve from 0.32861\n",
      "Epoch 566/4000\n",
      "25/25 - 0s - loss: 0.2164 - accuracy: 0.8936 - val_loss: 0.6715 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00566: val_loss did not improve from 0.32861\n",
      "Epoch 567/4000\n",
      "25/25 - 0s - loss: 0.2114 - accuracy: 0.8962 - val_loss: 0.6967 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00567: val_loss did not improve from 0.32861\n",
      "Epoch 568/4000\n",
      "25/25 - 0s - loss: 0.2159 - accuracy: 0.8949 - val_loss: 0.7252 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00568: val_loss did not improve from 0.32861\n",
      "Epoch 569/4000\n",
      "25/25 - 0s - loss: 0.2422 - accuracy: 0.8872 - val_loss: 0.6735 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00569: val_loss did not improve from 0.32861\n",
      "Epoch 570/4000\n",
      "25/25 - 0s - loss: 0.5252 - accuracy: 0.8690 - val_loss: 0.4725 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00570: val_loss did not improve from 0.32861\n",
      "Epoch 571/4000\n",
      "25/25 - 0s - loss: 0.2978 - accuracy: 0.8664 - val_loss: 0.9592 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00571: val_loss did not improve from 0.32861\n",
      "Epoch 572/4000\n",
      "25/25 - 0s - loss: 0.2813 - accuracy: 0.8833 - val_loss: 0.7996 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00572: val_loss did not improve from 0.32861\n",
      "Epoch 573/4000\n",
      "25/25 - 0s - loss: 0.2677 - accuracy: 0.8768 - val_loss: 0.8281 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00573: val_loss did not improve from 0.32861\n",
      "Epoch 574/4000\n",
      "25/25 - 0s - loss: 0.2856 - accuracy: 0.8677 - val_loss: 0.7047 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00574: val_loss did not improve from 0.32861\n",
      "Epoch 575/4000\n",
      "25/25 - 0s - loss: 0.3107 - accuracy: 0.8703 - val_loss: 0.8165 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00575: val_loss did not improve from 0.32861\n",
      "Epoch 576/4000\n",
      "25/25 - 0s - loss: 0.3663 - accuracy: 0.8521 - val_loss: 0.5910 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00576: val_loss did not improve from 0.32861\n",
      "Epoch 577/4000\n",
      "25/25 - 0s - loss: 0.2817 - accuracy: 0.8833 - val_loss: 0.6758 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00577: val_loss did not improve from 0.32861\n",
      "Epoch 578/4000\n",
      "25/25 - 0s - loss: 0.2983 - accuracy: 0.8586 - val_loss: 0.7572 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00578: val_loss did not improve from 0.32861\n",
      "Epoch 579/4000\n",
      "25/25 - 0s - loss: 0.2747 - accuracy: 0.8742 - val_loss: 0.7415 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00579: val_loss did not improve from 0.32861\n",
      "Epoch 580/4000\n",
      "25/25 - 0s - loss: 0.2867 - accuracy: 0.8729 - val_loss: 0.8747 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00580: val_loss did not improve from 0.32861\n",
      "Epoch 581/4000\n",
      "25/25 - 0s - loss: 0.2746 - accuracy: 0.8794 - val_loss: 1.1069 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00581: val_loss did not improve from 0.32861\n",
      "Epoch 582/4000\n",
      "25/25 - 0s - loss: 0.4382 - accuracy: 0.8547 - val_loss: 0.6858 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00582: val_loss did not improve from 0.32861\n",
      "Epoch 583/4000\n",
      "25/25 - 0s - loss: 0.3616 - accuracy: 0.8586 - val_loss: 0.7804 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00583: val_loss did not improve from 0.32861\n",
      "Epoch 584/4000\n",
      "25/25 - 0s - loss: 0.3185 - accuracy: 0.8677 - val_loss: 0.6886 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00584: val_loss did not improve from 0.32861\n",
      "Epoch 585/4000\n",
      "25/25 - 0s - loss: 0.3324 - accuracy: 0.8690 - val_loss: 0.7238 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00585: val_loss did not improve from 0.32861\n",
      "Epoch 586/4000\n",
      "25/25 - 0s - loss: 0.3103 - accuracy: 0.8677 - val_loss: 0.7806 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00586: val_loss did not improve from 0.32861\n",
      "Epoch 587/4000\n",
      "25/25 - 0s - loss: 0.2845 - accuracy: 0.8768 - val_loss: 0.7972 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00587: val_loss did not improve from 0.32861\n",
      "Epoch 588/4000\n",
      "25/25 - 0s - loss: 0.2677 - accuracy: 0.8846 - val_loss: 0.7024 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00588: val_loss did not improve from 0.32861\n",
      "Epoch 589/4000\n",
      "25/25 - 0s - loss: 0.2566 - accuracy: 0.8820 - val_loss: 0.7609 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00589: val_loss did not improve from 0.32861\n",
      "Epoch 590/4000\n",
      "25/25 - 0s - loss: 0.2565 - accuracy: 0.8846 - val_loss: 0.7310 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00590: val_loss did not improve from 0.32861\n",
      "Epoch 591/4000\n",
      "25/25 - 0s - loss: 0.2679 - accuracy: 0.8833 - val_loss: 0.7797 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00591: val_loss did not improve from 0.32861\n",
      "Epoch 592/4000\n",
      "25/25 - 0s - loss: 0.2564 - accuracy: 0.8833 - val_loss: 1.0440 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00592: val_loss did not improve from 0.32861\n",
      "Epoch 593/4000\n",
      "25/25 - 0s - loss: 0.2698 - accuracy: 0.8833 - val_loss: 1.1290 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00593: val_loss did not improve from 0.32861\n",
      "Epoch 594/4000\n",
      "25/25 - 0s - loss: 0.2954 - accuracy: 0.8781 - val_loss: 0.9865 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00594: val_loss did not improve from 0.32861\n",
      "Epoch 595/4000\n",
      "25/25 - 0s - loss: 0.2474 - accuracy: 0.8846 - val_loss: 0.8391 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00595: val_loss did not improve from 0.32861\n",
      "Epoch 596/4000\n",
      "25/25 - 0s - loss: 0.2449 - accuracy: 0.8833 - val_loss: 0.7141 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00596: val_loss did not improve from 0.32861\n",
      "Epoch 597/4000\n",
      "25/25 - 0s - loss: 0.2405 - accuracy: 0.8859 - val_loss: 0.7044 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00597: val_loss did not improve from 0.32861\n",
      "Epoch 598/4000\n",
      "25/25 - 0s - loss: 0.2392 - accuracy: 0.8923 - val_loss: 0.7112 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00598: val_loss did not improve from 0.32861\n",
      "Epoch 599/4000\n",
      "25/25 - 0s - loss: 0.2354 - accuracy: 0.8885 - val_loss: 0.7738 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00599: val_loss did not improve from 0.32861\n",
      "Epoch 600/4000\n",
      "25/25 - 0s - loss: 0.2367 - accuracy: 0.8911 - val_loss: 0.7742 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00600: val_loss did not improve from 0.32861\n",
      "Epoch 601/4000\n",
      "25/25 - 0s - loss: 0.2352 - accuracy: 0.8898 - val_loss: 0.7656 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00601: val_loss did not improve from 0.32861\n",
      "Epoch 602/4000\n",
      "25/25 - 0s - loss: 0.2357 - accuracy: 0.8885 - val_loss: 0.7613 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00602: val_loss did not improve from 0.32861\n",
      "Epoch 603/4000\n",
      "25/25 - 0s - loss: 0.2369 - accuracy: 0.8911 - val_loss: 0.7992 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00603: val_loss did not improve from 0.32861\n",
      "Epoch 604/4000\n",
      "25/25 - 0s - loss: 0.2327 - accuracy: 0.8885 - val_loss: 0.8291 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00604: val_loss did not improve from 0.32861\n",
      "Epoch 605/4000\n",
      "25/25 - 0s - loss: 0.2374 - accuracy: 0.8885 - val_loss: 0.8279 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00605: val_loss did not improve from 0.32861\n",
      "Epoch 606/4000\n",
      "25/25 - 0s - loss: 0.2384 - accuracy: 0.8911 - val_loss: 0.8589 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00606: val_loss did not improve from 0.32861\n",
      "Epoch 607/4000\n",
      "25/25 - 0s - loss: 0.2458 - accuracy: 0.8949 - val_loss: 1.5031 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00607: val_loss did not improve from 0.32861\n",
      "Epoch 608/4000\n",
      "25/25 - 0s - loss: 0.2437 - accuracy: 0.8898 - val_loss: 1.4762 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00608: val_loss did not improve from 0.32861\n",
      "Epoch 609/4000\n",
      "25/25 - 0s - loss: 0.2340 - accuracy: 0.8923 - val_loss: 1.5592 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00609: val_loss did not improve from 0.32861\n",
      "Epoch 610/4000\n",
      "25/25 - 0s - loss: 0.2679 - accuracy: 0.8664 - val_loss: 1.2089 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00610: val_loss did not improve from 0.32861\n",
      "Epoch 611/4000\n",
      "25/25 - 0s - loss: 0.2519 - accuracy: 0.8755 - val_loss: 1.3034 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00611: val_loss did not improve from 0.32861\n",
      "Epoch 612/4000\n",
      "25/25 - 0s - loss: 0.2507 - accuracy: 0.8885 - val_loss: 1.1734 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00612: val_loss did not improve from 0.32861\n",
      "Epoch 613/4000\n",
      "25/25 - 0s - loss: 0.2400 - accuracy: 0.8872 - val_loss: 1.0398 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00613: val_loss did not improve from 0.32861\n",
      "Epoch 614/4000\n",
      "25/25 - 0s - loss: 0.2294 - accuracy: 0.8962 - val_loss: 1.1497 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00614: val_loss did not improve from 0.32861\n",
      "Epoch 615/4000\n",
      "25/25 - 0s - loss: 0.2552 - accuracy: 0.8911 - val_loss: 0.8578 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00615: val_loss did not improve from 0.32861\n",
      "Epoch 616/4000\n",
      "25/25 - 0s - loss: 0.2538 - accuracy: 0.8911 - val_loss: 1.3774 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00616: val_loss did not improve from 0.32861\n",
      "Epoch 617/4000\n",
      "25/25 - 0s - loss: 0.2245 - accuracy: 0.8949 - val_loss: 1.3968 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00617: val_loss did not improve from 0.32861\n",
      "Epoch 618/4000\n",
      "25/25 - 0s - loss: 0.2242 - accuracy: 0.8923 - val_loss: 1.3433 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00618: val_loss did not improve from 0.32861\n",
      "Epoch 619/4000\n",
      "25/25 - 0s - loss: 0.2221 - accuracy: 0.8962 - val_loss: 1.3485 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00619: val_loss did not improve from 0.32861\n",
      "Epoch 620/4000\n",
      "25/25 - 0s - loss: 0.2190 - accuracy: 0.8988 - val_loss: 1.4003 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00620: val_loss did not improve from 0.32861\n",
      "Epoch 621/4000\n",
      "25/25 - 0s - loss: 0.2351 - accuracy: 0.8742 - val_loss: 1.3603 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00621: val_loss did not improve from 0.32861\n",
      "Epoch 622/4000\n",
      "25/25 - 0s - loss: 0.2277 - accuracy: 0.8936 - val_loss: 1.8180 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00622: val_loss did not improve from 0.32861\n",
      "Epoch 623/4000\n",
      "25/25 - 0s - loss: 0.2295 - accuracy: 0.8975 - val_loss: 1.9933 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00623: val_loss did not improve from 0.32861\n",
      "Epoch 624/4000\n",
      "25/25 - 0s - loss: 0.2182 - accuracy: 0.8988 - val_loss: 1.9001 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00624: val_loss did not improve from 0.32861\n",
      "Epoch 625/4000\n",
      "25/25 - 0s - loss: 0.2185 - accuracy: 0.8949 - val_loss: 1.9919 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00625: val_loss did not improve from 0.32861\n",
      "Epoch 626/4000\n",
      "25/25 - 0s - loss: 0.2196 - accuracy: 0.8988 - val_loss: 2.1517 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00626: val_loss did not improve from 0.32861\n",
      "Epoch 627/4000\n",
      "25/25 - 0s - loss: 0.2188 - accuracy: 0.8988 - val_loss: 2.4398 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00627: val_loss did not improve from 0.32861\n",
      "Epoch 628/4000\n",
      "25/25 - 0s - loss: 0.2217 - accuracy: 0.8988 - val_loss: 1.4861 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00628: val_loss did not improve from 0.32861\n",
      "Epoch 629/4000\n",
      "25/25 - 0s - loss: 0.2189 - accuracy: 0.8988 - val_loss: 1.7405 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00629: val_loss did not improve from 0.32861\n",
      "Epoch 630/4000\n",
      "25/25 - 0s - loss: 0.2207 - accuracy: 0.8975 - val_loss: 1.7721 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00630: val_loss did not improve from 0.32861\n",
      "Epoch 631/4000\n",
      "25/25 - 0s - loss: 0.2219 - accuracy: 0.8949 - val_loss: 1.8556 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00631: val_loss did not improve from 0.32861\n",
      "Epoch 632/4000\n",
      "25/25 - 0s - loss: 0.2205 - accuracy: 0.8923 - val_loss: 1.8460 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00632: val_loss did not improve from 0.32861\n",
      "Epoch 633/4000\n",
      "25/25 - 0s - loss: 0.2197 - accuracy: 0.8936 - val_loss: 1.8678 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00633: val_loss did not improve from 0.32861\n",
      "Epoch 634/4000\n",
      "25/25 - 0s - loss: 0.2189 - accuracy: 0.8936 - val_loss: 2.0273 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00634: val_loss did not improve from 0.32861\n",
      "Epoch 635/4000\n",
      "25/25 - 0s - loss: 0.2205 - accuracy: 0.8936 - val_loss: 1.9828 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00635: val_loss did not improve from 0.32861\n",
      "Epoch 636/4000\n",
      "25/25 - 0s - loss: 0.2202 - accuracy: 0.8911 - val_loss: 1.9634 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00636: val_loss did not improve from 0.32861\n",
      "Epoch 637/4000\n",
      "25/25 - 0s - loss: 0.2245 - accuracy: 0.8975 - val_loss: 1.9767 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00637: val_loss did not improve from 0.32861\n",
      "Epoch 638/4000\n",
      "25/25 - 0s - loss: 0.2179 - accuracy: 0.8936 - val_loss: 2.0698 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00638: val_loss did not improve from 0.32861\n",
      "Epoch 639/4000\n",
      "25/25 - 0s - loss: 0.2200 - accuracy: 0.8936 - val_loss: 2.0742 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00639: val_loss did not improve from 0.32861\n",
      "Epoch 640/4000\n",
      "25/25 - 0s - loss: 0.2299 - accuracy: 0.8781 - val_loss: 2.2050 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00640: val_loss did not improve from 0.32861\n",
      "Epoch 641/4000\n",
      "25/25 - 0s - loss: 0.2218 - accuracy: 0.8949 - val_loss: 2.3882 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00641: val_loss did not improve from 0.32861\n",
      "Epoch 642/4000\n",
      "25/25 - 0s - loss: 0.2200 - accuracy: 0.8936 - val_loss: 2.5292 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00642: val_loss did not improve from 0.32861\n",
      "Epoch 643/4000\n",
      "25/25 - 0s - loss: 0.2190 - accuracy: 0.8936 - val_loss: 2.4800 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00643: val_loss did not improve from 0.32861\n",
      "Epoch 644/4000\n",
      "25/25 - 0s - loss: 0.2203 - accuracy: 0.8936 - val_loss: 2.4012 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00644: val_loss did not improve from 0.32861\n",
      "Epoch 645/4000\n",
      "25/25 - 0s - loss: 0.2206 - accuracy: 0.8936 - val_loss: 2.3529 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00645: val_loss did not improve from 0.32861\n",
      "Epoch 646/4000\n",
      "25/25 - 0s - loss: 0.2190 - accuracy: 0.8936 - val_loss: 1.8851 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00646: val_loss did not improve from 0.32861\n",
      "Epoch 647/4000\n",
      "25/25 - 0s - loss: 0.2626 - accuracy: 0.8807 - val_loss: 1.2966 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00647: val_loss did not improve from 0.32861\n",
      "Epoch 648/4000\n",
      "25/25 - 0s - loss: 0.3486 - accuracy: 0.8716 - val_loss: 1.4350 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00648: val_loss did not improve from 0.32861\n",
      "Epoch 649/4000\n",
      "25/25 - 0s - loss: 0.2786 - accuracy: 0.8794 - val_loss: 1.3611 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00649: val_loss did not improve from 0.32861\n",
      "Epoch 650/4000\n",
      "25/25 - 0s - loss: 0.2479 - accuracy: 0.8833 - val_loss: 1.2811 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00650: val_loss did not improve from 0.32861\n",
      "Epoch 651/4000\n",
      "25/25 - 0s - loss: 0.2295 - accuracy: 0.8975 - val_loss: 1.9180 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00651: val_loss did not improve from 0.32861\n",
      "Epoch 652/4000\n",
      "25/25 - 0s - loss: 0.2394 - accuracy: 0.8911 - val_loss: 1.6729 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00652: val_loss did not improve from 0.32861\n",
      "Epoch 653/4000\n",
      "25/25 - 0s - loss: 0.2239 - accuracy: 0.8962 - val_loss: 1.5641 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00653: val_loss did not improve from 0.32861\n",
      "Epoch 654/4000\n",
      "25/25 - 0s - loss: 0.2224 - accuracy: 0.8975 - val_loss: 1.7174 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00654: val_loss did not improve from 0.32861\n",
      "Epoch 655/4000\n",
      "25/25 - 0s - loss: 0.2240 - accuracy: 0.8949 - val_loss: 1.7311 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00655: val_loss did not improve from 0.32861\n",
      "Epoch 656/4000\n",
      "25/25 - 0s - loss: 0.2398 - accuracy: 0.8949 - val_loss: 1.9065 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00656: val_loss did not improve from 0.32861\n",
      "Epoch 657/4000\n",
      "25/25 - 0s - loss: 0.2606 - accuracy: 0.8859 - val_loss: 2.5715 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00657: val_loss did not improve from 0.32861\n",
      "Epoch 658/4000\n",
      "25/25 - 0s - loss: 0.2872 - accuracy: 0.8820 - val_loss: 2.0292 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00658: val_loss did not improve from 0.32861\n",
      "Epoch 659/4000\n",
      "25/25 - 0s - loss: 0.2571 - accuracy: 0.8833 - val_loss: 1.8270 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00659: val_loss did not improve from 0.32861\n",
      "Epoch 660/4000\n",
      "25/25 - 0s - loss: 0.2487 - accuracy: 0.8846 - val_loss: 1.6967 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00660: val_loss did not improve from 0.32861\n",
      "Epoch 661/4000\n",
      "25/25 - 0s - loss: 0.2431 - accuracy: 0.8911 - val_loss: 1.9944 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00661: val_loss did not improve from 0.32861\n",
      "Epoch 662/4000\n",
      "25/25 - 0s - loss: 0.2302 - accuracy: 0.8885 - val_loss: 1.8146 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00662: val_loss did not improve from 0.32861\n",
      "Epoch 663/4000\n",
      "25/25 - 0s - loss: 0.2240 - accuracy: 0.8911 - val_loss: 1.9165 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00663: val_loss did not improve from 0.32861\n",
      "Epoch 664/4000\n",
      "25/25 - 0s - loss: 0.2231 - accuracy: 0.8911 - val_loss: 1.9727 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00664: val_loss did not improve from 0.32861\n",
      "Epoch 665/4000\n",
      "25/25 - 0s - loss: 0.2305 - accuracy: 0.8949 - val_loss: 2.1471 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00665: val_loss did not improve from 0.32861\n",
      "Epoch 666/4000\n",
      "25/25 - 0s - loss: 0.2198 - accuracy: 0.8936 - val_loss: 2.1729 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00666: val_loss did not improve from 0.32861\n",
      "Epoch 667/4000\n",
      "25/25 - 0s - loss: 0.2194 - accuracy: 0.8936 - val_loss: 2.2766 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00667: val_loss did not improve from 0.32861\n",
      "Epoch 668/4000\n",
      "25/25 - 0s - loss: 0.2216 - accuracy: 0.8885 - val_loss: 2.2787 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00668: val_loss did not improve from 0.32861\n",
      "Epoch 669/4000\n",
      "25/25 - 0s - loss: 0.2193 - accuracy: 0.8923 - val_loss: 2.3648 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00669: val_loss did not improve from 0.32861\n",
      "Epoch 670/4000\n",
      "25/25 - 0s - loss: 0.2248 - accuracy: 0.8936 - val_loss: 2.6133 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00670: val_loss did not improve from 0.32861\n",
      "Epoch 671/4000\n",
      "25/25 - 0s - loss: 0.2330 - accuracy: 0.8898 - val_loss: 2.4960 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00671: val_loss did not improve from 0.32861\n",
      "Epoch 672/4000\n",
      "25/25 - 0s - loss: 0.2294 - accuracy: 0.8807 - val_loss: 2.4170 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00672: val_loss did not improve from 0.32861\n",
      "Epoch 673/4000\n",
      "25/25 - 0s - loss: 0.2233 - accuracy: 0.8949 - val_loss: 2.3036 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00673: val_loss did not improve from 0.32861\n",
      "Epoch 674/4000\n",
      "25/25 - 0s - loss: 0.2208 - accuracy: 0.8949 - val_loss: 2.3185 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00674: val_loss did not improve from 0.32861\n",
      "Epoch 675/4000\n",
      "25/25 - 0s - loss: 0.2217 - accuracy: 0.8949 - val_loss: 2.2961 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00675: val_loss did not improve from 0.32861\n",
      "Epoch 676/4000\n",
      "25/25 - 0s - loss: 0.2207 - accuracy: 0.8949 - val_loss: 2.3325 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00676: val_loss did not improve from 0.32861\n",
      "Epoch 677/4000\n",
      "25/25 - 0s - loss: 0.2223 - accuracy: 0.8923 - val_loss: 2.4565 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00677: val_loss did not improve from 0.32861\n",
      "Epoch 678/4000\n",
      "25/25 - 0s - loss: 0.2217 - accuracy: 0.8936 - val_loss: 2.3505 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00678: val_loss did not improve from 0.32861\n",
      "Epoch 679/4000\n",
      "25/25 - 0s - loss: 0.2209 - accuracy: 0.8936 - val_loss: 2.3722 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00679: val_loss did not improve from 0.32861\n",
      "Epoch 680/4000\n",
      "25/25 - 0s - loss: 0.2197 - accuracy: 0.8949 - val_loss: 2.4231 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00680: val_loss did not improve from 0.32861\n",
      "Epoch 681/4000\n",
      "25/25 - 0s - loss: 0.2194 - accuracy: 0.8949 - val_loss: 2.5007 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00681: val_loss did not improve from 0.32861\n",
      "Epoch 682/4000\n",
      "25/25 - 0s - loss: 0.2277 - accuracy: 0.8885 - val_loss: 2.5199 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00682: val_loss did not improve from 0.32861\n",
      "Epoch 683/4000\n",
      "25/25 - 0s - loss: 0.2306 - accuracy: 0.8936 - val_loss: 2.5760 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00683: val_loss did not improve from 0.32861\n",
      "Epoch 684/4000\n",
      "25/25 - 0s - loss: 0.2318 - accuracy: 0.8923 - val_loss: 2.6212 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00684: val_loss did not improve from 0.32861\n",
      "Epoch 685/4000\n",
      "25/25 - 0s - loss: 0.2325 - accuracy: 0.8898 - val_loss: 2.6687 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00685: val_loss did not improve from 0.32861\n",
      "Epoch 686/4000\n",
      "25/25 - 0s - loss: 0.2203 - accuracy: 0.8949 - val_loss: 2.8676 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00686: val_loss did not improve from 0.32861\n",
      "Epoch 687/4000\n",
      "25/25 - 0s - loss: 0.2201 - accuracy: 0.8949 - val_loss: 2.9077 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00687: val_loss did not improve from 0.32861\n",
      "Epoch 688/4000\n",
      "25/25 - 0s - loss: 0.2193 - accuracy: 0.8923 - val_loss: 2.7918 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00688: val_loss did not improve from 0.32861\n",
      "Epoch 689/4000\n",
      "25/25 - 0s - loss: 0.2233 - accuracy: 0.8949 - val_loss: 2.7293 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00689: val_loss did not improve from 0.32861\n",
      "Epoch 690/4000\n",
      "25/25 - 0s - loss: 0.2217 - accuracy: 0.8975 - val_loss: 2.9739 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00690: val_loss did not improve from 0.32861\n",
      "Epoch 691/4000\n",
      "25/25 - 0s - loss: 0.2162 - accuracy: 0.8975 - val_loss: 3.0225 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00691: val_loss did not improve from 0.32861\n",
      "Epoch 692/4000\n",
      "25/25 - 0s - loss: 0.2193 - accuracy: 0.8949 - val_loss: 3.0135 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00692: val_loss did not improve from 0.32861\n",
      "Epoch 693/4000\n",
      "25/25 - 0s - loss: 0.2135 - accuracy: 0.9001 - val_loss: 3.0279 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00693: val_loss did not improve from 0.32861\n",
      "Epoch 694/4000\n",
      "25/25 - 0s - loss: 0.2141 - accuracy: 0.8975 - val_loss: 2.6856 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00694: val_loss did not improve from 0.32861\n",
      "Epoch 695/4000\n",
      "25/25 - 0s - loss: 0.2134 - accuracy: 0.8975 - val_loss: 2.6055 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00695: val_loss did not improve from 0.32861\n",
      "Epoch 696/4000\n",
      "25/25 - 0s - loss: 0.2147 - accuracy: 0.8936 - val_loss: 2.6137 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00696: val_loss did not improve from 0.32861\n",
      "Epoch 697/4000\n",
      "25/25 - 0s - loss: 0.2216 - accuracy: 0.8936 - val_loss: 2.3211 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00697: val_loss did not improve from 0.32861\n",
      "Epoch 698/4000\n",
      "25/25 - 0s - loss: 0.2192 - accuracy: 0.8975 - val_loss: 2.4376 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00698: val_loss did not improve from 0.32861\n",
      "Epoch 699/4000\n",
      "25/25 - 0s - loss: 0.2151 - accuracy: 0.8975 - val_loss: 2.6213 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00699: val_loss did not improve from 0.32861\n",
      "Epoch 700/4000\n",
      "25/25 - 0s - loss: 0.2172 - accuracy: 0.8988 - val_loss: 2.5105 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00700: val_loss did not improve from 0.32861\n",
      "Epoch 701/4000\n",
      "25/25 - 0s - loss: 0.2182 - accuracy: 0.8975 - val_loss: 2.5456 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00701: val_loss did not improve from 0.32861\n",
      "Epoch 702/4000\n",
      "25/25 - 0s - loss: 0.2184 - accuracy: 0.9001 - val_loss: 2.2645 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00702: val_loss did not improve from 0.32861\n",
      "Epoch 703/4000\n",
      "25/25 - 0s - loss: 0.2219 - accuracy: 0.8962 - val_loss: 2.4484 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00703: val_loss did not improve from 0.32861\n",
      "Epoch 704/4000\n",
      "25/25 - 0s - loss: 0.2192 - accuracy: 0.8911 - val_loss: 2.3624 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00704: val_loss did not improve from 0.32861\n",
      "Epoch 705/4000\n",
      "25/25 - 0s - loss: 0.2354 - accuracy: 0.9001 - val_loss: 2.5525 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00705: val_loss did not improve from 0.32861\n",
      "Epoch 706/4000\n",
      "25/25 - 0s - loss: 0.2189 - accuracy: 0.8988 - val_loss: 2.8147 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00706: val_loss did not improve from 0.32861\n",
      "Epoch 707/4000\n",
      "25/25 - 0s - loss: 0.2179 - accuracy: 0.8975 - val_loss: 3.0211 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00707: val_loss did not improve from 0.32861\n",
      "Epoch 708/4000\n",
      "25/25 - 0s - loss: 0.2170 - accuracy: 0.8975 - val_loss: 2.8818 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00708: val_loss did not improve from 0.32861\n",
      "Epoch 709/4000\n",
      "25/25 - 0s - loss: 0.2180 - accuracy: 0.8936 - val_loss: 2.8667 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00709: val_loss did not improve from 0.32861\n",
      "Epoch 710/4000\n",
      "25/25 - 0s - loss: 0.2159 - accuracy: 0.8988 - val_loss: 2.9550 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00710: val_loss did not improve from 0.32861\n",
      "Epoch 711/4000\n",
      "25/25 - 0s - loss: 0.2144 - accuracy: 0.8962 - val_loss: 3.0215 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00711: val_loss did not improve from 0.32861\n",
      "Epoch 712/4000\n",
      "25/25 - 0s - loss: 0.2133 - accuracy: 0.9014 - val_loss: 3.0364 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00712: val_loss did not improve from 0.32861\n",
      "Epoch 713/4000\n",
      "25/25 - 0s - loss: 0.2115 - accuracy: 0.9001 - val_loss: 3.0237 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00713: val_loss did not improve from 0.32861\n",
      "Epoch 714/4000\n",
      "25/25 - 0s - loss: 0.2166 - accuracy: 0.8911 - val_loss: 2.9478 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00714: val_loss did not improve from 0.32861\n",
      "Epoch 715/4000\n",
      "25/25 - 0s - loss: 0.2121 - accuracy: 0.8962 - val_loss: 2.9962 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00715: val_loss did not improve from 0.32861\n",
      "Epoch 716/4000\n",
      "25/25 - 0s - loss: 0.2135 - accuracy: 0.8975 - val_loss: 3.0800 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00716: val_loss did not improve from 0.32861\n",
      "Epoch 717/4000\n",
      "25/25 - 0s - loss: 0.2155 - accuracy: 0.8949 - val_loss: 3.0880 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00717: val_loss did not improve from 0.32861\n",
      "Epoch 718/4000\n",
      "25/25 - 0s - loss: 0.2125 - accuracy: 0.8975 - val_loss: 3.0181 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00718: val_loss did not improve from 0.32861\n",
      "Epoch 719/4000\n",
      "25/25 - 0s - loss: 0.2101 - accuracy: 0.8962 - val_loss: 3.1278 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00719: val_loss did not improve from 0.32861\n",
      "Epoch 720/4000\n",
      "25/25 - 0s - loss: 0.2125 - accuracy: 0.8988 - val_loss: 3.1379 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00720: val_loss did not improve from 0.32861\n",
      "Epoch 721/4000\n",
      "25/25 - 0s - loss: 0.2107 - accuracy: 0.8988 - val_loss: 3.2055 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00721: val_loss did not improve from 0.32861\n",
      "Epoch 722/4000\n",
      "25/25 - 0s - loss: 0.2104 - accuracy: 0.9014 - val_loss: 3.1989 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00722: val_loss did not improve from 0.32861\n",
      "Epoch 723/4000\n",
      "25/25 - 0s - loss: 0.2110 - accuracy: 0.9014 - val_loss: 3.1863 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00723: val_loss did not improve from 0.32861\n",
      "Epoch 724/4000\n",
      "25/25 - 0s - loss: 0.2138 - accuracy: 0.8988 - val_loss: 3.1939 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00724: val_loss did not improve from 0.32861\n",
      "Epoch 725/4000\n",
      "25/25 - 0s - loss: 0.2155 - accuracy: 0.8988 - val_loss: 3.2097 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00725: val_loss did not improve from 0.32861\n",
      "Epoch 726/4000\n",
      "25/25 - 0s - loss: 0.2143 - accuracy: 0.8962 - val_loss: 3.4278 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00726: val_loss did not improve from 0.32861\n",
      "Epoch 727/4000\n",
      "25/25 - 0s - loss: 0.2356 - accuracy: 0.9001 - val_loss: 2.7988 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00727: val_loss did not improve from 0.32861\n",
      "Epoch 728/4000\n",
      "25/25 - 0s - loss: 0.4801 - accuracy: 0.8820 - val_loss: 1.5074 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00728: val_loss did not improve from 0.32861\n",
      "Epoch 729/4000\n",
      "25/25 - 0s - loss: 0.2496 - accuracy: 0.8872 - val_loss: 2.0763 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00729: val_loss did not improve from 0.32861\n",
      "Epoch 730/4000\n",
      "25/25 - 0s - loss: 0.2491 - accuracy: 0.8872 - val_loss: 1.2357 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00730: val_loss did not improve from 0.32861\n",
      "Epoch 731/4000\n",
      "25/25 - 0s - loss: 0.2655 - accuracy: 0.8755 - val_loss: 1.3348 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00731: val_loss did not improve from 0.32861\n",
      "Epoch 732/4000\n",
      "25/25 - 0s - loss: 0.2804 - accuracy: 0.8664 - val_loss: 1.5015 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00732: val_loss did not improve from 0.32861\n",
      "Epoch 733/4000\n",
      "25/25 - 0s - loss: 0.2682 - accuracy: 0.8664 - val_loss: 2.1897 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00733: val_loss did not improve from 0.32861\n",
      "Epoch 734/4000\n",
      "25/25 - 0s - loss: 0.2500 - accuracy: 0.8846 - val_loss: 2.1712 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00734: val_loss did not improve from 0.32861\n",
      "Epoch 735/4000\n",
      "25/25 - 0s - loss: 0.2387 - accuracy: 0.8872 - val_loss: 2.5990 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00735: val_loss did not improve from 0.32861\n",
      "Epoch 736/4000\n",
      "25/25 - 0s - loss: 0.3018 - accuracy: 0.8846 - val_loss: 1.3506 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00736: val_loss did not improve from 0.32861\n",
      "Epoch 737/4000\n",
      "25/25 - 0s - loss: 0.2921 - accuracy: 0.8586 - val_loss: 1.6973 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00737: val_loss did not improve from 0.32861\n",
      "Epoch 738/4000\n",
      "25/25 - 0s - loss: 0.3196 - accuracy: 0.8846 - val_loss: 1.3571 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00738: val_loss did not improve from 0.32861\n",
      "Epoch 739/4000\n",
      "25/25 - 0s - loss: 0.3203 - accuracy: 0.8638 - val_loss: 3.0881 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00739: val_loss did not improve from 0.32861\n",
      "Epoch 740/4000\n",
      "25/25 - 0s - loss: 0.4077 - accuracy: 0.8457 - val_loss: 1.8437 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 00740: val_loss did not improve from 0.32861\n",
      "Epoch 741/4000\n",
      "25/25 - 0s - loss: 0.3233 - accuracy: 0.8690 - val_loss: 1.2673 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00741: val_loss did not improve from 0.32861\n",
      "Epoch 742/4000\n",
      "25/25 - 0s - loss: 0.3485 - accuracy: 0.8444 - val_loss: 1.1693 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 00742: val_loss did not improve from 0.32861\n",
      "Epoch 743/4000\n",
      "25/25 - 0s - loss: 0.2636 - accuracy: 0.8586 - val_loss: 1.4220 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00743: val_loss did not improve from 0.32861\n",
      "Epoch 744/4000\n",
      "25/25 - 0s - loss: 0.2512 - accuracy: 0.8677 - val_loss: 1.4972 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00744: val_loss did not improve from 0.32861\n",
      "Epoch 745/4000\n",
      "25/25 - 0s - loss: 0.2328 - accuracy: 0.8846 - val_loss: 1.4597 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00745: val_loss did not improve from 0.32861\n",
      "Epoch 746/4000\n",
      "25/25 - 0s - loss: 0.2335 - accuracy: 0.8885 - val_loss: 1.5327 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00746: val_loss did not improve from 0.32861\n",
      "Epoch 747/4000\n",
      "25/25 - 0s - loss: 0.2328 - accuracy: 0.8872 - val_loss: 1.6907 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00747: val_loss did not improve from 0.32861\n",
      "Epoch 748/4000\n",
      "25/25 - 0s - loss: 0.2340 - accuracy: 0.8872 - val_loss: 1.7049 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00748: val_loss did not improve from 0.32861\n",
      "Epoch 749/4000\n",
      "25/25 - 0s - loss: 0.2255 - accuracy: 0.8911 - val_loss: 1.7380 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00749: val_loss did not improve from 0.32861\n",
      "Epoch 750/4000\n",
      "25/25 - 0s - loss: 0.2269 - accuracy: 0.8936 - val_loss: 1.7227 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00750: val_loss did not improve from 0.32861\n",
      "Epoch 751/4000\n",
      "25/25 - 0s - loss: 0.2339 - accuracy: 0.8975 - val_loss: 1.8574 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00751: val_loss did not improve from 0.32861\n",
      "Epoch 752/4000\n",
      "25/25 - 0s - loss: 0.2350 - accuracy: 0.8949 - val_loss: 1.7705 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00752: val_loss did not improve from 0.32861\n",
      "Epoch 753/4000\n",
      "25/25 - 0s - loss: 0.2294 - accuracy: 0.8923 - val_loss: 1.9704 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00753: val_loss did not improve from 0.32861\n",
      "Epoch 754/4000\n",
      "25/25 - 0s - loss: 0.2291 - accuracy: 0.8885 - val_loss: 2.4471 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00754: val_loss did not improve from 0.32861\n",
      "Epoch 755/4000\n",
      "25/25 - 0s - loss: 0.2281 - accuracy: 0.8859 - val_loss: 2.7822 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00755: val_loss did not improve from 0.32861\n",
      "Epoch 756/4000\n",
      "25/25 - 0s - loss: 0.2278 - accuracy: 0.8911 - val_loss: 2.7961 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00756: val_loss did not improve from 0.32861\n",
      "Epoch 757/4000\n",
      "25/25 - 0s - loss: 0.2378 - accuracy: 0.8872 - val_loss: 2.4635 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00757: val_loss did not improve from 0.32861\n",
      "Epoch 758/4000\n",
      "25/25 - 0s - loss: 0.2309 - accuracy: 0.8768 - val_loss: 2.6514 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00758: val_loss did not improve from 0.32861\n",
      "Epoch 759/4000\n",
      "25/25 - 0s - loss: 0.2296 - accuracy: 0.8923 - val_loss: 2.6357 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00759: val_loss did not improve from 0.32861\n",
      "Epoch 760/4000\n",
      "25/25 - 0s - loss: 0.2233 - accuracy: 0.8923 - val_loss: 2.6868 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00760: val_loss did not improve from 0.32861\n",
      "Epoch 761/4000\n",
      "25/25 - 0s - loss: 0.2254 - accuracy: 0.8923 - val_loss: 2.7847 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00761: val_loss did not improve from 0.32861\n",
      "Epoch 762/4000\n",
      "25/25 - 0s - loss: 0.2254 - accuracy: 0.8923 - val_loss: 2.6238 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00762: val_loss did not improve from 0.32861\n",
      "Epoch 763/4000\n",
      "25/25 - 0s - loss: 0.2236 - accuracy: 0.8923 - val_loss: 2.7933 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00763: val_loss did not improve from 0.32861\n",
      "Epoch 764/4000\n",
      "25/25 - 0s - loss: 0.2217 - accuracy: 0.8923 - val_loss: 2.7659 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00764: val_loss did not improve from 0.32861\n",
      "Epoch 765/4000\n",
      "25/25 - 0s - loss: 0.2224 - accuracy: 0.8923 - val_loss: 2.8533 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00765: val_loss did not improve from 0.32861\n",
      "Epoch 766/4000\n",
      "25/25 - 0s - loss: 0.2277 - accuracy: 0.8911 - val_loss: 3.0501 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00766: val_loss did not improve from 0.32861\n",
      "Epoch 767/4000\n",
      "25/25 - 0s - loss: 0.2252 - accuracy: 0.8923 - val_loss: 3.1472 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00767: val_loss did not improve from 0.32861\n",
      "Epoch 768/4000\n",
      "25/25 - 0s - loss: 0.2285 - accuracy: 0.8923 - val_loss: 3.1618 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00768: val_loss did not improve from 0.32861\n",
      "Epoch 769/4000\n",
      "25/25 - 0s - loss: 0.2204 - accuracy: 0.8923 - val_loss: 2.9910 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00769: val_loss did not improve from 0.32861\n",
      "Epoch 770/4000\n",
      "25/25 - 0s - loss: 0.2253 - accuracy: 0.8936 - val_loss: 3.1791 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00770: val_loss did not improve from 0.32861\n",
      "Epoch 771/4000\n",
      "25/25 - 0s - loss: 0.2219 - accuracy: 0.8923 - val_loss: 3.1696 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00771: val_loss did not improve from 0.32861\n",
      "Epoch 772/4000\n",
      "25/25 - 0s - loss: 0.2220 - accuracy: 0.8923 - val_loss: 3.1888 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00772: val_loss did not improve from 0.32861\n",
      "Epoch 773/4000\n",
      "25/25 - 0s - loss: 0.2200 - accuracy: 0.8923 - val_loss: 3.2057 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00773: val_loss did not improve from 0.32861\n",
      "Epoch 774/4000\n",
      "25/25 - 0s - loss: 0.2240 - accuracy: 0.8923 - val_loss: 3.0904 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00774: val_loss did not improve from 0.32861\n",
      "Epoch 775/4000\n",
      "25/25 - 0s - loss: 0.2260 - accuracy: 0.8911 - val_loss: 3.0045 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00775: val_loss did not improve from 0.32861\n",
      "Epoch 776/4000\n",
      "25/25 - 0s - loss: 0.2203 - accuracy: 0.8923 - val_loss: 3.1472 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00776: val_loss did not improve from 0.32861\n",
      "Epoch 777/4000\n",
      "25/25 - 0s - loss: 0.2227 - accuracy: 0.8923 - val_loss: 3.4070 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00777: val_loss did not improve from 0.32861\n",
      "Epoch 778/4000\n",
      "25/25 - 0s - loss: 0.2266 - accuracy: 0.8911 - val_loss: 3.4859 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00778: val_loss did not improve from 0.32861\n",
      "Epoch 779/4000\n",
      "25/25 - 0s - loss: 0.2194 - accuracy: 0.8923 - val_loss: 3.4988 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00779: val_loss did not improve from 0.32861\n",
      "Epoch 780/4000\n",
      "25/25 - 0s - loss: 0.2258 - accuracy: 0.8923 - val_loss: 3.9153 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00780: val_loss did not improve from 0.32861\n",
      "Epoch 781/4000\n",
      "25/25 - 0s - loss: 0.2256 - accuracy: 0.8885 - val_loss: 3.8927 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00781: val_loss did not improve from 0.32861\n",
      "Epoch 782/4000\n",
      "25/25 - 0s - loss: 0.2179 - accuracy: 0.8923 - val_loss: 3.8959 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00782: val_loss did not improve from 0.32861\n",
      "Epoch 783/4000\n",
      "25/25 - 0s - loss: 0.2238 - accuracy: 0.8898 - val_loss: 3.8634 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00783: val_loss did not improve from 0.32861\n",
      "Epoch 784/4000\n",
      "25/25 - 0s - loss: 0.2215 - accuracy: 0.8923 - val_loss: 4.0682 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00784: val_loss did not improve from 0.32861\n",
      "Epoch 785/4000\n",
      "25/25 - 0s - loss: 0.2209 - accuracy: 0.8923 - val_loss: 3.8773 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00785: val_loss did not improve from 0.32861\n",
      "Epoch 786/4000\n",
      "25/25 - 0s - loss: 0.2206 - accuracy: 0.8923 - val_loss: 3.9134 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00786: val_loss did not improve from 0.32861\n",
      "Epoch 787/4000\n",
      "25/25 - 0s - loss: 0.2200 - accuracy: 0.8885 - val_loss: 3.8360 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00787: val_loss did not improve from 0.32861\n",
      "Epoch 788/4000\n",
      "25/25 - 0s - loss: 0.2307 - accuracy: 0.8781 - val_loss: 3.7048 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00788: val_loss did not improve from 0.32861\n",
      "Epoch 789/4000\n",
      "25/25 - 0s - loss: 0.2239 - accuracy: 0.8872 - val_loss: 4.0807 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00789: val_loss did not improve from 0.32861\n",
      "Epoch 790/4000\n",
      "25/25 - 0s - loss: 0.2254 - accuracy: 0.8923 - val_loss: 4.1076 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00790: val_loss did not improve from 0.32861\n",
      "Epoch 791/4000\n",
      "25/25 - 0s - loss: 0.2222 - accuracy: 0.8962 - val_loss: 4.2095 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00791: val_loss did not improve from 0.32861\n",
      "Epoch 792/4000\n",
      "25/25 - 0s - loss: 0.2325 - accuracy: 0.8768 - val_loss: 3.8554 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00792: val_loss did not improve from 0.32861\n",
      "Epoch 793/4000\n",
      "25/25 - 0s - loss: 0.2237 - accuracy: 0.8923 - val_loss: 3.3421 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00793: val_loss did not improve from 0.32861\n",
      "Epoch 794/4000\n",
      "25/25 - 0s - loss: 0.2315 - accuracy: 0.8781 - val_loss: 3.9073 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00794: val_loss did not improve from 0.32861\n",
      "Epoch 795/4000\n",
      "25/25 - 0s - loss: 0.2231 - accuracy: 0.8923 - val_loss: 4.1647 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00795: val_loss did not improve from 0.32861\n",
      "Epoch 796/4000\n",
      "25/25 - 0s - loss: 0.2189 - accuracy: 0.8923 - val_loss: 4.1188 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00796: val_loss did not improve from 0.32861\n",
      "Epoch 797/4000\n",
      "25/25 - 0s - loss: 0.2189 - accuracy: 0.8923 - val_loss: 4.1027 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00797: val_loss did not improve from 0.32861\n",
      "Epoch 798/4000\n",
      "25/25 - 0s - loss: 0.2217 - accuracy: 0.8911 - val_loss: 4.0681 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00798: val_loss did not improve from 0.32861\n",
      "Epoch 799/4000\n",
      "25/25 - 0s - loss: 0.2201 - accuracy: 0.8923 - val_loss: 3.8512 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00799: val_loss did not improve from 0.32861\n",
      "Epoch 800/4000\n",
      "25/25 - 0s - loss: 0.2216 - accuracy: 0.8923 - val_loss: 3.9163 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00800: val_loss did not improve from 0.32861\n",
      "Epoch 801/4000\n",
      "25/25 - 0s - loss: 0.2179 - accuracy: 0.8923 - val_loss: 3.9269 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00801: val_loss did not improve from 0.32861\n",
      "Epoch 802/4000\n",
      "25/25 - 0s - loss: 0.2205 - accuracy: 0.8923 - val_loss: 3.9059 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00802: val_loss did not improve from 0.32861\n",
      "Epoch 803/4000\n",
      "25/25 - 0s - loss: 0.2185 - accuracy: 0.8923 - val_loss: 3.9486 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00803: val_loss did not improve from 0.32861\n",
      "Epoch 804/4000\n",
      "25/25 - 0s - loss: 0.2187 - accuracy: 0.8923 - val_loss: 4.0401 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00804: val_loss did not improve from 0.32861\n",
      "Epoch 805/4000\n",
      "25/25 - 0s - loss: 0.2197 - accuracy: 0.8962 - val_loss: 4.1061 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00805: val_loss did not improve from 0.32861\n",
      "Epoch 806/4000\n",
      "25/25 - 0s - loss: 0.2180 - accuracy: 0.8962 - val_loss: 4.0813 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00806: val_loss did not improve from 0.32861\n",
      "Epoch 807/4000\n",
      "25/25 - 0s - loss: 0.2215 - accuracy: 0.8962 - val_loss: 4.2511 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00807: val_loss did not improve from 0.32861\n",
      "Epoch 808/4000\n",
      "25/25 - 0s - loss: 0.2218 - accuracy: 0.8936 - val_loss: 4.1696 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00808: val_loss did not improve from 0.32861\n",
      "Epoch 809/4000\n",
      "25/25 - 0s - loss: 0.2203 - accuracy: 0.8975 - val_loss: 4.8169 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00809: val_loss did not improve from 0.32861\n",
      "Epoch 810/4000\n",
      "25/25 - 0s - loss: 0.2157 - accuracy: 0.8975 - val_loss: 4.8687 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00810: val_loss did not improve from 0.32861\n",
      "Epoch 811/4000\n",
      "25/25 - 0s - loss: 0.2314 - accuracy: 0.8923 - val_loss: 5.4260 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00811: val_loss did not improve from 0.32861\n",
      "Epoch 812/4000\n",
      "25/25 - 0s - loss: 0.2407 - accuracy: 0.8690 - val_loss: 6.0107 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00812: val_loss did not improve from 0.32861\n",
      "Epoch 813/4000\n",
      "25/25 - 0s - loss: 0.2326 - accuracy: 0.8872 - val_loss: 5.4074 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00813: val_loss did not improve from 0.32861\n",
      "Epoch 814/4000\n",
      "25/25 - 0s - loss: 0.2293 - accuracy: 0.8872 - val_loss: 4.9212 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00814: val_loss did not improve from 0.32861\n",
      "Epoch 815/4000\n",
      "25/25 - 0s - loss: 0.2251 - accuracy: 0.8898 - val_loss: 4.7911 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00815: val_loss did not improve from 0.32861\n",
      "Epoch 816/4000\n",
      "25/25 - 0s - loss: 0.2256 - accuracy: 0.8885 - val_loss: 5.3786 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00816: val_loss did not improve from 0.32861\n",
      "Epoch 817/4000\n",
      "25/25 - 0s - loss: 0.2300 - accuracy: 0.8859 - val_loss: 4.8160 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00817: val_loss did not improve from 0.32861\n",
      "Epoch 818/4000\n",
      "25/25 - 0s - loss: 0.2255 - accuracy: 0.8898 - val_loss: 5.3303 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00818: val_loss did not improve from 0.32861\n",
      "Epoch 819/4000\n",
      "25/25 - 0s - loss: 0.2260 - accuracy: 0.8872 - val_loss: 5.5799 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00819: val_loss did not improve from 0.32861\n",
      "Epoch 820/4000\n",
      "25/25 - 0s - loss: 0.2214 - accuracy: 0.8923 - val_loss: 6.7438 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00820: val_loss did not improve from 0.32861\n",
      "Epoch 821/4000\n",
      "25/25 - 0s - loss: 0.3834 - accuracy: 0.8898 - val_loss: 6.9826 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00821: val_loss did not improve from 0.32861\n",
      "Epoch 822/4000\n",
      "25/25 - 0s - loss: 0.3770 - accuracy: 0.8729 - val_loss: 3.9261 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00822: val_loss did not improve from 0.32861\n",
      "Epoch 823/4000\n",
      "25/25 - 0s - loss: 0.3520 - accuracy: 0.8690 - val_loss: 3.5190 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00823: val_loss did not improve from 0.32861\n",
      "Epoch 824/4000\n",
      "25/25 - 0s - loss: 0.2977 - accuracy: 0.8560 - val_loss: 3.1591 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00824: val_loss did not improve from 0.32861\n",
      "Epoch 825/4000\n",
      "25/25 - 0s - loss: 0.3598 - accuracy: 0.8768 - val_loss: 2.7468 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00825: val_loss did not improve from 0.32861\n",
      "Epoch 826/4000\n",
      "25/25 - 0s - loss: 0.3157 - accuracy: 0.8664 - val_loss: 3.1981 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 00826: val_loss did not improve from 0.32861\n",
      "Epoch 827/4000\n",
      "25/25 - 0s - loss: 0.3256 - accuracy: 0.8599 - val_loss: 4.7094 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 00827: val_loss did not improve from 0.32861\n",
      "Epoch 828/4000\n",
      "25/25 - 0s - loss: 0.5444 - accuracy: 0.8470 - val_loss: 2.2924 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00828: val_loss did not improve from 0.32861\n",
      "Epoch 829/4000\n",
      "25/25 - 0s - loss: 0.4331 - accuracy: 0.8431 - val_loss: 1.3124 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00829: val_loss did not improve from 0.32861\n",
      "Epoch 830/4000\n",
      "25/25 - 0s - loss: 0.3436 - accuracy: 0.8392 - val_loss: 1.2138 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00830: val_loss did not improve from 0.32861\n",
      "Epoch 831/4000\n",
      "25/25 - 0s - loss: 0.3071 - accuracy: 0.8560 - val_loss: 1.5752 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00831: val_loss did not improve from 0.32861\n",
      "Epoch 832/4000\n",
      "25/25 - 0s - loss: 0.2740 - accuracy: 0.8742 - val_loss: 1.5907 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00832: val_loss did not improve from 0.32861\n",
      "Epoch 833/4000\n",
      "25/25 - 0s - loss: 0.2586 - accuracy: 0.8859 - val_loss: 1.6691 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00833: val_loss did not improve from 0.32861\n",
      "Epoch 834/4000\n",
      "25/25 - 0s - loss: 0.2557 - accuracy: 0.8833 - val_loss: 1.7722 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00834: val_loss did not improve from 0.32861\n",
      "Epoch 835/4000\n",
      "25/25 - 0s - loss: 0.2573 - accuracy: 0.8820 - val_loss: 1.8431 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00835: val_loss did not improve from 0.32861\n",
      "Epoch 836/4000\n",
      "25/25 - 0s - loss: 0.2585 - accuracy: 0.8677 - val_loss: 1.9147 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00836: val_loss did not improve from 0.32861\n",
      "Epoch 837/4000\n",
      "25/25 - 0s - loss: 0.2436 - accuracy: 0.8716 - val_loss: 1.9459 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00837: val_loss did not improve from 0.32861\n",
      "Epoch 838/4000\n",
      "25/25 - 0s - loss: 0.2427 - accuracy: 0.8781 - val_loss: 1.7554 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00838: val_loss did not improve from 0.32861\n",
      "Epoch 839/4000\n",
      "25/25 - 0s - loss: 0.2351 - accuracy: 0.8781 - val_loss: 1.9001 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00839: val_loss did not improve from 0.32861\n",
      "Epoch 840/4000\n",
      "25/25 - 0s - loss: 0.2384 - accuracy: 0.8820 - val_loss: 1.7485 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00840: val_loss did not improve from 0.32861\n",
      "Epoch 841/4000\n",
      "25/25 - 0s - loss: 0.2263 - accuracy: 0.8885 - val_loss: 1.7086 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00841: val_loss did not improve from 0.32861\n",
      "Epoch 842/4000\n",
      "25/25 - 0s - loss: 0.2289 - accuracy: 0.8833 - val_loss: 1.6906 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00842: val_loss did not improve from 0.32861\n",
      "Epoch 843/4000\n",
      "25/25 - 0s - loss: 0.2250 - accuracy: 0.8936 - val_loss: 1.7369 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00843: val_loss did not improve from 0.32861\n",
      "Epoch 844/4000\n",
      "25/25 - 0s - loss: 0.2300 - accuracy: 0.8885 - val_loss: 1.9422 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00844: val_loss did not improve from 0.32861\n",
      "Epoch 845/4000\n",
      "25/25 - 0s - loss: 0.2299 - accuracy: 0.8936 - val_loss: 1.9508 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00845: val_loss did not improve from 0.32861\n",
      "Epoch 846/4000\n",
      "25/25 - 0s - loss: 0.2355 - accuracy: 0.8949 - val_loss: 1.9049 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00846: val_loss did not improve from 0.32861\n",
      "Epoch 847/4000\n",
      "25/25 - 0s - loss: 0.2324 - accuracy: 0.8885 - val_loss: 1.9179 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00847: val_loss did not improve from 0.32861\n",
      "Epoch 848/4000\n",
      "25/25 - 0s - loss: 0.2287 - accuracy: 0.8846 - val_loss: 1.8310 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00848: val_loss did not improve from 0.32861\n",
      "Epoch 849/4000\n",
      "25/25 - 0s - loss: 0.2308 - accuracy: 0.8846 - val_loss: 1.7707 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00849: val_loss did not improve from 0.32861\n",
      "Epoch 850/4000\n",
      "25/25 - 0s - loss: 0.2309 - accuracy: 0.8872 - val_loss: 1.8065 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00850: val_loss did not improve from 0.32861\n",
      "Epoch 851/4000\n",
      "25/25 - 0s - loss: 0.2264 - accuracy: 0.8885 - val_loss: 1.7922 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00851: val_loss did not improve from 0.32861\n",
      "Epoch 852/4000\n",
      "25/25 - 0s - loss: 0.2272 - accuracy: 0.8885 - val_loss: 1.8771 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00852: val_loss did not improve from 0.32861\n",
      "Epoch 853/4000\n",
      "25/25 - 0s - loss: 0.2293 - accuracy: 0.8872 - val_loss: 1.8583 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00853: val_loss did not improve from 0.32861\n",
      "Epoch 854/4000\n",
      "25/25 - 0s - loss: 0.2288 - accuracy: 0.8872 - val_loss: 1.6334 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00854: val_loss did not improve from 0.32861\n",
      "Epoch 855/4000\n",
      "25/25 - 0s - loss: 0.2312 - accuracy: 0.8859 - val_loss: 1.6600 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00855: val_loss did not improve from 0.32861\n",
      "Epoch 856/4000\n",
      "25/25 - 0s - loss: 0.2251 - accuracy: 0.8898 - val_loss: 1.7749 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00856: val_loss did not improve from 0.32861\n",
      "Epoch 857/4000\n",
      "25/25 - 0s - loss: 0.2484 - accuracy: 0.8703 - val_loss: 1.9192 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00857: val_loss did not improve from 0.32861\n",
      "Epoch 858/4000\n",
      "25/25 - 0s - loss: 0.2298 - accuracy: 0.8898 - val_loss: 1.7599 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00858: val_loss did not improve from 0.32861\n",
      "Epoch 859/4000\n",
      "25/25 - 0s - loss: 0.2237 - accuracy: 0.8936 - val_loss: 1.8148 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00859: val_loss did not improve from 0.32861\n",
      "Epoch 860/4000\n",
      "25/25 - 0s - loss: 0.2328 - accuracy: 0.8923 - val_loss: 1.5491 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00860: val_loss did not improve from 0.32861\n",
      "Epoch 861/4000\n",
      "25/25 - 0s - loss: 0.3103 - accuracy: 0.8846 - val_loss: 1.2783 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00861: val_loss did not improve from 0.32861\n",
      "Epoch 862/4000\n",
      "25/25 - 0s - loss: 0.2453 - accuracy: 0.8807 - val_loss: 1.2302 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00862: val_loss did not improve from 0.32861\n",
      "Epoch 863/4000\n",
      "25/25 - 0s - loss: 0.2346 - accuracy: 0.8898 - val_loss: 1.3170 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00863: val_loss did not improve from 0.32861\n",
      "Epoch 864/4000\n",
      "25/25 - 0s - loss: 0.2354 - accuracy: 0.8885 - val_loss: 1.4643 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00864: val_loss did not improve from 0.32861\n",
      "Epoch 865/4000\n",
      "25/25 - 0s - loss: 0.2575 - accuracy: 0.8923 - val_loss: 3.1465 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00865: val_loss did not improve from 0.32861\n",
      "Epoch 866/4000\n",
      "25/25 - 0s - loss: 0.2408 - accuracy: 0.8898 - val_loss: 1.8226 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00866: val_loss did not improve from 0.32861\n",
      "Epoch 867/4000\n",
      "25/25 - 0s - loss: 0.2281 - accuracy: 0.8885 - val_loss: 1.8636 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00867: val_loss did not improve from 0.32861\n",
      "Epoch 868/4000\n",
      "25/25 - 0s - loss: 0.2296 - accuracy: 0.8898 - val_loss: 1.6579 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00868: val_loss did not improve from 0.32861\n",
      "Epoch 869/4000\n",
      "25/25 - 0s - loss: 0.2331 - accuracy: 0.8807 - val_loss: 1.3804 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00869: val_loss did not improve from 0.32861\n",
      "Epoch 870/4000\n",
      "25/25 - 0s - loss: 0.2752 - accuracy: 0.8742 - val_loss: 1.5961 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00870: val_loss did not improve from 0.32861\n",
      "Epoch 871/4000\n",
      "25/25 - 0s - loss: 0.2436 - accuracy: 0.8885 - val_loss: 1.5234 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00871: val_loss did not improve from 0.32861\n",
      "Epoch 872/4000\n",
      "25/25 - 0s - loss: 0.2630 - accuracy: 0.8768 - val_loss: 2.0110 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00872: val_loss did not improve from 0.32861\n",
      "Epoch 873/4000\n",
      "25/25 - 0s - loss: 0.2330 - accuracy: 0.8781 - val_loss: 1.9595 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00873: val_loss did not improve from 0.32861\n",
      "Epoch 874/4000\n",
      "25/25 - 0s - loss: 0.2277 - accuracy: 0.8923 - val_loss: 2.1995 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00874: val_loss did not improve from 0.32861\n",
      "Epoch 875/4000\n",
      "25/25 - 0s - loss: 0.2318 - accuracy: 0.8949 - val_loss: 2.2402 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00875: val_loss did not improve from 0.32861\n",
      "Epoch 876/4000\n",
      "25/25 - 0s - loss: 0.2295 - accuracy: 0.8936 - val_loss: 1.8745 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00876: val_loss did not improve from 0.32861\n",
      "Epoch 877/4000\n",
      "25/25 - 0s - loss: 0.2319 - accuracy: 0.8911 - val_loss: 1.7769 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00877: val_loss did not improve from 0.32861\n",
      "Epoch 878/4000\n",
      "25/25 - 0s - loss: 0.2252 - accuracy: 0.8936 - val_loss: 2.0584 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00878: val_loss did not improve from 0.32861\n",
      "Epoch 879/4000\n",
      "25/25 - 0s - loss: 0.2218 - accuracy: 0.8936 - val_loss: 2.1203 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00879: val_loss did not improve from 0.32861\n",
      "Epoch 880/4000\n",
      "25/25 - 0s - loss: 0.2181 - accuracy: 0.8923 - val_loss: 2.1695 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00880: val_loss did not improve from 0.32861\n",
      "Epoch 881/4000\n",
      "25/25 - 0s - loss: 0.2304 - accuracy: 0.8923 - val_loss: 2.1762 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00881: val_loss did not improve from 0.32861\n",
      "Epoch 882/4000\n",
      "25/25 - 0s - loss: 0.2360 - accuracy: 0.8923 - val_loss: 2.4244 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00882: val_loss did not improve from 0.32861\n",
      "Epoch 883/4000\n",
      "25/25 - 0s - loss: 0.2264 - accuracy: 0.8923 - val_loss: 2.2475 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00883: val_loss did not improve from 0.32861\n",
      "Epoch 884/4000\n",
      "25/25 - 0s - loss: 0.2226 - accuracy: 0.8911 - val_loss: 2.1778 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00884: val_loss did not improve from 0.32861\n",
      "Epoch 885/4000\n",
      "25/25 - 0s - loss: 0.2226 - accuracy: 0.8936 - val_loss: 1.9444 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00885: val_loss did not improve from 0.32861\n",
      "Epoch 886/4000\n",
      "25/25 - 0s - loss: 0.2269 - accuracy: 0.8885 - val_loss: 2.1027 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00886: val_loss did not improve from 0.32861\n",
      "Epoch 887/4000\n",
      "25/25 - 0s - loss: 0.2186 - accuracy: 0.8962 - val_loss: 2.2125 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00887: val_loss did not improve from 0.32861\n",
      "Epoch 888/4000\n",
      "25/25 - 0s - loss: 0.2196 - accuracy: 0.8898 - val_loss: 2.3045 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00888: val_loss did not improve from 0.32861\n",
      "Epoch 889/4000\n",
      "25/25 - 0s - loss: 0.2188 - accuracy: 0.8936 - val_loss: 2.3458 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00889: val_loss did not improve from 0.32861\n",
      "Epoch 890/4000\n",
      "25/25 - 0s - loss: 0.2222 - accuracy: 0.8872 - val_loss: 2.4497 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00890: val_loss did not improve from 0.32861\n",
      "Epoch 891/4000\n",
      "25/25 - 0s - loss: 0.2224 - accuracy: 0.8936 - val_loss: 2.7027 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00891: val_loss did not improve from 0.32861\n",
      "Epoch 892/4000\n",
      "25/25 - 0s - loss: 0.2293 - accuracy: 0.8911 - val_loss: 2.5705 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00892: val_loss did not improve from 0.32861\n",
      "Epoch 893/4000\n",
      "25/25 - 0s - loss: 0.2235 - accuracy: 0.8911 - val_loss: 2.5263 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00893: val_loss did not improve from 0.32861\n",
      "Epoch 894/4000\n",
      "25/25 - 0s - loss: 0.2165 - accuracy: 0.8923 - val_loss: 2.3486 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00894: val_loss did not improve from 0.32861\n",
      "Epoch 895/4000\n",
      "25/25 - 0s - loss: 0.2166 - accuracy: 0.8911 - val_loss: 2.4752 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00895: val_loss did not improve from 0.32861\n",
      "Epoch 896/4000\n",
      "25/25 - 0s - loss: 0.2157 - accuracy: 0.8923 - val_loss: 2.4239 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00896: val_loss did not improve from 0.32861\n",
      "Epoch 897/4000\n",
      "25/25 - 0s - loss: 0.2138 - accuracy: 0.8923 - val_loss: 2.4723 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00897: val_loss did not improve from 0.32861\n",
      "Epoch 898/4000\n",
      "25/25 - 0s - loss: 0.2149 - accuracy: 0.8911 - val_loss: 2.6078 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00898: val_loss did not improve from 0.32861\n",
      "Epoch 899/4000\n",
      "25/25 - 0s - loss: 0.4206 - accuracy: 0.8703 - val_loss: 5.5678 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00899: val_loss did not improve from 0.32861\n",
      "Epoch 900/4000\n",
      "25/25 - 0s - loss: 0.4721 - accuracy: 0.8158 - val_loss: 1.2679 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 00900: val_loss did not improve from 0.32861\n",
      "Epoch 901/4000\n",
      "25/25 - 0s - loss: 0.3491 - accuracy: 0.8288 - val_loss: 1.3736 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00901: val_loss did not improve from 0.32861\n",
      "Epoch 902/4000\n",
      "25/25 - 0s - loss: 0.3048 - accuracy: 0.8521 - val_loss: 0.9571 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00902: val_loss did not improve from 0.32861\n",
      "Epoch 903/4000\n",
      "25/25 - 0s - loss: 0.2801 - accuracy: 0.8729 - val_loss: 1.0327 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00903: val_loss did not improve from 0.32861\n",
      "Epoch 904/4000\n",
      "25/25 - 0s - loss: 0.2679 - accuracy: 0.8755 - val_loss: 1.0510 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00904: val_loss did not improve from 0.32861\n",
      "Epoch 905/4000\n",
      "25/25 - 0s - loss: 0.2508 - accuracy: 0.8807 - val_loss: 1.0885 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00905: val_loss did not improve from 0.32861\n",
      "Epoch 906/4000\n",
      "25/25 - 0s - loss: 0.2700 - accuracy: 0.8833 - val_loss: 1.0815 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00906: val_loss did not improve from 0.32861\n",
      "Epoch 907/4000\n",
      "25/25 - 0s - loss: 0.2744 - accuracy: 0.8703 - val_loss: 1.1274 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00907: val_loss did not improve from 0.32861\n",
      "Epoch 908/4000\n",
      "25/25 - 0s - loss: 0.2484 - accuracy: 0.8781 - val_loss: 1.2505 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00908: val_loss did not improve from 0.32861\n",
      "Epoch 909/4000\n",
      "25/25 - 0s - loss: 0.2412 - accuracy: 0.8885 - val_loss: 1.2977 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00909: val_loss did not improve from 0.32861\n",
      "Epoch 910/4000\n",
      "25/25 - 0s - loss: 0.2363 - accuracy: 0.8820 - val_loss: 1.3502 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00910: val_loss did not improve from 0.32861\n",
      "Epoch 911/4000\n",
      "25/25 - 0s - loss: 0.2362 - accuracy: 0.8885 - val_loss: 1.3506 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00911: val_loss did not improve from 0.32861\n",
      "Epoch 912/4000\n",
      "25/25 - 0s - loss: 0.2374 - accuracy: 0.8911 - val_loss: 1.3680 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00912: val_loss did not improve from 0.32861\n",
      "Epoch 913/4000\n",
      "25/25 - 0s - loss: 0.2340 - accuracy: 0.8872 - val_loss: 1.3789 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00913: val_loss did not improve from 0.32861\n",
      "Epoch 914/4000\n",
      "25/25 - 0s - loss: 0.2366 - accuracy: 0.8820 - val_loss: 1.2823 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00914: val_loss did not improve from 0.32861\n",
      "Epoch 915/4000\n",
      "25/25 - 0s - loss: 0.2368 - accuracy: 0.8872 - val_loss: 1.3386 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00915: val_loss did not improve from 0.32861\n",
      "Epoch 916/4000\n",
      "25/25 - 0s - loss: 0.2347 - accuracy: 0.8898 - val_loss: 1.3685 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00916: val_loss did not improve from 0.32861\n",
      "Epoch 917/4000\n",
      "25/25 - 0s - loss: 0.2387 - accuracy: 0.8923 - val_loss: 1.3170 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00917: val_loss did not improve from 0.32861\n",
      "Epoch 918/4000\n",
      "25/25 - 0s - loss: 0.2333 - accuracy: 0.8885 - val_loss: 1.4084 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00918: val_loss did not improve from 0.32861\n",
      "Epoch 919/4000\n",
      "25/25 - 0s - loss: 0.2320 - accuracy: 0.8898 - val_loss: 1.4109 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00919: val_loss did not improve from 0.32861\n",
      "Epoch 920/4000\n",
      "25/25 - 0s - loss: 0.2299 - accuracy: 0.8949 - val_loss: 1.5033 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00920: val_loss did not improve from 0.32861\n",
      "Epoch 921/4000\n",
      "25/25 - 0s - loss: 0.2293 - accuracy: 0.8975 - val_loss: 1.4885 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00921: val_loss did not improve from 0.32861\n",
      "Epoch 922/4000\n",
      "25/25 - 0s - loss: 0.2280 - accuracy: 0.8962 - val_loss: 1.4923 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00922: val_loss did not improve from 0.32861\n",
      "Epoch 923/4000\n",
      "25/25 - 0s - loss: 0.2325 - accuracy: 0.8911 - val_loss: 1.4549 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00923: val_loss did not improve from 0.32861\n",
      "Epoch 924/4000\n",
      "25/25 - 0s - loss: 0.2337 - accuracy: 0.8975 - val_loss: 1.4191 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00924: val_loss did not improve from 0.32861\n",
      "Epoch 925/4000\n",
      "25/25 - 0s - loss: 0.2272 - accuracy: 0.8962 - val_loss: 1.5554 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00925: val_loss did not improve from 0.32861\n",
      "Epoch 926/4000\n",
      "25/25 - 0s - loss: 0.2291 - accuracy: 0.8936 - val_loss: 1.6066 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00926: val_loss did not improve from 0.32861\n",
      "Epoch 927/4000\n",
      "25/25 - 0s - loss: 0.2277 - accuracy: 0.8962 - val_loss: 1.5845 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00927: val_loss did not improve from 0.32861\n",
      "Epoch 928/4000\n",
      "25/25 - 0s - loss: 0.2261 - accuracy: 0.8962 - val_loss: 1.6105 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00928: val_loss did not improve from 0.32861\n",
      "Epoch 929/4000\n",
      "25/25 - 0s - loss: 0.2244 - accuracy: 0.8975 - val_loss: 1.6577 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00929: val_loss did not improve from 0.32861\n",
      "Epoch 930/4000\n",
      "25/25 - 0s - loss: 0.2249 - accuracy: 0.8962 - val_loss: 1.6918 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00930: val_loss did not improve from 0.32861\n",
      "Epoch 931/4000\n",
      "25/25 - 0s - loss: 0.2246 - accuracy: 0.8962 - val_loss: 1.7496 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00931: val_loss did not improve from 0.32861\n",
      "Epoch 932/4000\n",
      "25/25 - 0s - loss: 0.2238 - accuracy: 0.8975 - val_loss: 1.7815 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00932: val_loss did not improve from 0.32861\n",
      "Epoch 933/4000\n",
      "25/25 - 0s - loss: 0.2242 - accuracy: 0.8936 - val_loss: 1.8013 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00933: val_loss did not improve from 0.32861\n",
      "Epoch 934/4000\n",
      "25/25 - 0s - loss: 0.2240 - accuracy: 0.8962 - val_loss: 1.8564 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00934: val_loss did not improve from 0.32861\n",
      "Epoch 935/4000\n",
      "25/25 - 0s - loss: 0.2926 - accuracy: 0.8885 - val_loss: 1.3362 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00935: val_loss did not improve from 0.32861\n",
      "Epoch 936/4000\n",
      "25/25 - 0s - loss: 0.4266 - accuracy: 0.8690 - val_loss: 1.3717 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00936: val_loss did not improve from 0.32861\n",
      "Epoch 937/4000\n",
      "25/25 - 0s - loss: 0.2457 - accuracy: 0.8794 - val_loss: 1.0721 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00937: val_loss did not improve from 0.32861\n",
      "Epoch 938/4000\n",
      "25/25 - 0s - loss: 0.2348 - accuracy: 0.8872 - val_loss: 1.1183 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00938: val_loss did not improve from 0.32861\n",
      "Epoch 939/4000\n",
      "25/25 - 0s - loss: 0.2313 - accuracy: 0.8885 - val_loss: 1.1742 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00939: val_loss did not improve from 0.32861\n",
      "Epoch 940/4000\n",
      "25/25 - 0s - loss: 0.2354 - accuracy: 0.8872 - val_loss: 1.2161 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00940: val_loss did not improve from 0.32861\n",
      "Epoch 941/4000\n",
      "25/25 - 0s - loss: 0.2336 - accuracy: 0.8820 - val_loss: 1.3251 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00941: val_loss did not improve from 0.32861\n",
      "Epoch 942/4000\n",
      "25/25 - 0s - loss: 0.2328 - accuracy: 0.8936 - val_loss: 1.3492 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00942: val_loss did not improve from 0.32861\n",
      "Epoch 943/4000\n",
      "25/25 - 0s - loss: 0.2322 - accuracy: 0.8898 - val_loss: 1.3236 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00943: val_loss did not improve from 0.32861\n",
      "Epoch 944/4000\n",
      "25/25 - 0s - loss: 0.2329 - accuracy: 0.8885 - val_loss: 1.4843 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00944: val_loss did not improve from 0.32861\n",
      "Epoch 945/4000\n",
      "25/25 - 0s - loss: 0.2318 - accuracy: 0.8911 - val_loss: 1.5234 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00945: val_loss did not improve from 0.32861\n",
      "Epoch 946/4000\n",
      "25/25 - 0s - loss: 0.2285 - accuracy: 0.8885 - val_loss: 1.4502 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00946: val_loss did not improve from 0.32861\n",
      "Epoch 947/4000\n",
      "25/25 - 0s - loss: 0.2314 - accuracy: 0.8898 - val_loss: 1.4665 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00947: val_loss did not improve from 0.32861\n",
      "Epoch 948/4000\n",
      "25/25 - 0s - loss: 0.2308 - accuracy: 0.8885 - val_loss: 1.5799 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00948: val_loss did not improve from 0.32861\n",
      "Epoch 949/4000\n",
      "25/25 - 0s - loss: 0.2371 - accuracy: 0.8898 - val_loss: 1.5578 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00949: val_loss did not improve from 0.32861\n",
      "Epoch 950/4000\n",
      "25/25 - 0s - loss: 0.2305 - accuracy: 0.8923 - val_loss: 1.4689 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00950: val_loss did not improve from 0.32861\n",
      "Epoch 951/4000\n",
      "25/25 - 0s - loss: 0.2307 - accuracy: 0.8923 - val_loss: 1.2731 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00951: val_loss did not improve from 0.32861\n",
      "Epoch 952/4000\n",
      "25/25 - 0s - loss: 0.2342 - accuracy: 0.8846 - val_loss: 1.2803 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00952: val_loss did not improve from 0.32861\n",
      "Epoch 953/4000\n",
      "25/25 - 0s - loss: 0.2322 - accuracy: 0.8911 - val_loss: 1.3936 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00953: val_loss did not improve from 0.32861\n",
      "Epoch 954/4000\n",
      "25/25 - 0s - loss: 0.2295 - accuracy: 0.8898 - val_loss: 1.4355 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00954: val_loss did not improve from 0.32861\n",
      "Epoch 955/4000\n",
      "25/25 - 0s - loss: 0.2276 - accuracy: 0.8898 - val_loss: 1.4636 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00955: val_loss did not improve from 0.32861\n",
      "Epoch 956/4000\n",
      "25/25 - 0s - loss: 0.2294 - accuracy: 0.8923 - val_loss: 1.4663 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00956: val_loss did not improve from 0.32861\n",
      "Epoch 957/4000\n",
      "25/25 - 0s - loss: 0.2338 - accuracy: 0.8923 - val_loss: 1.5277 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00957: val_loss did not improve from 0.32861\n",
      "Epoch 958/4000\n",
      "25/25 - 0s - loss: 0.2314 - accuracy: 0.8872 - val_loss: 1.5274 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00958: val_loss did not improve from 0.32861\n",
      "Epoch 959/4000\n",
      "25/25 - 0s - loss: 0.2309 - accuracy: 0.8911 - val_loss: 1.5409 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00959: val_loss did not improve from 0.32861\n",
      "Epoch 960/4000\n",
      "25/25 - 0s - loss: 0.2329 - accuracy: 0.8923 - val_loss: 1.5749 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00960: val_loss did not improve from 0.32861\n",
      "Epoch 961/4000\n",
      "25/25 - 0s - loss: 0.2354 - accuracy: 0.8820 - val_loss: 1.6477 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00961: val_loss did not improve from 0.32861\n",
      "Epoch 962/4000\n",
      "25/25 - 0s - loss: 0.2269 - accuracy: 0.8923 - val_loss: 1.7044 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00962: val_loss did not improve from 0.32861\n",
      "Epoch 963/4000\n",
      "25/25 - 0s - loss: 0.2287 - accuracy: 0.8923 - val_loss: 1.7022 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00963: val_loss did not improve from 0.32861\n",
      "Epoch 964/4000\n",
      "25/25 - 0s - loss: 0.2276 - accuracy: 0.8885 - val_loss: 1.7036 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00964: val_loss did not improve from 0.32861\n",
      "Epoch 965/4000\n",
      "25/25 - 0s - loss: 0.2308 - accuracy: 0.8859 - val_loss: 1.7215 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00965: val_loss did not improve from 0.32861\n",
      "Epoch 966/4000\n",
      "25/25 - 0s - loss: 0.2315 - accuracy: 0.8859 - val_loss: 1.7064 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00966: val_loss did not improve from 0.32861\n",
      "Epoch 967/4000\n",
      "25/25 - 0s - loss: 0.2279 - accuracy: 0.8885 - val_loss: 1.7029 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00967: val_loss did not improve from 0.32861\n",
      "Epoch 968/4000\n",
      "25/25 - 0s - loss: 0.2321 - accuracy: 0.8898 - val_loss: 1.6023 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00968: val_loss did not improve from 0.32861\n",
      "Epoch 969/4000\n",
      "25/25 - 0s - loss: 0.2318 - accuracy: 0.8949 - val_loss: 1.5227 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00969: val_loss did not improve from 0.32861\n",
      "Epoch 970/4000\n",
      "25/25 - 0s - loss: 0.2358 - accuracy: 0.8911 - val_loss: 1.6496 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00970: val_loss did not improve from 0.32861\n",
      "Epoch 971/4000\n",
      "25/25 - 0s - loss: 0.2362 - accuracy: 0.8898 - val_loss: 1.5615 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00971: val_loss did not improve from 0.32861\n",
      "Epoch 972/4000\n",
      "25/25 - 0s - loss: 0.2279 - accuracy: 0.8898 - val_loss: 1.5910 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00972: val_loss did not improve from 0.32861\n",
      "Epoch 973/4000\n",
      "25/25 - 0s - loss: 0.2340 - accuracy: 0.8859 - val_loss: 1.5053 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00973: val_loss did not improve from 0.32861\n",
      "Epoch 974/4000\n",
      "25/25 - 0s - loss: 0.2321 - accuracy: 0.8885 - val_loss: 1.4938 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00974: val_loss did not improve from 0.32861\n",
      "Epoch 975/4000\n",
      "25/25 - 0s - loss: 0.2349 - accuracy: 0.8962 - val_loss: 1.7777 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00975: val_loss did not improve from 0.32861\n",
      "Epoch 976/4000\n",
      "25/25 - 0s - loss: 0.2347 - accuracy: 0.8885 - val_loss: 1.9278 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00976: val_loss did not improve from 0.32861\n",
      "Epoch 977/4000\n",
      "25/25 - 0s - loss: 0.2457 - accuracy: 0.8923 - val_loss: 1.6594 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00977: val_loss did not improve from 0.32861\n",
      "Epoch 978/4000\n",
      "25/25 - 0s - loss: 0.2725 - accuracy: 0.8651 - val_loss: 1.2089 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00978: val_loss did not improve from 0.32861\n",
      "Epoch 979/4000\n",
      "25/25 - 0s - loss: 0.2701 - accuracy: 0.8820 - val_loss: 1.5735 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00979: val_loss did not improve from 0.32861\n",
      "Epoch 980/4000\n",
      "25/25 - 0s - loss: 0.2422 - accuracy: 0.8872 - val_loss: 1.6098 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00980: val_loss did not improve from 0.32861\n",
      "Epoch 981/4000\n",
      "25/25 - 0s - loss: 0.2276 - accuracy: 0.8923 - val_loss: 1.5964 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00981: val_loss did not improve from 0.32861\n",
      "Epoch 982/4000\n",
      "25/25 - 0s - loss: 0.2265 - accuracy: 0.8911 - val_loss: 1.7341 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00982: val_loss did not improve from 0.32861\n",
      "Epoch 983/4000\n",
      "25/25 - 0s - loss: 0.2253 - accuracy: 0.9027 - val_loss: 1.7278 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00983: val_loss did not improve from 0.32861\n",
      "Epoch 984/4000\n",
      "25/25 - 0s - loss: 0.2232 - accuracy: 0.8988 - val_loss: 1.6513 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00984: val_loss did not improve from 0.32861\n",
      "Epoch 985/4000\n",
      "25/25 - 0s - loss: 0.2205 - accuracy: 0.9001 - val_loss: 1.6664 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00985: val_loss did not improve from 0.32861\n",
      "Epoch 986/4000\n",
      "25/25 - 0s - loss: 0.2209 - accuracy: 0.9001 - val_loss: 1.7136 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00986: val_loss did not improve from 0.32861\n",
      "Epoch 987/4000\n",
      "25/25 - 0s - loss: 0.2205 - accuracy: 0.8988 - val_loss: 1.7058 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00987: val_loss did not improve from 0.32861\n",
      "Epoch 988/4000\n",
      "25/25 - 0s - loss: 0.2191 - accuracy: 0.9001 - val_loss: 1.7451 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00988: val_loss did not improve from 0.32861\n",
      "Epoch 989/4000\n",
      "25/25 - 0s - loss: 0.2310 - accuracy: 0.8936 - val_loss: 1.7267 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00989: val_loss did not improve from 0.32861\n",
      "Epoch 990/4000\n",
      "25/25 - 0s - loss: 0.2220 - accuracy: 0.9001 - val_loss: 1.8945 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00990: val_loss did not improve from 0.32861\n",
      "Epoch 991/4000\n",
      "25/25 - 0s - loss: 0.2265 - accuracy: 0.8975 - val_loss: 1.8036 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00991: val_loss did not improve from 0.32861\n",
      "Epoch 992/4000\n",
      "25/25 - 0s - loss: 0.2214 - accuracy: 0.9001 - val_loss: 1.9351 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00992: val_loss did not improve from 0.32861\n",
      "Epoch 993/4000\n",
      "25/25 - 0s - loss: 0.2273 - accuracy: 0.8936 - val_loss: 1.7739 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00993: val_loss did not improve from 0.32861\n",
      "Epoch 994/4000\n",
      "25/25 - 0s - loss: 0.2252 - accuracy: 0.8949 - val_loss: 2.1465 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00994: val_loss did not improve from 0.32861\n",
      "Epoch 995/4000\n",
      "25/25 - 0s - loss: 0.2248 - accuracy: 0.9001 - val_loss: 1.8543 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00995: val_loss did not improve from 0.32861\n",
      "Epoch 996/4000\n",
      "25/25 - 0s - loss: 0.2295 - accuracy: 0.8885 - val_loss: 1.6472 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00996: val_loss did not improve from 0.32861\n",
      "Epoch 997/4000\n",
      "25/25 - 0s - loss: 0.2222 - accuracy: 0.8911 - val_loss: 1.8746 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00997: val_loss did not improve from 0.32861\n",
      "Epoch 998/4000\n",
      "25/25 - 0s - loss: 0.2200 - accuracy: 0.8988 - val_loss: 1.7652 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00998: val_loss did not improve from 0.32861\n",
      "Epoch 999/4000\n",
      "25/25 - 0s - loss: 0.2199 - accuracy: 0.8949 - val_loss: 1.9936 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00999: val_loss did not improve from 0.32861\n",
      "Epoch 1000/4000\n",
      "25/25 - 0s - loss: 0.2222 - accuracy: 0.8975 - val_loss: 1.4757 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01000: val_loss did not improve from 0.32861\n",
      "Epoch 1001/4000\n",
      "25/25 - 0s - loss: 0.2237 - accuracy: 0.8949 - val_loss: 1.4726 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01001: val_loss did not improve from 0.32861\n",
      "Epoch 1002/4000\n",
      "25/25 - 0s - loss: 0.2180 - accuracy: 0.8975 - val_loss: 1.5870 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01002: val_loss did not improve from 0.32861\n",
      "Epoch 1003/4000\n",
      "25/25 - 0s - loss: 0.2173 - accuracy: 0.9014 - val_loss: 1.5820 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01003: val_loss did not improve from 0.32861\n",
      "Epoch 1004/4000\n",
      "25/25 - 0s - loss: 0.2153 - accuracy: 0.9014 - val_loss: 1.6758 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01004: val_loss did not improve from 0.32861\n",
      "Epoch 1005/4000\n",
      "25/25 - 0s - loss: 0.2241 - accuracy: 0.9014 - val_loss: 1.8430 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01005: val_loss did not improve from 0.32861\n",
      "Epoch 1006/4000\n",
      "25/25 - 0s - loss: 0.2185 - accuracy: 0.9014 - val_loss: 1.8999 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01006: val_loss did not improve from 0.32861\n",
      "Epoch 1007/4000\n",
      "25/25 - 0s - loss: 0.2143 - accuracy: 0.8988 - val_loss: 1.8920 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01007: val_loss did not improve from 0.32861\n",
      "Epoch 1008/4000\n",
      "25/25 - 0s - loss: 0.2132 - accuracy: 0.8975 - val_loss: 1.9442 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01008: val_loss did not improve from 0.32861\n",
      "Epoch 1009/4000\n",
      "25/25 - 0s - loss: 0.2119 - accuracy: 0.8975 - val_loss: 1.9347 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01009: val_loss did not improve from 0.32861\n",
      "Epoch 1010/4000\n",
      "25/25 - 0s - loss: 0.2142 - accuracy: 0.8936 - val_loss: 1.8910 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01010: val_loss did not improve from 0.32861\n",
      "Epoch 1011/4000\n",
      "25/25 - 0s - loss: 0.2114 - accuracy: 0.9027 - val_loss: 1.9220 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01011: val_loss did not improve from 0.32861\n",
      "Epoch 1012/4000\n",
      "25/25 - 0s - loss: 0.2300 - accuracy: 0.8820 - val_loss: 1.9087 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01012: val_loss did not improve from 0.32861\n",
      "Epoch 1013/4000\n",
      "25/25 - 0s - loss: 0.2185 - accuracy: 0.8988 - val_loss: 1.9208 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01013: val_loss did not improve from 0.32861\n",
      "Epoch 1014/4000\n",
      "25/25 - 0s - loss: 0.2156 - accuracy: 0.8962 - val_loss: 2.3088 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01014: val_loss did not improve from 0.32861\n",
      "Epoch 1015/4000\n",
      "25/25 - 0s - loss: 0.2220 - accuracy: 0.8962 - val_loss: 2.1906 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01015: val_loss did not improve from 0.32861\n",
      "Epoch 1016/4000\n",
      "25/25 - 0s - loss: 0.2329 - accuracy: 0.8923 - val_loss: 2.3363 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01016: val_loss did not improve from 0.32861\n",
      "Epoch 1017/4000\n",
      "25/25 - 0s - loss: 0.2409 - accuracy: 0.8794 - val_loss: 1.3891 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01017: val_loss did not improve from 0.32861\n",
      "Epoch 1018/4000\n",
      "25/25 - 0s - loss: 0.2535 - accuracy: 0.8885 - val_loss: 1.4086 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01018: val_loss did not improve from 0.32861\n",
      "Epoch 1019/4000\n",
      "25/25 - 0s - loss: 0.2329 - accuracy: 0.9001 - val_loss: 1.2461 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01019: val_loss did not improve from 0.32861\n",
      "Epoch 1020/4000\n",
      "25/25 - 0s - loss: 0.2201 - accuracy: 0.8988 - val_loss: 1.3801 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01020: val_loss did not improve from 0.32861\n",
      "Epoch 1021/4000\n",
      "25/25 - 0s - loss: 0.2174 - accuracy: 0.9014 - val_loss: 1.4439 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01021: val_loss did not improve from 0.32861\n",
      "Epoch 1022/4000\n",
      "25/25 - 0s - loss: 0.2234 - accuracy: 0.8794 - val_loss: 1.3333 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01022: val_loss did not improve from 0.32861\n",
      "Epoch 1023/4000\n",
      "25/25 - 0s - loss: 0.2260 - accuracy: 0.8975 - val_loss: 1.2496 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01023: val_loss did not improve from 0.32861\n",
      "Epoch 1024/4000\n",
      "25/25 - 0s - loss: 0.2173 - accuracy: 0.9014 - val_loss: 1.3617 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01024: val_loss did not improve from 0.32861\n",
      "Epoch 1025/4000\n",
      "25/25 - 0s - loss: 0.2210 - accuracy: 0.8936 - val_loss: 1.4427 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01025: val_loss did not improve from 0.32861\n",
      "Epoch 1026/4000\n",
      "25/25 - 0s - loss: 0.2149 - accuracy: 0.9014 - val_loss: 1.3396 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01026: val_loss did not improve from 0.32861\n",
      "Epoch 1027/4000\n",
      "25/25 - 0s - loss: 0.2135 - accuracy: 0.8975 - val_loss: 1.3611 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01027: val_loss did not improve from 0.32861\n",
      "Epoch 1028/4000\n",
      "25/25 - 0s - loss: 0.2126 - accuracy: 0.9027 - val_loss: 1.3404 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01028: val_loss did not improve from 0.32861\n",
      "Epoch 1029/4000\n",
      "25/25 - 0s - loss: 0.2155 - accuracy: 0.8988 - val_loss: 1.2598 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01029: val_loss did not improve from 0.32861\n",
      "Epoch 1030/4000\n",
      "25/25 - 0s - loss: 0.2251 - accuracy: 0.8936 - val_loss: 1.1699 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01030: val_loss did not improve from 0.32861\n",
      "Epoch 1031/4000\n",
      "25/25 - 0s - loss: 0.2222 - accuracy: 0.9001 - val_loss: 1.1233 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01031: val_loss did not improve from 0.32861\n",
      "Epoch 1032/4000\n",
      "25/25 - 0s - loss: 0.2189 - accuracy: 0.8898 - val_loss: 1.4467 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01032: val_loss did not improve from 0.32861\n",
      "Epoch 1033/4000\n",
      "25/25 - 0s - loss: 0.2540 - accuracy: 0.8898 - val_loss: 1.1528 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01033: val_loss did not improve from 0.32861\n",
      "Epoch 1034/4000\n",
      "25/25 - 0s - loss: 0.2347 - accuracy: 0.8885 - val_loss: 1.0278 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01034: val_loss did not improve from 0.32861\n",
      "Epoch 1035/4000\n",
      "25/25 - 0s - loss: 0.2234 - accuracy: 0.8923 - val_loss: 1.1985 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01035: val_loss did not improve from 0.32861\n",
      "Epoch 1036/4000\n",
      "25/25 - 0s - loss: 0.2214 - accuracy: 0.8962 - val_loss: 1.1409 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01036: val_loss did not improve from 0.32861\n",
      "Epoch 1037/4000\n",
      "25/25 - 0s - loss: 0.2230 - accuracy: 0.8872 - val_loss: 1.2386 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01037: val_loss did not improve from 0.32861\n",
      "Epoch 1038/4000\n",
      "25/25 - 0s - loss: 0.2234 - accuracy: 0.8859 - val_loss: 1.1268 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01038: val_loss did not improve from 0.32861\n",
      "Epoch 1039/4000\n",
      "25/25 - 0s - loss: 0.2211 - accuracy: 0.8962 - val_loss: 1.3321 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01039: val_loss did not improve from 0.32861\n",
      "Epoch 1040/4000\n",
      "25/25 - 0s - loss: 0.2170 - accuracy: 0.8949 - val_loss: 1.3139 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01040: val_loss did not improve from 0.32861\n",
      "Epoch 1041/4000\n",
      "25/25 - 0s - loss: 0.2137 - accuracy: 0.8936 - val_loss: 1.4656 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01041: val_loss did not improve from 0.32861\n",
      "Epoch 1042/4000\n",
      "25/25 - 0s - loss: 0.2188 - accuracy: 0.8962 - val_loss: 1.3626 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01042: val_loss did not improve from 0.32861\n",
      "Epoch 1043/4000\n",
      "25/25 - 0s - loss: 0.2182 - accuracy: 0.8936 - val_loss: 1.3620 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 01043: val_loss did not improve from 0.32861\n",
      "Epoch 1044/4000\n",
      "25/25 - 0s - loss: 0.2161 - accuracy: 0.8949 - val_loss: 1.5824 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01044: val_loss did not improve from 0.32861\n",
      "Epoch 1045/4000\n",
      "25/25 - 0s - loss: 0.2171 - accuracy: 0.8975 - val_loss: 1.4504 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01045: val_loss did not improve from 0.32861\n",
      "Epoch 1046/4000\n",
      "25/25 - 0s - loss: 0.2119 - accuracy: 0.8988 - val_loss: 1.4820 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01046: val_loss did not improve from 0.32861\n",
      "Epoch 1047/4000\n",
      "25/25 - 0s - loss: 0.2121 - accuracy: 0.9014 - val_loss: 1.5336 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01047: val_loss did not improve from 0.32861\n",
      "Epoch 1048/4000\n",
      "25/25 - 0s - loss: 0.2117 - accuracy: 0.9014 - val_loss: 1.5330 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01048: val_loss did not improve from 0.32861\n",
      "Epoch 1049/4000\n",
      "25/25 - 0s - loss: 0.2143 - accuracy: 0.8975 - val_loss: 1.4312 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01049: val_loss did not improve from 0.32861\n",
      "Epoch 1050/4000\n",
      "25/25 - 0s - loss: 0.2117 - accuracy: 0.9027 - val_loss: 1.4950 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01050: val_loss did not improve from 0.32861\n",
      "Epoch 1051/4000\n",
      "25/25 - 0s - loss: 0.2148 - accuracy: 0.8975 - val_loss: 1.3001 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01051: val_loss did not improve from 0.32861\n",
      "Epoch 1052/4000\n",
      "25/25 - 0s - loss: 0.2109 - accuracy: 0.9014 - val_loss: 1.4790 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01052: val_loss did not improve from 0.32861\n",
      "Epoch 1053/4000\n",
      "25/25 - 0s - loss: 0.2153 - accuracy: 0.9001 - val_loss: 1.4450 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01053: val_loss did not improve from 0.32861\n",
      "Epoch 1054/4000\n",
      "25/25 - 0s - loss: 0.2122 - accuracy: 0.9027 - val_loss: 1.6008 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01054: val_loss did not improve from 0.32861\n",
      "Epoch 1055/4000\n",
      "25/25 - 0s - loss: 0.2088 - accuracy: 0.9079 - val_loss: 1.4390 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01055: val_loss did not improve from 0.32861\n",
      "Epoch 1056/4000\n",
      "25/25 - 0s - loss: 0.2142 - accuracy: 0.8988 - val_loss: 1.3539 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01056: val_loss did not improve from 0.32861\n",
      "Epoch 1057/4000\n",
      "25/25 - 0s - loss: 0.2312 - accuracy: 0.8872 - val_loss: 1.3302 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01057: val_loss did not improve from 0.32861\n",
      "Epoch 1058/4000\n",
      "25/25 - 0s - loss: 0.2265 - accuracy: 0.8949 - val_loss: 1.2983 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01058: val_loss did not improve from 0.32861\n",
      "Epoch 1059/4000\n",
      "25/25 - 0s - loss: 0.2188 - accuracy: 0.8911 - val_loss: 1.5425 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01059: val_loss did not improve from 0.32861\n",
      "Epoch 1060/4000\n",
      "25/25 - 0s - loss: 0.2170 - accuracy: 0.8949 - val_loss: 1.5353 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01060: val_loss did not improve from 0.32861\n",
      "Epoch 1061/4000\n",
      "25/25 - 0s - loss: 0.2164 - accuracy: 0.8962 - val_loss: 1.5642 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01061: val_loss did not improve from 0.32861\n",
      "Epoch 1062/4000\n",
      "25/25 - 0s - loss: 0.2172 - accuracy: 0.8962 - val_loss: 1.8537 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01062: val_loss did not improve from 0.32861\n",
      "Epoch 1063/4000\n",
      "25/25 - 0s - loss: 0.2226 - accuracy: 0.8975 - val_loss: 1.6231 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01063: val_loss did not improve from 0.32861\n",
      "Epoch 1064/4000\n",
      "25/25 - 0s - loss: 0.2113 - accuracy: 0.8988 - val_loss: 1.5976 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01064: val_loss did not improve from 0.32861\n",
      "Epoch 1065/4000\n",
      "25/25 - 0s - loss: 0.2151 - accuracy: 0.8936 - val_loss: 1.6527 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01065: val_loss did not improve from 0.32861\n",
      "Epoch 1066/4000\n",
      "25/25 - 0s - loss: 0.2106 - accuracy: 0.8949 - val_loss: 1.6183 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01066: val_loss did not improve from 0.32861\n",
      "Epoch 1067/4000\n",
      "25/25 - 0s - loss: 0.2101 - accuracy: 0.9014 - val_loss: 1.6467 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01067: val_loss did not improve from 0.32861\n",
      "Epoch 1068/4000\n",
      "25/25 - 0s - loss: 0.2095 - accuracy: 0.8936 - val_loss: 1.5989 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01068: val_loss did not improve from 0.32861\n",
      "Epoch 1069/4000\n",
      "25/25 - 0s - loss: 0.2199 - accuracy: 0.8885 - val_loss: 1.7108 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01069: val_loss did not improve from 0.32861\n",
      "Epoch 1070/4000\n",
      "25/25 - 0s - loss: 0.2116 - accuracy: 0.8962 - val_loss: 1.7295 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01070: val_loss did not improve from 0.32861\n",
      "Epoch 1071/4000\n",
      "25/25 - 0s - loss: 0.2081 - accuracy: 0.9040 - val_loss: 1.6808 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01071: val_loss did not improve from 0.32861\n",
      "Epoch 1072/4000\n",
      "25/25 - 0s - loss: 0.3279 - accuracy: 0.9027 - val_loss: 1.2223 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01072: val_loss did not improve from 0.32861\n",
      "Epoch 1073/4000\n",
      "25/25 - 0s - loss: 0.3273 - accuracy: 0.8872 - val_loss: 1.4095 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 01073: val_loss did not improve from 0.32861\n",
      "Epoch 1074/4000\n",
      "25/25 - 0s - loss: 0.2896 - accuracy: 0.8651 - val_loss: 0.9585 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01074: val_loss did not improve from 0.32861\n",
      "Epoch 1075/4000\n",
      "25/25 - 0s - loss: 0.3633 - accuracy: 0.8534 - val_loss: 0.8746 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 01075: val_loss did not improve from 0.32861\n",
      "Epoch 1076/4000\n",
      "25/25 - 0s - loss: 0.4236 - accuracy: 0.8651 - val_loss: 1.3143 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 01076: val_loss did not improve from 0.32861\n",
      "Epoch 1077/4000\n",
      "25/25 - 0s - loss: 0.3243 - accuracy: 0.8651 - val_loss: 1.1793 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01077: val_loss did not improve from 0.32861\n",
      "Epoch 1078/4000\n",
      "25/25 - 0s - loss: 0.2741 - accuracy: 0.8690 - val_loss: 1.9918 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 01078: val_loss did not improve from 0.32861\n",
      "Epoch 1079/4000\n",
      "25/25 - 0s - loss: 0.2999 - accuracy: 0.8716 - val_loss: 2.2378 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01079: val_loss did not improve from 0.32861\n",
      "Epoch 1080/4000\n",
      "25/25 - 0s - loss: 0.4054 - accuracy: 0.8664 - val_loss: 1.7608 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01080: val_loss did not improve from 0.32861\n",
      "Epoch 1081/4000\n",
      "25/25 - 0s - loss: 0.2599 - accuracy: 0.8664 - val_loss: 1.8035 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01081: val_loss did not improve from 0.32861\n",
      "Epoch 1082/4000\n",
      "25/25 - 0s - loss: 0.2660 - accuracy: 0.8729 - val_loss: 1.5757 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01082: val_loss did not improve from 0.32861\n",
      "Epoch 1083/4000\n",
      "25/25 - 0s - loss: 0.2822 - accuracy: 0.8729 - val_loss: 1.6286 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01083: val_loss did not improve from 0.32861\n",
      "Epoch 1084/4000\n",
      "25/25 - 0s - loss: 0.2576 - accuracy: 0.8664 - val_loss: 1.7875 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01084: val_loss did not improve from 0.32861\n",
      "Epoch 1085/4000\n",
      "25/25 - 0s - loss: 0.2554 - accuracy: 0.8729 - val_loss: 1.8497 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01085: val_loss did not improve from 0.32861\n",
      "Epoch 1086/4000\n",
      "25/25 - 0s - loss: 0.2522 - accuracy: 0.8742 - val_loss: 1.7757 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01086: val_loss did not improve from 0.32861\n",
      "Epoch 1087/4000\n",
      "25/25 - 0s - loss: 0.2811 - accuracy: 0.8729 - val_loss: 1.5576 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01087: val_loss did not improve from 0.32861\n",
      "Epoch 1088/4000\n",
      "25/25 - 0s - loss: 0.2533 - accuracy: 0.8677 - val_loss: 1.6346 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01088: val_loss did not improve from 0.32861\n",
      "Epoch 1089/4000\n",
      "25/25 - 0s - loss: 0.2380 - accuracy: 0.8794 - val_loss: 1.6310 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01089: val_loss did not improve from 0.32861\n",
      "Epoch 1090/4000\n",
      "25/25 - 0s - loss: 0.2311 - accuracy: 0.8859 - val_loss: 1.7372 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01090: val_loss did not improve from 0.32861\n",
      "Epoch 1091/4000\n",
      "25/25 - 0s - loss: 0.2293 - accuracy: 0.8846 - val_loss: 1.8477 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01091: val_loss did not improve from 0.32861\n",
      "Epoch 1092/4000\n",
      "25/25 - 0s - loss: 0.2274 - accuracy: 0.8781 - val_loss: 1.6205 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01092: val_loss did not improve from 0.32861\n",
      "Epoch 1093/4000\n",
      "25/25 - 0s - loss: 0.2266 - accuracy: 0.8885 - val_loss: 1.6461 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01093: val_loss did not improve from 0.32861\n",
      "Epoch 1094/4000\n",
      "25/25 - 0s - loss: 0.2367 - accuracy: 0.8677 - val_loss: 1.9031 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01094: val_loss did not improve from 0.32861\n",
      "Epoch 1095/4000\n",
      "25/25 - 0s - loss: 0.2285 - accuracy: 0.8807 - val_loss: 1.8485 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01095: val_loss did not improve from 0.32861\n",
      "Epoch 1096/4000\n",
      "25/25 - 0s - loss: 0.2261 - accuracy: 0.8833 - val_loss: 1.8162 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01096: val_loss did not improve from 0.32861\n",
      "Epoch 1097/4000\n",
      "25/25 - 0s - loss: 0.2278 - accuracy: 0.8885 - val_loss: 1.8317 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01097: val_loss did not improve from 0.32861\n",
      "Epoch 1098/4000\n",
      "25/25 - 0s - loss: 0.2241 - accuracy: 0.8936 - val_loss: 1.8188 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01098: val_loss did not improve from 0.32861\n",
      "Epoch 1099/4000\n",
      "25/25 - 0s - loss: 0.2241 - accuracy: 0.8846 - val_loss: 1.9216 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01099: val_loss did not improve from 0.32861\n",
      "Epoch 1100/4000\n",
      "25/25 - 0s - loss: 0.2195 - accuracy: 0.8885 - val_loss: 1.8898 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01100: val_loss did not improve from 0.32861\n",
      "Epoch 1101/4000\n",
      "25/25 - 0s - loss: 0.2180 - accuracy: 0.8859 - val_loss: 2.1417 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01101: val_loss did not improve from 0.32861\n",
      "Epoch 1102/4000\n",
      "25/25 - 0s - loss: 0.2176 - accuracy: 0.8962 - val_loss: 2.0065 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01102: val_loss did not improve from 0.32861\n",
      "Epoch 1103/4000\n",
      "25/25 - 0s - loss: 0.2164 - accuracy: 0.8975 - val_loss: 2.0959 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01103: val_loss did not improve from 0.32861\n",
      "Epoch 1104/4000\n",
      "25/25 - 0s - loss: 0.2190 - accuracy: 0.8988 - val_loss: 2.0334 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01104: val_loss did not improve from 0.32861\n",
      "Epoch 1105/4000\n",
      "25/25 - 0s - loss: 0.2393 - accuracy: 0.8742 - val_loss: 2.2271 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01105: val_loss did not improve from 0.32861\n",
      "Epoch 1106/4000\n",
      "25/25 - 0s - loss: 0.2275 - accuracy: 0.8949 - val_loss: 1.9153 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01106: val_loss did not improve from 0.32861\n",
      "Epoch 1107/4000\n",
      "25/25 - 0s - loss: 0.2173 - accuracy: 0.9014 - val_loss: 2.1113 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01107: val_loss did not improve from 0.32861\n",
      "Epoch 1108/4000\n",
      "25/25 - 0s - loss: 0.2312 - accuracy: 0.8988 - val_loss: 2.0478 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01108: val_loss did not improve from 0.32861\n",
      "Epoch 1109/4000\n",
      "25/25 - 0s - loss: 0.2268 - accuracy: 0.8936 - val_loss: 1.8879 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01109: val_loss did not improve from 0.32861\n",
      "Epoch 1110/4000\n",
      "25/25 - 0s - loss: 0.2351 - accuracy: 0.8807 - val_loss: 2.0507 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01110: val_loss did not improve from 0.32861\n",
      "Epoch 1111/4000\n",
      "25/25 - 0s - loss: 0.2275 - accuracy: 0.8923 - val_loss: 1.8607 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01111: val_loss did not improve from 0.32861\n",
      "Epoch 1112/4000\n",
      "25/25 - 0s - loss: 0.2202 - accuracy: 0.9027 - val_loss: 1.9517 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01112: val_loss did not improve from 0.32861\n",
      "Epoch 1113/4000\n",
      "25/25 - 0s - loss: 0.2206 - accuracy: 0.8975 - val_loss: 1.9947 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01113: val_loss did not improve from 0.32861\n",
      "Epoch 1114/4000\n",
      "25/25 - 0s - loss: 0.2177 - accuracy: 0.8988 - val_loss: 2.0458 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01114: val_loss did not improve from 0.32861\n",
      "Epoch 1115/4000\n",
      "25/25 - 0s - loss: 0.2208 - accuracy: 0.9001 - val_loss: 1.9950 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01115: val_loss did not improve from 0.32861\n",
      "Epoch 1116/4000\n",
      "25/25 - 0s - loss: 0.2288 - accuracy: 0.8936 - val_loss: 2.0292 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01116: val_loss did not improve from 0.32861\n",
      "Epoch 1117/4000\n",
      "25/25 - 0s - loss: 0.2241 - accuracy: 0.8975 - val_loss: 1.9578 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01117: val_loss did not improve from 0.32861\n",
      "Epoch 1118/4000\n",
      "25/25 - 0s - loss: 0.2430 - accuracy: 0.8923 - val_loss: 2.8629 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 01118: val_loss did not improve from 0.32861\n",
      "Epoch 1119/4000\n",
      "25/25 - 0s - loss: 0.3602 - accuracy: 0.8625 - val_loss: 0.8803 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01119: val_loss did not improve from 0.32861\n",
      "Epoch 1120/4000\n",
      "25/25 - 0s - loss: 0.3019 - accuracy: 0.8638 - val_loss: 1.3781 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 01120: val_loss did not improve from 0.32861\n",
      "Epoch 1121/4000\n",
      "25/25 - 0s - loss: 0.2848 - accuracy: 0.8690 - val_loss: 0.9732 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 01121: val_loss did not improve from 0.32861\n",
      "Epoch 1122/4000\n",
      "25/25 - 0s - loss: 0.2774 - accuracy: 0.8742 - val_loss: 1.1629 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01122: val_loss did not improve from 0.32861\n",
      "Epoch 1123/4000\n",
      "25/25 - 0s - loss: 0.2433 - accuracy: 0.8859 - val_loss: 1.4478 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01123: val_loss did not improve from 0.32861\n",
      "Epoch 1124/4000\n",
      "25/25 - 0s - loss: 0.2274 - accuracy: 0.8962 - val_loss: 1.4432 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01124: val_loss did not improve from 0.32861\n",
      "Epoch 1125/4000\n",
      "25/25 - 0s - loss: 0.2299 - accuracy: 0.8962 - val_loss: 1.4871 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01125: val_loss did not improve from 0.32861\n",
      "Epoch 1126/4000\n",
      "25/25 - 0s - loss: 0.2269 - accuracy: 0.8936 - val_loss: 1.6496 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01126: val_loss did not improve from 0.32861\n",
      "Epoch 1127/4000\n",
      "25/25 - 0s - loss: 0.2307 - accuracy: 0.8975 - val_loss: 1.6244 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01127: val_loss did not improve from 0.32861\n",
      "Epoch 1128/4000\n",
      "25/25 - 0s - loss: 0.2169 - accuracy: 0.9001 - val_loss: 1.7405 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01128: val_loss did not improve from 0.32861\n",
      "Epoch 1129/4000\n",
      "25/25 - 0s - loss: 0.2197 - accuracy: 0.8949 - val_loss: 1.6597 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01129: val_loss did not improve from 0.32861\n",
      "Epoch 1130/4000\n",
      "25/25 - 0s - loss: 0.2231 - accuracy: 0.8885 - val_loss: 1.9910 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01130: val_loss did not improve from 0.32861\n",
      "Epoch 1131/4000\n",
      "25/25 - 0s - loss: 0.2281 - accuracy: 0.8936 - val_loss: 1.9164 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01131: val_loss did not improve from 0.32861\n",
      "Epoch 1132/4000\n",
      "25/25 - 0s - loss: 0.2181 - accuracy: 0.9001 - val_loss: 1.9035 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01132: val_loss did not improve from 0.32861\n",
      "Epoch 1133/4000\n",
      "25/25 - 0s - loss: 0.2180 - accuracy: 0.8988 - val_loss: 1.9966 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01133: val_loss did not improve from 0.32861\n",
      "Epoch 1134/4000\n",
      "25/25 - 0s - loss: 0.2187 - accuracy: 0.9001 - val_loss: 1.8444 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01134: val_loss did not improve from 0.32861\n",
      "Epoch 1135/4000\n",
      "25/25 - 0s - loss: 0.2148 - accuracy: 0.8975 - val_loss: 1.9409 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01135: val_loss did not improve from 0.32861\n",
      "Epoch 1136/4000\n",
      "25/25 - 0s - loss: 0.2183 - accuracy: 0.8975 - val_loss: 1.9094 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01136: val_loss did not improve from 0.32861\n",
      "Epoch 1137/4000\n",
      "25/25 - 0s - loss: 0.2170 - accuracy: 0.8988 - val_loss: 1.9120 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01137: val_loss did not improve from 0.32861\n",
      "Epoch 1138/4000\n",
      "25/25 - 0s - loss: 0.2166 - accuracy: 0.8936 - val_loss: 1.9690 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01138: val_loss did not improve from 0.32861\n",
      "Epoch 1139/4000\n",
      "25/25 - 0s - loss: 0.2168 - accuracy: 0.8949 - val_loss: 1.9897 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01139: val_loss did not improve from 0.32861\n",
      "Epoch 1140/4000\n",
      "25/25 - 0s - loss: 0.2182 - accuracy: 0.9001 - val_loss: 1.9079 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01140: val_loss did not improve from 0.32861\n",
      "Epoch 1141/4000\n",
      "25/25 - 0s - loss: 0.2216 - accuracy: 0.9001 - val_loss: 1.7938 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01141: val_loss did not improve from 0.32861\n",
      "Epoch 1142/4000\n",
      "25/25 - 0s - loss: 0.2178 - accuracy: 0.8949 - val_loss: 1.9374 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01142: val_loss did not improve from 0.32861\n",
      "Epoch 1143/4000\n",
      "25/25 - 0s - loss: 0.2173 - accuracy: 0.9001 - val_loss: 2.0609 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01143: val_loss did not improve from 0.32861\n",
      "Epoch 1144/4000\n",
      "25/25 - 0s - loss: 0.2211 - accuracy: 0.8975 - val_loss: 1.9019 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01144: val_loss did not improve from 0.32861\n",
      "Epoch 1145/4000\n",
      "25/25 - 0s - loss: 0.2167 - accuracy: 0.8988 - val_loss: 1.8973 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01145: val_loss did not improve from 0.32861\n",
      "Epoch 1146/4000\n",
      "25/25 - 0s - loss: 0.2139 - accuracy: 0.8975 - val_loss: 2.0448 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01146: val_loss did not improve from 0.32861\n",
      "Epoch 1147/4000\n",
      "25/25 - 0s - loss: 0.2166 - accuracy: 0.9001 - val_loss: 1.8396 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01147: val_loss did not improve from 0.32861\n",
      "Epoch 1148/4000\n",
      "25/25 - 0s - loss: 0.2121 - accuracy: 0.9053 - val_loss: 1.9257 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01148: val_loss did not improve from 0.32861\n",
      "Epoch 1149/4000\n",
      "25/25 - 0s - loss: 0.2119 - accuracy: 0.9014 - val_loss: 1.8177 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01149: val_loss did not improve from 0.32861\n",
      "Epoch 1150/4000\n",
      "25/25 - 0s - loss: 0.2148 - accuracy: 0.8962 - val_loss: 1.9112 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01150: val_loss did not improve from 0.32861\n",
      "Epoch 1151/4000\n",
      "25/25 - 0s - loss: 0.2118 - accuracy: 0.9001 - val_loss: 1.8290 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01151: val_loss did not improve from 0.32861\n",
      "Epoch 1152/4000\n",
      "25/25 - 0s - loss: 0.2127 - accuracy: 0.9001 - val_loss: 2.0609 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01152: val_loss did not improve from 0.32861\n",
      "Epoch 1153/4000\n",
      "25/25 - 0s - loss: 0.2129 - accuracy: 0.9001 - val_loss: 2.1030 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01153: val_loss did not improve from 0.32861\n",
      "Epoch 1154/4000\n",
      "25/25 - 0s - loss: 0.2162 - accuracy: 0.9001 - val_loss: 2.0898 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01154: val_loss did not improve from 0.32861\n",
      "Epoch 1155/4000\n",
      "25/25 - 0s - loss: 0.2149 - accuracy: 0.8936 - val_loss: 2.0129 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01155: val_loss did not improve from 0.32861\n",
      "Epoch 1156/4000\n",
      "25/25 - 0s - loss: 0.2123 - accuracy: 0.9014 - val_loss: 2.0247 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01156: val_loss did not improve from 0.32861\n",
      "Epoch 1157/4000\n",
      "25/25 - 0s - loss: 0.2080 - accuracy: 0.8988 - val_loss: 2.0732 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01157: val_loss did not improve from 0.32861\n",
      "Epoch 1158/4000\n",
      "25/25 - 0s - loss: 0.2109 - accuracy: 0.9014 - val_loss: 2.0400 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01158: val_loss did not improve from 0.32861\n",
      "Epoch 1159/4000\n",
      "25/25 - 0s - loss: 0.2102 - accuracy: 0.8975 - val_loss: 1.9981 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01159: val_loss did not improve from 0.32861\n",
      "Epoch 1160/4000\n",
      "25/25 - 0s - loss: 0.2141 - accuracy: 0.9001 - val_loss: 1.7810 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01160: val_loss did not improve from 0.32861\n",
      "Epoch 1161/4000\n",
      "25/25 - 0s - loss: 0.2177 - accuracy: 0.8975 - val_loss: 2.0748 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01161: val_loss did not improve from 0.32861\n",
      "Epoch 1162/4000\n",
      "25/25 - 0s - loss: 0.2086 - accuracy: 0.9040 - val_loss: 2.0466 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01162: val_loss did not improve from 0.32861\n",
      "Epoch 1163/4000\n",
      "25/25 - 0s - loss: 0.2103 - accuracy: 0.8962 - val_loss: 1.7582 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01163: val_loss did not improve from 0.32861\n",
      "Epoch 1164/4000\n",
      "25/25 - 0s - loss: 0.2101 - accuracy: 0.8988 - val_loss: 1.7821 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01164: val_loss did not improve from 0.32861\n",
      "Epoch 1165/4000\n",
      "25/25 - 0s - loss: 0.2146 - accuracy: 0.8949 - val_loss: 1.7630 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01165: val_loss did not improve from 0.32861\n",
      "Epoch 1166/4000\n",
      "25/25 - 0s - loss: 0.2093 - accuracy: 0.9027 - val_loss: 2.0000 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01166: val_loss did not improve from 0.32861\n",
      "Epoch 1167/4000\n",
      "25/25 - 0s - loss: 0.2145 - accuracy: 0.9027 - val_loss: 1.9761 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01167: val_loss did not improve from 0.32861\n",
      "Epoch 1168/4000\n",
      "25/25 - 0s - loss: 0.2092 - accuracy: 0.8949 - val_loss: 2.1052 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01168: val_loss did not improve from 0.32861\n",
      "Epoch 1169/4000\n",
      "25/25 - 0s - loss: 0.2154 - accuracy: 0.8949 - val_loss: 1.9902 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01169: val_loss did not improve from 0.32861\n",
      "Epoch 1170/4000\n",
      "25/25 - 0s - loss: 0.2153 - accuracy: 0.8988 - val_loss: 1.8683 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01170: val_loss did not improve from 0.32861\n",
      "Epoch 1171/4000\n",
      "25/25 - 0s - loss: 0.2157 - accuracy: 0.8911 - val_loss: 2.0094 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01171: val_loss did not improve from 0.32861\n",
      "Epoch 1172/4000\n",
      "25/25 - 0s - loss: 0.2119 - accuracy: 0.8911 - val_loss: 2.0397 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01172: val_loss did not improve from 0.32861\n",
      "Epoch 1173/4000\n",
      "25/25 - 0s - loss: 0.2231 - accuracy: 0.9053 - val_loss: 2.2344 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01173: val_loss did not improve from 0.32861\n",
      "Epoch 1174/4000\n",
      "25/25 - 0s - loss: 0.2298 - accuracy: 0.9027 - val_loss: 2.1313 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01174: val_loss did not improve from 0.32861\n",
      "Epoch 1175/4000\n",
      "25/25 - 0s - loss: 0.2336 - accuracy: 0.8807 - val_loss: 2.2853 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01175: val_loss did not improve from 0.32861\n",
      "Epoch 1176/4000\n",
      "25/25 - 0s - loss: 0.2211 - accuracy: 0.8846 - val_loss: 2.4834 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01176: val_loss did not improve from 0.32861\n",
      "Epoch 1177/4000\n",
      "25/25 - 0s - loss: 0.2214 - accuracy: 0.8833 - val_loss: 2.6979 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01177: val_loss did not improve from 0.32861\n",
      "Epoch 1178/4000\n",
      "25/25 - 0s - loss: 0.2210 - accuracy: 0.8949 - val_loss: 2.6311 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01178: val_loss did not improve from 0.32861\n",
      "Epoch 1179/4000\n",
      "25/25 - 0s - loss: 0.2251 - accuracy: 0.8936 - val_loss: 2.3639 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01179: val_loss did not improve from 0.32861\n",
      "Epoch 1180/4000\n",
      "25/25 - 0s - loss: 0.2227 - accuracy: 0.8911 - val_loss: 2.1493 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01180: val_loss did not improve from 0.32861\n",
      "Epoch 1181/4000\n",
      "25/25 - 0s - loss: 0.2161 - accuracy: 0.8807 - val_loss: 2.1325 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01181: val_loss did not improve from 0.32861\n",
      "Epoch 1182/4000\n",
      "25/25 - 0s - loss: 0.2096 - accuracy: 0.9014 - val_loss: 2.2106 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01182: val_loss did not improve from 0.32861\n",
      "Epoch 1183/4000\n",
      "25/25 - 0s - loss: 0.2116 - accuracy: 0.8988 - val_loss: 2.4273 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01183: val_loss did not improve from 0.32861\n",
      "Epoch 1184/4000\n",
      "25/25 - 0s - loss: 0.2292 - accuracy: 0.8833 - val_loss: 2.1063 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01184: val_loss did not improve from 0.32861\n",
      "Epoch 1185/4000\n",
      "25/25 - 0s - loss: 0.2046 - accuracy: 0.9001 - val_loss: 2.2293 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01185: val_loss did not improve from 0.32861\n",
      "Epoch 1186/4000\n",
      "25/25 - 0s - loss: 0.2188 - accuracy: 0.8962 - val_loss: 2.2242 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01186: val_loss did not improve from 0.32861\n",
      "Epoch 1187/4000\n",
      "25/25 - 0s - loss: 0.2133 - accuracy: 0.9014 - val_loss: 2.1604 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01187: val_loss did not improve from 0.32861\n",
      "Epoch 1188/4000\n",
      "25/25 - 0s - loss: 0.2140 - accuracy: 0.9014 - val_loss: 2.3865 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01188: val_loss did not improve from 0.32861\n",
      "Epoch 1189/4000\n",
      "25/25 - 0s - loss: 0.2178 - accuracy: 0.9066 - val_loss: 2.8744 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01189: val_loss did not improve from 0.32861\n",
      "Epoch 1190/4000\n",
      "25/25 - 0s - loss: 0.2190 - accuracy: 0.8833 - val_loss: 4.1895 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01190: val_loss did not improve from 0.32861\n",
      "Epoch 1191/4000\n",
      "25/25 - 0s - loss: 0.2171 - accuracy: 0.8988 - val_loss: 3.9560 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01191: val_loss did not improve from 0.32861\n",
      "Epoch 1192/4000\n",
      "25/25 - 0s - loss: 0.2170 - accuracy: 0.9001 - val_loss: 4.1506 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01192: val_loss did not improve from 0.32861\n",
      "Epoch 1193/4000\n",
      "25/25 - 0s - loss: 0.2245 - accuracy: 0.8859 - val_loss: 4.0167 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01193: val_loss did not improve from 0.32861\n",
      "Epoch 1194/4000\n",
      "25/25 - 0s - loss: 0.2222 - accuracy: 0.8975 - val_loss: 3.9576 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01194: val_loss did not improve from 0.32861\n",
      "Epoch 1195/4000\n",
      "25/25 - 0s - loss: 0.2161 - accuracy: 0.8988 - val_loss: 3.9781 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01195: val_loss did not improve from 0.32861\n",
      "Epoch 1196/4000\n",
      "25/25 - 0s - loss: 0.2179 - accuracy: 0.8911 - val_loss: 3.7807 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01196: val_loss did not improve from 0.32861\n",
      "Epoch 1197/4000\n",
      "25/25 - 0s - loss: 0.2271 - accuracy: 0.8872 - val_loss: 3.5388 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01197: val_loss did not improve from 0.32861\n",
      "Epoch 1198/4000\n",
      "25/25 - 0s - loss: 0.2241 - accuracy: 0.8923 - val_loss: 3.2713 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01198: val_loss did not improve from 0.32861\n",
      "Epoch 1199/4000\n",
      "25/25 - 0s - loss: 0.2159 - accuracy: 0.8949 - val_loss: 3.6867 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01199: val_loss did not improve from 0.32861\n",
      "Epoch 1200/4000\n",
      "25/25 - 0s - loss: 0.2124 - accuracy: 0.8988 - val_loss: 3.8419 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01200: val_loss did not improve from 0.32861\n",
      "Epoch 1201/4000\n",
      "25/25 - 0s - loss: 0.2119 - accuracy: 0.9027 - val_loss: 3.9653 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01201: val_loss did not improve from 0.32861\n",
      "Epoch 1202/4000\n",
      "25/25 - 0s - loss: 0.2119 - accuracy: 0.8988 - val_loss: 4.1378 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01202: val_loss did not improve from 0.32861\n",
      "Epoch 1203/4000\n",
      "25/25 - 0s - loss: 0.2141 - accuracy: 0.8988 - val_loss: 4.2409 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01203: val_loss did not improve from 0.32861\n",
      "Epoch 1204/4000\n",
      "25/25 - 0s - loss: 0.2220 - accuracy: 0.8833 - val_loss: 4.6696 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01204: val_loss did not improve from 0.32861\n",
      "Epoch 1205/4000\n",
      "25/25 - 0s - loss: 0.2153 - accuracy: 0.8975 - val_loss: 4.4442 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01205: val_loss did not improve from 0.32861\n",
      "Epoch 1206/4000\n",
      "25/25 - 0s - loss: 0.2091 - accuracy: 0.8949 - val_loss: 4.7531 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01206: val_loss did not improve from 0.32861\n",
      "Epoch 1207/4000\n",
      "25/25 - 0s - loss: 0.2230 - accuracy: 0.8911 - val_loss: 4.5786 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01207: val_loss did not improve from 0.32861\n",
      "Epoch 1208/4000\n",
      "25/25 - 0s - loss: 0.2156 - accuracy: 0.8923 - val_loss: 4.6712 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01208: val_loss did not improve from 0.32861\n",
      "Epoch 1209/4000\n",
      "25/25 - 0s - loss: 0.2202 - accuracy: 0.8975 - val_loss: 5.0012 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01209: val_loss did not improve from 0.32861\n",
      "Epoch 1210/4000\n",
      "25/25 - 0s - loss: 0.2261 - accuracy: 0.8820 - val_loss: 5.1027 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01210: val_loss did not improve from 0.32861\n",
      "Epoch 1211/4000\n",
      "25/25 - 0s - loss: 0.2135 - accuracy: 0.8885 - val_loss: 5.2343 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01211: val_loss did not improve from 0.32861\n",
      "Epoch 1212/4000\n",
      "25/25 - 0s - loss: 0.2117 - accuracy: 0.8936 - val_loss: 5.3249 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01212: val_loss did not improve from 0.32861\n",
      "Epoch 1213/4000\n",
      "25/25 - 0s - loss: 0.2086 - accuracy: 0.9001 - val_loss: 5.1023 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01213: val_loss did not improve from 0.32861\n",
      "Epoch 1214/4000\n",
      "25/25 - 0s - loss: 0.2119 - accuracy: 0.8975 - val_loss: 4.9527 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01214: val_loss did not improve from 0.32861\n",
      "Epoch 1215/4000\n",
      "25/25 - 0s - loss: 0.2137 - accuracy: 0.8885 - val_loss: 5.4544 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01215: val_loss did not improve from 0.32861\n",
      "Epoch 1216/4000\n",
      "25/25 - 0s - loss: 0.2107 - accuracy: 0.8949 - val_loss: 5.1406 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01216: val_loss did not improve from 0.32861\n",
      "Epoch 1217/4000\n",
      "25/25 - 0s - loss: 0.2067 - accuracy: 0.8988 - val_loss: 5.1703 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01217: val_loss did not improve from 0.32861\n",
      "Epoch 1218/4000\n",
      "25/25 - 0s - loss: 0.2226 - accuracy: 0.8833 - val_loss: 5.1011 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01218: val_loss did not improve from 0.32861\n",
      "Epoch 1219/4000\n",
      "25/25 - 0s - loss: 0.2171 - accuracy: 0.8872 - val_loss: 5.1224 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01219: val_loss did not improve from 0.32861\n",
      "Epoch 1220/4000\n",
      "25/25 - 0s - loss: 0.2076 - accuracy: 0.9027 - val_loss: 5.4171 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01220: val_loss did not improve from 0.32861\n",
      "Epoch 1221/4000\n",
      "25/25 - 0s - loss: 0.2095 - accuracy: 0.9014 - val_loss: 5.2912 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01221: val_loss did not improve from 0.32861\n",
      "Epoch 1222/4000\n",
      "25/25 - 0s - loss: 0.2136 - accuracy: 0.8949 - val_loss: 5.2888 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01222: val_loss did not improve from 0.32861\n",
      "Epoch 1223/4000\n",
      "25/25 - 0s - loss: 0.2074 - accuracy: 0.9001 - val_loss: 5.2767 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01223: val_loss did not improve from 0.32861\n",
      "Epoch 1224/4000\n",
      "25/25 - 0s - loss: 0.2091 - accuracy: 0.8988 - val_loss: 5.2202 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01224: val_loss did not improve from 0.32861\n",
      "Epoch 1225/4000\n",
      "25/25 - 0s - loss: 0.2111 - accuracy: 0.8988 - val_loss: 5.2386 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01225: val_loss did not improve from 0.32861\n",
      "Epoch 1226/4000\n",
      "25/25 - 0s - loss: 0.2082 - accuracy: 0.9027 - val_loss: 5.2607 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01226: val_loss did not improve from 0.32861\n",
      "Epoch 1227/4000\n",
      "25/25 - 0s - loss: 0.2086 - accuracy: 0.8975 - val_loss: 5.2019 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01227: val_loss did not improve from 0.32861\n",
      "Epoch 1228/4000\n",
      "25/25 - 0s - loss: 0.2076 - accuracy: 0.9053 - val_loss: 5.1721 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01228: val_loss did not improve from 0.32861\n",
      "Epoch 1229/4000\n",
      "25/25 - 0s - loss: 0.2103 - accuracy: 0.9014 - val_loss: 5.1012 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01229: val_loss did not improve from 0.32861\n",
      "Epoch 1230/4000\n",
      "25/25 - 0s - loss: 0.2074 - accuracy: 0.8962 - val_loss: 5.2431 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01230: val_loss did not improve from 0.32861\n",
      "Epoch 1231/4000\n",
      "25/25 - 0s - loss: 0.2097 - accuracy: 0.9001 - val_loss: 5.2122 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01231: val_loss did not improve from 0.32861\n",
      "Epoch 1232/4000\n",
      "25/25 - 0s - loss: 0.2160 - accuracy: 0.9040 - val_loss: 5.1189 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01232: val_loss did not improve from 0.32861\n",
      "Epoch 1233/4000\n",
      "25/25 - 0s - loss: 0.2193 - accuracy: 0.8911 - val_loss: 4.7406 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01233: val_loss did not improve from 0.32861\n",
      "Epoch 1234/4000\n",
      "25/25 - 0s - loss: 0.2084 - accuracy: 0.8988 - val_loss: 4.5214 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01234: val_loss did not improve from 0.32861\n",
      "Epoch 1235/4000\n",
      "25/25 - 0s - loss: 0.2067 - accuracy: 0.9001 - val_loss: 4.8411 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01235: val_loss did not improve from 0.32861\n",
      "Epoch 1236/4000\n",
      "25/25 - 0s - loss: 0.2077 - accuracy: 0.9014 - val_loss: 4.8622 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01236: val_loss did not improve from 0.32861\n",
      "Epoch 1237/4000\n",
      "25/25 - 0s - loss: 0.2095 - accuracy: 0.8975 - val_loss: 4.8313 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01237: val_loss did not improve from 0.32861\n",
      "Epoch 1238/4000\n",
      "25/25 - 0s - loss: 0.2101 - accuracy: 0.9014 - val_loss: 4.8569 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01238: val_loss did not improve from 0.32861\n",
      "Epoch 1239/4000\n",
      "25/25 - 0s - loss: 0.2084 - accuracy: 0.8988 - val_loss: 4.1133 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01239: val_loss did not improve from 0.32861\n",
      "Epoch 1240/4000\n",
      "25/25 - 0s - loss: 0.2087 - accuracy: 0.8962 - val_loss: 3.8348 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01240: val_loss did not improve from 0.32861\n",
      "Epoch 1241/4000\n",
      "25/25 - 0s - loss: 0.2070 - accuracy: 0.9027 - val_loss: 3.9710 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01241: val_loss did not improve from 0.32861\n",
      "Epoch 1242/4000\n",
      "25/25 - 0s - loss: 0.2079 - accuracy: 0.9001 - val_loss: 4.2868 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01242: val_loss did not improve from 0.32861\n",
      "Epoch 1243/4000\n",
      "25/25 - 0s - loss: 0.2119 - accuracy: 0.9001 - val_loss: 4.1653 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01243: val_loss did not improve from 0.32861\n",
      "Epoch 1244/4000\n",
      "25/25 - 0s - loss: 0.2088 - accuracy: 0.8975 - val_loss: 4.1858 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01244: val_loss did not improve from 0.32861\n",
      "Epoch 1245/4000\n",
      "25/25 - 0s - loss: 0.2094 - accuracy: 0.9001 - val_loss: 4.1351 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01245: val_loss did not improve from 0.32861\n",
      "Epoch 1246/4000\n",
      "25/25 - 0s - loss: 0.2102 - accuracy: 0.8949 - val_loss: 4.3506 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01246: val_loss did not improve from 0.32861\n",
      "Epoch 1247/4000\n",
      "25/25 - 0s - loss: 0.2149 - accuracy: 0.9014 - val_loss: 4.2303 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01247: val_loss did not improve from 0.32861\n",
      "Epoch 1248/4000\n",
      "25/25 - 0s - loss: 0.2105 - accuracy: 0.8975 - val_loss: 4.3765 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01248: val_loss did not improve from 0.32861\n",
      "Epoch 1249/4000\n",
      "25/25 - 0s - loss: 0.2165 - accuracy: 0.9001 - val_loss: 4.0592 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01249: val_loss did not improve from 0.32861\n",
      "Epoch 1250/4000\n",
      "25/25 - 0s - loss: 0.2107 - accuracy: 0.8988 - val_loss: 4.2909 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01250: val_loss did not improve from 0.32861\n",
      "Epoch 1251/4000\n",
      "25/25 - 0s - loss: 0.2091 - accuracy: 0.8975 - val_loss: 4.2025 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01251: val_loss did not improve from 0.32861\n",
      "Epoch 1252/4000\n",
      "25/25 - 0s - loss: 0.2098 - accuracy: 0.8988 - val_loss: 4.0206 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01252: val_loss did not improve from 0.32861\n",
      "Epoch 1253/4000\n",
      "25/25 - 0s - loss: 0.2071 - accuracy: 0.9014 - val_loss: 4.2670 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01253: val_loss did not improve from 0.32861\n",
      "Epoch 1254/4000\n",
      "25/25 - 0s - loss: 0.2067 - accuracy: 0.9001 - val_loss: 4.2946 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01254: val_loss did not improve from 0.32861\n",
      "Epoch 1255/4000\n",
      "25/25 - 0s - loss: 0.2073 - accuracy: 0.9027 - val_loss: 4.3786 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01255: val_loss did not improve from 0.32861\n",
      "Epoch 1256/4000\n",
      "25/25 - 0s - loss: 0.2108 - accuracy: 0.8962 - val_loss: 4.4761 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01256: val_loss did not improve from 0.32861\n",
      "Epoch 1257/4000\n",
      "25/25 - 0s - loss: 0.2099 - accuracy: 0.8988 - val_loss: 4.4942 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01257: val_loss did not improve from 0.32861\n",
      "Epoch 1258/4000\n",
      "25/25 - 0s - loss: 0.2139 - accuracy: 0.8923 - val_loss: 4.7533 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01258: val_loss did not improve from 0.32861\n",
      "Epoch 1259/4000\n",
      "25/25 - 0s - loss: 0.2176 - accuracy: 0.8936 - val_loss: 3.7427 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01259: val_loss did not improve from 0.32861\n",
      "Epoch 1260/4000\n",
      "25/25 - 0s - loss: 0.2173 - accuracy: 0.9001 - val_loss: 4.0672 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01260: val_loss did not improve from 0.32861\n",
      "Epoch 1261/4000\n",
      "25/25 - 0s - loss: 0.2133 - accuracy: 0.9001 - val_loss: 4.9488 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01261: val_loss did not improve from 0.32861\n",
      "Epoch 1262/4000\n",
      "25/25 - 0s - loss: 0.2540 - accuracy: 0.8885 - val_loss: 4.1951 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 01262: val_loss did not improve from 0.32861\n",
      "Epoch 1263/4000\n",
      "25/25 - 0s - loss: 0.3879 - accuracy: 0.8807 - val_loss: 3.3767 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 01263: val_loss did not improve from 0.32861\n",
      "Epoch 1264/4000\n",
      "25/25 - 0s - loss: 0.2932 - accuracy: 0.8742 - val_loss: 0.7352 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 01264: val_loss did not improve from 0.32861\n",
      "Epoch 1265/4000\n",
      "25/25 - 0s - loss: 0.2810 - accuracy: 0.8664 - val_loss: 0.7609 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01265: val_loss did not improve from 0.32861\n",
      "Epoch 1266/4000\n",
      "25/25 - 0s - loss: 0.2885 - accuracy: 0.8703 - val_loss: 1.0766 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 01266: val_loss did not improve from 0.32861\n",
      "Epoch 1267/4000\n",
      "25/25 - 0s - loss: 0.3166 - accuracy: 0.8833 - val_loss: 0.9116 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01267: val_loss did not improve from 0.32861\n",
      "Epoch 1268/4000\n",
      "25/25 - 0s - loss: 0.2532 - accuracy: 0.8820 - val_loss: 2.2912 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01268: val_loss did not improve from 0.32861\n",
      "Epoch 1269/4000\n",
      "25/25 - 0s - loss: 0.2624 - accuracy: 0.8923 - val_loss: 1.5239 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01269: val_loss did not improve from 0.32861\n",
      "Epoch 1270/4000\n",
      "25/25 - 0s - loss: 0.2475 - accuracy: 0.8820 - val_loss: 1.9473 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01270: val_loss did not improve from 0.32861\n",
      "Epoch 1271/4000\n",
      "25/25 - 0s - loss: 0.2287 - accuracy: 0.8911 - val_loss: 1.4422 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01271: val_loss did not improve from 0.32861\n",
      "Epoch 1272/4000\n",
      "25/25 - 0s - loss: 0.2233 - accuracy: 0.8885 - val_loss: 1.1889 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01272: val_loss did not improve from 0.32861\n",
      "Epoch 1273/4000\n",
      "25/25 - 0s - loss: 0.2284 - accuracy: 0.9014 - val_loss: 1.2342 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01273: val_loss did not improve from 0.32861\n",
      "Epoch 1274/4000\n",
      "25/25 - 0s - loss: 0.3075 - accuracy: 0.8859 - val_loss: 3.4679 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01274: val_loss did not improve from 0.32861\n",
      "Epoch 1275/4000\n",
      "25/25 - 0s - loss: 0.3380 - accuracy: 0.8664 - val_loss: 0.9936 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01275: val_loss did not improve from 0.32861\n",
      "Epoch 1276/4000\n",
      "25/25 - 0s - loss: 0.3520 - accuracy: 0.8833 - val_loss: 1.0789 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01276: val_loss did not improve from 0.32861\n",
      "Epoch 1277/4000\n",
      "25/25 - 0s - loss: 0.2565 - accuracy: 0.8923 - val_loss: 1.3613 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01277: val_loss did not improve from 0.32861\n",
      "Epoch 1278/4000\n",
      "25/25 - 0s - loss: 0.2439 - accuracy: 0.8898 - val_loss: 1.4052 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01278: val_loss did not improve from 0.32861\n",
      "Epoch 1279/4000\n",
      "25/25 - 0s - loss: 0.2433 - accuracy: 0.8949 - val_loss: 1.8840 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01279: val_loss did not improve from 0.32861\n",
      "Epoch 1280/4000\n",
      "25/25 - 0s - loss: 0.2905 - accuracy: 0.8781 - val_loss: 0.7640 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01280: val_loss did not improve from 0.32861\n",
      "Epoch 1281/4000\n",
      "25/25 - 0s - loss: 0.3144 - accuracy: 0.8470 - val_loss: 0.9058 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01281: val_loss did not improve from 0.32861\n",
      "Epoch 1282/4000\n",
      "25/25 - 0s - loss: 0.2612 - accuracy: 0.8794 - val_loss: 0.9997 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01282: val_loss did not improve from 0.32861\n",
      "Epoch 1283/4000\n",
      "25/25 - 0s - loss: 0.2424 - accuracy: 0.8936 - val_loss: 1.0167 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01283: val_loss did not improve from 0.32861\n",
      "Epoch 1284/4000\n",
      "25/25 - 0s - loss: 0.2306 - accuracy: 0.8911 - val_loss: 1.2658 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01284: val_loss did not improve from 0.32861\n",
      "Epoch 1285/4000\n",
      "25/25 - 0s - loss: 0.2285 - accuracy: 0.8975 - val_loss: 1.1458 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01285: val_loss did not improve from 0.32861\n",
      "Epoch 1286/4000\n",
      "25/25 - 0s - loss: 0.2237 - accuracy: 0.9014 - val_loss: 1.1310 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01286: val_loss did not improve from 0.32861\n",
      "Epoch 1287/4000\n",
      "25/25 - 0s - loss: 0.2229 - accuracy: 0.8911 - val_loss: 1.1854 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01287: val_loss did not improve from 0.32861\n",
      "Epoch 1288/4000\n",
      "25/25 - 0s - loss: 0.2255 - accuracy: 0.8975 - val_loss: 1.2796 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01288: val_loss did not improve from 0.32861\n",
      "Epoch 1289/4000\n",
      "25/25 - 0s - loss: 0.2211 - accuracy: 0.8988 - val_loss: 1.4242 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01289: val_loss did not improve from 0.32861\n",
      "Epoch 1290/4000\n",
      "25/25 - 0s - loss: 0.2191 - accuracy: 0.8962 - val_loss: 1.3967 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01290: val_loss did not improve from 0.32861\n",
      "Epoch 1291/4000\n",
      "25/25 - 0s - loss: 0.2173 - accuracy: 0.8949 - val_loss: 1.6050 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01291: val_loss did not improve from 0.32861\n",
      "Epoch 1292/4000\n",
      "25/25 - 0s - loss: 0.2198 - accuracy: 0.9001 - val_loss: 1.5475 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01292: val_loss did not improve from 0.32861\n",
      "Epoch 1293/4000\n",
      "25/25 - 0s - loss: 0.2205 - accuracy: 0.9014 - val_loss: 1.6012 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01293: val_loss did not improve from 0.32861\n",
      "Epoch 1294/4000\n",
      "25/25 - 0s - loss: 0.2197 - accuracy: 0.9001 - val_loss: 1.6733 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01294: val_loss did not improve from 0.32861\n",
      "Epoch 1295/4000\n",
      "25/25 - 0s - loss: 0.2193 - accuracy: 0.8988 - val_loss: 1.8323 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01295: val_loss did not improve from 0.32861\n",
      "Epoch 1296/4000\n",
      "25/25 - 0s - loss: 0.2194 - accuracy: 0.8923 - val_loss: 1.6880 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01296: val_loss did not improve from 0.32861\n",
      "Epoch 1297/4000\n",
      "25/25 - 0s - loss: 0.2214 - accuracy: 0.9014 - val_loss: 2.1130 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01297: val_loss did not improve from 0.32861\n",
      "Epoch 1298/4000\n",
      "25/25 - 0s - loss: 0.2186 - accuracy: 0.9014 - val_loss: 2.5638 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01298: val_loss did not improve from 0.32861\n",
      "Epoch 1299/4000\n",
      "25/25 - 0s - loss: 0.2197 - accuracy: 0.9040 - val_loss: 1.9412 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01299: val_loss did not improve from 0.32861\n",
      "Epoch 1300/4000\n",
      "25/25 - 0s - loss: 0.2353 - accuracy: 0.8949 - val_loss: 1.5534 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01300: val_loss did not improve from 0.32861\n",
      "Epoch 1301/4000\n",
      "25/25 - 0s - loss: 0.2214 - accuracy: 0.8923 - val_loss: 1.6804 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01301: val_loss did not improve from 0.32861\n",
      "Epoch 1302/4000\n",
      "25/25 - 0s - loss: 0.2149 - accuracy: 0.9027 - val_loss: 1.7338 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01302: val_loss did not improve from 0.32861\n",
      "Epoch 1303/4000\n",
      "25/25 - 0s - loss: 0.2227 - accuracy: 0.8962 - val_loss: 1.3470 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01303: val_loss did not improve from 0.32861\n",
      "Epoch 1304/4000\n",
      "25/25 - 0s - loss: 0.2193 - accuracy: 0.8936 - val_loss: 1.5222 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01304: val_loss did not improve from 0.32861\n",
      "Epoch 1305/4000\n",
      "25/25 - 0s - loss: 0.2210 - accuracy: 0.8936 - val_loss: 1.6881 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01305: val_loss did not improve from 0.32861\n",
      "Epoch 1306/4000\n",
      "25/25 - 0s - loss: 0.2196 - accuracy: 0.8923 - val_loss: 1.7781 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01306: val_loss did not improve from 0.32861\n",
      "Epoch 1307/4000\n",
      "25/25 - 0s - loss: 0.2227 - accuracy: 0.8975 - val_loss: 1.8904 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01307: val_loss did not improve from 0.32861\n",
      "Epoch 1308/4000\n",
      "25/25 - 0s - loss: 0.2194 - accuracy: 0.8962 - val_loss: 1.8390 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01308: val_loss did not improve from 0.32861\n",
      "Epoch 1309/4000\n",
      "25/25 - 0s - loss: 0.2173 - accuracy: 0.8962 - val_loss: 1.9975 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01309: val_loss did not improve from 0.32861\n",
      "Epoch 1310/4000\n",
      "25/25 - 0s - loss: 0.2234 - accuracy: 0.8988 - val_loss: 1.7453 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01310: val_loss did not improve from 0.32861\n",
      "Epoch 1311/4000\n",
      "25/25 - 0s - loss: 0.2255 - accuracy: 0.8936 - val_loss: 1.7744 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01311: val_loss did not improve from 0.32861\n",
      "Epoch 1312/4000\n",
      "25/25 - 0s - loss: 0.2198 - accuracy: 0.8949 - val_loss: 1.7572 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01312: val_loss did not improve from 0.32861\n",
      "Epoch 1313/4000\n",
      "25/25 - 0s - loss: 0.2228 - accuracy: 0.8898 - val_loss: 1.5276 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01313: val_loss did not improve from 0.32861\n",
      "Epoch 1314/4000\n",
      "25/25 - 0s - loss: 0.2218 - accuracy: 0.8885 - val_loss: 1.6727 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01314: val_loss did not improve from 0.32861\n",
      "Epoch 1315/4000\n",
      "25/25 - 0s - loss: 0.2354 - accuracy: 0.8846 - val_loss: 1.5134 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01315: val_loss did not improve from 0.32861\n",
      "Epoch 1316/4000\n",
      "25/25 - 0s - loss: 0.2203 - accuracy: 0.8949 - val_loss: 1.7857 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01316: val_loss did not improve from 0.32861\n",
      "Epoch 1317/4000\n",
      "25/25 - 0s - loss: 0.2298 - accuracy: 0.8911 - val_loss: 1.9363 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01317: val_loss did not improve from 0.32861\n",
      "Epoch 1318/4000\n",
      "25/25 - 0s - loss: 0.2290 - accuracy: 0.8936 - val_loss: 5.7533 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01318: val_loss did not improve from 0.32861\n",
      "Epoch 1319/4000\n",
      "25/25 - 0s - loss: 0.2775 - accuracy: 0.8833 - val_loss: 2.7811 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01319: val_loss did not improve from 0.32861\n",
      "Epoch 1320/4000\n",
      "25/25 - 0s - loss: 0.3127 - accuracy: 0.8872 - val_loss: 1.7845 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01320: val_loss did not improve from 0.32861\n",
      "Epoch 1321/4000\n",
      "25/25 - 0s - loss: 0.2470 - accuracy: 0.8898 - val_loss: 2.3304 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01321: val_loss did not improve from 0.32861\n",
      "Epoch 1322/4000\n",
      "25/25 - 0s - loss: 0.2700 - accuracy: 0.8833 - val_loss: 1.9032 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01322: val_loss did not improve from 0.32861\n",
      "Epoch 1323/4000\n",
      "25/25 - 0s - loss: 0.2423 - accuracy: 0.8846 - val_loss: 1.8745 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01323: val_loss did not improve from 0.32861\n",
      "Epoch 1324/4000\n",
      "25/25 - 0s - loss: 0.2274 - accuracy: 0.8962 - val_loss: 1.8357 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01324: val_loss did not improve from 0.32861\n",
      "Epoch 1325/4000\n",
      "25/25 - 0s - loss: 0.2222 - accuracy: 0.8898 - val_loss: 2.1080 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01325: val_loss did not improve from 0.32861\n",
      "Epoch 1326/4000\n",
      "25/25 - 0s - loss: 0.2360 - accuracy: 0.8885 - val_loss: 2.3037 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01326: val_loss did not improve from 0.32861\n",
      "Epoch 1327/4000\n",
      "25/25 - 0s - loss: 0.2197 - accuracy: 0.8885 - val_loss: 2.3023 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01327: val_loss did not improve from 0.32861\n",
      "Epoch 1328/4000\n",
      "25/25 - 0s - loss: 0.2215 - accuracy: 0.8833 - val_loss: 2.3798 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01328: val_loss did not improve from 0.32861\n",
      "Epoch 1329/4000\n",
      "25/25 - 0s - loss: 0.2220 - accuracy: 0.8936 - val_loss: 2.3821 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01329: val_loss did not improve from 0.32861\n",
      "Epoch 1330/4000\n",
      "25/25 - 0s - loss: 0.2220 - accuracy: 0.8949 - val_loss: 2.1480 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01330: val_loss did not improve from 0.32861\n",
      "Epoch 1331/4000\n",
      "25/25 - 0s - loss: 0.2216 - accuracy: 0.8936 - val_loss: 2.0665 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01331: val_loss did not improve from 0.32861\n",
      "Epoch 1332/4000\n",
      "25/25 - 0s - loss: 0.2336 - accuracy: 0.8962 - val_loss: 2.1251 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01332: val_loss did not improve from 0.32861\n",
      "Epoch 1333/4000\n",
      "25/25 - 0s - loss: 0.2220 - accuracy: 0.8872 - val_loss: 2.0430 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01333: val_loss did not improve from 0.32861\n",
      "Epoch 1334/4000\n",
      "25/25 - 0s - loss: 0.2244 - accuracy: 0.8859 - val_loss: 1.8010 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01334: val_loss did not improve from 0.32861\n",
      "Epoch 1335/4000\n",
      "25/25 - 0s - loss: 0.2206 - accuracy: 0.8911 - val_loss: 2.0669 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01335: val_loss did not improve from 0.32861\n",
      "Epoch 1336/4000\n",
      "25/25 - 0s - loss: 0.2520 - accuracy: 0.8677 - val_loss: 1.5529 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01336: val_loss did not improve from 0.32861\n",
      "Epoch 1337/4000\n",
      "25/25 - 0s - loss: 0.2257 - accuracy: 0.8872 - val_loss: 1.5905 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01337: val_loss did not improve from 0.32861\n",
      "Epoch 1338/4000\n",
      "25/25 - 0s - loss: 0.2188 - accuracy: 0.8962 - val_loss: 1.6621 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01338: val_loss did not improve from 0.32861\n",
      "Epoch 1339/4000\n",
      "25/25 - 0s - loss: 0.2168 - accuracy: 0.8975 - val_loss: 1.6960 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01339: val_loss did not improve from 0.32861\n",
      "Epoch 1340/4000\n",
      "25/25 - 0s - loss: 0.2156 - accuracy: 0.8949 - val_loss: 1.7212 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01340: val_loss did not improve from 0.32861\n",
      "Epoch 1341/4000\n",
      "25/25 - 0s - loss: 0.2160 - accuracy: 0.8911 - val_loss: 1.8736 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01341: val_loss did not improve from 0.32861\n",
      "Epoch 1342/4000\n",
      "25/25 - 0s - loss: 0.2166 - accuracy: 0.8949 - val_loss: 1.8407 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01342: val_loss did not improve from 0.32861\n",
      "Epoch 1343/4000\n",
      "25/25 - 0s - loss: 0.2152 - accuracy: 0.8949 - val_loss: 1.8424 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01343: val_loss did not improve from 0.32861\n",
      "Epoch 1344/4000\n",
      "25/25 - 0s - loss: 0.2112 - accuracy: 0.8949 - val_loss: 1.7287 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01344: val_loss did not improve from 0.32861\n",
      "Epoch 1345/4000\n",
      "25/25 - 0s - loss: 0.2137 - accuracy: 0.8936 - val_loss: 1.7698 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01345: val_loss did not improve from 0.32861\n",
      "Epoch 1346/4000\n",
      "25/25 - 0s - loss: 0.2122 - accuracy: 0.8936 - val_loss: 1.9142 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01346: val_loss did not improve from 0.32861\n",
      "Epoch 1347/4000\n",
      "25/25 - 0s - loss: 0.2131 - accuracy: 0.8962 - val_loss: 1.7270 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01347: val_loss did not improve from 0.32861\n",
      "Epoch 1348/4000\n",
      "25/25 - 0s - loss: 0.2182 - accuracy: 0.8975 - val_loss: 1.7734 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01348: val_loss did not improve from 0.32861\n",
      "Epoch 1349/4000\n",
      "25/25 - 0s - loss: 0.2149 - accuracy: 0.8975 - val_loss: 1.6185 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01349: val_loss did not improve from 0.32861\n",
      "Epoch 1350/4000\n",
      "25/25 - 0s - loss: 0.2119 - accuracy: 0.8911 - val_loss: 1.7192 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01350: val_loss did not improve from 0.32861\n",
      "Epoch 1351/4000\n",
      "25/25 - 0s - loss: 0.2267 - accuracy: 0.8898 - val_loss: 1.4603 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01351: val_loss did not improve from 0.32861\n",
      "Epoch 1352/4000\n",
      "25/25 - 0s - loss: 0.2727 - accuracy: 0.8599 - val_loss: 1.2164 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01352: val_loss did not improve from 0.32861\n",
      "Epoch 1353/4000\n",
      "25/25 - 0s - loss: 0.2508 - accuracy: 0.8859 - val_loss: 1.2378 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01353: val_loss did not improve from 0.32861\n",
      "Epoch 1354/4000\n",
      "25/25 - 0s - loss: 0.3616 - accuracy: 0.8833 - val_loss: 0.9421 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01354: val_loss did not improve from 0.32861\n",
      "Epoch 1355/4000\n",
      "25/25 - 0s - loss: 0.3360 - accuracy: 0.8495 - val_loss: 1.5348 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01355: val_loss did not improve from 0.32861\n",
      "Epoch 1356/4000\n",
      "25/25 - 0s - loss: 0.2548 - accuracy: 0.8781 - val_loss: 1.2690 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01356: val_loss did not improve from 0.32861\n",
      "Epoch 1357/4000\n",
      "25/25 - 0s - loss: 0.2425 - accuracy: 0.8729 - val_loss: 1.2914 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01357: val_loss did not improve from 0.32861\n",
      "Epoch 1358/4000\n",
      "25/25 - 0s - loss: 0.2396 - accuracy: 0.8846 - val_loss: 1.2938 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01358: val_loss did not improve from 0.32861\n",
      "Epoch 1359/4000\n",
      "25/25 - 0s - loss: 0.2297 - accuracy: 0.8859 - val_loss: 1.3322 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01359: val_loss did not improve from 0.32861\n",
      "Epoch 1360/4000\n",
      "25/25 - 0s - loss: 0.2288 - accuracy: 0.8949 - val_loss: 1.4417 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01360: val_loss did not improve from 0.32861\n",
      "Epoch 1361/4000\n",
      "25/25 - 0s - loss: 0.2282 - accuracy: 0.8923 - val_loss: 1.4825 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01361: val_loss did not improve from 0.32861\n",
      "Epoch 1362/4000\n",
      "25/25 - 0s - loss: 0.2364 - accuracy: 0.8846 - val_loss: 1.4858 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01362: val_loss did not improve from 0.32861\n",
      "Epoch 1363/4000\n",
      "25/25 - 0s - loss: 0.2323 - accuracy: 0.8807 - val_loss: 1.5338 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01363: val_loss did not improve from 0.32861\n",
      "Epoch 1364/4000\n",
      "25/25 - 0s - loss: 0.2329 - accuracy: 0.8846 - val_loss: 1.4886 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01364: val_loss did not improve from 0.32861\n",
      "Epoch 1365/4000\n",
      "25/25 - 0s - loss: 0.2400 - accuracy: 0.8846 - val_loss: 1.3338 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01365: val_loss did not improve from 0.32861\n",
      "Epoch 1366/4000\n",
      "25/25 - 0s - loss: 0.2382 - accuracy: 0.8833 - val_loss: 1.3039 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01366: val_loss did not improve from 0.32861\n",
      "Epoch 1367/4000\n",
      "25/25 - 0s - loss: 0.2326 - accuracy: 0.8936 - val_loss: 1.4131 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01367: val_loss did not improve from 0.32861\n",
      "Epoch 1368/4000\n",
      "25/25 - 0s - loss: 0.2353 - accuracy: 0.8833 - val_loss: 1.3350 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01368: val_loss did not improve from 0.32861\n",
      "Epoch 1369/4000\n",
      "25/25 - 0s - loss: 0.2314 - accuracy: 0.8885 - val_loss: 1.3810 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01369: val_loss did not improve from 0.32861\n",
      "Epoch 1370/4000\n",
      "25/25 - 0s - loss: 0.2641 - accuracy: 0.8872 - val_loss: 1.4822 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01370: val_loss did not improve from 0.32861\n",
      "Epoch 1371/4000\n",
      "25/25 - 0s - loss: 0.2405 - accuracy: 0.8846 - val_loss: 1.7848 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01371: val_loss did not improve from 0.32861\n",
      "Epoch 1372/4000\n",
      "25/25 - 0s - loss: 0.2330 - accuracy: 0.8872 - val_loss: 1.9272 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01372: val_loss did not improve from 0.32861\n",
      "Epoch 1373/4000\n",
      "25/25 - 0s - loss: 0.2294 - accuracy: 0.8898 - val_loss: 2.0987 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01373: val_loss did not improve from 0.32861\n",
      "Epoch 1374/4000\n",
      "25/25 - 0s - loss: 0.2297 - accuracy: 0.8911 - val_loss: 2.1488 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01374: val_loss did not improve from 0.32861\n",
      "Epoch 1375/4000\n",
      "25/25 - 0s - loss: 0.2309 - accuracy: 0.8898 - val_loss: 2.1319 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01375: val_loss did not improve from 0.32861\n",
      "Epoch 1376/4000\n",
      "25/25 - 0s - loss: 0.2319 - accuracy: 0.8885 - val_loss: 1.8609 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01376: val_loss did not improve from 0.32861\n",
      "Epoch 1377/4000\n",
      "25/25 - 0s - loss: 0.2257 - accuracy: 0.8872 - val_loss: 1.7469 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01377: val_loss did not improve from 0.32861\n",
      "Epoch 1378/4000\n",
      "25/25 - 0s - loss: 0.2316 - accuracy: 0.8833 - val_loss: 1.6475 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01378: val_loss did not improve from 0.32861\n",
      "Epoch 1379/4000\n",
      "25/25 - 0s - loss: 0.2274 - accuracy: 0.8885 - val_loss: 1.8382 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01379: val_loss did not improve from 0.32861\n",
      "Epoch 1380/4000\n",
      "25/25 - 0s - loss: 0.2262 - accuracy: 0.8898 - val_loss: 1.9052 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01380: val_loss did not improve from 0.32861\n",
      "Epoch 1381/4000\n",
      "25/25 - 0s - loss: 0.2325 - accuracy: 0.8833 - val_loss: 1.7370 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01381: val_loss did not improve from 0.32861\n",
      "Epoch 1382/4000\n",
      "25/25 - 0s - loss: 0.2275 - accuracy: 0.8923 - val_loss: 2.0508 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01382: val_loss did not improve from 0.32861\n",
      "Epoch 1383/4000\n",
      "25/25 - 0s - loss: 0.2355 - accuracy: 0.8833 - val_loss: 2.3138 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01383: val_loss did not improve from 0.32861\n",
      "Epoch 1384/4000\n",
      "25/25 - 0s - loss: 0.2259 - accuracy: 0.8885 - val_loss: 2.2054 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01384: val_loss did not improve from 0.32861\n",
      "Epoch 1385/4000\n",
      "25/25 - 0s - loss: 0.2257 - accuracy: 0.8923 - val_loss: 2.2244 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01385: val_loss did not improve from 0.32861\n",
      "Epoch 1386/4000\n",
      "25/25 - 0s - loss: 0.2240 - accuracy: 0.8885 - val_loss: 2.1954 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01386: val_loss did not improve from 0.32861\n",
      "Epoch 1387/4000\n",
      "25/25 - 0s - loss: 0.2315 - accuracy: 0.8794 - val_loss: 2.2881 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01387: val_loss did not improve from 0.32861\n",
      "Epoch 1388/4000\n",
      "25/25 - 0s - loss: 0.2386 - accuracy: 0.8781 - val_loss: 2.3726 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01388: val_loss did not improve from 0.32861\n",
      "Epoch 1389/4000\n",
      "25/25 - 0s - loss: 0.2326 - accuracy: 0.8923 - val_loss: 2.8409 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01389: val_loss did not improve from 0.32861\n",
      "Epoch 1390/4000\n",
      "25/25 - 0s - loss: 0.2801 - accuracy: 0.8729 - val_loss: 2.1701 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 01390: val_loss did not improve from 0.32861\n",
      "Epoch 1391/4000\n",
      "25/25 - 0s - loss: 0.3308 - accuracy: 0.8534 - val_loss: 1.0339 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01391: val_loss did not improve from 0.32861\n",
      "Epoch 1392/4000\n",
      "25/25 - 0s - loss: 0.2751 - accuracy: 0.8742 - val_loss: 1.5290 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01392: val_loss did not improve from 0.32861\n",
      "Epoch 1393/4000\n",
      "25/25 - 0s - loss: 0.2645 - accuracy: 0.8547 - val_loss: 1.0565 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01393: val_loss did not improve from 0.32861\n",
      "Epoch 1394/4000\n",
      "25/25 - 0s - loss: 0.2477 - accuracy: 0.8560 - val_loss: 0.9516 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01394: val_loss did not improve from 0.32861\n",
      "Epoch 1395/4000\n",
      "25/25 - 0s - loss: 0.2464 - accuracy: 0.8716 - val_loss: 0.9558 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01395: val_loss did not improve from 0.32861\n",
      "Epoch 1396/4000\n",
      "25/25 - 0s - loss: 0.2401 - accuracy: 0.8807 - val_loss: 0.7894 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01396: val_loss did not improve from 0.32861\n",
      "Epoch 1397/4000\n",
      "25/25 - 0s - loss: 0.2433 - accuracy: 0.8768 - val_loss: 0.9698 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01397: val_loss did not improve from 0.32861\n",
      "Epoch 1398/4000\n",
      "25/25 - 0s - loss: 0.2344 - accuracy: 0.8807 - val_loss: 1.0291 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01398: val_loss did not improve from 0.32861\n",
      "Epoch 1399/4000\n",
      "25/25 - 0s - loss: 0.2330 - accuracy: 0.8859 - val_loss: 1.0255 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01399: val_loss did not improve from 0.32861\n",
      "Epoch 1400/4000\n",
      "25/25 - 0s - loss: 0.2449 - accuracy: 0.8833 - val_loss: 1.0610 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01400: val_loss did not improve from 0.32861\n",
      "Epoch 1401/4000\n",
      "25/25 - 0s - loss: 0.2492 - accuracy: 0.8716 - val_loss: 1.1061 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01401: val_loss did not improve from 0.32861\n",
      "Epoch 1402/4000\n",
      "25/25 - 0s - loss: 0.2409 - accuracy: 0.8768 - val_loss: 1.0229 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01402: val_loss did not improve from 0.32861\n",
      "Epoch 1403/4000\n",
      "25/25 - 0s - loss: 0.2336 - accuracy: 0.8807 - val_loss: 0.9750 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01403: val_loss did not improve from 0.32861\n",
      "Epoch 1404/4000\n",
      "25/25 - 0s - loss: 0.2308 - accuracy: 0.8833 - val_loss: 0.9636 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01404: val_loss did not improve from 0.32861\n",
      "Epoch 1405/4000\n",
      "25/25 - 0s - loss: 0.2356 - accuracy: 0.8755 - val_loss: 1.0497 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01405: val_loss did not improve from 0.32861\n",
      "Epoch 1406/4000\n",
      "25/25 - 0s - loss: 0.2324 - accuracy: 0.8768 - val_loss: 1.0344 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01406: val_loss did not improve from 0.32861\n",
      "Epoch 1407/4000\n",
      "25/25 - 0s - loss: 0.2309 - accuracy: 0.8859 - val_loss: 0.9687 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01407: val_loss did not improve from 0.32861\n",
      "Epoch 1408/4000\n",
      "25/25 - 0s - loss: 0.2298 - accuracy: 0.8911 - val_loss: 1.1119 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01408: val_loss did not improve from 0.32861\n",
      "Epoch 1409/4000\n",
      "25/25 - 0s - loss: 0.2401 - accuracy: 0.8807 - val_loss: 0.9733 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01409: val_loss did not improve from 0.32861\n",
      "Epoch 1410/4000\n",
      "25/25 - 0s - loss: 0.2378 - accuracy: 0.8885 - val_loss: 0.9240 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01410: val_loss did not improve from 0.32861\n",
      "Epoch 1411/4000\n",
      "25/25 - 0s - loss: 0.2320 - accuracy: 0.8807 - val_loss: 1.0620 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01411: val_loss did not improve from 0.32861\n",
      "Epoch 1412/4000\n",
      "25/25 - 0s - loss: 0.2385 - accuracy: 0.8820 - val_loss: 0.8974 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01412: val_loss did not improve from 0.32861\n",
      "Epoch 1413/4000\n",
      "25/25 - 0s - loss: 0.2307 - accuracy: 0.8807 - val_loss: 0.9640 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01413: val_loss did not improve from 0.32861\n",
      "Epoch 1414/4000\n",
      "25/25 - 0s - loss: 0.2347 - accuracy: 0.8833 - val_loss: 1.0199 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01414: val_loss did not improve from 0.32861\n",
      "Epoch 1415/4000\n",
      "25/25 - 0s - loss: 0.2347 - accuracy: 0.8794 - val_loss: 1.0800 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01415: val_loss did not improve from 0.32861\n",
      "Epoch 1416/4000\n",
      "25/25 - 0s - loss: 0.2403 - accuracy: 0.8755 - val_loss: 1.1695 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01416: val_loss did not improve from 0.32861\n",
      "Epoch 1417/4000\n",
      "25/25 - 0s - loss: 0.2366 - accuracy: 0.8768 - val_loss: 1.0768 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01417: val_loss did not improve from 0.32861\n",
      "Epoch 1418/4000\n",
      "25/25 - 0s - loss: 0.2339 - accuracy: 0.8807 - val_loss: 0.9495 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01418: val_loss did not improve from 0.32861\n",
      "Epoch 1419/4000\n",
      "25/25 - 0s - loss: 0.2321 - accuracy: 0.8859 - val_loss: 1.0531 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01419: val_loss did not improve from 0.32861\n",
      "Epoch 1420/4000\n",
      "25/25 - 0s - loss: 0.2291 - accuracy: 0.8846 - val_loss: 1.0604 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01420: val_loss did not improve from 0.32861\n",
      "Epoch 1421/4000\n",
      "25/25 - 0s - loss: 0.2268 - accuracy: 0.8885 - val_loss: 1.0816 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01421: val_loss did not improve from 0.32861\n",
      "Epoch 1422/4000\n",
      "25/25 - 0s - loss: 0.2323 - accuracy: 0.8833 - val_loss: 1.0590 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01422: val_loss did not improve from 0.32861\n",
      "Epoch 1423/4000\n",
      "25/25 - 0s - loss: 0.2312 - accuracy: 0.8833 - val_loss: 1.1223 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01423: val_loss did not improve from 0.32861\n",
      "Epoch 1424/4000\n",
      "25/25 - 0s - loss: 0.2288 - accuracy: 0.8859 - val_loss: 1.1212 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01424: val_loss did not improve from 0.32861\n",
      "Epoch 1425/4000\n",
      "25/25 - 0s - loss: 0.2297 - accuracy: 0.8833 - val_loss: 1.1329 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01425: val_loss did not improve from 0.32861\n",
      "Epoch 1426/4000\n",
      "25/25 - 0s - loss: 0.2266 - accuracy: 0.8820 - val_loss: 1.2789 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01426: val_loss did not improve from 0.32861\n",
      "Epoch 1427/4000\n",
      "25/25 - 0s - loss: 0.2317 - accuracy: 0.8846 - val_loss: 1.1309 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01427: val_loss did not improve from 0.32861\n",
      "Epoch 1428/4000\n",
      "25/25 - 0s - loss: 0.2272 - accuracy: 0.8820 - val_loss: 1.2109 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01428: val_loss did not improve from 0.32861\n",
      "Epoch 1429/4000\n",
      "25/25 - 0s - loss: 0.2346 - accuracy: 0.8794 - val_loss: 1.1545 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01429: val_loss did not improve from 0.32861\n",
      "Epoch 1430/4000\n",
      "25/25 - 0s - loss: 0.2269 - accuracy: 0.8898 - val_loss: 1.1546 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01430: val_loss did not improve from 0.32861\n",
      "Epoch 1431/4000\n",
      "25/25 - 0s - loss: 0.2339 - accuracy: 0.8872 - val_loss: 1.1827 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01431: val_loss did not improve from 0.32861\n",
      "Epoch 1432/4000\n",
      "25/25 - 1s - loss: 0.2322 - accuracy: 0.8846 - val_loss: 1.1071 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01432: val_loss did not improve from 0.32861\n",
      "Epoch 1433/4000\n",
      "25/25 - 1s - loss: 0.2308 - accuracy: 0.8807 - val_loss: 1.0280 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01433: val_loss did not improve from 0.32861\n",
      "Epoch 1434/4000\n",
      "25/25 - 1s - loss: 0.2320 - accuracy: 0.8781 - val_loss: 1.1046 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01434: val_loss did not improve from 0.32861\n",
      "Epoch 1435/4000\n",
      "25/25 - 0s - loss: 0.2276 - accuracy: 0.8911 - val_loss: 1.2279 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01435: val_loss did not improve from 0.32861\n",
      "Epoch 1436/4000\n",
      "25/25 - 0s - loss: 0.2272 - accuracy: 0.8859 - val_loss: 1.1526 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01436: val_loss did not improve from 0.32861\n",
      "Epoch 1437/4000\n",
      "25/25 - 0s - loss: 0.2266 - accuracy: 0.8846 - val_loss: 1.2170 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01437: val_loss did not improve from 0.32861\n",
      "Epoch 1438/4000\n",
      "25/25 - 0s - loss: 0.2285 - accuracy: 0.8872 - val_loss: 1.1305 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01438: val_loss did not improve from 0.32861\n",
      "Epoch 1439/4000\n",
      "25/25 - 0s - loss: 0.2380 - accuracy: 0.8846 - val_loss: 1.0559 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01439: val_loss did not improve from 0.32861\n",
      "Epoch 1440/4000\n",
      "25/25 - 0s - loss: 0.2264 - accuracy: 0.8833 - val_loss: 1.1624 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01440: val_loss did not improve from 0.32861\n",
      "Epoch 1441/4000\n",
      "25/25 - 0s - loss: 0.2279 - accuracy: 0.8859 - val_loss: 1.2180 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01441: val_loss did not improve from 0.32861\n",
      "Epoch 1442/4000\n",
      "25/25 - 0s - loss: 0.2390 - accuracy: 0.8833 - val_loss: 1.1331 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01442: val_loss did not improve from 0.32861\n",
      "Epoch 1443/4000\n",
      "25/25 - 0s - loss: 0.2395 - accuracy: 0.8742 - val_loss: 1.3362 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01443: val_loss did not improve from 0.32861\n",
      "Epoch 1444/4000\n",
      "25/25 - 0s - loss: 0.2309 - accuracy: 0.8846 - val_loss: 1.1549 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01444: val_loss did not improve from 0.32861\n",
      "Epoch 1445/4000\n",
      "25/25 - 0s - loss: 0.2278 - accuracy: 0.8872 - val_loss: 1.1699 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01445: val_loss did not improve from 0.32861\n",
      "Epoch 1446/4000\n",
      "25/25 - 0s - loss: 0.2282 - accuracy: 0.8872 - val_loss: 1.2392 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01446: val_loss did not improve from 0.32861\n",
      "Epoch 1447/4000\n",
      "25/25 - 0s - loss: 0.2308 - accuracy: 0.8872 - val_loss: 1.1776 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01447: val_loss did not improve from 0.32861\n",
      "Epoch 1448/4000\n",
      "25/25 - 0s - loss: 0.2301 - accuracy: 0.8833 - val_loss: 1.3619 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01448: val_loss did not improve from 0.32861\n",
      "Epoch 1449/4000\n",
      "25/25 - 0s - loss: 0.2304 - accuracy: 0.8885 - val_loss: 1.3097 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01449: val_loss did not improve from 0.32861\n",
      "Epoch 1450/4000\n",
      "25/25 - 0s - loss: 0.2289 - accuracy: 0.8846 - val_loss: 1.4299 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01450: val_loss did not improve from 0.32861\n",
      "Epoch 1451/4000\n",
      "25/25 - 0s - loss: 0.2594 - accuracy: 0.8755 - val_loss: 1.1755 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01451: val_loss did not improve from 0.32861\n",
      "Epoch 1452/4000\n",
      "25/25 - 0s - loss: 0.2322 - accuracy: 0.8742 - val_loss: 1.0772 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01452: val_loss did not improve from 0.32861\n",
      "Epoch 1453/4000\n",
      "25/25 - 0s - loss: 0.2292 - accuracy: 0.8768 - val_loss: 1.2001 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01453: val_loss did not improve from 0.32861\n",
      "Epoch 1454/4000\n",
      "25/25 - 0s - loss: 0.2403 - accuracy: 0.8794 - val_loss: 1.1490 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01454: val_loss did not improve from 0.32861\n",
      "Epoch 1455/4000\n",
      "25/25 - 0s - loss: 0.2319 - accuracy: 0.8885 - val_loss: 1.0633 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 01455: val_loss did not improve from 0.32861\n",
      "Epoch 1456/4000\n",
      "25/25 - 0s - loss: 0.2302 - accuracy: 0.8794 - val_loss: 0.9164 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01456: val_loss did not improve from 0.32861\n",
      "Epoch 1457/4000\n",
      "25/25 - 0s - loss: 0.2212 - accuracy: 0.8872 - val_loss: 0.9580 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01457: val_loss did not improve from 0.32861\n",
      "Epoch 1458/4000\n",
      "25/25 - 0s - loss: 0.2185 - accuracy: 0.8911 - val_loss: 0.9517 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01458: val_loss did not improve from 0.32861\n",
      "Epoch 1459/4000\n",
      "25/25 - 0s - loss: 0.2203 - accuracy: 0.8885 - val_loss: 1.0145 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01459: val_loss did not improve from 0.32861\n",
      "Epoch 1460/4000\n",
      "25/25 - 0s - loss: 0.2193 - accuracy: 0.8846 - val_loss: 1.0030 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01460: val_loss did not improve from 0.32861\n",
      "Epoch 1461/4000\n",
      "25/25 - 0s - loss: 0.2226 - accuracy: 0.8936 - val_loss: 0.9380 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01461: val_loss did not improve from 0.32861\n",
      "Epoch 1462/4000\n",
      "25/25 - 0s - loss: 0.2407 - accuracy: 0.8807 - val_loss: 1.0212 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01462: val_loss did not improve from 0.32861\n",
      "Epoch 1463/4000\n",
      "25/25 - 0s - loss: 0.2322 - accuracy: 0.8949 - val_loss: 1.0361 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01463: val_loss did not improve from 0.32861\n",
      "Epoch 1464/4000\n",
      "25/25 - 0s - loss: 0.2328 - accuracy: 0.8846 - val_loss: 0.9407 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01464: val_loss did not improve from 0.32861\n",
      "Epoch 1465/4000\n",
      "25/25 - 0s - loss: 0.2293 - accuracy: 0.8911 - val_loss: 1.1197 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 01465: val_loss did not improve from 0.32861\n",
      "Epoch 1466/4000\n",
      "25/25 - 0s - loss: 0.2244 - accuracy: 0.8988 - val_loss: 1.1244 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01466: val_loss did not improve from 0.32861\n",
      "Epoch 1467/4000\n",
      "25/25 - 0s - loss: 0.2751 - accuracy: 0.8807 - val_loss: 0.8294 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01467: val_loss did not improve from 0.32861\n",
      "Epoch 1468/4000\n",
      "25/25 - 0s - loss: 0.2325 - accuracy: 0.8911 - val_loss: 0.8642 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01468: val_loss did not improve from 0.32861\n",
      "Epoch 1469/4000\n",
      "25/25 - 0s - loss: 0.2255 - accuracy: 0.8936 - val_loss: 0.9029 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01469: val_loss did not improve from 0.32861\n",
      "Epoch 1470/4000\n",
      "25/25 - 0s - loss: 0.2221 - accuracy: 0.8923 - val_loss: 0.8767 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01470: val_loss did not improve from 0.32861\n",
      "Epoch 1471/4000\n",
      "25/25 - 0s - loss: 0.2251 - accuracy: 0.8898 - val_loss: 0.9680 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01471: val_loss did not improve from 0.32861\n",
      "Epoch 1472/4000\n",
      "25/25 - 0s - loss: 0.2417 - accuracy: 0.8820 - val_loss: 0.8996 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01472: val_loss did not improve from 0.32861\n",
      "Epoch 1473/4000\n",
      "25/25 - 0s - loss: 0.2253 - accuracy: 0.8885 - val_loss: 0.9122 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01473: val_loss did not improve from 0.32861\n",
      "Epoch 1474/4000\n",
      "25/25 - 0s - loss: 0.2261 - accuracy: 0.8885 - val_loss: 0.8924 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01474: val_loss did not improve from 0.32861\n",
      "Epoch 1475/4000\n",
      "25/25 - 0s - loss: 0.2230 - accuracy: 0.8872 - val_loss: 0.9166 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01475: val_loss did not improve from 0.32861\n",
      "Epoch 1476/4000\n",
      "25/25 - 0s - loss: 0.2176 - accuracy: 0.8936 - val_loss: 0.9571 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01476: val_loss did not improve from 0.32861\n",
      "Epoch 1477/4000\n",
      "25/25 - 0s - loss: 0.2178 - accuracy: 0.8936 - val_loss: 0.9757 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01477: val_loss did not improve from 0.32861\n",
      "Epoch 1478/4000\n",
      "25/25 - 0s - loss: 0.2213 - accuracy: 0.8898 - val_loss: 0.9850 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01478: val_loss did not improve from 0.32861\n",
      "Epoch 1479/4000\n",
      "25/25 - 0s - loss: 0.2158 - accuracy: 0.8923 - val_loss: 0.9559 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01479: val_loss did not improve from 0.32861\n",
      "Epoch 1480/4000\n",
      "25/25 - 0s - loss: 0.2151 - accuracy: 0.9014 - val_loss: 0.9633 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01480: val_loss did not improve from 0.32861\n",
      "Epoch 1481/4000\n",
      "25/25 - 0s - loss: 0.2225 - accuracy: 0.8923 - val_loss: 1.0379 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01481: val_loss did not improve from 0.32861\n",
      "Epoch 1482/4000\n",
      "25/25 - 0s - loss: 0.2144 - accuracy: 0.8936 - val_loss: 0.9714 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01482: val_loss did not improve from 0.32861\n",
      "Epoch 1483/4000\n",
      "25/25 - 0s - loss: 0.2130 - accuracy: 0.9053 - val_loss: 0.9380 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01483: val_loss did not improve from 0.32861\n",
      "Epoch 1484/4000\n",
      "25/25 - 0s - loss: 0.2206 - accuracy: 0.8911 - val_loss: 1.0924 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01484: val_loss did not improve from 0.32861\n",
      "Epoch 1485/4000\n",
      "25/25 - 0s - loss: 0.4308 - accuracy: 0.8560 - val_loss: 1.3177 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 01485: val_loss did not improve from 0.32861\n",
      "Epoch 1486/4000\n",
      "25/25 - 0s - loss: 0.6420 - accuracy: 0.8547 - val_loss: 2.4746 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 01486: val_loss did not improve from 0.32861\n",
      "Epoch 1487/4000\n",
      "25/25 - 0s - loss: 0.3999 - accuracy: 0.8599 - val_loss: 1.0624 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01487: val_loss did not improve from 0.32861\n",
      "Epoch 1488/4000\n",
      "25/25 - 0s - loss: 0.2741 - accuracy: 0.8794 - val_loss: 0.8296 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01488: val_loss did not improve from 0.32861\n",
      "Epoch 1489/4000\n",
      "25/25 - 0s - loss: 0.2543 - accuracy: 0.8833 - val_loss: 1.0316 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01489: val_loss did not improve from 0.32861\n",
      "Epoch 1490/4000\n",
      "25/25 - 0s - loss: 0.2347 - accuracy: 0.8962 - val_loss: 1.1585 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01490: val_loss did not improve from 0.32861\n",
      "Epoch 1491/4000\n",
      "25/25 - 0s - loss: 0.2297 - accuracy: 0.8949 - val_loss: 1.1981 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01491: val_loss did not improve from 0.32861\n",
      "Epoch 1492/4000\n",
      "25/25 - 0s - loss: 0.2419 - accuracy: 0.8690 - val_loss: 1.7028 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01492: val_loss did not improve from 0.32861\n",
      "Epoch 1493/4000\n",
      "25/25 - 0s - loss: 0.2259 - accuracy: 0.8949 - val_loss: 1.4166 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01493: val_loss did not improve from 0.32861\n",
      "Epoch 1494/4000\n",
      "25/25 - 0s - loss: 0.2268 - accuracy: 0.8885 - val_loss: 1.3927 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01494: val_loss did not improve from 0.32861\n",
      "Epoch 1495/4000\n",
      "25/25 - 0s - loss: 0.2187 - accuracy: 0.8898 - val_loss: 1.5514 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01495: val_loss did not improve from 0.32861\n",
      "Epoch 1496/4000\n",
      "25/25 - 0s - loss: 0.2209 - accuracy: 0.9040 - val_loss: 1.3745 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01496: val_loss did not improve from 0.32861\n",
      "Epoch 1497/4000\n",
      "25/25 - 0s - loss: 0.2127 - accuracy: 0.9001 - val_loss: 1.3511 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01497: val_loss did not improve from 0.32861\n",
      "Epoch 1498/4000\n",
      "25/25 - 0s - loss: 0.2135 - accuracy: 0.8975 - val_loss: 1.3187 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01498: val_loss did not improve from 0.32861\n",
      "Epoch 1499/4000\n",
      "25/25 - 0s - loss: 0.2121 - accuracy: 0.9001 - val_loss: 1.3288 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01499: val_loss did not improve from 0.32861\n",
      "Epoch 1500/4000\n",
      "25/25 - 0s - loss: 0.2162 - accuracy: 0.8923 - val_loss: 1.2899 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01500: val_loss did not improve from 0.32861\n",
      "Epoch 1501/4000\n",
      "25/25 - 0s - loss: 0.2113 - accuracy: 0.8988 - val_loss: 1.3617 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01501: val_loss did not improve from 0.32861\n",
      "Epoch 1502/4000\n",
      "25/25 - 0s - loss: 0.2189 - accuracy: 0.8988 - val_loss: 1.3337 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01502: val_loss did not improve from 0.32861\n",
      "Epoch 1503/4000\n",
      "25/25 - 0s - loss: 0.2234 - accuracy: 0.8859 - val_loss: 1.3835 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01503: val_loss did not improve from 0.32861\n",
      "Epoch 1504/4000\n",
      "25/25 - 0s - loss: 0.2160 - accuracy: 0.8975 - val_loss: 1.3240 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01504: val_loss did not improve from 0.32861\n",
      "Epoch 1505/4000\n",
      "25/25 - 0s - loss: 0.2137 - accuracy: 0.8911 - val_loss: 1.4303 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01505: val_loss did not improve from 0.32861\n",
      "Epoch 1506/4000\n",
      "25/25 - 0s - loss: 0.2107 - accuracy: 0.8988 - val_loss: 1.4612 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01506: val_loss did not improve from 0.32861\n",
      "Epoch 1507/4000\n",
      "25/25 - 0s - loss: 0.2113 - accuracy: 0.8988 - val_loss: 1.4107 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01507: val_loss did not improve from 0.32861\n",
      "Epoch 1508/4000\n",
      "25/25 - 0s - loss: 0.2123 - accuracy: 0.8936 - val_loss: 1.4809 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01508: val_loss did not improve from 0.32861\n",
      "Epoch 1509/4000\n",
      "25/25 - 0s - loss: 0.2103 - accuracy: 0.8936 - val_loss: 1.4961 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01509: val_loss did not improve from 0.32861\n",
      "Epoch 1510/4000\n",
      "25/25 - 0s - loss: 0.2157 - accuracy: 0.8975 - val_loss: 1.4034 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01510: val_loss did not improve from 0.32861\n",
      "Epoch 1511/4000\n",
      "25/25 - 0s - loss: 0.2094 - accuracy: 0.8949 - val_loss: 1.5564 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01511: val_loss did not improve from 0.32861\n",
      "Epoch 1512/4000\n",
      "25/25 - 0s - loss: 0.2100 - accuracy: 0.9040 - val_loss: 1.5132 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01512: val_loss did not improve from 0.32861\n",
      "Epoch 1513/4000\n",
      "25/25 - 0s - loss: 0.2113 - accuracy: 0.9001 - val_loss: 1.5159 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01513: val_loss did not improve from 0.32861\n",
      "Epoch 1514/4000\n",
      "25/25 - 0s - loss: 0.2076 - accuracy: 0.9001 - val_loss: 1.5581 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01514: val_loss did not improve from 0.32861\n",
      "Epoch 1515/4000\n",
      "25/25 - 0s - loss: 0.2126 - accuracy: 0.8911 - val_loss: 1.7248 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01515: val_loss did not improve from 0.32861\n",
      "Epoch 1516/4000\n",
      "25/25 - 0s - loss: 0.2140 - accuracy: 0.8936 - val_loss: 1.6761 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01516: val_loss did not improve from 0.32861\n",
      "Epoch 1517/4000\n",
      "25/25 - 0s - loss: 0.2129 - accuracy: 0.9001 - val_loss: 2.0079 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01517: val_loss did not improve from 0.32861\n",
      "Epoch 1518/4000\n",
      "25/25 - 0s - loss: 0.2176 - accuracy: 0.8962 - val_loss: 1.9208 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01518: val_loss did not improve from 0.32861\n",
      "Epoch 1519/4000\n",
      "25/25 - 0s - loss: 0.2213 - accuracy: 0.8923 - val_loss: 1.9215 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01519: val_loss did not improve from 0.32861\n",
      "Epoch 1520/4000\n",
      "25/25 - 0s - loss: 0.2223 - accuracy: 0.8820 - val_loss: 1.8092 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01520: val_loss did not improve from 0.32861\n",
      "Epoch 1521/4000\n",
      "25/25 - 0s - loss: 0.2209 - accuracy: 0.8781 - val_loss: 1.6292 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01521: val_loss did not improve from 0.32861\n",
      "Epoch 1522/4000\n",
      "25/25 - 0s - loss: 0.2429 - accuracy: 0.8729 - val_loss: 1.4856 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01522: val_loss did not improve from 0.32861\n",
      "Epoch 1523/4000\n",
      "25/25 - 0s - loss: 0.2203 - accuracy: 0.8794 - val_loss: 1.9076 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01523: val_loss did not improve from 0.32861\n",
      "Epoch 1524/4000\n",
      "25/25 - 0s - loss: 0.2157 - accuracy: 0.8949 - val_loss: 1.7431 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01524: val_loss did not improve from 0.32861\n",
      "Epoch 1525/4000\n",
      "25/25 - 0s - loss: 0.2207 - accuracy: 0.8885 - val_loss: 1.9306 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01525: val_loss did not improve from 0.32861\n",
      "Epoch 1526/4000\n",
      "25/25 - 0s - loss: 0.2213 - accuracy: 0.8988 - val_loss: 1.8570 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01526: val_loss did not improve from 0.32861\n",
      "Epoch 1527/4000\n",
      "25/25 - 0s - loss: 0.2543 - accuracy: 0.8936 - val_loss: 1.7473 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01527: val_loss did not improve from 0.32861\n",
      "Epoch 1528/4000\n",
      "25/25 - 0s - loss: 0.2193 - accuracy: 0.8859 - val_loss: 2.0036 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01528: val_loss did not improve from 0.32861\n",
      "Epoch 1529/4000\n",
      "25/25 - 0s - loss: 0.2176 - accuracy: 0.8911 - val_loss: 2.0435 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01529: val_loss did not improve from 0.32861\n",
      "Epoch 1530/4000\n",
      "25/25 - 0s - loss: 0.2195 - accuracy: 0.8833 - val_loss: 2.2633 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01530: val_loss did not improve from 0.32861\n",
      "Epoch 1531/4000\n",
      "25/25 - 0s - loss: 0.2231 - accuracy: 0.8962 - val_loss: 2.2309 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01531: val_loss did not improve from 0.32861\n",
      "Epoch 1532/4000\n",
      "25/25 - 0s - loss: 0.2193 - accuracy: 0.8833 - val_loss: 2.7966 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01532: val_loss did not improve from 0.32861\n",
      "Epoch 1533/4000\n",
      "25/25 - 0s - loss: 0.2216 - accuracy: 0.8949 - val_loss: 2.8787 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01533: val_loss did not improve from 0.32861\n",
      "Epoch 1534/4000\n",
      "25/25 - 0s - loss: 0.2132 - accuracy: 0.8949 - val_loss: 2.5023 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01534: val_loss did not improve from 0.32861\n",
      "Epoch 1535/4000\n",
      "25/25 - 0s - loss: 0.2170 - accuracy: 0.8898 - val_loss: 2.6850 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01535: val_loss did not improve from 0.32861\n",
      "Epoch 1536/4000\n",
      "25/25 - 0s - loss: 0.2128 - accuracy: 0.8936 - val_loss: 2.8397 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01536: val_loss did not improve from 0.32861\n",
      "Epoch 1537/4000\n",
      "25/25 - 0s - loss: 0.2150 - accuracy: 0.8962 - val_loss: 2.9382 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01537: val_loss did not improve from 0.32861\n",
      "Epoch 1538/4000\n",
      "25/25 - 0s - loss: 0.2113 - accuracy: 0.8911 - val_loss: 2.9369 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01538: val_loss did not improve from 0.32861\n",
      "Epoch 1539/4000\n",
      "25/25 - 0s - loss: 0.2133 - accuracy: 0.8962 - val_loss: 3.0662 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01539: val_loss did not improve from 0.32861\n",
      "Epoch 1540/4000\n",
      "25/25 - 0s - loss: 0.2115 - accuracy: 0.8975 - val_loss: 3.1398 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01540: val_loss did not improve from 0.32861\n",
      "Epoch 1541/4000\n",
      "25/25 - 0s - loss: 0.2170 - accuracy: 0.8936 - val_loss: 3.4512 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01541: val_loss did not improve from 0.32861\n",
      "Epoch 1542/4000\n",
      "25/25 - 0s - loss: 0.2165 - accuracy: 0.8898 - val_loss: 3.7954 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01542: val_loss did not improve from 0.32861\n",
      "Epoch 1543/4000\n",
      "25/25 - 0s - loss: 0.2132 - accuracy: 0.8936 - val_loss: 3.6482 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01543: val_loss did not improve from 0.32861\n",
      "Epoch 1544/4000\n",
      "25/25 - 0s - loss: 0.2166 - accuracy: 0.8885 - val_loss: 3.8827 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01544: val_loss did not improve from 0.32861\n",
      "Epoch 1545/4000\n",
      "25/25 - 0s - loss: 0.2144 - accuracy: 0.8975 - val_loss: 4.0784 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01545: val_loss did not improve from 0.32861\n",
      "Epoch 1546/4000\n",
      "25/25 - 0s - loss: 0.2129 - accuracy: 0.8898 - val_loss: 4.0719 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01546: val_loss did not improve from 0.32861\n",
      "Epoch 1547/4000\n",
      "25/25 - 0s - loss: 0.2128 - accuracy: 0.8949 - val_loss: 4.0723 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01547: val_loss did not improve from 0.32861\n",
      "Epoch 1548/4000\n",
      "25/25 - 0s - loss: 0.2144 - accuracy: 0.8911 - val_loss: 4.1588 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01548: val_loss did not improve from 0.32861\n",
      "Epoch 1549/4000\n",
      "25/25 - 0s - loss: 0.2106 - accuracy: 0.8962 - val_loss: 4.3356 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01549: val_loss did not improve from 0.32861\n",
      "Epoch 1550/4000\n",
      "25/25 - 0s - loss: 0.2121 - accuracy: 0.8936 - val_loss: 4.4320 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01550: val_loss did not improve from 0.32861\n",
      "Epoch 1551/4000\n",
      "25/25 - 0s - loss: 0.2135 - accuracy: 0.8936 - val_loss: 4.5348 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01551: val_loss did not improve from 0.32861\n",
      "Epoch 1552/4000\n",
      "25/25 - 0s - loss: 0.2214 - accuracy: 0.8859 - val_loss: 4.4301 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01552: val_loss did not improve from 0.32861\n",
      "Epoch 1553/4000\n",
      "25/25 - 0s - loss: 0.2139 - accuracy: 0.8936 - val_loss: 4.2685 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01553: val_loss did not improve from 0.32861\n",
      "Epoch 1554/4000\n",
      "25/25 - 0s - loss: 0.2126 - accuracy: 0.8949 - val_loss: 4.3052 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01554: val_loss did not improve from 0.32861\n",
      "Epoch 1555/4000\n",
      "25/25 - 0s - loss: 0.2169 - accuracy: 0.8911 - val_loss: 4.3661 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01555: val_loss did not improve from 0.32861\n",
      "Epoch 1556/4000\n",
      "25/25 - 0s - loss: 0.2177 - accuracy: 0.8898 - val_loss: 4.6885 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01556: val_loss did not improve from 0.32861\n",
      "Epoch 1557/4000\n",
      "25/25 - 0s - loss: 0.2168 - accuracy: 0.8936 - val_loss: 4.4746 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01557: val_loss did not improve from 0.32861\n",
      "Epoch 1558/4000\n",
      "25/25 - 0s - loss: 0.2138 - accuracy: 0.8936 - val_loss: 4.5528 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01558: val_loss did not improve from 0.32861\n",
      "Epoch 1559/4000\n",
      "25/25 - 0s - loss: 0.2112 - accuracy: 0.8936 - val_loss: 4.4667 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01559: val_loss did not improve from 0.32861\n",
      "Epoch 1560/4000\n",
      "25/25 - 0s - loss: 0.2122 - accuracy: 0.8936 - val_loss: 4.5220 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01560: val_loss did not improve from 0.32861\n",
      "Epoch 1561/4000\n",
      "25/25 - 0s - loss: 0.2149 - accuracy: 0.8923 - val_loss: 4.5345 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01561: val_loss did not improve from 0.32861\n",
      "Epoch 1562/4000\n",
      "25/25 - 0s - loss: 0.2153 - accuracy: 0.8872 - val_loss: 4.8157 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01562: val_loss did not improve from 0.32861\n",
      "Epoch 1563/4000\n",
      "25/25 - 0s - loss: 0.2132 - accuracy: 0.8872 - val_loss: 4.5795 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01563: val_loss did not improve from 0.32861\n",
      "Epoch 1564/4000\n",
      "25/25 - 0s - loss: 0.2123 - accuracy: 0.8911 - val_loss: 4.8090 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01564: val_loss did not improve from 0.32861\n",
      "Epoch 1565/4000\n",
      "25/25 - 0s - loss: 0.2132 - accuracy: 0.8949 - val_loss: 4.8537 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01565: val_loss did not improve from 0.32861\n",
      "Epoch 1566/4000\n",
      "25/25 - 0s - loss: 0.2120 - accuracy: 0.8898 - val_loss: 4.8215 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01566: val_loss did not improve from 0.32861\n",
      "Epoch 1567/4000\n",
      "25/25 - 0s - loss: 0.2120 - accuracy: 0.8988 - val_loss: 4.8724 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01567: val_loss did not improve from 0.32861\n",
      "Epoch 1568/4000\n",
      "25/25 - 0s - loss: 0.2125 - accuracy: 0.8962 - val_loss: 4.9280 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01568: val_loss did not improve from 0.32861\n",
      "Epoch 1569/4000\n",
      "25/25 - 0s - loss: 0.2168 - accuracy: 0.8949 - val_loss: 5.5785 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01569: val_loss did not improve from 0.32861\n",
      "Epoch 1570/4000\n",
      "25/25 - 0s - loss: 0.2211 - accuracy: 0.8962 - val_loss: 3.8757 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01570: val_loss did not improve from 0.32861\n",
      "Epoch 1571/4000\n",
      "25/25 - 0s - loss: 0.2421 - accuracy: 0.8755 - val_loss: 4.0804 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01571: val_loss did not improve from 0.32861\n",
      "Epoch 1572/4000\n",
      "25/25 - 0s - loss: 0.2151 - accuracy: 0.8923 - val_loss: 4.1490 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01572: val_loss did not improve from 0.32861\n",
      "Epoch 1573/4000\n",
      "25/25 - 0s - loss: 0.2140 - accuracy: 0.8949 - val_loss: 4.2033 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01573: val_loss did not improve from 0.32861\n",
      "Epoch 1574/4000\n",
      "25/25 - 0s - loss: 0.2146 - accuracy: 0.8872 - val_loss: 4.1742 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01574: val_loss did not improve from 0.32861\n",
      "Epoch 1575/4000\n",
      "25/25 - 0s - loss: 0.2151 - accuracy: 0.8923 - val_loss: 4.2704 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01575: val_loss did not improve from 0.32861\n",
      "Epoch 1576/4000\n",
      "25/25 - 0s - loss: 0.2123 - accuracy: 0.8962 - val_loss: 4.2202 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01576: val_loss did not improve from 0.32861\n",
      "Epoch 1577/4000\n",
      "25/25 - 0s - loss: 0.2148 - accuracy: 0.9001 - val_loss: 4.4881 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01577: val_loss did not improve from 0.32861\n",
      "Epoch 1578/4000\n",
      "25/25 - 0s - loss: 0.2124 - accuracy: 0.8949 - val_loss: 4.7743 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01578: val_loss did not improve from 0.32861\n",
      "Epoch 1579/4000\n",
      "25/25 - 0s - loss: 0.3916 - accuracy: 0.8885 - val_loss: 3.7699 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01579: val_loss did not improve from 0.32861\n",
      "Epoch 1580/4000\n",
      "25/25 - 0s - loss: 0.5710 - accuracy: 0.8729 - val_loss: 2.3366 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01580: val_loss did not improve from 0.32861\n",
      "Epoch 1581/4000\n",
      "25/25 - 0s - loss: 0.6300 - accuracy: 0.8314 - val_loss: 1.7819 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01581: val_loss did not improve from 0.32861\n",
      "Epoch 1582/4000\n",
      "25/25 - 0s - loss: 0.3444 - accuracy: 0.8405 - val_loss: 1.5344 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01582: val_loss did not improve from 0.32861\n",
      "Epoch 1583/4000\n",
      "25/25 - 0s - loss: 0.2815 - accuracy: 0.8664 - val_loss: 2.1948 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01583: val_loss did not improve from 0.32861\n",
      "Epoch 1584/4000\n",
      "25/25 - 0s - loss: 0.2656 - accuracy: 0.8781 - val_loss: 2.4101 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01584: val_loss did not improve from 0.32861\n",
      "Epoch 1585/4000\n",
      "25/25 - 0s - loss: 0.2555 - accuracy: 0.8872 - val_loss: 2.1425 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01585: val_loss did not improve from 0.32861\n",
      "Epoch 1586/4000\n",
      "25/25 - 0s - loss: 0.2449 - accuracy: 0.8872 - val_loss: 2.2169 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01586: val_loss did not improve from 0.32861\n",
      "Epoch 1587/4000\n",
      "25/25 - 0s - loss: 0.2881 - accuracy: 0.8586 - val_loss: 2.1997 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01587: val_loss did not improve from 0.32861\n",
      "Epoch 1588/4000\n",
      "25/25 - 0s - loss: 0.2546 - accuracy: 0.8962 - val_loss: 2.1128 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01588: val_loss did not improve from 0.32861\n",
      "Epoch 1589/4000\n",
      "25/25 - 0s - loss: 0.2423 - accuracy: 0.8923 - val_loss: 2.2540 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01589: val_loss did not improve from 0.32861\n",
      "Epoch 1590/4000\n",
      "25/25 - 0s - loss: 0.2515 - accuracy: 0.8872 - val_loss: 2.3212 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01590: val_loss did not improve from 0.32861\n",
      "Epoch 1591/4000\n",
      "25/25 - 0s - loss: 0.2513 - accuracy: 0.8898 - val_loss: 2.1823 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01591: val_loss did not improve from 0.32861\n",
      "Epoch 1592/4000\n",
      "25/25 - 0s - loss: 0.2523 - accuracy: 0.8949 - val_loss: 2.0733 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01592: val_loss did not improve from 0.32861\n",
      "Epoch 1593/4000\n",
      "25/25 - 0s - loss: 0.2508 - accuracy: 0.8911 - val_loss: 2.1443 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01593: val_loss did not improve from 0.32861\n",
      "Epoch 1594/4000\n",
      "25/25 - 0s - loss: 0.2464 - accuracy: 0.8975 - val_loss: 2.0771 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01594: val_loss did not improve from 0.32861\n",
      "Epoch 1595/4000\n",
      "25/25 - 0s - loss: 0.2445 - accuracy: 0.8911 - val_loss: 2.0711 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01595: val_loss did not improve from 0.32861\n",
      "Epoch 1596/4000\n",
      "25/25 - 0s - loss: 0.2447 - accuracy: 0.8988 - val_loss: 2.0749 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01596: val_loss did not improve from 0.32861\n",
      "Epoch 1597/4000\n",
      "25/25 - 0s - loss: 0.2453 - accuracy: 0.8911 - val_loss: 2.6824 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01597: val_loss did not improve from 0.32861\n",
      "Epoch 1598/4000\n",
      "25/25 - 0s - loss: 0.2702 - accuracy: 0.8898 - val_loss: 2.4307 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01598: val_loss did not improve from 0.32861\n",
      "Epoch 1599/4000\n",
      "25/25 - 0s - loss: 0.2537 - accuracy: 0.8820 - val_loss: 2.4007 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01599: val_loss did not improve from 0.32861\n",
      "Epoch 1600/4000\n",
      "25/25 - 0s - loss: 0.2547 - accuracy: 0.8846 - val_loss: 2.4639 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01600: val_loss did not improve from 0.32861\n",
      "Epoch 1601/4000\n",
      "25/25 - 0s - loss: 0.2432 - accuracy: 0.8885 - val_loss: 3.1043 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01601: val_loss did not improve from 0.32861\n",
      "Epoch 1602/4000\n",
      "25/25 - 0s - loss: 0.2471 - accuracy: 0.8833 - val_loss: 3.1312 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01602: val_loss did not improve from 0.32861\n",
      "Epoch 1603/4000\n",
      "25/25 - 0s - loss: 0.2500 - accuracy: 0.8794 - val_loss: 2.8619 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01603: val_loss did not improve from 0.32861\n",
      "Epoch 1604/4000\n",
      "25/25 - 0s - loss: 0.2510 - accuracy: 0.8794 - val_loss: 2.8807 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01604: val_loss did not improve from 0.32861\n",
      "Epoch 1605/4000\n",
      "25/25 - 0s - loss: 0.2477 - accuracy: 0.8742 - val_loss: 5.7036 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01605: val_loss did not improve from 0.32861\n",
      "Epoch 1606/4000\n",
      "25/25 - 0s - loss: 0.2405 - accuracy: 0.8859 - val_loss: 6.3246 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01606: val_loss did not improve from 0.32861\n",
      "Epoch 1607/4000\n",
      "25/25 - 0s - loss: 0.2458 - accuracy: 0.8794 - val_loss: 6.1301 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01607: val_loss did not improve from 0.32861\n",
      "Epoch 1608/4000\n",
      "25/25 - 0s - loss: 0.2389 - accuracy: 0.8885 - val_loss: 6.5137 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01608: val_loss did not improve from 0.32861\n",
      "Epoch 1609/4000\n",
      "25/25 - 0s - loss: 0.2549 - accuracy: 0.8859 - val_loss: 6.9209 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01609: val_loss did not improve from 0.32861\n",
      "Epoch 1610/4000\n",
      "25/25 - 0s - loss: 0.2448 - accuracy: 0.8768 - val_loss: 7.0319 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01610: val_loss did not improve from 0.32861\n",
      "Epoch 1611/4000\n",
      "25/25 - 0s - loss: 0.2354 - accuracy: 0.8898 - val_loss: 6.6980 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01611: val_loss did not improve from 0.32861\n",
      "Epoch 1612/4000\n",
      "25/25 - 0s - loss: 0.2329 - accuracy: 0.8911 - val_loss: 6.6627 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01612: val_loss did not improve from 0.32861\n",
      "Epoch 1613/4000\n",
      "25/25 - 0s - loss: 0.2326 - accuracy: 0.8846 - val_loss: 6.5838 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01613: val_loss did not improve from 0.32861\n",
      "Epoch 1614/4000\n",
      "25/25 - 0s - loss: 0.2297 - accuracy: 0.8898 - val_loss: 6.6281 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01614: val_loss did not improve from 0.32861\n",
      "Epoch 1615/4000\n",
      "25/25 - 0s - loss: 0.2378 - accuracy: 0.8885 - val_loss: 6.5900 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01615: val_loss did not improve from 0.32861\n",
      "Epoch 1616/4000\n",
      "25/25 - 0s - loss: 0.2306 - accuracy: 0.8936 - val_loss: 6.6323 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01616: val_loss did not improve from 0.32861\n",
      "Epoch 1617/4000\n",
      "25/25 - 0s - loss: 0.2317 - accuracy: 0.8898 - val_loss: 6.6204 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01617: val_loss did not improve from 0.32861\n",
      "Epoch 1618/4000\n",
      "25/25 - 0s - loss: 0.2332 - accuracy: 0.8846 - val_loss: 6.6445 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01618: val_loss did not improve from 0.32861\n",
      "Epoch 1619/4000\n",
      "25/25 - 0s - loss: 0.2397 - accuracy: 0.8846 - val_loss: 6.5006 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01619: val_loss did not improve from 0.32861\n",
      "Epoch 1620/4000\n",
      "25/25 - 0s - loss: 0.2331 - accuracy: 0.8859 - val_loss: 6.3949 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01620: val_loss did not improve from 0.32861\n",
      "Epoch 1621/4000\n",
      "25/25 - 0s - loss: 0.2347 - accuracy: 0.8885 - val_loss: 6.4520 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01621: val_loss did not improve from 0.32861\n",
      "Epoch 1622/4000\n",
      "25/25 - 0s - loss: 0.2428 - accuracy: 0.8885 - val_loss: 6.5188 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01622: val_loss did not improve from 0.32861\n",
      "Epoch 1623/4000\n",
      "25/25 - 0s - loss: 0.2300 - accuracy: 0.8898 - val_loss: 6.6335 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01623: val_loss did not improve from 0.32861\n",
      "Epoch 1624/4000\n",
      "25/25 - 0s - loss: 0.2326 - accuracy: 0.8923 - val_loss: 6.5573 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01624: val_loss did not improve from 0.32861\n",
      "Epoch 1625/4000\n",
      "25/25 - 0s - loss: 0.2296 - accuracy: 0.8898 - val_loss: 6.5714 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01625: val_loss did not improve from 0.32861\n",
      "Epoch 1626/4000\n",
      "25/25 - 0s - loss: 0.2364 - accuracy: 0.8859 - val_loss: 6.4403 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01626: val_loss did not improve from 0.32861\n",
      "Epoch 1627/4000\n",
      "25/25 - 0s - loss: 0.2333 - accuracy: 0.8833 - val_loss: 6.5891 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01627: val_loss did not improve from 0.32861\n",
      "Epoch 1628/4000\n",
      "25/25 - 0s - loss: 0.2304 - accuracy: 0.8833 - val_loss: 6.4471 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01628: val_loss did not improve from 0.32861\n",
      "Epoch 1629/4000\n",
      "25/25 - 0s - loss: 0.2309 - accuracy: 0.8885 - val_loss: 6.3702 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01629: val_loss did not improve from 0.32861\n",
      "Epoch 1630/4000\n",
      "25/25 - 0s - loss: 0.2320 - accuracy: 0.8885 - val_loss: 6.4210 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01630: val_loss did not improve from 0.32861\n",
      "Epoch 1631/4000\n",
      "25/25 - 0s - loss: 0.2306 - accuracy: 0.8911 - val_loss: 6.4562 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01631: val_loss did not improve from 0.32861\n",
      "Epoch 1632/4000\n",
      "25/25 - 0s - loss: 0.2303 - accuracy: 0.8885 - val_loss: 6.4420 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01632: val_loss did not improve from 0.32861\n",
      "Epoch 1633/4000\n",
      "25/25 - 0s - loss: 0.2322 - accuracy: 0.8820 - val_loss: 6.4037 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01633: val_loss did not improve from 0.32861\n",
      "Epoch 1634/4000\n",
      "25/25 - 0s - loss: 0.2384 - accuracy: 0.8846 - val_loss: 6.2800 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01634: val_loss did not improve from 0.32861\n",
      "Epoch 1635/4000\n",
      "25/25 - 0s - loss: 0.2397 - accuracy: 0.8703 - val_loss: 6.2154 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01635: val_loss did not improve from 0.32861\n",
      "Epoch 1636/4000\n",
      "25/25 - 0s - loss: 0.2382 - accuracy: 0.8872 - val_loss: 6.1591 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01636: val_loss did not improve from 0.32861\n",
      "Epoch 1637/4000\n",
      "25/25 - 0s - loss: 0.2337 - accuracy: 0.8820 - val_loss: 6.2564 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01637: val_loss did not improve from 0.32861\n",
      "Epoch 1638/4000\n",
      "25/25 - 0s - loss: 0.2404 - accuracy: 0.8742 - val_loss: 6.6509 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01638: val_loss did not improve from 0.32861\n",
      "Epoch 1639/4000\n",
      "25/25 - 0s - loss: 0.2380 - accuracy: 0.8833 - val_loss: 6.4273 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01639: val_loss did not improve from 0.32861\n",
      "Epoch 1640/4000\n",
      "25/25 - 0s - loss: 0.2360 - accuracy: 0.8833 - val_loss: 6.4145 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01640: val_loss did not improve from 0.32861\n",
      "Epoch 1641/4000\n",
      "25/25 - 0s - loss: 0.2380 - accuracy: 0.8911 - val_loss: 6.3453 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01641: val_loss did not improve from 0.32861\n",
      "Epoch 1642/4000\n",
      "25/25 - 0s - loss: 0.2348 - accuracy: 0.8872 - val_loss: 6.2950 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01642: val_loss did not improve from 0.32861\n",
      "Epoch 1643/4000\n",
      "25/25 - 0s - loss: 0.2340 - accuracy: 0.8833 - val_loss: 6.3730 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01643: val_loss did not improve from 0.32861\n",
      "Epoch 1644/4000\n",
      "25/25 - 0s - loss: 0.2362 - accuracy: 0.8936 - val_loss: 6.2074 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01644: val_loss did not improve from 0.32861\n",
      "Epoch 1645/4000\n",
      "25/25 - 0s - loss: 0.2381 - accuracy: 0.8833 - val_loss: 6.2746 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01645: val_loss did not improve from 0.32861\n",
      "Epoch 1646/4000\n",
      "25/25 - 0s - loss: 0.2370 - accuracy: 0.8911 - val_loss: 5.9098 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01646: val_loss did not improve from 0.32861\n",
      "Epoch 1647/4000\n",
      "25/25 - 0s - loss: 0.2371 - accuracy: 0.8872 - val_loss: 6.0017 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01647: val_loss did not improve from 0.32861\n",
      "Epoch 1648/4000\n",
      "25/25 - 0s - loss: 0.2352 - accuracy: 0.8859 - val_loss: 5.9783 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01648: val_loss did not improve from 0.32861\n",
      "Epoch 1649/4000\n",
      "25/25 - 0s - loss: 0.2360 - accuracy: 0.8820 - val_loss: 6.0373 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01649: val_loss did not improve from 0.32861\n",
      "Epoch 1650/4000\n",
      "25/25 - 0s - loss: 0.2340 - accuracy: 0.8885 - val_loss: 6.1131 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01650: val_loss did not improve from 0.32861\n",
      "Epoch 1651/4000\n",
      "25/25 - 0s - loss: 0.2353 - accuracy: 0.8885 - val_loss: 6.1140 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01651: val_loss did not improve from 0.32861\n",
      "Epoch 1652/4000\n",
      "25/25 - 0s - loss: 0.2342 - accuracy: 0.8885 - val_loss: 5.9825 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01652: val_loss did not improve from 0.32861\n",
      "Epoch 1653/4000\n",
      "25/25 - 0s - loss: 0.2536 - accuracy: 0.8586 - val_loss: 5.9001 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01653: val_loss did not improve from 0.32861\n",
      "Epoch 1654/4000\n",
      "25/25 - 0s - loss: 0.2375 - accuracy: 0.8898 - val_loss: 5.9497 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01654: val_loss did not improve from 0.32861\n",
      "Epoch 1655/4000\n",
      "25/25 - 0s - loss: 0.2371 - accuracy: 0.8859 - val_loss: 5.8380 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01655: val_loss did not improve from 0.32861\n",
      "Epoch 1656/4000\n",
      "25/25 - 0s - loss: 0.2345 - accuracy: 0.8885 - val_loss: 5.8346 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01656: val_loss did not improve from 0.32861\n",
      "Epoch 1657/4000\n",
      "25/25 - 0s - loss: 0.2340 - accuracy: 0.8859 - val_loss: 5.7076 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01657: val_loss did not improve from 0.32861\n",
      "Epoch 1658/4000\n",
      "25/25 - 0s - loss: 0.2352 - accuracy: 0.8898 - val_loss: 5.8010 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01658: val_loss did not improve from 0.32861\n",
      "Epoch 1659/4000\n",
      "25/25 - 0s - loss: 0.2353 - accuracy: 0.8833 - val_loss: 5.9111 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01659: val_loss did not improve from 0.32861\n",
      "Epoch 1660/4000\n",
      "25/25 - 0s - loss: 0.2324 - accuracy: 0.8911 - val_loss: 5.8493 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01660: val_loss did not improve from 0.32861\n",
      "Epoch 1661/4000\n",
      "25/25 - 0s - loss: 0.2350 - accuracy: 0.8936 - val_loss: 5.6996 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01661: val_loss did not improve from 0.32861\n",
      "Epoch 1662/4000\n",
      "25/25 - 0s - loss: 0.2338 - accuracy: 0.8898 - val_loss: 5.6506 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01662: val_loss did not improve from 0.32861\n",
      "Epoch 1663/4000\n",
      "25/25 - 0s - loss: 0.2338 - accuracy: 0.8898 - val_loss: 5.6640 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01663: val_loss did not improve from 0.32861\n",
      "Epoch 1664/4000\n",
      "25/25 - 0s - loss: 0.2369 - accuracy: 0.8846 - val_loss: 5.8561 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01664: val_loss did not improve from 0.32861\n",
      "Epoch 1665/4000\n",
      "25/25 - 0s - loss: 0.2360 - accuracy: 0.8872 - val_loss: 5.8537 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01665: val_loss did not improve from 0.32861\n",
      "Epoch 1666/4000\n",
      "25/25 - 0s - loss: 0.2352 - accuracy: 0.8923 - val_loss: 5.9483 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01666: val_loss did not improve from 0.32861\n",
      "Epoch 1667/4000\n",
      "25/25 - 0s - loss: 0.2330 - accuracy: 0.8898 - val_loss: 5.9589 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01667: val_loss did not improve from 0.32861\n",
      "Epoch 1668/4000\n",
      "25/25 - 0s - loss: 0.2317 - accuracy: 0.8859 - val_loss: 5.9865 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01668: val_loss did not improve from 0.32861\n",
      "Epoch 1669/4000\n",
      "25/25 - 0s - loss: 0.2328 - accuracy: 0.8885 - val_loss: 6.0676 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01669: val_loss did not improve from 0.32861\n",
      "Epoch 1670/4000\n",
      "25/25 - 0s - loss: 0.2347 - accuracy: 0.8846 - val_loss: 6.1387 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01670: val_loss did not improve from 0.32861\n",
      "Epoch 1671/4000\n",
      "25/25 - 1s - loss: 0.2304 - accuracy: 0.8872 - val_loss: 6.0468 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01671: val_loss did not improve from 0.32861\n",
      "Epoch 1672/4000\n",
      "25/25 - 0s - loss: 0.2317 - accuracy: 0.8820 - val_loss: 6.0702 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01672: val_loss did not improve from 0.32861\n",
      "Epoch 1673/4000\n",
      "25/25 - 0s - loss: 0.2307 - accuracy: 0.8898 - val_loss: 5.9877 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01673: val_loss did not improve from 0.32861\n",
      "Epoch 1674/4000\n",
      "25/25 - 0s - loss: 0.2346 - accuracy: 0.8885 - val_loss: 5.9608 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01674: val_loss did not improve from 0.32861\n",
      "Epoch 1675/4000\n",
      "25/25 - 0s - loss: 0.2354 - accuracy: 0.8885 - val_loss: 5.9375 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01675: val_loss did not improve from 0.32861\n",
      "Epoch 1676/4000\n",
      "25/25 - 0s - loss: 0.2317 - accuracy: 0.8898 - val_loss: 6.0442 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01676: val_loss did not improve from 0.32861\n",
      "Epoch 1677/4000\n",
      "25/25 - 0s - loss: 0.2324 - accuracy: 0.8820 - val_loss: 6.1127 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01677: val_loss did not improve from 0.32861\n",
      "Epoch 1678/4000\n",
      "25/25 - 1s - loss: 0.2307 - accuracy: 0.8898 - val_loss: 5.9361 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01678: val_loss did not improve from 0.32861\n",
      "Epoch 1679/4000\n",
      "25/25 - 0s - loss: 0.2321 - accuracy: 0.8898 - val_loss: 6.0616 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01679: val_loss did not improve from 0.32861\n",
      "Epoch 1680/4000\n",
      "25/25 - 0s - loss: 0.2306 - accuracy: 0.8885 - val_loss: 6.0457 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01680: val_loss did not improve from 0.32861\n",
      "Epoch 1681/4000\n",
      "25/25 - 0s - loss: 0.2321 - accuracy: 0.8885 - val_loss: 5.8215 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01681: val_loss did not improve from 0.32861\n",
      "Epoch 1682/4000\n",
      "25/25 - 0s - loss: 0.2358 - accuracy: 0.8872 - val_loss: 5.9281 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01682: val_loss did not improve from 0.32861\n",
      "Epoch 1683/4000\n",
      "25/25 - 0s - loss: 0.2317 - accuracy: 0.8898 - val_loss: 5.8331 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01683: val_loss did not improve from 0.32861\n",
      "Epoch 1684/4000\n",
      "25/25 - 1s - loss: 0.2336 - accuracy: 0.8872 - val_loss: 5.8277 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01684: val_loss did not improve from 0.32861\n",
      "Epoch 1685/4000\n",
      "25/25 - 0s - loss: 0.2313 - accuracy: 0.8911 - val_loss: 5.9281 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01685: val_loss did not improve from 0.32861\n",
      "Epoch 1686/4000\n",
      "25/25 - 0s - loss: 0.2311 - accuracy: 0.8859 - val_loss: 5.8326 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01686: val_loss did not improve from 0.32861\n",
      "Epoch 1687/4000\n",
      "25/25 - 0s - loss: 0.2320 - accuracy: 0.8872 - val_loss: 5.8153 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01687: val_loss did not improve from 0.32861\n",
      "Epoch 1688/4000\n",
      "25/25 - 0s - loss: 0.2307 - accuracy: 0.8872 - val_loss: 5.9434 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01688: val_loss did not improve from 0.32861\n",
      "Epoch 1689/4000\n",
      "25/25 - 1s - loss: 0.2332 - accuracy: 0.8911 - val_loss: 5.8815 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01689: val_loss did not improve from 0.32861\n",
      "Epoch 1690/4000\n",
      "25/25 - 1s - loss: 0.2371 - accuracy: 0.8872 - val_loss: 5.8443 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01690: val_loss did not improve from 0.32861\n",
      "Epoch 1691/4000\n",
      "25/25 - 1s - loss: 0.2333 - accuracy: 0.8923 - val_loss: 5.8487 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01691: val_loss did not improve from 0.32861\n",
      "Epoch 1692/4000\n",
      "25/25 - 0s - loss: 0.2344 - accuracy: 0.8885 - val_loss: 5.9001 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01692: val_loss did not improve from 0.32861\n",
      "Epoch 1693/4000\n",
      "25/25 - 1s - loss: 0.2313 - accuracy: 0.8885 - val_loss: 5.4360 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01693: val_loss did not improve from 0.32861\n",
      "Epoch 1694/4000\n",
      "25/25 - 0s - loss: 0.2310 - accuracy: 0.8872 - val_loss: 5.6112 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01694: val_loss did not improve from 0.32861\n",
      "Epoch 1695/4000\n",
      "25/25 - 0s - loss: 0.2343 - accuracy: 0.8936 - val_loss: 5.6996 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01695: val_loss did not improve from 0.32861\n",
      "Epoch 1696/4000\n",
      "25/25 - 0s - loss: 0.2344 - accuracy: 0.8859 - val_loss: 5.9844 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01696: val_loss did not improve from 0.32861\n",
      "Epoch 1697/4000\n",
      "25/25 - 0s - loss: 0.2333 - accuracy: 0.8885 - val_loss: 6.0311 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01697: val_loss did not improve from 0.32861\n",
      "Epoch 1698/4000\n",
      "25/25 - 0s - loss: 0.2494 - accuracy: 0.8755 - val_loss: 6.0037 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01698: val_loss did not improve from 0.32861\n",
      "Epoch 1699/4000\n",
      "25/25 - 1s - loss: 0.2394 - accuracy: 0.8923 - val_loss: 5.2536 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01699: val_loss did not improve from 0.32861\n",
      "Epoch 1700/4000\n",
      "25/25 - 1s - loss: 0.2254 - accuracy: 0.8898 - val_loss: 5.7312 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01700: val_loss did not improve from 0.32861\n",
      "Epoch 1701/4000\n",
      "25/25 - 1s - loss: 0.2502 - accuracy: 0.8949 - val_loss: 5.1864 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01701: val_loss did not improve from 0.32861\n",
      "Epoch 1702/4000\n",
      "25/25 - 0s - loss: 0.2274 - accuracy: 0.8898 - val_loss: 5.0527 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01702: val_loss did not improve from 0.32861\n",
      "Epoch 1703/4000\n",
      "25/25 - 0s - loss: 0.2290 - accuracy: 0.8923 - val_loss: 4.4236 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01703: val_loss did not improve from 0.32861\n",
      "Epoch 1704/4000\n",
      "25/25 - 2s - loss: 0.2255 - accuracy: 0.8885 - val_loss: 4.4671 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01704: val_loss did not improve from 0.32861\n",
      "Epoch 1705/4000\n",
      "25/25 - 3s - loss: 0.2232 - accuracy: 0.8936 - val_loss: 4.6702 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01705: val_loss did not improve from 0.32861\n",
      "Epoch 1706/4000\n",
      "25/25 - 1s - loss: 0.2236 - accuracy: 0.8898 - val_loss: 4.6910 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01706: val_loss did not improve from 0.32861\n",
      "Epoch 1707/4000\n",
      "25/25 - 0s - loss: 0.2316 - accuracy: 0.8898 - val_loss: 4.7831 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01707: val_loss did not improve from 0.32861\n",
      "Epoch 1708/4000\n",
      "25/25 - 0s - loss: 0.2428 - accuracy: 0.8885 - val_loss: 4.1993 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01708: val_loss did not improve from 0.32861\n",
      "Epoch 1709/4000\n",
      "25/25 - 1s - loss: 0.2621 - accuracy: 0.8807 - val_loss: 4.6550 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01709: val_loss did not improve from 0.32861\n",
      "Epoch 1710/4000\n",
      "25/25 - 0s - loss: 0.2275 - accuracy: 0.8885 - val_loss: 5.3886 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01710: val_loss did not improve from 0.32861\n",
      "Epoch 1711/4000\n",
      "25/25 - 1s - loss: 0.2267 - accuracy: 0.8923 - val_loss: 5.7542 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01711: val_loss did not improve from 0.32861\n",
      "Epoch 1712/4000\n",
      "25/25 - 1s - loss: 0.2354 - accuracy: 0.8923 - val_loss: 5.6557 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01712: val_loss did not improve from 0.32861\n",
      "Epoch 1713/4000\n",
      "25/25 - 2s - loss: 0.2469 - accuracy: 0.8885 - val_loss: 6.5721 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01713: val_loss did not improve from 0.32861\n",
      "Epoch 1714/4000\n",
      "25/25 - 1s - loss: 0.2342 - accuracy: 0.8962 - val_loss: 6.3622 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01714: val_loss did not improve from 0.32861\n",
      "Epoch 1715/4000\n",
      "25/25 - 0s - loss: 0.2246 - accuracy: 0.8923 - val_loss: 6.7036 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01715: val_loss did not improve from 0.32861\n",
      "Epoch 1716/4000\n",
      "25/25 - 0s - loss: 0.2407 - accuracy: 0.8898 - val_loss: 5.8672 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01716: val_loss did not improve from 0.32861\n",
      "Epoch 1717/4000\n",
      "25/25 - 0s - loss: 0.2260 - accuracy: 0.8911 - val_loss: 6.1927 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01717: val_loss did not improve from 0.32861\n",
      "Epoch 1718/4000\n",
      "25/25 - 0s - loss: 0.2340 - accuracy: 0.8949 - val_loss: 7.2031 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01718: val_loss did not improve from 0.32861\n",
      "Epoch 1719/4000\n",
      "25/25 - 0s - loss: 0.2321 - accuracy: 0.8820 - val_loss: 7.4354 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01719: val_loss did not improve from 0.32861\n",
      "Epoch 1720/4000\n",
      "25/25 - 0s - loss: 0.2272 - accuracy: 0.8911 - val_loss: 6.0125 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01720: val_loss did not improve from 0.32861\n",
      "Epoch 1721/4000\n",
      "25/25 - 0s - loss: 0.2263 - accuracy: 0.8911 - val_loss: 6.1826 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01721: val_loss did not improve from 0.32861\n",
      "Epoch 1722/4000\n",
      "25/25 - 0s - loss: 0.2309 - accuracy: 0.8859 - val_loss: 6.2329 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01722: val_loss did not improve from 0.32861\n",
      "Epoch 1723/4000\n",
      "25/25 - 0s - loss: 0.2234 - accuracy: 0.8911 - val_loss: 6.7510 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01723: val_loss did not improve from 0.32861\n",
      "Epoch 1724/4000\n",
      "25/25 - 0s - loss: 0.2237 - accuracy: 0.8923 - val_loss: 6.4754 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01724: val_loss did not improve from 0.32861\n",
      "Epoch 1725/4000\n",
      "25/25 - 0s - loss: 0.2223 - accuracy: 0.8949 - val_loss: 6.6688 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01725: val_loss did not improve from 0.32861\n",
      "Epoch 1726/4000\n",
      "25/25 - 0s - loss: 0.2242 - accuracy: 0.8859 - val_loss: 6.7484 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01726: val_loss did not improve from 0.32861\n",
      "Epoch 1727/4000\n",
      "25/25 - 0s - loss: 0.2344 - accuracy: 0.8768 - val_loss: 6.2670 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01727: val_loss did not improve from 0.32861\n",
      "Epoch 1728/4000\n",
      "25/25 - 0s - loss: 0.2221 - accuracy: 0.8923 - val_loss: 6.4680 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01728: val_loss did not improve from 0.32861\n",
      "Epoch 1729/4000\n",
      "25/25 - 0s - loss: 0.2437 - accuracy: 0.8794 - val_loss: 6.1987 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01729: val_loss did not improve from 0.32861\n",
      "Epoch 1730/4000\n",
      "25/25 - 0s - loss: 0.2335 - accuracy: 0.8898 - val_loss: 6.1894 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01730: val_loss did not improve from 0.32861\n",
      "Epoch 1731/4000\n",
      "25/25 - 0s - loss: 0.2312 - accuracy: 0.8911 - val_loss: 6.0750 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01731: val_loss did not improve from 0.32861\n",
      "Epoch 1732/4000\n",
      "25/25 - 0s - loss: 0.2290 - accuracy: 0.8768 - val_loss: 6.2045 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01732: val_loss did not improve from 0.32861\n",
      "Epoch 1733/4000\n",
      "25/25 - 0s - loss: 0.2244 - accuracy: 0.8949 - val_loss: 6.3588 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01733: val_loss did not improve from 0.32861\n",
      "Epoch 1734/4000\n",
      "25/25 - 0s - loss: 0.2191 - accuracy: 0.8911 - val_loss: 6.4649 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01734: val_loss did not improve from 0.32861\n",
      "Epoch 1735/4000\n",
      "25/25 - 0s - loss: 0.2218 - accuracy: 0.8962 - val_loss: 6.2500 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01735: val_loss did not improve from 0.32861\n",
      "Epoch 1736/4000\n",
      "25/25 - 0s - loss: 0.2259 - accuracy: 0.8949 - val_loss: 6.3635 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01736: val_loss did not improve from 0.32861\n",
      "Epoch 1737/4000\n",
      "25/25 - 0s - loss: 0.2504 - accuracy: 0.8573 - val_loss: 6.8310 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01737: val_loss did not improve from 0.32861\n",
      "Epoch 1738/4000\n",
      "25/25 - 0s - loss: 0.2217 - accuracy: 0.8885 - val_loss: 6.8801 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01738: val_loss did not improve from 0.32861\n",
      "Epoch 1739/4000\n",
      "25/25 - 0s - loss: 0.2204 - accuracy: 0.8936 - val_loss: 6.8834 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01739: val_loss did not improve from 0.32861\n",
      "Epoch 1740/4000\n",
      "25/25 - 0s - loss: 0.2182 - accuracy: 0.8936 - val_loss: 6.8494 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01740: val_loss did not improve from 0.32861\n",
      "Epoch 1741/4000\n",
      "25/25 - 0s - loss: 0.2170 - accuracy: 0.8898 - val_loss: 6.9085 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01741: val_loss did not improve from 0.32861\n",
      "Epoch 1742/4000\n",
      "25/25 - 0s - loss: 0.2191 - accuracy: 0.8898 - val_loss: 7.0219 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01742: val_loss did not improve from 0.32861\n",
      "Epoch 1743/4000\n",
      "25/25 - 0s - loss: 0.2224 - accuracy: 0.8898 - val_loss: 6.8826 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01743: val_loss did not improve from 0.32861\n",
      "Epoch 1744/4000\n",
      "25/25 - 0s - loss: 0.2250 - accuracy: 0.8911 - val_loss: 6.5835 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01744: val_loss did not improve from 0.32861\n",
      "Epoch 1745/4000\n",
      "25/25 - 0s - loss: 0.2184 - accuracy: 0.8846 - val_loss: 6.5046 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01745: val_loss did not improve from 0.32861\n",
      "Epoch 1746/4000\n",
      "25/25 - 0s - loss: 0.2171 - accuracy: 0.8911 - val_loss: 6.5944 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01746: val_loss did not improve from 0.32861\n",
      "Epoch 1747/4000\n",
      "25/25 - 0s - loss: 0.2199 - accuracy: 0.9001 - val_loss: 6.8201 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01747: val_loss did not improve from 0.32861\n",
      "Epoch 1748/4000\n",
      "25/25 - 0s - loss: 0.2230 - accuracy: 0.8859 - val_loss: 6.9683 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01748: val_loss did not improve from 0.32861\n",
      "Epoch 1749/4000\n",
      "25/25 - 0s - loss: 0.2189 - accuracy: 0.8911 - val_loss: 7.1676 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01749: val_loss did not improve from 0.32861\n",
      "Epoch 1750/4000\n",
      "25/25 - 0s - loss: 0.2267 - accuracy: 0.8911 - val_loss: 7.1978 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01750: val_loss did not improve from 0.32861\n",
      "Epoch 1751/4000\n",
      "25/25 - 0s - loss: 0.2178 - accuracy: 0.8885 - val_loss: 7.2444 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01751: val_loss did not improve from 0.32861\n",
      "Epoch 1752/4000\n",
      "25/25 - 0s - loss: 0.2181 - accuracy: 0.8898 - val_loss: 7.3248 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01752: val_loss did not improve from 0.32861\n",
      "Epoch 1753/4000\n",
      "25/25 - 0s - loss: 0.2173 - accuracy: 0.8923 - val_loss: 7.1214 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01753: val_loss did not improve from 0.32861\n",
      "Epoch 1754/4000\n",
      "25/25 - 0s - loss: 0.2459 - accuracy: 0.8807 - val_loss: 7.0702 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01754: val_loss did not improve from 0.32861\n",
      "Epoch 1755/4000\n",
      "25/25 - 0s - loss: 0.2419 - accuracy: 0.8898 - val_loss: 5.8777 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01755: val_loss did not improve from 0.32861\n",
      "Epoch 1756/4000\n",
      "25/25 - 0s - loss: 0.2316 - accuracy: 0.8859 - val_loss: 6.2598 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01756: val_loss did not improve from 0.32861\n",
      "Epoch 1757/4000\n",
      "25/25 - 0s - loss: 0.2257 - accuracy: 0.8794 - val_loss: 6.8943 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01757: val_loss did not improve from 0.32861\n",
      "Epoch 1758/4000\n",
      "25/25 - 0s - loss: 0.2206 - accuracy: 0.8975 - val_loss: 6.7240 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01758: val_loss did not improve from 0.32861\n",
      "Epoch 1759/4000\n",
      "25/25 - 0s - loss: 0.2243 - accuracy: 0.8833 - val_loss: 6.7974 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01759: val_loss did not improve from 0.32861\n",
      "Epoch 1760/4000\n",
      "25/25 - 0s - loss: 0.2215 - accuracy: 0.8885 - val_loss: 6.9474 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01760: val_loss did not improve from 0.32861\n",
      "Epoch 1761/4000\n",
      "25/25 - 0s - loss: 0.2239 - accuracy: 0.8911 - val_loss: 6.8371 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01761: val_loss did not improve from 0.32861\n",
      "Epoch 1762/4000\n",
      "25/25 - 0s - loss: 0.2213 - accuracy: 0.8898 - val_loss: 6.8238 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01762: val_loss did not improve from 0.32861\n",
      "Epoch 1763/4000\n",
      "25/25 - 0s - loss: 0.2210 - accuracy: 0.8949 - val_loss: 6.8682 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01763: val_loss did not improve from 0.32861\n",
      "Epoch 1764/4000\n",
      "25/25 - 0s - loss: 0.2182 - accuracy: 0.8923 - val_loss: 6.9458 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01764: val_loss did not improve from 0.32861\n",
      "Epoch 1765/4000\n",
      "25/25 - 0s - loss: 0.2291 - accuracy: 0.8729 - val_loss: 7.0383 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01765: val_loss did not improve from 0.32861\n",
      "Epoch 1766/4000\n",
      "25/25 - 0s - loss: 0.2307 - accuracy: 0.8859 - val_loss: 6.8944 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01766: val_loss did not improve from 0.32861\n",
      "Epoch 1767/4000\n",
      "25/25 - 0s - loss: 0.2187 - accuracy: 0.8936 - val_loss: 6.9601 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01767: val_loss did not improve from 0.32861\n",
      "Epoch 1768/4000\n",
      "25/25 - 0s - loss: 0.2182 - accuracy: 0.8911 - val_loss: 6.8900 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01768: val_loss did not improve from 0.32861\n",
      "Epoch 1769/4000\n",
      "25/25 - 0s - loss: 0.2174 - accuracy: 0.8898 - val_loss: 6.8862 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01769: val_loss did not improve from 0.32861\n",
      "Epoch 1770/4000\n",
      "25/25 - 0s - loss: 0.2155 - accuracy: 0.8923 - val_loss: 7.0069 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01770: val_loss did not improve from 0.32861\n",
      "Epoch 1771/4000\n",
      "25/25 - 0s - loss: 0.2192 - accuracy: 0.8885 - val_loss: 6.8091 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01771: val_loss did not improve from 0.32861\n",
      "Epoch 1772/4000\n",
      "25/25 - 0s - loss: 0.2196 - accuracy: 0.8923 - val_loss: 6.6837 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01772: val_loss did not improve from 0.32861\n",
      "Epoch 1773/4000\n",
      "25/25 - 0s - loss: 0.2191 - accuracy: 0.8885 - val_loss: 6.7563 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01773: val_loss did not improve from 0.32861\n",
      "Epoch 1774/4000\n",
      "25/25 - 0s - loss: 0.2261 - accuracy: 0.8872 - val_loss: 6.4566 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01774: val_loss did not improve from 0.32861\n",
      "Epoch 1775/4000\n",
      "25/25 - 0s - loss: 0.2245 - accuracy: 0.8859 - val_loss: 6.2758 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01775: val_loss did not improve from 0.32861\n",
      "Epoch 1776/4000\n",
      "25/25 - 0s - loss: 0.2261 - accuracy: 0.8936 - val_loss: 6.2431 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01776: val_loss did not improve from 0.32861\n",
      "Epoch 1777/4000\n",
      "25/25 - 0s - loss: 0.2194 - accuracy: 0.8936 - val_loss: 6.1937 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01777: val_loss did not improve from 0.32861\n",
      "Epoch 1778/4000\n",
      "25/25 - 0s - loss: 0.2191 - accuracy: 0.8859 - val_loss: 6.4106 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01778: val_loss did not improve from 0.32861\n",
      "Epoch 1779/4000\n",
      "25/25 - 0s - loss: 0.2174 - accuracy: 0.8872 - val_loss: 6.5465 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01779: val_loss did not improve from 0.32861\n",
      "Epoch 1780/4000\n",
      "25/25 - 0s - loss: 0.2159 - accuracy: 0.8885 - val_loss: 6.6006 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01780: val_loss did not improve from 0.32861\n",
      "Epoch 1781/4000\n",
      "25/25 - 0s - loss: 0.2178 - accuracy: 0.8911 - val_loss: 6.3202 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01781: val_loss did not improve from 0.32861\n",
      "Epoch 1782/4000\n",
      "25/25 - 0s - loss: 0.2184 - accuracy: 0.8949 - val_loss: 6.1276 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01782: val_loss did not improve from 0.32861\n",
      "Epoch 1783/4000\n",
      "25/25 - 0s - loss: 0.2163 - accuracy: 0.8936 - val_loss: 6.3167 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01783: val_loss did not improve from 0.32861\n",
      "Epoch 1784/4000\n",
      "25/25 - 0s - loss: 0.2152 - accuracy: 0.8962 - val_loss: 6.4692 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01784: val_loss did not improve from 0.32861\n",
      "Epoch 1785/4000\n",
      "25/25 - 0s - loss: 0.2150 - accuracy: 0.8949 - val_loss: 6.4447 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01785: val_loss did not improve from 0.32861\n",
      "Epoch 1786/4000\n",
      "25/25 - 0s - loss: 0.2174 - accuracy: 0.8949 - val_loss: 6.6261 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01786: val_loss did not improve from 0.32861\n",
      "Epoch 1787/4000\n",
      "25/25 - 0s - loss: 0.2263 - accuracy: 0.8885 - val_loss: 6.0487 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01787: val_loss did not improve from 0.32861\n",
      "Epoch 1788/4000\n",
      "25/25 - 0s - loss: 0.2349 - accuracy: 0.8885 - val_loss: 6.5881 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01788: val_loss did not improve from 0.32861\n",
      "Epoch 1789/4000\n",
      "25/25 - 0s - loss: 0.3969 - accuracy: 0.8833 - val_loss: 4.3991 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 01789: val_loss did not improve from 0.32861\n",
      "Epoch 1790/4000\n",
      "25/25 - 0s - loss: 0.3285 - accuracy: 0.8534 - val_loss: 2.9168 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01790: val_loss did not improve from 0.32861\n",
      "Epoch 1791/4000\n",
      "25/25 - 0s - loss: 0.2670 - accuracy: 0.8794 - val_loss: 6.7445 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01791: val_loss did not improve from 0.32861\n",
      "Epoch 1792/4000\n",
      "25/25 - 0s - loss: 0.3795 - accuracy: 0.8833 - val_loss: 5.4642 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01792: val_loss did not improve from 0.32861\n",
      "Epoch 1793/4000\n",
      "25/25 - 0s - loss: 0.3169 - accuracy: 0.8534 - val_loss: 3.6299 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01793: val_loss did not improve from 0.32861\n",
      "Epoch 1794/4000\n",
      "25/25 - 0s - loss: 0.3161 - accuracy: 0.8638 - val_loss: 4.0622 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01794: val_loss did not improve from 0.32861\n",
      "Epoch 1795/4000\n",
      "25/25 - 0s - loss: 0.3521 - accuracy: 0.8664 - val_loss: 5.8402 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01795: val_loss did not improve from 0.32861\n",
      "Epoch 1796/4000\n",
      "25/25 - 0s - loss: 0.3816 - accuracy: 0.8547 - val_loss: 3.0503 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01796: val_loss did not improve from 0.32861\n",
      "Epoch 1797/4000\n",
      "25/25 - 0s - loss: 0.2815 - accuracy: 0.8885 - val_loss: 4.1830 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01797: val_loss did not improve from 0.32861\n",
      "Epoch 1798/4000\n",
      "25/25 - 0s - loss: 0.2600 - accuracy: 0.8962 - val_loss: 4.0395 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01798: val_loss did not improve from 0.32861\n",
      "Epoch 1799/4000\n",
      "25/25 - 0s - loss: 0.2570 - accuracy: 0.8872 - val_loss: 3.6488 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01799: val_loss did not improve from 0.32861\n",
      "Epoch 1800/4000\n",
      "25/25 - 0s - loss: 0.2684 - accuracy: 0.8781 - val_loss: 3.7178 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01800: val_loss did not improve from 0.32861\n",
      "Epoch 1801/4000\n",
      "25/25 - 0s - loss: 0.2471 - accuracy: 0.8846 - val_loss: 3.4518 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01801: val_loss did not improve from 0.32861\n",
      "Epoch 1802/4000\n",
      "25/25 - 0s - loss: 0.2590 - accuracy: 0.8898 - val_loss: 3.2821 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01802: val_loss did not improve from 0.32861\n",
      "Epoch 1803/4000\n",
      "25/25 - 0s - loss: 0.2490 - accuracy: 0.8936 - val_loss: 3.6284 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01803: val_loss did not improve from 0.32861\n",
      "Epoch 1804/4000\n",
      "25/25 - 0s - loss: 0.2445 - accuracy: 0.8949 - val_loss: 3.7272 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01804: val_loss did not improve from 0.32861\n",
      "Epoch 1805/4000\n",
      "25/25 - 0s - loss: 0.2341 - accuracy: 0.8975 - val_loss: 3.5291 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01805: val_loss did not improve from 0.32861\n",
      "Epoch 1806/4000\n",
      "25/25 - 0s - loss: 0.2355 - accuracy: 0.8975 - val_loss: 3.5021 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01806: val_loss did not improve from 0.32861\n",
      "Epoch 1807/4000\n",
      "25/25 - 0s - loss: 0.2289 - accuracy: 0.8975 - val_loss: 3.6642 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01807: val_loss did not improve from 0.32861\n",
      "Epoch 1808/4000\n",
      "25/25 - 0s - loss: 0.2317 - accuracy: 0.8949 - val_loss: 3.6706 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01808: val_loss did not improve from 0.32861\n",
      "Epoch 1809/4000\n",
      "25/25 - 0s - loss: 0.2280 - accuracy: 0.8962 - val_loss: 3.6553 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01809: val_loss did not improve from 0.32861\n",
      "Epoch 1810/4000\n",
      "25/25 - 0s - loss: 0.2497 - accuracy: 0.8936 - val_loss: 3.0897 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01810: val_loss did not improve from 0.32861\n",
      "Epoch 1811/4000\n",
      "25/25 - 0s - loss: 0.2392 - accuracy: 0.8936 - val_loss: 7.5977 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01811: val_loss did not improve from 0.32861\n",
      "Epoch 1812/4000\n",
      "25/25 - 0s - loss: 0.2439 - accuracy: 0.8833 - val_loss: 8.4697 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01812: val_loss did not improve from 0.32861\n",
      "Epoch 1813/4000\n",
      "25/25 - 0s - loss: 0.2553 - accuracy: 0.8820 - val_loss: 8.6768 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01813: val_loss did not improve from 0.32861\n",
      "Epoch 1814/4000\n",
      "25/25 - 0s - loss: 0.2457 - accuracy: 0.8742 - val_loss: 9.2618 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01814: val_loss did not improve from 0.32861\n",
      "Epoch 1815/4000\n",
      "25/25 - 0s - loss: 0.2433 - accuracy: 0.8898 - val_loss: 8.7102 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01815: val_loss did not improve from 0.32861\n",
      "Epoch 1816/4000\n",
      "25/25 - 0s - loss: 0.2388 - accuracy: 0.8859 - val_loss: 10.1722 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01816: val_loss did not improve from 0.32861\n",
      "Epoch 1817/4000\n",
      "25/25 - 0s - loss: 0.2306 - accuracy: 0.8923 - val_loss: 11.1190 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01817: val_loss did not improve from 0.32861\n",
      "Epoch 1818/4000\n",
      "25/25 - 0s - loss: 0.2349 - accuracy: 0.8846 - val_loss: 10.9050 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01818: val_loss did not improve from 0.32861\n",
      "Epoch 1819/4000\n",
      "25/25 - 0s - loss: 0.2328 - accuracy: 0.8949 - val_loss: 11.0732 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01819: val_loss did not improve from 0.32861\n",
      "Epoch 1820/4000\n",
      "25/25 - 0s - loss: 0.2268 - accuracy: 0.8872 - val_loss: 11.0858 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01820: val_loss did not improve from 0.32861\n",
      "Epoch 1821/4000\n",
      "25/25 - 0s - loss: 0.2334 - accuracy: 0.8859 - val_loss: 11.1467 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01821: val_loss did not improve from 0.32861\n",
      "Epoch 1822/4000\n",
      "25/25 - 0s - loss: 0.2340 - accuracy: 0.8936 - val_loss: 9.8315 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01822: val_loss did not improve from 0.32861\n",
      "Epoch 1823/4000\n",
      "25/25 - 0s - loss: 0.2819 - accuracy: 0.8820 - val_loss: 5.8508 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01823: val_loss did not improve from 0.32861\n",
      "Epoch 1824/4000\n",
      "25/25 - 0s - loss: 0.2324 - accuracy: 0.8872 - val_loss: 6.5560 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01824: val_loss did not improve from 0.32861\n",
      "Epoch 1825/4000\n",
      "25/25 - 0s - loss: 0.2278 - accuracy: 0.8949 - val_loss: 6.8436 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01825: val_loss did not improve from 0.32861\n",
      "Epoch 1826/4000\n",
      "25/25 - 0s - loss: 0.2410 - accuracy: 0.8768 - val_loss: 6.5130 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01826: val_loss did not improve from 0.32861\n",
      "Epoch 1827/4000\n",
      "25/25 - 0s - loss: 0.2287 - accuracy: 0.8923 - val_loss: 6.5215 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01827: val_loss did not improve from 0.32861\n",
      "Epoch 1828/4000\n",
      "25/25 - 0s - loss: 0.2487 - accuracy: 0.8923 - val_loss: 5.7182 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01828: val_loss did not improve from 0.32861\n",
      "Epoch 1829/4000\n",
      "25/25 - 0s - loss: 0.2816 - accuracy: 0.8833 - val_loss: 3.6590 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01829: val_loss did not improve from 0.32861\n",
      "Epoch 1830/4000\n",
      "25/25 - 0s - loss: 0.2401 - accuracy: 0.8768 - val_loss: 3.5977 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01830: val_loss did not improve from 0.32861\n",
      "Epoch 1831/4000\n",
      "25/25 - 0s - loss: 0.2420 - accuracy: 0.8820 - val_loss: 3.8964 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01831: val_loss did not improve from 0.32861\n",
      "Epoch 1832/4000\n",
      "25/25 - 0s - loss: 0.2310 - accuracy: 0.8988 - val_loss: 3.9391 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01832: val_loss did not improve from 0.32861\n",
      "Epoch 1833/4000\n",
      "25/25 - 0s - loss: 0.2314 - accuracy: 0.8949 - val_loss: 4.1129 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01833: val_loss did not improve from 0.32861\n",
      "Epoch 1834/4000\n",
      "25/25 - 0s - loss: 0.2342 - accuracy: 0.8975 - val_loss: 4.1070 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01834: val_loss did not improve from 0.32861\n",
      "Epoch 1835/4000\n",
      "25/25 - 0s - loss: 0.2316 - accuracy: 0.9001 - val_loss: 4.2150 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01835: val_loss did not improve from 0.32861\n",
      "Epoch 1836/4000\n",
      "25/25 - 0s - loss: 0.2257 - accuracy: 0.8936 - val_loss: 4.2610 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01836: val_loss did not improve from 0.32861\n",
      "Epoch 1837/4000\n",
      "25/25 - 0s - loss: 0.2245 - accuracy: 0.9014 - val_loss: 4.3458 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01837: val_loss did not improve from 0.32861\n",
      "Epoch 1838/4000\n",
      "25/25 - 0s - loss: 0.2303 - accuracy: 0.8885 - val_loss: 4.4306 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01838: val_loss did not improve from 0.32861\n",
      "Epoch 1839/4000\n",
      "25/25 - 0s - loss: 0.2219 - accuracy: 0.8975 - val_loss: 4.4897 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01839: val_loss did not improve from 0.32861\n",
      "Epoch 1840/4000\n",
      "25/25 - 0s - loss: 0.2256 - accuracy: 0.8911 - val_loss: 4.6645 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01840: val_loss did not improve from 0.32861\n",
      "Epoch 1841/4000\n",
      "25/25 - 0s - loss: 0.2208 - accuracy: 0.8923 - val_loss: 4.6954 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01841: val_loss did not improve from 0.32861\n",
      "Epoch 1842/4000\n",
      "25/25 - 0s - loss: 0.2251 - accuracy: 0.9040 - val_loss: 4.6691 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01842: val_loss did not improve from 0.32861\n",
      "Epoch 1843/4000\n",
      "25/25 - 0s - loss: 0.2205 - accuracy: 0.8988 - val_loss: 4.8587 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01843: val_loss did not improve from 0.32861\n",
      "Epoch 1844/4000\n",
      "25/25 - 0s - loss: 0.2327 - accuracy: 0.8936 - val_loss: 4.4295 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01844: val_loss did not improve from 0.32861\n",
      "Epoch 1845/4000\n",
      "25/25 - 0s - loss: 0.2280 - accuracy: 0.8911 - val_loss: 4.4416 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01845: val_loss did not improve from 0.32861\n",
      "Epoch 1846/4000\n",
      "25/25 - 0s - loss: 0.2234 - accuracy: 0.9027 - val_loss: 4.6196 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01846: val_loss did not improve from 0.32861\n",
      "Epoch 1847/4000\n",
      "25/25 - 0s - loss: 0.2241 - accuracy: 0.8988 - val_loss: 4.4043 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01847: val_loss did not improve from 0.32861\n",
      "Epoch 1848/4000\n",
      "25/25 - 0s - loss: 0.2201 - accuracy: 0.9001 - val_loss: 4.3839 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01848: val_loss did not improve from 0.32861\n",
      "Epoch 1849/4000\n",
      "25/25 - 0s - loss: 0.2192 - accuracy: 0.8975 - val_loss: 4.4452 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01849: val_loss did not improve from 0.32861\n",
      "Epoch 1850/4000\n",
      "25/25 - 0s - loss: 0.2188 - accuracy: 0.8962 - val_loss: 4.4685 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01850: val_loss did not improve from 0.32861\n",
      "Epoch 1851/4000\n",
      "25/25 - 0s - loss: 0.2178 - accuracy: 0.9014 - val_loss: 4.4413 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01851: val_loss did not improve from 0.32861\n",
      "Epoch 1852/4000\n",
      "25/25 - 0s - loss: 0.2269 - accuracy: 0.8936 - val_loss: 4.5506 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01852: val_loss did not improve from 0.32861\n",
      "Epoch 1853/4000\n",
      "25/25 - 0s - loss: 0.2260 - accuracy: 0.8975 - val_loss: 4.6436 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01853: val_loss did not improve from 0.32861\n",
      "Epoch 1854/4000\n",
      "25/25 - 0s - loss: 0.2340 - accuracy: 0.8872 - val_loss: 4.5372 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01854: val_loss did not improve from 0.32861\n",
      "Epoch 1855/4000\n",
      "25/25 - 0s - loss: 0.2233 - accuracy: 0.8936 - val_loss: 4.5267 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01855: val_loss did not improve from 0.32861\n",
      "Epoch 1856/4000\n",
      "25/25 - 0s - loss: 0.2344 - accuracy: 0.8923 - val_loss: 4.2339 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01856: val_loss did not improve from 0.32861\n",
      "Epoch 1857/4000\n",
      "25/25 - 0s - loss: 0.2293 - accuracy: 0.8911 - val_loss: 4.6451 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01857: val_loss did not improve from 0.32861\n",
      "Epoch 1858/4000\n",
      "25/25 - 0s - loss: 0.2292 - accuracy: 0.8923 - val_loss: 4.4139 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01858: val_loss did not improve from 0.32861\n",
      "Epoch 1859/4000\n",
      "25/25 - 0s - loss: 0.2353 - accuracy: 0.8807 - val_loss: 5.3190 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01859: val_loss did not improve from 0.32861\n",
      "Epoch 1860/4000\n",
      "25/25 - 0s - loss: 0.2245 - accuracy: 0.8911 - val_loss: 5.1623 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01860: val_loss did not improve from 0.32861\n",
      "Epoch 1861/4000\n",
      "25/25 - 0s - loss: 0.2462 - accuracy: 0.8885 - val_loss: 5.2061 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01861: val_loss did not improve from 0.32861\n",
      "Epoch 1862/4000\n",
      "25/25 - 0s - loss: 0.2314 - accuracy: 0.8911 - val_loss: 5.4097 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01862: val_loss did not improve from 0.32861\n",
      "Epoch 1863/4000\n",
      "25/25 - 0s - loss: 0.2262 - accuracy: 0.8859 - val_loss: 5.3333 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01863: val_loss did not improve from 0.32861\n",
      "Epoch 1864/4000\n",
      "25/25 - 0s - loss: 0.2293 - accuracy: 0.8911 - val_loss: 5.4788 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01864: val_loss did not improve from 0.32861\n",
      "Epoch 1865/4000\n",
      "25/25 - 0s - loss: 0.2198 - accuracy: 0.8898 - val_loss: 5.5814 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01865: val_loss did not improve from 0.32861\n",
      "Epoch 1866/4000\n",
      "25/25 - 0s - loss: 0.2169 - accuracy: 0.8975 - val_loss: 5.3858 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01866: val_loss did not improve from 0.32861\n",
      "Epoch 1867/4000\n",
      "25/25 - 0s - loss: 0.2196 - accuracy: 0.8975 - val_loss: 5.3413 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01867: val_loss did not improve from 0.32861\n",
      "Epoch 1868/4000\n",
      "25/25 - 0s - loss: 0.3046 - accuracy: 0.8379 - val_loss: 6.0297 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01868: val_loss did not improve from 0.32861\n",
      "Epoch 1869/4000\n",
      "25/25 - 0s - loss: 0.2496 - accuracy: 0.8781 - val_loss: 5.6783 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01869: val_loss did not improve from 0.32861\n",
      "Epoch 1870/4000\n",
      "25/25 - 0s - loss: 0.2322 - accuracy: 0.8833 - val_loss: 5.3476 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01870: val_loss did not improve from 0.32861\n",
      "Epoch 1871/4000\n",
      "25/25 - 0s - loss: 0.2385 - accuracy: 0.8859 - val_loss: 4.5637 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01871: val_loss did not improve from 0.32861\n",
      "Epoch 1872/4000\n",
      "25/25 - 0s - loss: 0.2253 - accuracy: 0.8949 - val_loss: 4.8471 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01872: val_loss did not improve from 0.32861\n",
      "Epoch 1873/4000\n",
      "25/25 - 0s - loss: 0.2482 - accuracy: 0.8923 - val_loss: 4.8041 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01873: val_loss did not improve from 0.32861\n",
      "Epoch 1874/4000\n",
      "25/25 - 0s - loss: 0.2292 - accuracy: 0.8911 - val_loss: 4.9806 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01874: val_loss did not improve from 0.32861\n",
      "Epoch 1875/4000\n",
      "25/25 - 0s - loss: 0.2268 - accuracy: 0.8859 - val_loss: 4.7315 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01875: val_loss did not improve from 0.32861\n",
      "Epoch 1876/4000\n",
      "25/25 - 0s - loss: 0.2204 - accuracy: 0.8988 - val_loss: 4.5893 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01876: val_loss did not improve from 0.32861\n",
      "Epoch 1877/4000\n",
      "25/25 - 0s - loss: 0.2215 - accuracy: 0.9001 - val_loss: 4.3443 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01877: val_loss did not improve from 0.32861\n",
      "Epoch 1878/4000\n",
      "25/25 - 0s - loss: 0.2349 - accuracy: 0.8923 - val_loss: 8.4663 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01878: val_loss did not improve from 0.32861\n",
      "Epoch 1879/4000\n",
      "25/25 - 0s - loss: 0.2572 - accuracy: 0.8690 - val_loss: 9.2517 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01879: val_loss did not improve from 0.32861\n",
      "Epoch 1880/4000\n",
      "25/25 - 0s - loss: 0.2875 - accuracy: 0.8742 - val_loss: 13.2679 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01880: val_loss did not improve from 0.32861\n",
      "Epoch 1881/4000\n",
      "25/25 - 0s - loss: 0.4275 - accuracy: 0.8392 - val_loss: 9.3478 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 01881: val_loss did not improve from 0.32861\n",
      "Epoch 1882/4000\n",
      "25/25 - 0s - loss: 0.4481 - accuracy: 0.8612 - val_loss: 8.5599 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 01882: val_loss did not improve from 0.32861\n",
      "Epoch 1883/4000\n",
      "25/25 - 0s - loss: 0.5290 - accuracy: 0.8599 - val_loss: 11.9299 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 01883: val_loss did not improve from 0.32861\n",
      "Epoch 1884/4000\n",
      "25/25 - 0s - loss: 0.3597 - accuracy: 0.8508 - val_loss: 7.0274 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01884: val_loss did not improve from 0.32861\n",
      "Epoch 1885/4000\n",
      "25/25 - 0s - loss: 0.3489 - accuracy: 0.8651 - val_loss: 7.1521 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 01885: val_loss did not improve from 0.32861\n",
      "Epoch 1886/4000\n",
      "25/25 - 0s - loss: 0.3044 - accuracy: 0.8664 - val_loss: 7.1003 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 01886: val_loss did not improve from 0.32861\n",
      "Epoch 1887/4000\n",
      "25/25 - 0s - loss: 0.3040 - accuracy: 0.8703 - val_loss: 7.7556 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 01887: val_loss did not improve from 0.32861\n",
      "Epoch 1888/4000\n",
      "25/25 - 0s - loss: 0.3296 - accuracy: 0.8521 - val_loss: 8.0995 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01888: val_loss did not improve from 0.32861\n",
      "Epoch 1889/4000\n",
      "25/25 - 0s - loss: 0.2896 - accuracy: 0.8638 - val_loss: 8.3156 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01889: val_loss did not improve from 0.32861\n",
      "Epoch 1890/4000\n",
      "25/25 - 0s - loss: 0.2791 - accuracy: 0.8794 - val_loss: 8.5767 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01890: val_loss did not improve from 0.32861\n",
      "Epoch 1891/4000\n",
      "25/25 - 0s - loss: 0.2805 - accuracy: 0.8768 - val_loss: 8.6285 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01891: val_loss did not improve from 0.32861\n",
      "Epoch 1892/4000\n",
      "25/25 - 0s - loss: 0.2818 - accuracy: 0.8638 - val_loss: 8.6275 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01892: val_loss did not improve from 0.32861\n",
      "Epoch 1893/4000\n",
      "25/25 - 0s - loss: 0.2698 - accuracy: 0.8859 - val_loss: 8.7387 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01893: val_loss did not improve from 0.32861\n",
      "Epoch 1894/4000\n",
      "25/25 - 0s - loss: 0.2662 - accuracy: 0.8859 - val_loss: 8.8029 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01894: val_loss did not improve from 0.32861\n",
      "Epoch 1895/4000\n",
      "25/25 - 0s - loss: 0.2795 - accuracy: 0.8794 - val_loss: 8.5280 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01895: val_loss did not improve from 0.32861\n",
      "Epoch 1896/4000\n",
      "25/25 - 0s - loss: 0.2747 - accuracy: 0.8859 - val_loss: 8.3291 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01896: val_loss did not improve from 0.32861\n",
      "Epoch 1897/4000\n",
      "25/25 - 0s - loss: 0.2690 - accuracy: 0.8846 - val_loss: 8.4842 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01897: val_loss did not improve from 0.32861\n",
      "Epoch 1898/4000\n",
      "25/25 - 0s - loss: 0.2651 - accuracy: 0.8820 - val_loss: 8.7128 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01898: val_loss did not improve from 0.32861\n",
      "Epoch 1899/4000\n",
      "25/25 - 0s - loss: 0.2640 - accuracy: 0.8885 - val_loss: 8.8161 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01899: val_loss did not improve from 0.32861\n",
      "Epoch 1900/4000\n",
      "25/25 - 0s - loss: 0.2625 - accuracy: 0.8885 - val_loss: 8.9228 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01900: val_loss did not improve from 0.32861\n",
      "Epoch 1901/4000\n",
      "25/25 - 0s - loss: 0.2614 - accuracy: 0.8911 - val_loss: 8.9050 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01901: val_loss did not improve from 0.32861\n",
      "Epoch 1902/4000\n",
      "25/25 - 0s - loss: 0.2609 - accuracy: 0.8898 - val_loss: 9.0193 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01902: val_loss did not improve from 0.32861\n",
      "Epoch 1903/4000\n",
      "25/25 - 0s - loss: 0.2603 - accuracy: 0.8911 - val_loss: 8.9886 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01903: val_loss did not improve from 0.32861\n",
      "Epoch 1904/4000\n",
      "25/25 - 0s - loss: 0.2588 - accuracy: 0.8898 - val_loss: 9.6653 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01904: val_loss did not improve from 0.32861\n",
      "Epoch 1905/4000\n",
      "25/25 - 0s - loss: 0.2602 - accuracy: 0.8846 - val_loss: 9.1804 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01905: val_loss did not improve from 0.32861\n",
      "Epoch 1906/4000\n",
      "25/25 - 0s - loss: 0.2626 - accuracy: 0.8885 - val_loss: 9.0276 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01906: val_loss did not improve from 0.32861\n",
      "Epoch 1907/4000\n",
      "25/25 - 0s - loss: 0.2564 - accuracy: 0.8885 - val_loss: 8.9122 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01907: val_loss did not improve from 0.32861\n",
      "Epoch 1908/4000\n",
      "25/25 - 0s - loss: 0.2585 - accuracy: 0.8833 - val_loss: 9.1028 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01908: val_loss did not improve from 0.32861\n",
      "Epoch 1909/4000\n",
      "25/25 - 0s - loss: 0.2583 - accuracy: 0.8911 - val_loss: 9.1304 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01909: val_loss did not improve from 0.32861\n",
      "Epoch 1910/4000\n",
      "25/25 - 0s - loss: 0.2591 - accuracy: 0.8846 - val_loss: 9.1065 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01910: val_loss did not improve from 0.32861\n",
      "Epoch 1911/4000\n",
      "25/25 - 0s - loss: 0.2544 - accuracy: 0.8898 - val_loss: 9.2957 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01911: val_loss did not improve from 0.32861\n",
      "Epoch 1912/4000\n",
      "25/25 - 0s - loss: 0.2563 - accuracy: 0.8911 - val_loss: 9.4594 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01912: val_loss did not improve from 0.32861\n",
      "Epoch 1913/4000\n",
      "25/25 - 0s - loss: 0.2560 - accuracy: 0.8872 - val_loss: 9.5526 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01913: val_loss did not improve from 0.32861\n",
      "Epoch 1914/4000\n",
      "25/25 - 0s - loss: 0.2545 - accuracy: 0.8898 - val_loss: 9.4949 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01914: val_loss did not improve from 0.32861\n",
      "Epoch 1915/4000\n",
      "25/25 - 0s - loss: 0.2558 - accuracy: 0.8898 - val_loss: 9.3980 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01915: val_loss did not improve from 0.32861\n",
      "Epoch 1916/4000\n",
      "25/25 - 0s - loss: 0.2548 - accuracy: 0.8885 - val_loss: 9.3904 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01916: val_loss did not improve from 0.32861\n",
      "Epoch 1917/4000\n",
      "25/25 - 0s - loss: 0.2533 - accuracy: 0.8911 - val_loss: 9.5827 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01917: val_loss did not improve from 0.32861\n",
      "Epoch 1918/4000\n",
      "25/25 - 0s - loss: 0.2559 - accuracy: 0.8898 - val_loss: 9.3519 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01918: val_loss did not improve from 0.32861\n",
      "Epoch 1919/4000\n",
      "25/25 - 0s - loss: 0.2625 - accuracy: 0.8833 - val_loss: 9.6101 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01919: val_loss did not improve from 0.32861\n",
      "Epoch 1920/4000\n",
      "25/25 - 0s - loss: 0.2581 - accuracy: 0.8885 - val_loss: 9.7323 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01920: val_loss did not improve from 0.32861\n",
      "Epoch 1921/4000\n",
      "25/25 - 0s - loss: 0.2543 - accuracy: 0.8885 - val_loss: 9.7652 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01921: val_loss did not improve from 0.32861\n",
      "Epoch 1922/4000\n",
      "25/25 - 0s - loss: 0.2582 - accuracy: 0.8885 - val_loss: 9.8563 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01922: val_loss did not improve from 0.32861\n",
      "Epoch 1923/4000\n",
      "25/25 - 0s - loss: 0.2541 - accuracy: 0.8898 - val_loss: 9.9304 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01923: val_loss did not improve from 0.32861\n",
      "Epoch 1924/4000\n",
      "25/25 - 0s - loss: 0.2540 - accuracy: 0.8898 - val_loss: 9.6981 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01924: val_loss did not improve from 0.32861\n",
      "Epoch 1925/4000\n",
      "25/25 - 0s - loss: 0.2548 - accuracy: 0.8911 - val_loss: 9.7396 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01925: val_loss did not improve from 0.32861\n",
      "Epoch 1926/4000\n",
      "25/25 - 0s - loss: 0.2578 - accuracy: 0.8898 - val_loss: 9.8935 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01926: val_loss did not improve from 0.32861\n",
      "Epoch 1927/4000\n",
      "25/25 - 0s - loss: 0.2554 - accuracy: 0.8885 - val_loss: 10.1546 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01927: val_loss did not improve from 0.32861\n",
      "Epoch 1928/4000\n",
      "25/25 - 0s - loss: 0.2537 - accuracy: 0.8898 - val_loss: 10.1329 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01928: val_loss did not improve from 0.32861\n",
      "Epoch 1929/4000\n",
      "25/25 - 0s - loss: 0.2608 - accuracy: 0.8859 - val_loss: 10.0890 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01929: val_loss did not improve from 0.32861\n",
      "Epoch 1930/4000\n",
      "25/25 - 0s - loss: 0.2549 - accuracy: 0.8885 - val_loss: 10.1397 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01930: val_loss did not improve from 0.32861\n",
      "Epoch 1931/4000\n",
      "25/25 - 0s - loss: 0.2548 - accuracy: 0.8911 - val_loss: 10.1695 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01931: val_loss did not improve from 0.32861\n",
      "Epoch 1932/4000\n",
      "25/25 - 0s - loss: 0.2554 - accuracy: 0.8859 - val_loss: 10.1292 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01932: val_loss did not improve from 0.32861\n",
      "Epoch 1933/4000\n",
      "25/25 - 0s - loss: 0.2638 - accuracy: 0.8820 - val_loss: 10.1477 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01933: val_loss did not improve from 0.32861\n",
      "Epoch 1934/4000\n",
      "25/25 - 0s - loss: 0.2521 - accuracy: 0.8911 - val_loss: 10.2940 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01934: val_loss did not improve from 0.32861\n",
      "Epoch 1935/4000\n",
      "25/25 - 0s - loss: 0.2604 - accuracy: 0.8859 - val_loss: 9.8191 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01935: val_loss did not improve from 0.32861\n",
      "Epoch 1936/4000\n",
      "25/25 - 0s - loss: 0.2600 - accuracy: 0.8885 - val_loss: 10.0501 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01936: val_loss did not improve from 0.32861\n",
      "Epoch 1937/4000\n",
      "25/25 - 0s - loss: 0.2527 - accuracy: 0.8936 - val_loss: 10.4475 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01937: val_loss did not improve from 0.32861\n",
      "Epoch 1938/4000\n",
      "25/25 - 0s - loss: 0.2474 - accuracy: 0.8923 - val_loss: 10.4243 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01938: val_loss did not improve from 0.32861\n",
      "Epoch 1939/4000\n",
      "25/25 - 0s - loss: 0.2521 - accuracy: 0.8885 - val_loss: 10.2387 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01939: val_loss did not improve from 0.32861\n",
      "Epoch 1940/4000\n",
      "25/25 - 0s - loss: 0.2746 - accuracy: 0.8898 - val_loss: 10.1374 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01940: val_loss did not improve from 0.32861\n",
      "Epoch 1941/4000\n",
      "25/25 - 0s - loss: 0.2493 - accuracy: 0.8923 - val_loss: 10.1530 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01941: val_loss did not improve from 0.32861\n",
      "Epoch 1942/4000\n",
      "25/25 - 0s - loss: 0.2425 - accuracy: 0.8923 - val_loss: 10.6876 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01942: val_loss did not improve from 0.32861\n",
      "Epoch 1943/4000\n",
      "25/25 - 0s - loss: 0.2426 - accuracy: 0.8898 - val_loss: 10.8421 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01943: val_loss did not improve from 0.32861\n",
      "Epoch 1944/4000\n",
      "25/25 - 0s - loss: 0.2410 - accuracy: 0.8936 - val_loss: 10.9110 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01944: val_loss did not improve from 0.32861\n",
      "Epoch 1945/4000\n",
      "25/25 - 0s - loss: 0.2496 - accuracy: 0.8949 - val_loss: 11.1254 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01945: val_loss did not improve from 0.32861\n",
      "Epoch 1946/4000\n",
      "25/25 - 0s - loss: 0.2406 - accuracy: 0.8936 - val_loss: 11.0250 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01946: val_loss did not improve from 0.32861\n",
      "Epoch 1947/4000\n",
      "25/25 - 0s - loss: 0.2408 - accuracy: 0.8885 - val_loss: 11.1148 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01947: val_loss did not improve from 0.32861\n",
      "Epoch 1948/4000\n",
      "25/25 - 0s - loss: 0.2387 - accuracy: 0.8898 - val_loss: 11.1702 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01948: val_loss did not improve from 0.32861\n",
      "Epoch 1949/4000\n",
      "25/25 - 0s - loss: 0.2748 - accuracy: 0.8949 - val_loss: 10.8542 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01949: val_loss did not improve from 0.32861\n",
      "Epoch 1950/4000\n",
      "25/25 - 0s - loss: 0.2773 - accuracy: 0.8677 - val_loss: 10.9062 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01950: val_loss did not improve from 0.32861\n",
      "Epoch 1951/4000\n",
      "25/25 - 0s - loss: 0.2620 - accuracy: 0.8677 - val_loss: 10.9163 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 01951: val_loss did not improve from 0.32861\n",
      "Epoch 1952/4000\n",
      "25/25 - 0s - loss: 0.2441 - accuracy: 0.8859 - val_loss: 11.0719 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01952: val_loss did not improve from 0.32861\n",
      "Epoch 1953/4000\n",
      "25/25 - 0s - loss: 0.2465 - accuracy: 0.8833 - val_loss: 11.5627 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01953: val_loss did not improve from 0.32861\n",
      "Epoch 1954/4000\n",
      "25/25 - 0s - loss: 0.2490 - accuracy: 0.8768 - val_loss: 11.8186 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01954: val_loss did not improve from 0.32861\n",
      "Epoch 1955/4000\n",
      "25/25 - 0s - loss: 0.2524 - accuracy: 0.8936 - val_loss: 11.5504 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01955: val_loss did not improve from 0.32861\n",
      "Epoch 1956/4000\n",
      "25/25 - 0s - loss: 0.2433 - accuracy: 0.8885 - val_loss: 11.5778 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01956: val_loss did not improve from 0.32861\n",
      "Epoch 1957/4000\n",
      "25/25 - 0s - loss: 0.2468 - accuracy: 0.8872 - val_loss: 11.7075 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01957: val_loss did not improve from 0.32861\n",
      "Epoch 1958/4000\n",
      "25/25 - 0s - loss: 0.2419 - accuracy: 0.8885 - val_loss: 12.0364 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01958: val_loss did not improve from 0.32861\n",
      "Epoch 1959/4000\n",
      "25/25 - 0s - loss: 0.2435 - accuracy: 0.8911 - val_loss: 12.0866 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01959: val_loss did not improve from 0.32861\n",
      "Epoch 1960/4000\n",
      "25/25 - 0s - loss: 0.2471 - accuracy: 0.8872 - val_loss: 12.0297 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01960: val_loss did not improve from 0.32861\n",
      "Epoch 1961/4000\n",
      "25/25 - 0s - loss: 0.2412 - accuracy: 0.8898 - val_loss: 12.0522 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01961: val_loss did not improve from 0.32861\n",
      "Epoch 1962/4000\n",
      "25/25 - 0s - loss: 0.2390 - accuracy: 0.8885 - val_loss: 11.3983 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 01962: val_loss did not improve from 0.32861\n",
      "Epoch 1963/4000\n",
      "25/25 - 0s - loss: 0.2463 - accuracy: 0.8962 - val_loss: 12.5122 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01963: val_loss did not improve from 0.32861\n",
      "Epoch 1964/4000\n",
      "25/25 - 0s - loss: 0.2435 - accuracy: 0.8781 - val_loss: 12.5879 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01964: val_loss did not improve from 0.32861\n",
      "Epoch 1965/4000\n",
      "25/25 - 0s - loss: 0.2427 - accuracy: 0.8923 - val_loss: 12.1279 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01965: val_loss did not improve from 0.32861\n",
      "Epoch 1966/4000\n",
      "25/25 - 0s - loss: 0.2387 - accuracy: 0.8911 - val_loss: 12.0624 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01966: val_loss did not improve from 0.32861\n",
      "Epoch 1967/4000\n",
      "25/25 - 0s - loss: 0.2389 - accuracy: 0.8949 - val_loss: 11.9578 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01967: val_loss did not improve from 0.32861\n",
      "Epoch 1968/4000\n",
      "25/25 - 0s - loss: 0.2416 - accuracy: 0.8898 - val_loss: 12.1435 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01968: val_loss did not improve from 0.32861\n",
      "Epoch 1969/4000\n",
      "25/25 - 0s - loss: 0.2492 - accuracy: 0.8846 - val_loss: 11.2543 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01969: val_loss did not improve from 0.32861\n",
      "Epoch 1970/4000\n",
      "25/25 - 0s - loss: 0.2870 - accuracy: 0.8781 - val_loss: 12.1188 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01970: val_loss did not improve from 0.32861\n",
      "Epoch 1971/4000\n",
      "25/25 - 0s - loss: 0.2638 - accuracy: 0.8846 - val_loss: 11.9183 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01971: val_loss did not improve from 0.32861\n",
      "Epoch 1972/4000\n",
      "25/25 - 0s - loss: 0.2538 - accuracy: 0.8833 - val_loss: 12.8194 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01972: val_loss did not improve from 0.32861\n",
      "Epoch 1973/4000\n",
      "25/25 - 0s - loss: 0.2523 - accuracy: 0.8846 - val_loss: 13.0598 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01973: val_loss did not improve from 0.32861\n",
      "Epoch 1974/4000\n",
      "25/25 - 0s - loss: 0.2499 - accuracy: 0.8936 - val_loss: 13.4670 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01974: val_loss did not improve from 0.32861\n",
      "Epoch 1975/4000\n",
      "25/25 - 0s - loss: 0.2606 - accuracy: 0.8677 - val_loss: 13.6122 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01975: val_loss did not improve from 0.32861\n",
      "Epoch 1976/4000\n",
      "25/25 - 0s - loss: 0.2586 - accuracy: 0.8703 - val_loss: 13.7756 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01976: val_loss did not improve from 0.32861\n",
      "Epoch 1977/4000\n",
      "25/25 - 0s - loss: 0.2510 - accuracy: 0.8768 - val_loss: 13.6701 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01977: val_loss did not improve from 0.32861\n",
      "Epoch 1978/4000\n",
      "25/25 - 0s - loss: 0.2603 - accuracy: 0.8859 - val_loss: 13.5991 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01978: val_loss did not improve from 0.32861\n",
      "Epoch 1979/4000\n",
      "25/25 - 0s - loss: 0.2457 - accuracy: 0.8911 - val_loss: 13.2542 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01979: val_loss did not improve from 0.32861\n",
      "Epoch 1980/4000\n",
      "25/25 - 0s - loss: 0.2555 - accuracy: 0.8807 - val_loss: 13.6399 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01980: val_loss did not improve from 0.32861\n",
      "Epoch 1981/4000\n",
      "25/25 - 0s - loss: 0.2434 - accuracy: 0.8936 - val_loss: 13.8421 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01981: val_loss did not improve from 0.32861\n",
      "Epoch 1982/4000\n",
      "25/25 - 0s - loss: 0.2502 - accuracy: 0.8911 - val_loss: 12.4262 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01982: val_loss did not improve from 0.32861\n",
      "Epoch 1983/4000\n",
      "25/25 - 0s - loss: 0.2874 - accuracy: 0.8885 - val_loss: 15.1660 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01983: val_loss did not improve from 0.32861\n",
      "Epoch 1984/4000\n",
      "25/25 - 0s - loss: 0.2955 - accuracy: 0.8586 - val_loss: 10.8618 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01984: val_loss did not improve from 0.32861\n",
      "Epoch 1985/4000\n",
      "25/25 - 0s - loss: 0.3006 - accuracy: 0.8716 - val_loss: 9.6171 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01985: val_loss did not improve from 0.32861\n",
      "Epoch 1986/4000\n",
      "25/25 - 0s - loss: 0.2638 - accuracy: 0.8872 - val_loss: 9.8438 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01986: val_loss did not improve from 0.32861\n",
      "Epoch 1987/4000\n",
      "25/25 - 0s - loss: 0.2587 - accuracy: 0.8911 - val_loss: 10.0474 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01987: val_loss did not improve from 0.32861\n",
      "Epoch 1988/4000\n",
      "25/25 - 0s - loss: 0.2586 - accuracy: 0.8859 - val_loss: 10.0657 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01988: val_loss did not improve from 0.32861\n",
      "Epoch 1989/4000\n",
      "25/25 - 0s - loss: 0.2561 - accuracy: 0.8872 - val_loss: 9.9446 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01989: val_loss did not improve from 0.32861\n",
      "Epoch 1990/4000\n",
      "25/25 - 0s - loss: 0.2591 - accuracy: 0.8846 - val_loss: 9.9186 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01990: val_loss did not improve from 0.32861\n",
      "Epoch 1991/4000\n",
      "25/25 - 0s - loss: 0.2569 - accuracy: 0.8885 - val_loss: 9.8953 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01991: val_loss did not improve from 0.32861\n",
      "Epoch 1992/4000\n",
      "25/25 - 0s - loss: 0.2550 - accuracy: 0.8898 - val_loss: 9.9312 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01992: val_loss did not improve from 0.32861\n",
      "Epoch 1993/4000\n",
      "25/25 - 0s - loss: 0.2574 - accuracy: 0.8885 - val_loss: 9.8553 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01993: val_loss did not improve from 0.32861\n",
      "Epoch 1994/4000\n",
      "25/25 - 0s - loss: 0.2631 - accuracy: 0.8872 - val_loss: 10.0458 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01994: val_loss did not improve from 0.32861\n",
      "Epoch 1995/4000\n",
      "25/25 - 0s - loss: 0.2586 - accuracy: 0.8898 - val_loss: 10.2163 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01995: val_loss did not improve from 0.32861\n",
      "Epoch 1996/4000\n",
      "25/25 - 0s - loss: 0.2569 - accuracy: 0.8911 - val_loss: 9.9273 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01996: val_loss did not improve from 0.32861\n",
      "Epoch 1997/4000\n",
      "25/25 - 0s - loss: 0.2661 - accuracy: 0.8703 - val_loss: 10.0544 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01997: val_loss did not improve from 0.32861\n",
      "Epoch 1998/4000\n",
      "25/25 - 0s - loss: 0.2646 - accuracy: 0.8742 - val_loss: 10.2956 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01998: val_loss did not improve from 0.32861\n",
      "Epoch 1999/4000\n",
      "25/25 - 0s - loss: 0.2540 - accuracy: 0.8872 - val_loss: 10.2223 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01999: val_loss did not improve from 0.32861\n",
      "Epoch 2000/4000\n",
      "25/25 - 0s - loss: 0.2570 - accuracy: 0.8846 - val_loss: 10.4160 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02000: val_loss did not improve from 0.32861\n",
      "Epoch 2001/4000\n",
      "25/25 - 0s - loss: 0.2492 - accuracy: 0.8846 - val_loss: 10.4719 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02001: val_loss did not improve from 0.32861\n",
      "Epoch 2002/4000\n",
      "25/25 - 0s - loss: 0.2469 - accuracy: 0.8936 - val_loss: 10.3554 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02002: val_loss did not improve from 0.32861\n",
      "Epoch 2003/4000\n",
      "25/25 - 0s - loss: 0.2498 - accuracy: 0.8923 - val_loss: 10.3244 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02003: val_loss did not improve from 0.32861\n",
      "Epoch 2004/4000\n",
      "25/25 - 0s - loss: 0.2474 - accuracy: 0.8872 - val_loss: 10.2630 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02004: val_loss did not improve from 0.32861\n",
      "Epoch 2005/4000\n",
      "25/25 - 0s - loss: 0.2471 - accuracy: 0.8807 - val_loss: 10.5265 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02005: val_loss did not improve from 0.32861\n",
      "Epoch 2006/4000\n",
      "25/25 - 0s - loss: 0.2447 - accuracy: 0.8911 - val_loss: 10.7028 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02006: val_loss did not improve from 0.32861\n",
      "Epoch 2007/4000\n",
      "25/25 - 0s - loss: 0.2460 - accuracy: 0.8898 - val_loss: 10.8003 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02007: val_loss did not improve from 0.32861\n",
      "Epoch 2008/4000\n",
      "25/25 - 0s - loss: 0.2450 - accuracy: 0.8936 - val_loss: 10.7422 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02008: val_loss did not improve from 0.32861\n",
      "Epoch 2009/4000\n",
      "25/25 - 0s - loss: 0.2465 - accuracy: 0.8898 - val_loss: 10.8750 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02009: val_loss did not improve from 0.32861\n",
      "Epoch 2010/4000\n",
      "25/25 - 0s - loss: 0.2448 - accuracy: 0.8885 - val_loss: 10.7775 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02010: val_loss did not improve from 0.32861\n",
      "Epoch 2011/4000\n",
      "25/25 - 0s - loss: 0.2441 - accuracy: 0.8911 - val_loss: 10.6749 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02011: val_loss did not improve from 0.32861\n",
      "Epoch 2012/4000\n",
      "25/25 - 0s - loss: 0.2594 - accuracy: 0.8820 - val_loss: 10.8901 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02012: val_loss did not improve from 0.32861\n",
      "Epoch 2013/4000\n",
      "25/25 - 0s - loss: 0.2616 - accuracy: 0.8716 - val_loss: 13.4376 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02013: val_loss did not improve from 0.32861\n",
      "Epoch 2014/4000\n",
      "25/25 - 0s - loss: 0.2925 - accuracy: 0.8781 - val_loss: 7.7509 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02014: val_loss did not improve from 0.32861\n",
      "Epoch 2015/4000\n",
      "25/25 - 0s - loss: 0.3445 - accuracy: 0.8833 - val_loss: 7.6992 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02015: val_loss did not improve from 0.32861\n",
      "Epoch 2016/4000\n",
      "25/25 - 0s - loss: 0.3262 - accuracy: 0.8599 - val_loss: 9.1635 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02016: val_loss did not improve from 0.32861\n",
      "Epoch 2017/4000\n",
      "25/25 - 0s - loss: 0.2562 - accuracy: 0.8794 - val_loss: 8.7995 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02017: val_loss did not improve from 0.32861\n",
      "Epoch 2018/4000\n",
      "25/25 - 0s - loss: 0.2501 - accuracy: 0.8807 - val_loss: 8.7484 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02018: val_loss did not improve from 0.32861\n",
      "Epoch 2019/4000\n",
      "25/25 - 0s - loss: 0.2519 - accuracy: 0.8729 - val_loss: 8.6298 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02019: val_loss did not improve from 0.32861\n",
      "Epoch 2020/4000\n",
      "25/25 - 0s - loss: 0.2462 - accuracy: 0.8872 - val_loss: 8.6449 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02020: val_loss did not improve from 0.32861\n",
      "Epoch 2021/4000\n",
      "25/25 - 0s - loss: 0.2481 - accuracy: 0.8859 - val_loss: 8.4930 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02021: val_loss did not improve from 0.32861\n",
      "Epoch 2022/4000\n",
      "25/25 - 0s - loss: 0.2455 - accuracy: 0.8859 - val_loss: 8.6128 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02022: val_loss did not improve from 0.32861\n",
      "Epoch 2023/4000\n",
      "25/25 - 0s - loss: 0.2486 - accuracy: 0.8859 - val_loss: 8.6477 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02023: val_loss did not improve from 0.32861\n",
      "Epoch 2024/4000\n",
      "25/25 - 0s - loss: 0.2466 - accuracy: 0.8885 - val_loss: 8.8618 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02024: val_loss did not improve from 0.32861\n",
      "Epoch 2025/4000\n",
      "25/25 - 0s - loss: 0.2436 - accuracy: 0.8872 - val_loss: 8.6707 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02025: val_loss did not improve from 0.32861\n",
      "Epoch 2026/4000\n",
      "25/25 - 0s - loss: 0.2471 - accuracy: 0.8833 - val_loss: 9.2466 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02026: val_loss did not improve from 0.32861\n",
      "Epoch 2027/4000\n",
      "25/25 - 0s - loss: 0.2446 - accuracy: 0.8846 - val_loss: 9.0787 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02027: val_loss did not improve from 0.32861\n",
      "Epoch 2028/4000\n",
      "25/25 - 0s - loss: 0.2479 - accuracy: 0.8885 - val_loss: 9.0311 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02028: val_loss did not improve from 0.32861\n",
      "Epoch 2029/4000\n",
      "25/25 - 0s - loss: 0.2485 - accuracy: 0.8807 - val_loss: 8.8597 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02029: val_loss did not improve from 0.32861\n",
      "Epoch 2030/4000\n",
      "25/25 - 0s - loss: 0.2465 - accuracy: 0.8846 - val_loss: 8.3646 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02030: val_loss did not improve from 0.32861\n",
      "Epoch 2031/4000\n",
      "25/25 - 0s - loss: 0.2456 - accuracy: 0.8872 - val_loss: 8.5966 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02031: val_loss did not improve from 0.32861\n",
      "Epoch 2032/4000\n",
      "25/25 - 0s - loss: 0.2419 - accuracy: 0.8872 - val_loss: 8.4802 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02032: val_loss did not improve from 0.32861\n",
      "Epoch 2033/4000\n",
      "25/25 - 0s - loss: 0.2402 - accuracy: 0.8911 - val_loss: 8.7350 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02033: val_loss did not improve from 0.32861\n",
      "Epoch 2034/4000\n",
      "25/25 - 0s - loss: 0.2442 - accuracy: 0.8885 - val_loss: 9.0002 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02034: val_loss did not improve from 0.32861\n",
      "Epoch 2035/4000\n",
      "25/25 - 0s - loss: 0.2542 - accuracy: 0.8872 - val_loss: 8.7702 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02035: val_loss did not improve from 0.32861\n",
      "Epoch 2036/4000\n",
      "25/25 - 0s - loss: 0.2440 - accuracy: 0.8911 - val_loss: 8.8253 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02036: val_loss did not improve from 0.32861\n",
      "Epoch 2037/4000\n",
      "25/25 - 0s - loss: 0.2410 - accuracy: 0.8898 - val_loss: 8.7554 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02037: val_loss did not improve from 0.32861\n",
      "Epoch 2038/4000\n",
      "25/25 - 0s - loss: 0.2467 - accuracy: 0.8859 - val_loss: 8.4387 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02038: val_loss did not improve from 0.32861\n",
      "Epoch 2039/4000\n",
      "25/25 - 0s - loss: 0.2458 - accuracy: 0.8885 - val_loss: 8.5620 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02039: val_loss did not improve from 0.32861\n",
      "Epoch 2040/4000\n",
      "25/25 - 0s - loss: 0.2487 - accuracy: 0.8807 - val_loss: 7.9814 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02040: val_loss did not improve from 0.32861\n",
      "Epoch 2041/4000\n",
      "25/25 - 0s - loss: 0.2527 - accuracy: 0.8833 - val_loss: 7.5679 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02041: val_loss did not improve from 0.32861\n",
      "Epoch 2042/4000\n",
      "25/25 - 0s - loss: 0.2460 - accuracy: 0.8885 - val_loss: 8.3255 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02042: val_loss did not improve from 0.32861\n",
      "Epoch 2043/4000\n",
      "25/25 - 0s - loss: 0.2395 - accuracy: 0.8885 - val_loss: 8.1728 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02043: val_loss did not improve from 0.32861\n",
      "Epoch 2044/4000\n",
      "25/25 - 0s - loss: 0.2408 - accuracy: 0.8820 - val_loss: 8.8725 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02044: val_loss did not improve from 0.32861\n",
      "Epoch 2045/4000\n",
      "25/25 - 0s - loss: 0.2384 - accuracy: 0.8872 - val_loss: 8.8498 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02045: val_loss did not improve from 0.32861\n",
      "Epoch 2046/4000\n",
      "25/25 - 0s - loss: 0.2356 - accuracy: 0.8923 - val_loss: 8.8334 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02046: val_loss did not improve from 0.32861\n",
      "Epoch 2047/4000\n",
      "25/25 - 0s - loss: 0.2364 - accuracy: 0.8898 - val_loss: 9.0235 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02047: val_loss did not improve from 0.32861\n",
      "Epoch 2048/4000\n",
      "25/25 - 0s - loss: 0.2483 - accuracy: 0.8923 - val_loss: 9.0884 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02048: val_loss did not improve from 0.32861\n",
      "Epoch 2049/4000\n",
      "25/25 - 0s - loss: 0.3972 - accuracy: 0.8885 - val_loss: 9.9043 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02049: val_loss did not improve from 0.32861\n",
      "Epoch 2050/4000\n",
      "25/25 - 0s - loss: 0.4635 - accuracy: 0.8638 - val_loss: 4.1089 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02050: val_loss did not improve from 0.32861\n",
      "Epoch 2051/4000\n",
      "25/25 - 0s - loss: 0.3211 - accuracy: 0.8482 - val_loss: 3.2455 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 02051: val_loss did not improve from 0.32861\n",
      "Epoch 2052/4000\n",
      "25/25 - 0s - loss: 0.3276 - accuracy: 0.8651 - val_loss: 3.6415 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02052: val_loss did not improve from 0.32861\n",
      "Epoch 2053/4000\n",
      "25/25 - 0s - loss: 0.3402 - accuracy: 0.8807 - val_loss: 4.3881 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02053: val_loss did not improve from 0.32861\n",
      "Epoch 2054/4000\n",
      "25/25 - 0s - loss: 0.2689 - accuracy: 0.8846 - val_loss: 4.6181 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02054: val_loss did not improve from 0.32861\n",
      "Epoch 2055/4000\n",
      "25/25 - 0s - loss: 0.2596 - accuracy: 0.8872 - val_loss: 4.8443 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02055: val_loss did not improve from 0.32861\n",
      "Epoch 2056/4000\n",
      "25/25 - 0s - loss: 0.2613 - accuracy: 0.8820 - val_loss: 4.8561 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02056: val_loss did not improve from 0.32861\n",
      "Epoch 2057/4000\n",
      "25/25 - 0s - loss: 0.2548 - accuracy: 0.8859 - val_loss: 5.9422 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02057: val_loss did not improve from 0.32861\n",
      "Epoch 2058/4000\n",
      "25/25 - 0s - loss: 0.2620 - accuracy: 0.8872 - val_loss: 11.0368 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02058: val_loss did not improve from 0.32861\n",
      "Epoch 2059/4000\n",
      "25/25 - 0s - loss: 0.2665 - accuracy: 0.8781 - val_loss: 7.4721 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02059: val_loss did not improve from 0.32861\n",
      "Epoch 2060/4000\n",
      "25/25 - 0s - loss: 0.2564 - accuracy: 0.8898 - val_loss: 7.5335 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02060: val_loss did not improve from 0.32861\n",
      "Epoch 2061/4000\n",
      "25/25 - 0s - loss: 0.2480 - accuracy: 0.8859 - val_loss: 8.1614 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02061: val_loss did not improve from 0.32861\n",
      "Epoch 2062/4000\n",
      "25/25 - 0s - loss: 0.2468 - accuracy: 0.8885 - val_loss: 8.6172 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02062: val_loss did not improve from 0.32861\n",
      "Epoch 2063/4000\n",
      "25/25 - 0s - loss: 0.2454 - accuracy: 0.8872 - val_loss: 8.7248 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02063: val_loss did not improve from 0.32861\n",
      "Epoch 2064/4000\n",
      "25/25 - 0s - loss: 0.2441 - accuracy: 0.8898 - val_loss: 9.4561 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02064: val_loss did not improve from 0.32861\n",
      "Epoch 2065/4000\n",
      "25/25 - 0s - loss: 0.2401 - accuracy: 0.8898 - val_loss: 9.9269 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02065: val_loss did not improve from 0.32861\n",
      "Epoch 2066/4000\n",
      "25/25 - 0s - loss: 0.2398 - accuracy: 0.8898 - val_loss: 10.0805 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02066: val_loss did not improve from 0.32861\n",
      "Epoch 2067/4000\n",
      "25/25 - 0s - loss: 0.2536 - accuracy: 0.8716 - val_loss: 11.5784 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02067: val_loss did not improve from 0.32861\n",
      "Epoch 2068/4000\n",
      "25/25 - 0s - loss: 0.2427 - accuracy: 0.8949 - val_loss: 8.3651 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02068: val_loss did not improve from 0.32861\n",
      "Epoch 2069/4000\n",
      "25/25 - 0s - loss: 0.2409 - accuracy: 0.8911 - val_loss: 8.4233 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02069: val_loss did not improve from 0.32861\n",
      "Epoch 2070/4000\n",
      "25/25 - 0s - loss: 0.2441 - accuracy: 0.8820 - val_loss: 8.6771 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02070: val_loss did not improve from 0.32861\n",
      "Epoch 2071/4000\n",
      "25/25 - 0s - loss: 0.2364 - accuracy: 0.8833 - val_loss: 9.0176 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02071: val_loss did not improve from 0.32861\n",
      "Epoch 2072/4000\n",
      "25/25 - 0s - loss: 0.2365 - accuracy: 0.8936 - val_loss: 8.7950 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02072: val_loss did not improve from 0.32861\n",
      "Epoch 2073/4000\n",
      "25/25 - 0s - loss: 0.2349 - accuracy: 0.8923 - val_loss: 8.6699 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02073: val_loss did not improve from 0.32861\n",
      "Epoch 2074/4000\n",
      "25/25 - 0s - loss: 0.2322 - accuracy: 0.8936 - val_loss: 9.1930 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02074: val_loss did not improve from 0.32861\n",
      "Epoch 2075/4000\n",
      "25/25 - 0s - loss: 0.2358 - accuracy: 0.8872 - val_loss: 9.2596 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02075: val_loss did not improve from 0.32861\n",
      "Epoch 2076/4000\n",
      "25/25 - 0s - loss: 0.2305 - accuracy: 0.8872 - val_loss: 9.4122 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02076: val_loss did not improve from 0.32861\n",
      "Epoch 2077/4000\n",
      "25/25 - 0s - loss: 0.2367 - accuracy: 0.8923 - val_loss: 12.6154 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02077: val_loss did not improve from 0.32861\n",
      "Epoch 2078/4000\n",
      "25/25 - 0s - loss: 0.2258 - accuracy: 0.8898 - val_loss: 10.8246 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02078: val_loss did not improve from 0.32861\n",
      "Epoch 2079/4000\n",
      "25/25 - 0s - loss: 0.2269 - accuracy: 0.8936 - val_loss: 10.2289 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02079: val_loss did not improve from 0.32861\n",
      "Epoch 2080/4000\n",
      "25/25 - 0s - loss: 0.2270 - accuracy: 0.8949 - val_loss: 10.1482 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02080: val_loss did not improve from 0.32861\n",
      "Epoch 2081/4000\n",
      "25/25 - 0s - loss: 0.2281 - accuracy: 0.8962 - val_loss: 10.1683 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02081: val_loss did not improve from 0.32861\n",
      "Epoch 2082/4000\n",
      "25/25 - 0s - loss: 0.2295 - accuracy: 0.8975 - val_loss: 10.3198 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02082: val_loss did not improve from 0.32861\n",
      "Epoch 2083/4000\n",
      "25/25 - 0s - loss: 0.2265 - accuracy: 0.8962 - val_loss: 10.0516 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02083: val_loss did not improve from 0.32861\n",
      "Epoch 2084/4000\n",
      "25/25 - 0s - loss: 0.2272 - accuracy: 0.8949 - val_loss: 9.8195 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02084: val_loss did not improve from 0.32861\n",
      "Epoch 2085/4000\n",
      "25/25 - 0s - loss: 0.2257 - accuracy: 0.8949 - val_loss: 10.0274 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02085: val_loss did not improve from 0.32861\n",
      "Epoch 2086/4000\n",
      "25/25 - 0s - loss: 0.2265 - accuracy: 0.8988 - val_loss: 10.2315 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02086: val_loss did not improve from 0.32861\n",
      "Epoch 2087/4000\n",
      "25/25 - 0s - loss: 0.2285 - accuracy: 0.8975 - val_loss: 10.3531 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02087: val_loss did not improve from 0.32861\n",
      "Epoch 2088/4000\n",
      "25/25 - 0s - loss: 0.2266 - accuracy: 0.8911 - val_loss: 10.3022 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02088: val_loss did not improve from 0.32861\n",
      "Epoch 2089/4000\n",
      "25/25 - 0s - loss: 0.2262 - accuracy: 0.8898 - val_loss: 9.7180 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02089: val_loss did not improve from 0.32861\n",
      "Epoch 2090/4000\n",
      "25/25 - 0s - loss: 0.2280 - accuracy: 0.8962 - val_loss: 10.1861 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02090: val_loss did not improve from 0.32861\n",
      "Epoch 2091/4000\n",
      "25/25 - 0s - loss: 0.2253 - accuracy: 0.8923 - val_loss: 9.8920 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02091: val_loss did not improve from 0.32861\n",
      "Epoch 2092/4000\n",
      "25/25 - 0s - loss: 0.2303 - accuracy: 0.8911 - val_loss: 10.4565 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02092: val_loss did not improve from 0.32861\n",
      "Epoch 2093/4000\n",
      "25/25 - 0s - loss: 0.2282 - accuracy: 0.8923 - val_loss: 10.0013 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02093: val_loss did not improve from 0.32861\n",
      "Epoch 2094/4000\n",
      "25/25 - 0s - loss: 0.2244 - accuracy: 0.8936 - val_loss: 9.6468 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02094: val_loss did not improve from 0.32861\n",
      "Epoch 2095/4000\n",
      "25/25 - 0s - loss: 0.2251 - accuracy: 0.8936 - val_loss: 9.6962 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02095: val_loss did not improve from 0.32861\n",
      "Epoch 2096/4000\n",
      "25/25 - 0s - loss: 0.2259 - accuracy: 0.8975 - val_loss: 9.4396 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02096: val_loss did not improve from 0.32861\n",
      "Epoch 2097/4000\n",
      "25/25 - 0s - loss: 0.2253 - accuracy: 0.8936 - val_loss: 9.6364 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02097: val_loss did not improve from 0.32861\n",
      "Epoch 2098/4000\n",
      "25/25 - 0s - loss: 0.2225 - accuracy: 0.8923 - val_loss: 9.2991 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02098: val_loss did not improve from 0.32861\n",
      "Epoch 2099/4000\n",
      "25/25 - 0s - loss: 0.2303 - accuracy: 0.8923 - val_loss: 9.6379 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02099: val_loss did not improve from 0.32861\n",
      "Epoch 2100/4000\n",
      "25/25 - 0s - loss: 0.2271 - accuracy: 0.9027 - val_loss: 9.7055 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02100: val_loss did not improve from 0.32861\n",
      "Epoch 2101/4000\n",
      "25/25 - 0s - loss: 0.2273 - accuracy: 0.8872 - val_loss: 9.9843 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02101: val_loss did not improve from 0.32861\n",
      "Epoch 2102/4000\n",
      "25/25 - 0s - loss: 0.2294 - accuracy: 0.8936 - val_loss: 9.7855 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02102: val_loss did not improve from 0.32861\n",
      "Epoch 2103/4000\n",
      "25/25 - 0s - loss: 0.2331 - accuracy: 0.8794 - val_loss: 10.3909 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02103: val_loss did not improve from 0.32861\n",
      "Epoch 2104/4000\n",
      "25/25 - 0s - loss: 0.2283 - accuracy: 0.8833 - val_loss: 10.0163 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02104: val_loss did not improve from 0.32861\n",
      "Epoch 2105/4000\n",
      "25/25 - 0s - loss: 0.2327 - accuracy: 0.8898 - val_loss: 9.7208 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02105: val_loss did not improve from 0.32861\n",
      "Epoch 2106/4000\n",
      "25/25 - 0s - loss: 0.2321 - accuracy: 0.8898 - val_loss: 10.1832 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02106: val_loss did not improve from 0.32861\n",
      "Epoch 2107/4000\n",
      "25/25 - 0s - loss: 0.2276 - accuracy: 0.8898 - val_loss: 9.7164 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02107: val_loss did not improve from 0.32861\n",
      "Epoch 2108/4000\n",
      "25/25 - 0s - loss: 0.2267 - accuracy: 0.8923 - val_loss: 10.8016 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02108: val_loss did not improve from 0.32861\n",
      "Epoch 2109/4000\n",
      "25/25 - 0s - loss: 0.2253 - accuracy: 0.8962 - val_loss: 11.5334 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02109: val_loss did not improve from 0.32861\n",
      "Epoch 2110/4000\n",
      "25/25 - 0s - loss: 0.2233 - accuracy: 0.8872 - val_loss: 11.6620 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02110: val_loss did not improve from 0.32861\n",
      "Epoch 2111/4000\n",
      "25/25 - 0s - loss: 0.2354 - accuracy: 0.8807 - val_loss: 10.2509 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02111: val_loss did not improve from 0.32861\n",
      "Epoch 2112/4000\n",
      "25/25 - 0s - loss: 0.2269 - accuracy: 0.8898 - val_loss: 10.0840 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02112: val_loss did not improve from 0.32861\n",
      "Epoch 2113/4000\n",
      "25/25 - 0s - loss: 0.2223 - accuracy: 0.8975 - val_loss: 10.7854 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02113: val_loss did not improve from 0.32861\n",
      "Epoch 2114/4000\n",
      "25/25 - 0s - loss: 0.2241 - accuracy: 0.8911 - val_loss: 10.7606 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02114: val_loss did not improve from 0.32861\n",
      "Epoch 2115/4000\n",
      "25/25 - 0s - loss: 0.2233 - accuracy: 0.8949 - val_loss: 10.7576 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02115: val_loss did not improve from 0.32861\n",
      "Epoch 2116/4000\n",
      "25/25 - 1s - loss: 0.2264 - accuracy: 0.8923 - val_loss: 10.6148 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02116: val_loss did not improve from 0.32861\n",
      "Epoch 2117/4000\n",
      "25/25 - 0s - loss: 0.2283 - accuracy: 0.8898 - val_loss: 10.6777 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02117: val_loss did not improve from 0.32861\n",
      "Epoch 2118/4000\n",
      "25/25 - 0s - loss: 0.2289 - accuracy: 0.8923 - val_loss: 10.9399 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02118: val_loss did not improve from 0.32861\n",
      "Epoch 2119/4000\n",
      "25/25 - 0s - loss: 0.2273 - accuracy: 0.8911 - val_loss: 11.2708 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02119: val_loss did not improve from 0.32861\n",
      "Epoch 2120/4000\n",
      "25/25 - 0s - loss: 0.2244 - accuracy: 0.8923 - val_loss: 10.5333 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02120: val_loss did not improve from 0.32861\n",
      "Epoch 2121/4000\n",
      "25/25 - 0s - loss: 0.2225 - accuracy: 0.8949 - val_loss: 11.0282 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02121: val_loss did not improve from 0.32861\n",
      "Epoch 2122/4000\n",
      "25/25 - 0s - loss: 0.2289 - accuracy: 0.8859 - val_loss: 11.3255 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02122: val_loss did not improve from 0.32861\n",
      "Epoch 2123/4000\n",
      "25/25 - 0s - loss: 0.2368 - accuracy: 0.8872 - val_loss: 11.3000 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02123: val_loss did not improve from 0.32861\n",
      "Epoch 2124/4000\n",
      "25/25 - 0s - loss: 0.2300 - accuracy: 0.8872 - val_loss: 10.7550 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02124: val_loss did not improve from 0.32861\n",
      "Epoch 2125/4000\n",
      "25/25 - 0s - loss: 0.2283 - accuracy: 0.8923 - val_loss: 10.2510 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02125: val_loss did not improve from 0.32861\n",
      "Epoch 2126/4000\n",
      "25/25 - 0s - loss: 0.2260 - accuracy: 0.8936 - val_loss: 11.3016 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02126: val_loss did not improve from 0.32861\n",
      "Epoch 2127/4000\n",
      "25/25 - 0s - loss: 0.2313 - accuracy: 0.8911 - val_loss: 13.1753 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02127: val_loss did not improve from 0.32861\n",
      "Epoch 2128/4000\n",
      "25/25 - 0s - loss: 0.2575 - accuracy: 0.8820 - val_loss: 12.5122 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02128: val_loss did not improve from 0.32861\n",
      "Epoch 2129/4000\n",
      "25/25 - 0s - loss: 0.2413 - accuracy: 0.8898 - val_loss: 12.3859 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02129: val_loss did not improve from 0.32861\n",
      "Epoch 2130/4000\n",
      "25/25 - 0s - loss: 0.2311 - accuracy: 0.8898 - val_loss: 17.0164 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02130: val_loss did not improve from 0.32861\n",
      "Epoch 2131/4000\n",
      "25/25 - 0s - loss: 0.2380 - accuracy: 0.8846 - val_loss: 14.7497 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02131: val_loss did not improve from 0.32861\n",
      "Epoch 2132/4000\n",
      "25/25 - 0s - loss: 0.2323 - accuracy: 0.8859 - val_loss: 14.8796 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02132: val_loss did not improve from 0.32861\n",
      "Epoch 2133/4000\n",
      "25/25 - 0s - loss: 0.2370 - accuracy: 0.8820 - val_loss: 14.7925 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02133: val_loss did not improve from 0.32861\n",
      "Epoch 2134/4000\n",
      "25/25 - 0s - loss: 0.2258 - accuracy: 0.8949 - val_loss: 16.0201 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02134: val_loss did not improve from 0.32861\n",
      "Epoch 2135/4000\n",
      "25/25 - 0s - loss: 0.2325 - accuracy: 0.8872 - val_loss: 16.1346 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02135: val_loss did not improve from 0.32861\n",
      "Epoch 2136/4000\n",
      "25/25 - 0s - loss: 0.2269 - accuracy: 0.8962 - val_loss: 15.5234 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02136: val_loss did not improve from 0.32861\n",
      "Epoch 2137/4000\n",
      "25/25 - 0s - loss: 0.2260 - accuracy: 0.8936 - val_loss: 15.4969 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02137: val_loss did not improve from 0.32861\n",
      "Epoch 2138/4000\n",
      "25/25 - 0s - loss: 0.2259 - accuracy: 0.8962 - val_loss: 15.4631 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02138: val_loss did not improve from 0.32861\n",
      "Epoch 2139/4000\n",
      "25/25 - 0s - loss: 0.2270 - accuracy: 0.8949 - val_loss: 15.4188 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02139: val_loss did not improve from 0.32861\n",
      "Epoch 2140/4000\n",
      "25/25 - 0s - loss: 0.2328 - accuracy: 0.8936 - val_loss: 16.0071 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02140: val_loss did not improve from 0.32861\n",
      "Epoch 2141/4000\n",
      "25/25 - 0s - loss: 0.2287 - accuracy: 0.8923 - val_loss: 16.7382 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02141: val_loss did not improve from 0.32861\n",
      "Epoch 2142/4000\n",
      "25/25 - 0s - loss: 0.2272 - accuracy: 0.8885 - val_loss: 15.2829 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02142: val_loss did not improve from 0.32861\n",
      "Epoch 2143/4000\n",
      "25/25 - 0s - loss: 0.2302 - accuracy: 0.8949 - val_loss: 14.8697 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02143: val_loss did not improve from 0.32861\n",
      "Epoch 2144/4000\n",
      "25/25 - 0s - loss: 0.2236 - accuracy: 0.8949 - val_loss: 15.2603 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02144: val_loss did not improve from 0.32861\n",
      "Epoch 2145/4000\n",
      "25/25 - 0s - loss: 0.2266 - accuracy: 0.8885 - val_loss: 15.5797 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02145: val_loss did not improve from 0.32861\n",
      "Epoch 2146/4000\n",
      "25/25 - 0s - loss: 0.2332 - accuracy: 0.8911 - val_loss: 15.4718 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02146: val_loss did not improve from 0.32861\n",
      "Epoch 2147/4000\n",
      "25/25 - 0s - loss: 0.2263 - accuracy: 0.8923 - val_loss: 15.5464 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02147: val_loss did not improve from 0.32861\n",
      "Epoch 2148/4000\n",
      "25/25 - 0s - loss: 0.2301 - accuracy: 0.8936 - val_loss: 14.8658 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02148: val_loss did not improve from 0.32861\n",
      "Epoch 2149/4000\n",
      "25/25 - 0s - loss: 0.2266 - accuracy: 0.8923 - val_loss: 14.1063 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02149: val_loss did not improve from 0.32861\n",
      "Epoch 2150/4000\n",
      "25/25 - 0s - loss: 0.2246 - accuracy: 0.8898 - val_loss: 14.8498 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02150: val_loss did not improve from 0.32861\n",
      "Epoch 2151/4000\n",
      "25/25 - 0s - loss: 0.2248 - accuracy: 0.8962 - val_loss: 14.8742 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02151: val_loss did not improve from 0.32861\n",
      "Epoch 2152/4000\n",
      "25/25 - 0s - loss: 0.2252 - accuracy: 0.8949 - val_loss: 15.0305 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02152: val_loss did not improve from 0.32861\n",
      "Epoch 2153/4000\n",
      "25/25 - 0s - loss: 0.2452 - accuracy: 0.8781 - val_loss: 15.0173 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02153: val_loss did not improve from 0.32861\n",
      "Epoch 2154/4000\n",
      "25/25 - 0s - loss: 0.5358 - accuracy: 0.8392 - val_loss: 14.4038 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02154: val_loss did not improve from 0.32861\n",
      "Epoch 2155/4000\n",
      "25/25 - 0s - loss: 0.2911 - accuracy: 0.8768 - val_loss: 17.2253 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02155: val_loss did not improve from 0.32861\n",
      "Epoch 2156/4000\n",
      "25/25 - 0s - loss: 0.4899 - accuracy: 0.8846 - val_loss: 7.7812 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02156: val_loss did not improve from 0.32861\n",
      "Epoch 2157/4000\n",
      "25/25 - 0s - loss: 1.3906 - accuracy: 0.8482 - val_loss: 7.1482 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 02157: val_loss did not improve from 0.32861\n",
      "Epoch 2158/4000\n",
      "25/25 - 0s - loss: 0.3078 - accuracy: 0.8612 - val_loss: 6.3699 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02158: val_loss did not improve from 0.32861\n",
      "Epoch 2159/4000\n",
      "25/25 - 0s - loss: 0.2727 - accuracy: 0.8833 - val_loss: 5.7837 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02159: val_loss did not improve from 0.32861\n",
      "Epoch 2160/4000\n",
      "25/25 - 0s - loss: 0.2649 - accuracy: 0.8846 - val_loss: 6.1694 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02160: val_loss did not improve from 0.32861\n",
      "Epoch 2161/4000\n",
      "25/25 - 0s - loss: 0.2637 - accuracy: 0.8846 - val_loss: 6.1797 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02161: val_loss did not improve from 0.32861\n",
      "Epoch 2162/4000\n",
      "25/25 - 0s - loss: 0.2611 - accuracy: 0.8859 - val_loss: 5.5179 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02162: val_loss did not improve from 0.32861\n",
      "Epoch 2163/4000\n",
      "25/25 - 0s - loss: 0.2579 - accuracy: 0.8859 - val_loss: 5.3053 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02163: val_loss did not improve from 0.32861\n",
      "Epoch 2164/4000\n",
      "25/25 - 0s - loss: 0.2523 - accuracy: 0.8898 - val_loss: 5.3788 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02164: val_loss did not improve from 0.32861\n",
      "Epoch 2165/4000\n",
      "25/25 - 0s - loss: 0.2497 - accuracy: 0.8833 - val_loss: 5.5621 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02165: val_loss did not improve from 0.32861\n",
      "Epoch 2166/4000\n",
      "25/25 - 0s - loss: 0.2598 - accuracy: 0.8911 - val_loss: 5.8227 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02166: val_loss did not improve from 0.32861\n",
      "Epoch 2167/4000\n",
      "25/25 - 0s - loss: 0.2537 - accuracy: 0.8807 - val_loss: 6.0269 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02167: val_loss did not improve from 0.32861\n",
      "Epoch 2168/4000\n",
      "25/25 - 0s - loss: 0.2654 - accuracy: 0.8872 - val_loss: 3.1167 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02168: val_loss did not improve from 0.32861\n",
      "Epoch 2169/4000\n",
      "25/25 - 0s - loss: 0.2621 - accuracy: 0.8911 - val_loss: 3.2569 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02169: val_loss did not improve from 0.32861\n",
      "Epoch 2170/4000\n",
      "25/25 - 0s - loss: 0.2576 - accuracy: 0.8885 - val_loss: 3.4949 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02170: val_loss did not improve from 0.32861\n",
      "Epoch 2171/4000\n",
      "25/25 - 0s - loss: 0.2607 - accuracy: 0.8885 - val_loss: 3.5522 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02171: val_loss did not improve from 0.32861\n",
      "Epoch 2172/4000\n",
      "25/25 - 0s - loss: 0.2546 - accuracy: 0.8872 - val_loss: 3.8210 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02172: val_loss did not improve from 0.32861\n",
      "Epoch 2173/4000\n",
      "25/25 - 0s - loss: 0.2666 - accuracy: 0.8923 - val_loss: 4.0206 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02173: val_loss did not improve from 0.32861\n",
      "Epoch 2174/4000\n",
      "25/25 - 0s - loss: 0.2489 - accuracy: 0.8923 - val_loss: 4.0502 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02174: val_loss did not improve from 0.32861\n",
      "Epoch 2175/4000\n",
      "25/25 - 0s - loss: 0.2468 - accuracy: 0.8923 - val_loss: 4.1722 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02175: val_loss did not improve from 0.32861\n",
      "Epoch 2176/4000\n",
      "25/25 - 0s - loss: 0.2471 - accuracy: 0.8859 - val_loss: 4.1493 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02176: val_loss did not improve from 0.32861\n",
      "Epoch 2177/4000\n",
      "25/25 - 0s - loss: 0.2568 - accuracy: 0.8755 - val_loss: 4.2956 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02177: val_loss did not improve from 0.32861\n",
      "Epoch 2178/4000\n",
      "25/25 - 0s - loss: 0.2479 - accuracy: 0.8898 - val_loss: 4.1893 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02178: val_loss did not improve from 0.32861\n",
      "Epoch 2179/4000\n",
      "25/25 - 0s - loss: 0.2483 - accuracy: 0.8885 - val_loss: 4.2942 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02179: val_loss did not improve from 0.32861\n",
      "Epoch 2180/4000\n",
      "25/25 - 0s - loss: 0.2495 - accuracy: 0.8949 - val_loss: 4.1530 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02180: val_loss did not improve from 0.32861\n",
      "Epoch 2181/4000\n",
      "25/25 - 0s - loss: 0.2504 - accuracy: 0.8911 - val_loss: 4.2778 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02181: val_loss did not improve from 0.32861\n",
      "Epoch 2182/4000\n",
      "25/25 - 0s - loss: 0.2610 - accuracy: 0.8898 - val_loss: 4.4104 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02182: val_loss did not improve from 0.32861\n",
      "Epoch 2183/4000\n",
      "25/25 - 0s - loss: 0.2593 - accuracy: 0.8898 - val_loss: 2.9094 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02183: val_loss did not improve from 0.32861\n",
      "Epoch 2184/4000\n",
      "25/25 - 0s - loss: 0.2524 - accuracy: 0.8794 - val_loss: 2.5097 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02184: val_loss did not improve from 0.32861\n",
      "Epoch 2185/4000\n",
      "25/25 - 0s - loss: 0.2442 - accuracy: 0.8949 - val_loss: 2.4458 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02185: val_loss did not improve from 0.32861\n",
      "Epoch 2186/4000\n",
      "25/25 - 1s - loss: 0.2418 - accuracy: 0.8923 - val_loss: 2.5944 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02186: val_loss did not improve from 0.32861\n",
      "Epoch 2187/4000\n",
      "25/25 - 0s - loss: 0.2430 - accuracy: 0.8885 - val_loss: 2.6965 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02187: val_loss did not improve from 0.32861\n",
      "Epoch 2188/4000\n",
      "25/25 - 0s - loss: 0.2418 - accuracy: 0.8885 - val_loss: 2.7682 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02188: val_loss did not improve from 0.32861\n",
      "Epoch 2189/4000\n",
      "25/25 - 0s - loss: 0.2422 - accuracy: 0.8898 - val_loss: 2.7600 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02189: val_loss did not improve from 0.32861\n",
      "Epoch 2190/4000\n",
      "25/25 - 0s - loss: 0.2395 - accuracy: 0.8820 - val_loss: 2.7029 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02190: val_loss did not improve from 0.32861\n",
      "Epoch 2191/4000\n",
      "25/25 - 0s - loss: 0.2370 - accuracy: 0.8833 - val_loss: 2.7908 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02191: val_loss did not improve from 0.32861\n",
      "Epoch 2192/4000\n",
      "25/25 - 0s - loss: 0.2393 - accuracy: 0.8820 - val_loss: 2.7890 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02192: val_loss did not improve from 0.32861\n",
      "Epoch 2193/4000\n",
      "25/25 - 0s - loss: 0.2363 - accuracy: 0.8898 - val_loss: 2.8545 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02193: val_loss did not improve from 0.32861\n",
      "Epoch 2194/4000\n",
      "25/25 - 0s - loss: 0.2389 - accuracy: 0.8898 - val_loss: 2.9397 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02194: val_loss did not improve from 0.32861\n",
      "Epoch 2195/4000\n",
      "25/25 - 0s - loss: 0.2541 - accuracy: 0.8859 - val_loss: 2.8325 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02195: val_loss did not improve from 0.32861\n",
      "Epoch 2196/4000\n",
      "25/25 - 0s - loss: 0.2363 - accuracy: 0.8949 - val_loss: 2.8893 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02196: val_loss did not improve from 0.32861\n",
      "Epoch 2197/4000\n",
      "25/25 - 0s - loss: 0.2369 - accuracy: 0.8911 - val_loss: 2.9240 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02197: val_loss did not improve from 0.32861\n",
      "Epoch 2198/4000\n",
      "25/25 - 0s - loss: 0.2368 - accuracy: 0.8898 - val_loss: 2.9785 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02198: val_loss did not improve from 0.32861\n",
      "Epoch 2199/4000\n",
      "25/25 - 0s - loss: 0.2387 - accuracy: 0.8872 - val_loss: 3.1024 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02199: val_loss did not improve from 0.32861\n",
      "Epoch 2200/4000\n",
      "25/25 - 0s - loss: 0.2390 - accuracy: 0.8859 - val_loss: 2.8528 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02200: val_loss did not improve from 0.32861\n",
      "Epoch 2201/4000\n",
      "25/25 - 0s - loss: 0.2396 - accuracy: 0.8872 - val_loss: 2.7945 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02201: val_loss did not improve from 0.32861\n",
      "Epoch 2202/4000\n",
      "25/25 - 0s - loss: 0.2371 - accuracy: 0.8885 - val_loss: 2.7594 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02202: val_loss did not improve from 0.32861\n",
      "Epoch 2203/4000\n",
      "25/25 - 0s - loss: 0.2391 - accuracy: 0.8859 - val_loss: 2.8371 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02203: val_loss did not improve from 0.32861\n",
      "Epoch 2204/4000\n",
      "25/25 - 0s - loss: 0.2380 - accuracy: 0.8859 - val_loss: 2.8246 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02204: val_loss did not improve from 0.32861\n",
      "Epoch 2205/4000\n",
      "25/25 - 0s - loss: 0.2346 - accuracy: 0.8898 - val_loss: 2.8750 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02205: val_loss did not improve from 0.32861\n",
      "Epoch 2206/4000\n",
      "25/25 - 0s - loss: 0.2429 - accuracy: 0.8872 - val_loss: 2.8412 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02206: val_loss did not improve from 0.32861\n",
      "Epoch 2207/4000\n",
      "25/25 - 0s - loss: 0.2363 - accuracy: 0.8872 - val_loss: 2.9263 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02207: val_loss did not improve from 0.32861\n",
      "Epoch 2208/4000\n",
      "25/25 - 0s - loss: 0.2354 - accuracy: 0.8911 - val_loss: 2.9348 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02208: val_loss did not improve from 0.32861\n",
      "Epoch 2209/4000\n",
      "25/25 - 0s - loss: 0.2371 - accuracy: 0.8872 - val_loss: 2.8752 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02209: val_loss did not improve from 0.32861\n",
      "Epoch 2210/4000\n",
      "25/25 - 0s - loss: 0.2434 - accuracy: 0.8846 - val_loss: 2.8800 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02210: val_loss did not improve from 0.32861\n",
      "Epoch 2211/4000\n",
      "25/25 - 0s - loss: 0.2364 - accuracy: 0.8885 - val_loss: 2.9045 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02211: val_loss did not improve from 0.32861\n",
      "Epoch 2212/4000\n",
      "25/25 - 0s - loss: 0.2347 - accuracy: 0.8898 - val_loss: 2.9265 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02212: val_loss did not improve from 0.32861\n",
      "Epoch 2213/4000\n",
      "25/25 - 0s - loss: 0.2470 - accuracy: 0.8755 - val_loss: 2.9743 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02213: val_loss did not improve from 0.32861\n",
      "Epoch 2214/4000\n",
      "25/25 - 0s - loss: 0.2368 - accuracy: 0.8872 - val_loss: 2.9395 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02214: val_loss did not improve from 0.32861\n",
      "Epoch 2215/4000\n",
      "25/25 - 0s - loss: 0.2386 - accuracy: 0.8859 - val_loss: 3.0383 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02215: val_loss did not improve from 0.32861\n",
      "Epoch 2216/4000\n",
      "25/25 - 0s - loss: 0.2387 - accuracy: 0.8885 - val_loss: 2.8387 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02216: val_loss did not improve from 0.32861\n",
      "Epoch 2217/4000\n",
      "25/25 - 0s - loss: 0.2355 - accuracy: 0.8807 - val_loss: 2.8188 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02217: val_loss did not improve from 0.32861\n",
      "Epoch 2218/4000\n",
      "25/25 - 0s - loss: 0.2339 - accuracy: 0.8898 - val_loss: 2.8955 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02218: val_loss did not improve from 0.32861\n",
      "Epoch 2219/4000\n",
      "25/25 - 0s - loss: 0.2422 - accuracy: 0.8859 - val_loss: 2.4905 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02219: val_loss did not improve from 0.32861\n",
      "Epoch 2220/4000\n",
      "25/25 - 0s - loss: 0.4489 - accuracy: 0.8664 - val_loss: 4.7023 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02220: val_loss did not improve from 0.32861\n",
      "Epoch 2221/4000\n",
      "25/25 - 0s - loss: 0.3128 - accuracy: 0.8703 - val_loss: 5.9280 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 02221: val_loss did not improve from 0.32861\n",
      "Epoch 2222/4000\n",
      "25/25 - 0s - loss: 0.3091 - accuracy: 0.8729 - val_loss: 7.7289 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02222: val_loss did not improve from 0.32861\n",
      "Epoch 2223/4000\n",
      "25/25 - 0s - loss: 0.2586 - accuracy: 0.8872 - val_loss: 8.3784 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02223: val_loss did not improve from 0.32861\n",
      "Epoch 2224/4000\n",
      "25/25 - 0s - loss: 0.2847 - accuracy: 0.8716 - val_loss: 8.6304 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02224: val_loss did not improve from 0.32861\n",
      "Epoch 2225/4000\n",
      "25/25 - 0s - loss: 0.2610 - accuracy: 0.8846 - val_loss: 17.0093 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02225: val_loss did not improve from 0.32861\n",
      "Epoch 2226/4000\n",
      "25/25 - 0s - loss: 0.2710 - accuracy: 0.8677 - val_loss: 23.2976 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02226: val_loss did not improve from 0.32861\n",
      "Epoch 2227/4000\n",
      "25/25 - 0s - loss: 0.2568 - accuracy: 0.8755 - val_loss: 21.5351 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02227: val_loss did not improve from 0.32861\n",
      "Epoch 2228/4000\n",
      "25/25 - 0s - loss: 0.2487 - accuracy: 0.8898 - val_loss: 19.8973 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02228: val_loss did not improve from 0.32861\n",
      "Epoch 2229/4000\n",
      "25/25 - 0s - loss: 0.2494 - accuracy: 0.8923 - val_loss: 19.9894 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02229: val_loss did not improve from 0.32861\n",
      "Epoch 2230/4000\n",
      "25/25 - 0s - loss: 0.2479 - accuracy: 0.8923 - val_loss: 20.6636 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02230: val_loss did not improve from 0.32861\n",
      "Epoch 2231/4000\n",
      "25/25 - 0s - loss: 0.2442 - accuracy: 0.8923 - val_loss: 20.5499 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02231: val_loss did not improve from 0.32861\n",
      "Epoch 2232/4000\n",
      "25/25 - 0s - loss: 0.2590 - accuracy: 0.8820 - val_loss: 23.0201 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02232: val_loss did not improve from 0.32861\n",
      "Epoch 2233/4000\n",
      "25/25 - 0s - loss: 0.2710 - accuracy: 0.8807 - val_loss: 19.8690 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02233: val_loss did not improve from 0.32861\n",
      "Epoch 2234/4000\n",
      "25/25 - 0s - loss: 0.2471 - accuracy: 0.8872 - val_loss: 20.6600 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02234: val_loss did not improve from 0.32861\n",
      "Epoch 2235/4000\n",
      "25/25 - 0s - loss: 0.2410 - accuracy: 0.8885 - val_loss: 21.3790 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02235: val_loss did not improve from 0.32861\n",
      "Epoch 2236/4000\n",
      "25/25 - 0s - loss: 0.2432 - accuracy: 0.8885 - val_loss: 22.0631 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02236: val_loss did not improve from 0.32861\n",
      "Epoch 2237/4000\n",
      "25/25 - 0s - loss: 0.2449 - accuracy: 0.8859 - val_loss: 22.6664 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02237: val_loss did not improve from 0.32861\n",
      "Epoch 2238/4000\n",
      "25/25 - 0s - loss: 0.2394 - accuracy: 0.8949 - val_loss: 23.5667 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02238: val_loss did not improve from 0.32861\n",
      "Epoch 2239/4000\n",
      "25/25 - 0s - loss: 0.2404 - accuracy: 0.8898 - val_loss: 27.5254 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02239: val_loss did not improve from 0.32861\n",
      "Epoch 2240/4000\n",
      "25/25 - 0s - loss: 0.2469 - accuracy: 0.8872 - val_loss: 26.4993 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02240: val_loss did not improve from 0.32861\n",
      "Epoch 2241/4000\n",
      "25/25 - 0s - loss: 0.2429 - accuracy: 0.8885 - val_loss: 26.9420 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02241: val_loss did not improve from 0.32861\n",
      "Epoch 2242/4000\n",
      "25/25 - 0s - loss: 0.2424 - accuracy: 0.8898 - val_loss: 26.4672 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02242: val_loss did not improve from 0.32861\n",
      "Epoch 2243/4000\n",
      "25/25 - 0s - loss: 0.2392 - accuracy: 0.8911 - val_loss: 26.8804 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02243: val_loss did not improve from 0.32861\n",
      "Epoch 2244/4000\n",
      "25/25 - 0s - loss: 0.2444 - accuracy: 0.8859 - val_loss: 26.2109 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02244: val_loss did not improve from 0.32861\n",
      "Epoch 2245/4000\n",
      "25/25 - 0s - loss: 0.2427 - accuracy: 0.8911 - val_loss: 26.0461 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02245: val_loss did not improve from 0.32861\n",
      "Epoch 2246/4000\n",
      "25/25 - 0s - loss: 0.2397 - accuracy: 0.8859 - val_loss: 26.2690 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02246: val_loss did not improve from 0.32861\n",
      "Epoch 2247/4000\n",
      "25/25 - 0s - loss: 0.2397 - accuracy: 0.8859 - val_loss: 26.7833 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02247: val_loss did not improve from 0.32861\n",
      "Epoch 2248/4000\n",
      "25/25 - 0s - loss: 0.2428 - accuracy: 0.8923 - val_loss: 26.3264 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02248: val_loss did not improve from 0.32861\n",
      "Epoch 2249/4000\n",
      "25/25 - 0s - loss: 0.2403 - accuracy: 0.8885 - val_loss: 26.4671 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02249: val_loss did not improve from 0.32861\n",
      "Epoch 2250/4000\n",
      "25/25 - 0s - loss: 0.2449 - accuracy: 0.8923 - val_loss: 27.7801 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02250: val_loss did not improve from 0.32861\n",
      "Epoch 2251/4000\n",
      "25/25 - 0s - loss: 0.2430 - accuracy: 0.8898 - val_loss: 27.7818 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02251: val_loss did not improve from 0.32861\n",
      "Epoch 2252/4000\n",
      "25/25 - 0s - loss: 0.2378 - accuracy: 0.8885 - val_loss: 26.9150 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02252: val_loss did not improve from 0.32861\n",
      "Epoch 2253/4000\n",
      "25/25 - 0s - loss: 0.2454 - accuracy: 0.8846 - val_loss: 27.1992 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02253: val_loss did not improve from 0.32861\n",
      "Epoch 2254/4000\n",
      "25/25 - 0s - loss: 0.2397 - accuracy: 0.8872 - val_loss: 26.7731 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02254: val_loss did not improve from 0.32861\n",
      "Epoch 2255/4000\n",
      "25/25 - 0s - loss: 0.2392 - accuracy: 0.8885 - val_loss: 27.2162 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02255: val_loss did not improve from 0.32861\n",
      "Epoch 2256/4000\n",
      "25/25 - 0s - loss: 0.2405 - accuracy: 0.8885 - val_loss: 27.0642 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02256: val_loss did not improve from 0.32861\n",
      "Epoch 2257/4000\n",
      "25/25 - 0s - loss: 0.2510 - accuracy: 0.8742 - val_loss: 26.5683 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02257: val_loss did not improve from 0.32861\n",
      "Epoch 2258/4000\n",
      "25/25 - 0s - loss: 0.2466 - accuracy: 0.8898 - val_loss: 28.6499 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02258: val_loss did not improve from 0.32861\n",
      "Epoch 2259/4000\n",
      "25/25 - 0s - loss: 0.2465 - accuracy: 0.8885 - val_loss: 29.1337 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02259: val_loss did not improve from 0.32861\n",
      "Epoch 2260/4000\n",
      "25/25 - 0s - loss: 0.2419 - accuracy: 0.8911 - val_loss: 28.5828 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02260: val_loss did not improve from 0.32861\n",
      "Epoch 2261/4000\n",
      "25/25 - 0s - loss: 0.2457 - accuracy: 0.8807 - val_loss: 27.7443 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02261: val_loss did not improve from 0.32861\n",
      "Epoch 2262/4000\n",
      "25/25 - 0s - loss: 0.2416 - accuracy: 0.8911 - val_loss: 28.1452 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02262: val_loss did not improve from 0.32861\n",
      "Epoch 2263/4000\n",
      "25/25 - 0s - loss: 0.2420 - accuracy: 0.8820 - val_loss: 26.8644 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02263: val_loss did not improve from 0.32861\n",
      "Epoch 2264/4000\n",
      "25/25 - 0s - loss: 0.2412 - accuracy: 0.8859 - val_loss: 27.3414 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02264: val_loss did not improve from 0.32861\n",
      "Epoch 2265/4000\n",
      "25/25 - 0s - loss: 0.2404 - accuracy: 0.8898 - val_loss: 26.0799 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02265: val_loss did not improve from 0.32861\n",
      "Epoch 2266/4000\n",
      "25/25 - 0s - loss: 0.2401 - accuracy: 0.8872 - val_loss: 26.3112 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02266: val_loss did not improve from 0.32861\n",
      "Epoch 2267/4000\n",
      "25/25 - 0s - loss: 0.2405 - accuracy: 0.8859 - val_loss: 26.0716 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02267: val_loss did not improve from 0.32861\n",
      "Epoch 2268/4000\n",
      "25/25 - 0s - loss: 0.2449 - accuracy: 0.8807 - val_loss: 25.7104 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02268: val_loss did not improve from 0.32861\n",
      "Epoch 2269/4000\n",
      "25/25 - 0s - loss: 0.2444 - accuracy: 0.8911 - val_loss: 28.1977 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02269: val_loss did not improve from 0.32861\n",
      "Epoch 2270/4000\n",
      "25/25 - 0s - loss: 0.2393 - accuracy: 0.8911 - val_loss: 28.1717 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02270: val_loss did not improve from 0.32861\n",
      "Epoch 2271/4000\n",
      "25/25 - 0s - loss: 0.2425 - accuracy: 0.8885 - val_loss: 29.0837 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02271: val_loss did not improve from 0.32861\n",
      "Epoch 2272/4000\n",
      "25/25 - 0s - loss: 0.2434 - accuracy: 0.8859 - val_loss: 27.5924 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02272: val_loss did not improve from 0.32861\n",
      "Epoch 2273/4000\n",
      "25/25 - 0s - loss: 0.2397 - accuracy: 0.8936 - val_loss: 27.3407 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02273: val_loss did not improve from 0.32861\n",
      "Epoch 2274/4000\n",
      "25/25 - 0s - loss: 0.2417 - accuracy: 0.8898 - val_loss: 27.7523 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02274: val_loss did not improve from 0.32861\n",
      "Epoch 2275/4000\n",
      "25/25 - 0s - loss: 0.2415 - accuracy: 0.8911 - val_loss: 27.1648 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02275: val_loss did not improve from 0.32861\n",
      "Epoch 2276/4000\n",
      "25/25 - 0s - loss: 0.2391 - accuracy: 0.8885 - val_loss: 27.3009 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02276: val_loss did not improve from 0.32861\n",
      "Epoch 2277/4000\n",
      "25/25 - 0s - loss: 0.2400 - accuracy: 0.8911 - val_loss: 27.1479 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02277: val_loss did not improve from 0.32861\n",
      "Epoch 2278/4000\n",
      "25/25 - 0s - loss: 0.2383 - accuracy: 0.8911 - val_loss: 26.3902 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02278: val_loss did not improve from 0.32861\n",
      "Epoch 2279/4000\n",
      "25/25 - 0s - loss: 0.2474 - accuracy: 0.8846 - val_loss: 27.0019 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02279: val_loss did not improve from 0.32861\n",
      "Epoch 2280/4000\n",
      "25/25 - 0s - loss: 0.2390 - accuracy: 0.8898 - val_loss: 27.2680 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02280: val_loss did not improve from 0.32861\n",
      "Epoch 2281/4000\n",
      "25/25 - 0s - loss: 0.2399 - accuracy: 0.8911 - val_loss: 27.5989 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02281: val_loss did not improve from 0.32861\n",
      "Epoch 2282/4000\n",
      "25/25 - 0s - loss: 0.2409 - accuracy: 0.8859 - val_loss: 27.4571 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02282: val_loss did not improve from 0.32861\n",
      "Epoch 2283/4000\n",
      "25/25 - 0s - loss: 0.2400 - accuracy: 0.8820 - val_loss: 27.7565 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02283: val_loss did not improve from 0.32861\n",
      "Epoch 2284/4000\n",
      "25/25 - 0s - loss: 0.2407 - accuracy: 0.8872 - val_loss: 28.7559 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02284: val_loss did not improve from 0.32861\n",
      "Epoch 2285/4000\n",
      "25/25 - 0s - loss: 0.2396 - accuracy: 0.8885 - val_loss: 28.2067 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02285: val_loss did not improve from 0.32861\n",
      "Epoch 2286/4000\n",
      "25/25 - 0s - loss: 0.2388 - accuracy: 0.8923 - val_loss: 29.1489 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02286: val_loss did not improve from 0.32861\n",
      "Epoch 2287/4000\n",
      "25/25 - 0s - loss: 0.2403 - accuracy: 0.8872 - val_loss: 29.2401 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02287: val_loss did not improve from 0.32861\n",
      "Epoch 2288/4000\n",
      "25/25 - 0s - loss: 0.2410 - accuracy: 0.8872 - val_loss: 29.0916 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02288: val_loss did not improve from 0.32861\n",
      "Epoch 2289/4000\n",
      "25/25 - 0s - loss: 0.2464 - accuracy: 0.8833 - val_loss: 31.3084 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02289: val_loss did not improve from 0.32861\n",
      "Epoch 2290/4000\n",
      "25/25 - 0s - loss: 0.2651 - accuracy: 0.8807 - val_loss: 21.9094 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02290: val_loss did not improve from 0.32861\n",
      "Epoch 2291/4000\n",
      "25/25 - 0s - loss: 0.2629 - accuracy: 0.8833 - val_loss: 23.7127 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02291: val_loss did not improve from 0.32861\n",
      "Epoch 2292/4000\n",
      "25/25 - 0s - loss: 0.2588 - accuracy: 0.8846 - val_loss: 23.6657 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02292: val_loss did not improve from 0.32861\n",
      "Epoch 2293/4000\n",
      "25/25 - 0s - loss: 0.2467 - accuracy: 0.8833 - val_loss: 23.9522 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02293: val_loss did not improve from 0.32861\n",
      "Epoch 2294/4000\n",
      "25/25 - 0s - loss: 0.2423 - accuracy: 0.8846 - val_loss: 23.3832 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02294: val_loss did not improve from 0.32861\n",
      "Epoch 2295/4000\n",
      "25/25 - 0s - loss: 0.2733 - accuracy: 0.8599 - val_loss: 26.0470 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02295: val_loss did not improve from 0.32861\n",
      "Epoch 2296/4000\n",
      "25/25 - 0s - loss: 0.2497 - accuracy: 0.8936 - val_loss: 25.6590 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02296: val_loss did not improve from 0.32861\n",
      "Epoch 2297/4000\n",
      "25/25 - 0s - loss: 0.2449 - accuracy: 0.8898 - val_loss: 25.6701 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02297: val_loss did not improve from 0.32861\n",
      "Epoch 2298/4000\n",
      "25/25 - 0s - loss: 0.2414 - accuracy: 0.8872 - val_loss: 25.1818 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02298: val_loss did not improve from 0.32861\n",
      "Epoch 2299/4000\n",
      "25/25 - 0s - loss: 0.2403 - accuracy: 0.8898 - val_loss: 25.2232 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02299: val_loss did not improve from 0.32861\n",
      "Epoch 2300/4000\n",
      "25/25 - 0s - loss: 0.2421 - accuracy: 0.8885 - val_loss: 24.7047 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02300: val_loss did not improve from 0.32861\n",
      "Epoch 2301/4000\n",
      "25/25 - 0s - loss: 0.2404 - accuracy: 0.8911 - val_loss: 24.4782 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02301: val_loss did not improve from 0.32861\n",
      "Epoch 2302/4000\n",
      "25/25 - 0s - loss: 0.2414 - accuracy: 0.8872 - val_loss: 25.3188 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02302: val_loss did not improve from 0.32861\n",
      "Epoch 2303/4000\n",
      "25/25 - 0s - loss: 0.2375 - accuracy: 0.8846 - val_loss: 26.8671 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02303: val_loss did not improve from 0.32861\n",
      "Epoch 2304/4000\n",
      "25/25 - 0s - loss: 0.2441 - accuracy: 0.8729 - val_loss: 26.3174 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02304: val_loss did not improve from 0.32861\n",
      "Epoch 2305/4000\n",
      "25/25 - 0s - loss: 0.2373 - accuracy: 0.8898 - val_loss: 26.9626 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02305: val_loss did not improve from 0.32861\n",
      "Epoch 2306/4000\n",
      "25/25 - 0s - loss: 0.2371 - accuracy: 0.8872 - val_loss: 26.5249 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02306: val_loss did not improve from 0.32861\n",
      "Epoch 2307/4000\n",
      "25/25 - 0s - loss: 0.2381 - accuracy: 0.8911 - val_loss: 26.4446 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02307: val_loss did not improve from 0.32861\n",
      "Epoch 2308/4000\n",
      "25/25 - 0s - loss: 0.2348 - accuracy: 0.8911 - val_loss: 26.0162 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02308: val_loss did not improve from 0.32861\n",
      "Epoch 2309/4000\n",
      "25/25 - 0s - loss: 0.2352 - accuracy: 0.8859 - val_loss: 26.2006 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02309: val_loss did not improve from 0.32861\n",
      "Epoch 2310/4000\n",
      "25/25 - 0s - loss: 0.2344 - accuracy: 0.8898 - val_loss: 26.6617 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02310: val_loss did not improve from 0.32861\n",
      "Epoch 2311/4000\n",
      "25/25 - 0s - loss: 0.2461 - accuracy: 0.8781 - val_loss: 26.1035 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02311: val_loss did not improve from 0.32861\n",
      "Epoch 2312/4000\n",
      "25/25 - 0s - loss: 0.2383 - accuracy: 0.8872 - val_loss: 27.6272 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02312: val_loss did not improve from 0.32861\n",
      "Epoch 2313/4000\n",
      "25/25 - 0s - loss: 0.2402 - accuracy: 0.8794 - val_loss: 26.6453 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02313: val_loss did not improve from 0.32861\n",
      "Epoch 2314/4000\n",
      "25/25 - 0s - loss: 0.2367 - accuracy: 0.8846 - val_loss: 26.1607 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02314: val_loss did not improve from 0.32861\n",
      "Epoch 2315/4000\n",
      "25/25 - 0s - loss: 0.2565 - accuracy: 0.8807 - val_loss: 26.2891 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02315: val_loss did not improve from 0.32861\n",
      "Epoch 2316/4000\n",
      "25/25 - 0s - loss: 0.2412 - accuracy: 0.8859 - val_loss: 26.9613 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02316: val_loss did not improve from 0.32861\n",
      "Epoch 2317/4000\n",
      "25/25 - 0s - loss: 0.2448 - accuracy: 0.8846 - val_loss: 30.9808 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02317: val_loss did not improve from 0.32861\n",
      "Epoch 2318/4000\n",
      "25/25 - 0s - loss: 0.2461 - accuracy: 0.8859 - val_loss: 31.0759 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02318: val_loss did not improve from 0.32861\n",
      "Epoch 2319/4000\n",
      "25/25 - 0s - loss: 0.2369 - accuracy: 0.8885 - val_loss: 29.4857 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02319: val_loss did not improve from 0.32861\n",
      "Epoch 2320/4000\n",
      "25/25 - 0s - loss: 0.2508 - accuracy: 0.8885 - val_loss: 28.9448 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02320: val_loss did not improve from 0.32861\n",
      "Epoch 2321/4000\n",
      "25/25 - 0s - loss: 0.2399 - accuracy: 0.8859 - val_loss: 27.8793 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02321: val_loss did not improve from 0.32861\n",
      "Epoch 2322/4000\n",
      "25/25 - 0s - loss: 0.2402 - accuracy: 0.8923 - val_loss: 28.6870 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02322: val_loss did not improve from 0.32861\n",
      "Epoch 2323/4000\n",
      "25/25 - 0s - loss: 0.2407 - accuracy: 0.8807 - val_loss: 27.9439 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02323: val_loss did not improve from 0.32861\n",
      "Epoch 2324/4000\n",
      "25/25 - 0s - loss: 0.2359 - accuracy: 0.8911 - val_loss: 28.5938 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02324: val_loss did not improve from 0.32861\n",
      "Epoch 2325/4000\n",
      "25/25 - 0s - loss: 0.2378 - accuracy: 0.8859 - val_loss: 29.4602 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02325: val_loss did not improve from 0.32861\n",
      "Epoch 2326/4000\n",
      "25/25 - 0s - loss: 0.2368 - accuracy: 0.8885 - val_loss: 28.5459 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02326: val_loss did not improve from 0.32861\n",
      "Epoch 2327/4000\n",
      "25/25 - 0s - loss: 0.2376 - accuracy: 0.8872 - val_loss: 29.2355 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02327: val_loss did not improve from 0.32861\n",
      "Epoch 2328/4000\n",
      "25/25 - 0s - loss: 0.2399 - accuracy: 0.8820 - val_loss: 27.7902 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02328: val_loss did not improve from 0.32861\n",
      "Epoch 2329/4000\n",
      "25/25 - 0s - loss: 0.2387 - accuracy: 0.8898 - val_loss: 29.0080 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02329: val_loss did not improve from 0.32861\n",
      "Epoch 2330/4000\n",
      "25/25 - 0s - loss: 0.2419 - accuracy: 0.8898 - val_loss: 28.4026 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02330: val_loss did not improve from 0.32861\n",
      "Epoch 2331/4000\n",
      "25/25 - 0s - loss: 0.2373 - accuracy: 0.8936 - val_loss: 27.7878 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02331: val_loss did not improve from 0.32861\n",
      "Epoch 2332/4000\n",
      "25/25 - 0s - loss: 0.2382 - accuracy: 0.8859 - val_loss: 29.1352 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02332: val_loss did not improve from 0.32861\n",
      "Epoch 2333/4000\n",
      "25/25 - 0s - loss: 0.2446 - accuracy: 0.8859 - val_loss: 22.4690 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02333: val_loss did not improve from 0.32861\n",
      "Epoch 2334/4000\n",
      "25/25 - 0s - loss: 0.5014 - accuracy: 0.8405 - val_loss: 5.4719 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02334: val_loss did not improve from 0.32861\n",
      "Epoch 2335/4000\n",
      "25/25 - 0s - loss: 0.6299 - accuracy: 0.8573 - val_loss: 7.7199 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02335: val_loss did not improve from 0.32861\n",
      "Epoch 2336/4000\n",
      "25/25 - 0s - loss: 0.4817 - accuracy: 0.8080 - val_loss: 8.8095 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02336: val_loss did not improve from 0.32861\n",
      "Epoch 2337/4000\n",
      "25/25 - 0s - loss: 0.3981 - accuracy: 0.8262 - val_loss: 9.6638 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02337: val_loss did not improve from 0.32861\n",
      "Epoch 2338/4000\n",
      "25/25 - 0s - loss: 0.3956 - accuracy: 0.8327 - val_loss: 12.1932 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02338: val_loss did not improve from 0.32861\n",
      "Epoch 2339/4000\n",
      "25/25 - 0s - loss: 0.4250 - accuracy: 0.8184 - val_loss: 16.4812 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02339: val_loss did not improve from 0.32861\n",
      "Epoch 2340/4000\n",
      "25/25 - 0s - loss: 0.3344 - accuracy: 0.8547 - val_loss: 17.1940 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02340: val_loss did not improve from 0.32861\n",
      "Epoch 2341/4000\n",
      "25/25 - 0s - loss: 0.2866 - accuracy: 0.8625 - val_loss: 16.1347 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02341: val_loss did not improve from 0.32861\n",
      "Epoch 2342/4000\n",
      "25/25 - 0s - loss: 0.2774 - accuracy: 0.8768 - val_loss: 16.5039 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02342: val_loss did not improve from 0.32861\n",
      "Epoch 2343/4000\n",
      "25/25 - 0s - loss: 0.2785 - accuracy: 0.8638 - val_loss: 16.9069 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02343: val_loss did not improve from 0.32861\n",
      "Epoch 2344/4000\n",
      "25/25 - 0s - loss: 0.2750 - accuracy: 0.8755 - val_loss: 16.9904 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02344: val_loss did not improve from 0.32861\n",
      "Epoch 2345/4000\n",
      "25/25 - 0s - loss: 0.2723 - accuracy: 0.8716 - val_loss: 16.9848 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02345: val_loss did not improve from 0.32861\n",
      "Epoch 2346/4000\n",
      "25/25 - 0s - loss: 0.2773 - accuracy: 0.8716 - val_loss: 17.1631 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02346: val_loss did not improve from 0.32861\n",
      "Epoch 2347/4000\n",
      "25/25 - 0s - loss: 0.2593 - accuracy: 0.8807 - val_loss: 16.9755 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02347: val_loss did not improve from 0.32861\n",
      "Epoch 2348/4000\n",
      "25/25 - 0s - loss: 0.2583 - accuracy: 0.8755 - val_loss: 17.1122 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02348: val_loss did not improve from 0.32861\n",
      "Epoch 2349/4000\n",
      "25/25 - 0s - loss: 0.2580 - accuracy: 0.8729 - val_loss: 17.1182 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02349: val_loss did not improve from 0.32861\n",
      "Epoch 2350/4000\n",
      "25/25 - 0s - loss: 0.2584 - accuracy: 0.8716 - val_loss: 17.2375 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02350: val_loss did not improve from 0.32861\n",
      "Epoch 2351/4000\n",
      "25/25 - 0s - loss: 0.3113 - accuracy: 0.8599 - val_loss: 17.2111 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02351: val_loss did not improve from 0.32861\n",
      "Epoch 2352/4000\n",
      "25/25 - 0s - loss: 0.2637 - accuracy: 0.8781 - val_loss: 17.1683 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02352: val_loss did not improve from 0.32861\n",
      "Epoch 2353/4000\n",
      "25/25 - 0s - loss: 0.2565 - accuracy: 0.8833 - val_loss: 17.0758 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02353: val_loss did not improve from 0.32861\n",
      "Epoch 2354/4000\n",
      "25/25 - 0s - loss: 0.2606 - accuracy: 0.8794 - val_loss: 17.1192 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02354: val_loss did not improve from 0.32861\n",
      "Epoch 2355/4000\n",
      "25/25 - 0s - loss: 0.2540 - accuracy: 0.8820 - val_loss: 17.1816 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02355: val_loss did not improve from 0.32861\n",
      "Epoch 2356/4000\n",
      "25/25 - 0s - loss: 0.2529 - accuracy: 0.8807 - val_loss: 17.4259 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02356: val_loss did not improve from 0.32861\n",
      "Epoch 2357/4000\n",
      "25/25 - 0s - loss: 0.2560 - accuracy: 0.8794 - val_loss: 17.6105 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02357: val_loss did not improve from 0.32861\n",
      "Epoch 2358/4000\n",
      "25/25 - 0s - loss: 0.2536 - accuracy: 0.8794 - val_loss: 17.6059 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02358: val_loss did not improve from 0.32861\n",
      "Epoch 2359/4000\n",
      "25/25 - 0s - loss: 0.2557 - accuracy: 0.8729 - val_loss: 17.7021 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02359: val_loss did not improve from 0.32861\n",
      "Epoch 2360/4000\n",
      "25/25 - 0s - loss: 0.2519 - accuracy: 0.8768 - val_loss: 17.9274 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02360: val_loss did not improve from 0.32861\n",
      "Epoch 2361/4000\n",
      "25/25 - 0s - loss: 0.2501 - accuracy: 0.8872 - val_loss: 20.3348 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02361: val_loss did not improve from 0.32861\n",
      "Epoch 2362/4000\n",
      "25/25 - 0s - loss: 0.2457 - accuracy: 0.8768 - val_loss: 25.4466 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02362: val_loss did not improve from 0.32861\n",
      "Epoch 2363/4000\n",
      "25/25 - 0s - loss: 0.2467 - accuracy: 0.8794 - val_loss: 22.0452 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02363: val_loss did not improve from 0.32861\n",
      "Epoch 2364/4000\n",
      "25/25 - 0s - loss: 0.2483 - accuracy: 0.8716 - val_loss: 21.6738 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02364: val_loss did not improve from 0.32861\n",
      "Epoch 2365/4000\n",
      "25/25 - 0s - loss: 0.2539 - accuracy: 0.8599 - val_loss: 21.8430 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02365: val_loss did not improve from 0.32861\n",
      "Epoch 2366/4000\n",
      "25/25 - 0s - loss: 0.2454 - accuracy: 0.8846 - val_loss: 21.8779 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02366: val_loss did not improve from 0.32861\n",
      "Epoch 2367/4000\n",
      "25/25 - 0s - loss: 0.2412 - accuracy: 0.8794 - val_loss: 21.9087 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02367: val_loss did not improve from 0.32861\n",
      "Epoch 2368/4000\n",
      "25/25 - 0s - loss: 0.2383 - accuracy: 0.8820 - val_loss: 21.8645 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02368: val_loss did not improve from 0.32861\n",
      "Epoch 2369/4000\n",
      "25/25 - 0s - loss: 0.2372 - accuracy: 0.8833 - val_loss: 22.2192 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02369: val_loss did not improve from 0.32861\n",
      "Epoch 2370/4000\n",
      "25/25 - 0s - loss: 0.2363 - accuracy: 0.8820 - val_loss: 22.3550 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02370: val_loss did not improve from 0.32861\n",
      "Epoch 2371/4000\n",
      "25/25 - 0s - loss: 0.2368 - accuracy: 0.8846 - val_loss: 22.4138 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02371: val_loss did not improve from 0.32861\n",
      "Epoch 2372/4000\n",
      "25/25 - 0s - loss: 0.2376 - accuracy: 0.8846 - val_loss: 22.6596 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02372: val_loss did not improve from 0.32861\n",
      "Epoch 2373/4000\n",
      "25/25 - 0s - loss: 0.2368 - accuracy: 0.8820 - val_loss: 22.5618 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02373: val_loss did not improve from 0.32861\n",
      "Epoch 2374/4000\n",
      "25/25 - 0s - loss: 0.2362 - accuracy: 0.8794 - val_loss: 22.6901 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02374: val_loss did not improve from 0.32861\n",
      "Epoch 2375/4000\n",
      "25/25 - 0s - loss: 0.2416 - accuracy: 0.8781 - val_loss: 22.9072 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02375: val_loss did not improve from 0.32861\n",
      "Epoch 2376/4000\n",
      "25/25 - 0s - loss: 0.2385 - accuracy: 0.8768 - val_loss: 22.9486 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02376: val_loss did not improve from 0.32861\n",
      "Epoch 2377/4000\n",
      "25/25 - 0s - loss: 0.2445 - accuracy: 0.8781 - val_loss: 23.3515 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02377: val_loss did not improve from 0.32861\n",
      "Epoch 2378/4000\n",
      "25/25 - 0s - loss: 0.2375 - accuracy: 0.8820 - val_loss: 23.3365 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02378: val_loss did not improve from 0.32861\n",
      "Epoch 2379/4000\n",
      "25/25 - 0s - loss: 0.2369 - accuracy: 0.8833 - val_loss: 23.3219 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02379: val_loss did not improve from 0.32861\n",
      "Epoch 2380/4000\n",
      "25/25 - 0s - loss: 0.2367 - accuracy: 0.8846 - val_loss: 23.2066 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02380: val_loss did not improve from 0.32861\n",
      "Epoch 2381/4000\n",
      "25/25 - 0s - loss: 0.2355 - accuracy: 0.8846 - val_loss: 22.9462 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02381: val_loss did not improve from 0.32861\n",
      "Epoch 2382/4000\n",
      "25/25 - 0s - loss: 0.2392 - accuracy: 0.8768 - val_loss: 23.1020 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02382: val_loss did not improve from 0.32861\n",
      "Epoch 2383/4000\n",
      "25/25 - 0s - loss: 0.2518 - accuracy: 0.8716 - val_loss: 23.6841 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02383: val_loss did not improve from 0.32861\n",
      "Epoch 2384/4000\n",
      "25/25 - 0s - loss: 0.2404 - accuracy: 0.8820 - val_loss: 23.1161 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02384: val_loss did not improve from 0.32861\n",
      "Epoch 2385/4000\n",
      "25/25 - 0s - loss: 0.2375 - accuracy: 0.8833 - val_loss: 22.5074 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02385: val_loss did not improve from 0.32861\n",
      "Epoch 2386/4000\n",
      "25/25 - 0s - loss: 0.2389 - accuracy: 0.8794 - val_loss: 22.4399 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02386: val_loss did not improve from 0.32861\n",
      "Epoch 2387/4000\n",
      "25/25 - 0s - loss: 0.2365 - accuracy: 0.8742 - val_loss: 22.4691 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02387: val_loss did not improve from 0.32861\n",
      "Epoch 2388/4000\n",
      "25/25 - 0s - loss: 0.2613 - accuracy: 0.8742 - val_loss: 23.7704 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02388: val_loss did not improve from 0.32861\n",
      "Epoch 2389/4000\n",
      "25/25 - 0s - loss: 0.2696 - accuracy: 0.8807 - val_loss: 26.5064 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02389: val_loss did not improve from 0.32861\n",
      "Epoch 2390/4000\n",
      "25/25 - 0s - loss: 0.2842 - accuracy: 0.8781 - val_loss: 23.4153 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02390: val_loss did not improve from 0.32861\n",
      "Epoch 2391/4000\n",
      "25/25 - 0s - loss: 0.2487 - accuracy: 0.8703 - val_loss: 23.1920 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02391: val_loss did not improve from 0.32861\n",
      "Epoch 2392/4000\n",
      "25/25 - 0s - loss: 0.2673 - accuracy: 0.8729 - val_loss: 27.1556 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02392: val_loss did not improve from 0.32861\n",
      "Epoch 2393/4000\n",
      "25/25 - 0s - loss: 0.2752 - accuracy: 0.8612 - val_loss: 28.6873 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02393: val_loss did not improve from 0.32861\n",
      "Epoch 2394/4000\n",
      "25/25 - 0s - loss: 0.2698 - accuracy: 0.8690 - val_loss: 30.3930 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02394: val_loss did not improve from 0.32861\n",
      "Epoch 2395/4000\n",
      "25/25 - 0s - loss: 0.2653 - accuracy: 0.8703 - val_loss: 29.8313 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02395: val_loss did not improve from 0.32861\n",
      "Epoch 2396/4000\n",
      "25/25 - 0s - loss: 0.2650 - accuracy: 0.8729 - val_loss: 28.2438 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02396: val_loss did not improve from 0.32861\n",
      "Epoch 2397/4000\n",
      "25/25 - 0s - loss: 0.2687 - accuracy: 0.8625 - val_loss: 27.5604 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02397: val_loss did not improve from 0.32861\n",
      "Epoch 2398/4000\n",
      "25/25 - 0s - loss: 0.2705 - accuracy: 0.8664 - val_loss: 27.0160 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02398: val_loss did not improve from 0.32861\n",
      "Epoch 2399/4000\n",
      "25/25 - 0s - loss: 0.2659 - accuracy: 0.8690 - val_loss: 26.8945 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02399: val_loss did not improve from 0.32861\n",
      "Epoch 2400/4000\n",
      "25/25 - 0s - loss: 0.2691 - accuracy: 0.8599 - val_loss: 27.4694 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02400: val_loss did not improve from 0.32861\n",
      "Epoch 2401/4000\n",
      "25/25 - 0s - loss: 0.2700 - accuracy: 0.8612 - val_loss: 27.4161 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02401: val_loss did not improve from 0.32861\n",
      "Epoch 2402/4000\n",
      "25/25 - 0s - loss: 0.2700 - accuracy: 0.8625 - val_loss: 27.6063 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02402: val_loss did not improve from 0.32861\n",
      "Epoch 2403/4000\n",
      "25/25 - 0s - loss: 0.2658 - accuracy: 0.8690 - val_loss: 27.6457 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02403: val_loss did not improve from 0.32861\n",
      "Epoch 2404/4000\n",
      "25/25 - 0s - loss: 0.2666 - accuracy: 0.8716 - val_loss: 27.8162 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02404: val_loss did not improve from 0.32861\n",
      "Epoch 2405/4000\n",
      "25/25 - 0s - loss: 0.2801 - accuracy: 0.8547 - val_loss: 27.6217 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02405: val_loss did not improve from 0.32861\n",
      "Epoch 2406/4000\n",
      "25/25 - 0s - loss: 0.2642 - accuracy: 0.8638 - val_loss: 28.1586 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02406: val_loss did not improve from 0.32861\n",
      "Epoch 2407/4000\n",
      "25/25 - 0s - loss: 0.2863 - accuracy: 0.8612 - val_loss: 27.2789 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02407: val_loss did not improve from 0.32861\n",
      "Epoch 2408/4000\n",
      "25/25 - 0s - loss: 0.2901 - accuracy: 0.8418 - val_loss: 26.2346 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02408: val_loss did not improve from 0.32861\n",
      "Epoch 2409/4000\n",
      "25/25 - 0s - loss: 0.2710 - accuracy: 0.8547 - val_loss: 26.7995 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02409: val_loss did not improve from 0.32861\n",
      "Epoch 2410/4000\n",
      "25/25 - 0s - loss: 0.2639 - accuracy: 0.8586 - val_loss: 28.1025 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02410: val_loss did not improve from 0.32861\n",
      "Epoch 2411/4000\n",
      "25/25 - 0s - loss: 0.2608 - accuracy: 0.8690 - val_loss: 29.0821 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02411: val_loss did not improve from 0.32861\n",
      "Epoch 2412/4000\n",
      "25/25 - 0s - loss: 0.2579 - accuracy: 0.8703 - val_loss: 29.2981 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02412: val_loss did not improve from 0.32861\n",
      "Epoch 2413/4000\n",
      "25/25 - 0s - loss: 0.2577 - accuracy: 0.8729 - val_loss: 27.9812 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02413: val_loss did not improve from 0.32861\n",
      "Epoch 2414/4000\n",
      "25/25 - 0s - loss: 0.2594 - accuracy: 0.8716 - val_loss: 27.4911 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02414: val_loss did not improve from 0.32861\n",
      "Epoch 2415/4000\n",
      "25/25 - 0s - loss: 0.2719 - accuracy: 0.8560 - val_loss: 27.5537 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02415: val_loss did not improve from 0.32861\n",
      "Epoch 2416/4000\n",
      "25/25 - 0s - loss: 0.2653 - accuracy: 0.8651 - val_loss: 27.9503 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02416: val_loss did not improve from 0.32861\n",
      "Epoch 2417/4000\n",
      "25/25 - 0s - loss: 0.2610 - accuracy: 0.8703 - val_loss: 28.1564 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02417: val_loss did not improve from 0.32861\n",
      "Epoch 2418/4000\n",
      "25/25 - 0s - loss: 0.2577 - accuracy: 0.8768 - val_loss: 27.9725 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02418: val_loss did not improve from 0.32861\n",
      "Epoch 2419/4000\n",
      "25/25 - 0s - loss: 0.2588 - accuracy: 0.8677 - val_loss: 27.7112 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02419: val_loss did not improve from 0.32861\n",
      "Epoch 2420/4000\n",
      "25/25 - 0s - loss: 0.2575 - accuracy: 0.8716 - val_loss: 27.5952 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02420: val_loss did not improve from 0.32861\n",
      "Epoch 2421/4000\n",
      "25/25 - 0s - loss: 0.2631 - accuracy: 0.8664 - val_loss: 27.9469 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02421: val_loss did not improve from 0.32861\n",
      "Epoch 2422/4000\n",
      "25/25 - 0s - loss: 0.2838 - accuracy: 0.8431 - val_loss: 27.5070 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02422: val_loss did not improve from 0.32861\n",
      "Epoch 2423/4000\n",
      "25/25 - 0s - loss: 0.2673 - accuracy: 0.8703 - val_loss: 29.3698 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02423: val_loss did not improve from 0.32861\n",
      "Epoch 2424/4000\n",
      "25/25 - 0s - loss: 0.3527 - accuracy: 0.8625 - val_loss: 13.0833 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02424: val_loss did not improve from 0.32861\n",
      "Epoch 2425/4000\n",
      "25/25 - 0s - loss: 0.3700 - accuracy: 0.8612 - val_loss: 11.1668 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02425: val_loss did not improve from 0.32861\n",
      "Epoch 2426/4000\n",
      "25/25 - 0s - loss: 0.2783 - accuracy: 0.8599 - val_loss: 14.5247 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02426: val_loss did not improve from 0.32861\n",
      "Epoch 2427/4000\n",
      "25/25 - 0s - loss: 0.2715 - accuracy: 0.8729 - val_loss: 18.9663 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02427: val_loss did not improve from 0.32861\n",
      "Epoch 2428/4000\n",
      "25/25 - 0s - loss: 0.2679 - accuracy: 0.8690 - val_loss: 20.6403 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02428: val_loss did not improve from 0.32861\n",
      "Epoch 2429/4000\n",
      "25/25 - 0s - loss: 0.2662 - accuracy: 0.8729 - val_loss: 23.5846 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02429: val_loss did not improve from 0.32861\n",
      "Epoch 2430/4000\n",
      "25/25 - 0s - loss: 0.2711 - accuracy: 0.8690 - val_loss: 15.2935 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02430: val_loss did not improve from 0.32861\n",
      "Epoch 2431/4000\n",
      "25/25 - 0s - loss: 0.2656 - accuracy: 0.8729 - val_loss: 18.9089 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02431: val_loss did not improve from 0.32861\n",
      "Epoch 2432/4000\n",
      "25/25 - 0s - loss: 0.2639 - accuracy: 0.8703 - val_loss: 19.4919 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02432: val_loss did not improve from 0.32861\n",
      "Epoch 2433/4000\n",
      "25/25 - 0s - loss: 0.2637 - accuracy: 0.8703 - val_loss: 19.7567 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02433: val_loss did not improve from 0.32861\n",
      "Epoch 2434/4000\n",
      "25/25 - 0s - loss: 0.2647 - accuracy: 0.8664 - val_loss: 19.8799 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02434: val_loss did not improve from 0.32861\n",
      "Epoch 2435/4000\n",
      "25/25 - 0s - loss: 0.2746 - accuracy: 0.8716 - val_loss: 17.6868 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02435: val_loss did not improve from 0.32861\n",
      "Epoch 2436/4000\n",
      "25/25 - 0s - loss: 0.2694 - accuracy: 0.8677 - val_loss: 17.8124 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02436: val_loss did not improve from 0.32861\n",
      "Epoch 2437/4000\n",
      "25/25 - 0s - loss: 0.2695 - accuracy: 0.8677 - val_loss: 19.0452 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02437: val_loss did not improve from 0.32861\n",
      "Epoch 2438/4000\n",
      "25/25 - 0s - loss: 0.2639 - accuracy: 0.8690 - val_loss: 19.4553 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02438: val_loss did not improve from 0.32861\n",
      "Epoch 2439/4000\n",
      "25/25 - 0s - loss: 0.2698 - accuracy: 0.8703 - val_loss: 19.6261 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02439: val_loss did not improve from 0.32861\n",
      "Epoch 2440/4000\n",
      "25/25 - 0s - loss: 0.2745 - accuracy: 0.8651 - val_loss: 13.9141 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02440: val_loss did not improve from 0.32861\n",
      "Epoch 2441/4000\n",
      "25/25 - 0s - loss: 0.2627 - accuracy: 0.8612 - val_loss: 13.6629 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02441: val_loss did not improve from 0.32861\n",
      "Epoch 2442/4000\n",
      "25/25 - 0s - loss: 0.2621 - accuracy: 0.8664 - val_loss: 13.1977 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 02442: val_loss did not improve from 0.32861\n",
      "Epoch 2443/4000\n",
      "25/25 - 0s - loss: 0.2582 - accuracy: 0.8703 - val_loss: 11.0859 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02443: val_loss did not improve from 0.32861\n",
      "Epoch 2444/4000\n",
      "25/25 - 0s - loss: 0.2614 - accuracy: 0.8664 - val_loss: 12.0366 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02444: val_loss did not improve from 0.32861\n",
      "Epoch 2445/4000\n",
      "25/25 - 0s - loss: 0.2595 - accuracy: 0.8703 - val_loss: 12.5133 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02445: val_loss did not improve from 0.32861\n",
      "Epoch 2446/4000\n",
      "25/25 - 0s - loss: 0.2571 - accuracy: 0.8716 - val_loss: 14.1398 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02446: val_loss did not improve from 0.32861\n",
      "Epoch 2447/4000\n",
      "25/25 - 0s - loss: 0.2654 - accuracy: 0.8573 - val_loss: 14.8509 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02447: val_loss did not improve from 0.32861\n",
      "Epoch 2448/4000\n",
      "25/25 - 0s - loss: 0.2956 - accuracy: 0.8573 - val_loss: 18.7223 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02448: val_loss did not improve from 0.32861\n",
      "Epoch 2449/4000\n",
      "25/25 - 0s - loss: 0.2921 - accuracy: 0.8677 - val_loss: 39.4131 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02449: val_loss did not improve from 0.32861\n",
      "Epoch 2450/4000\n",
      "25/25 - 0s - loss: 0.2914 - accuracy: 0.8664 - val_loss: 33.0242 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02450: val_loss did not improve from 0.32861\n",
      "Epoch 2451/4000\n",
      "25/25 - 0s - loss: 0.2597 - accuracy: 0.8690 - val_loss: 35.0281 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02451: val_loss did not improve from 0.32861\n",
      "Epoch 2452/4000\n",
      "25/25 - 0s - loss: 0.2576 - accuracy: 0.8690 - val_loss: 34.6974 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02452: val_loss did not improve from 0.32861\n",
      "Epoch 2453/4000\n",
      "25/25 - 0s - loss: 0.2535 - accuracy: 0.8768 - val_loss: 35.3873 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02453: val_loss did not improve from 0.32861\n",
      "Epoch 2454/4000\n",
      "25/25 - 0s - loss: 0.2531 - accuracy: 0.8768 - val_loss: 34.6557 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02454: val_loss did not improve from 0.32861\n",
      "Epoch 2455/4000\n",
      "25/25 - 0s - loss: 0.2543 - accuracy: 0.8794 - val_loss: 34.9417 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02455: val_loss did not improve from 0.32861\n",
      "Epoch 2456/4000\n",
      "25/25 - 0s - loss: 0.2641 - accuracy: 0.8651 - val_loss: 34.0681 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02456: val_loss did not improve from 0.32861\n",
      "Epoch 2457/4000\n",
      "25/25 - 1s - loss: 0.2579 - accuracy: 0.8768 - val_loss: 34.8968 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02457: val_loss did not improve from 0.32861\n",
      "Epoch 2458/4000\n",
      "25/25 - 0s - loss: 0.2567 - accuracy: 0.8781 - val_loss: 34.6057 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02458: val_loss did not improve from 0.32861\n",
      "Epoch 2459/4000\n",
      "25/25 - 0s - loss: 0.2598 - accuracy: 0.8703 - val_loss: 36.9884 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02459: val_loss did not improve from 0.32861\n",
      "Epoch 2460/4000\n",
      "25/25 - 0s - loss: 0.2567 - accuracy: 0.8677 - val_loss: 36.2679 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02460: val_loss did not improve from 0.32861\n",
      "Epoch 2461/4000\n",
      "25/25 - 0s - loss: 0.2550 - accuracy: 0.8677 - val_loss: 38.3237 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02461: val_loss did not improve from 0.32861\n",
      "Epoch 2462/4000\n",
      "25/25 - 0s - loss: 0.2530 - accuracy: 0.8742 - val_loss: 38.8084 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02462: val_loss did not improve from 0.32861\n",
      "Epoch 2463/4000\n",
      "25/25 - 0s - loss: 0.2535 - accuracy: 0.8729 - val_loss: 37.8028 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02463: val_loss did not improve from 0.32861\n",
      "Epoch 2464/4000\n",
      "25/25 - 0s - loss: 0.2509 - accuracy: 0.8755 - val_loss: 38.6206 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02464: val_loss did not improve from 0.32861\n",
      "Epoch 2465/4000\n",
      "25/25 - 0s - loss: 0.2599 - accuracy: 0.8690 - val_loss: 39.9234 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02465: val_loss did not improve from 0.32861\n",
      "Epoch 2466/4000\n",
      "25/25 - 0s - loss: 0.2540 - accuracy: 0.8755 - val_loss: 39.7308 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02466: val_loss did not improve from 0.32861\n",
      "Epoch 2467/4000\n",
      "25/25 - 0s - loss: 0.2551 - accuracy: 0.8703 - val_loss: 40.1343 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02467: val_loss did not improve from 0.32861\n",
      "Epoch 2468/4000\n",
      "25/25 - 0s - loss: 0.2603 - accuracy: 0.8703 - val_loss: 41.1432 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02468: val_loss did not improve from 0.32861\n",
      "Epoch 2469/4000\n",
      "25/25 - 0s - loss: 0.2639 - accuracy: 0.8599 - val_loss: 39.7788 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02469: val_loss did not improve from 0.32861\n",
      "Epoch 2470/4000\n",
      "25/25 - 0s - loss: 0.2763 - accuracy: 0.8599 - val_loss: 45.2934 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02470: val_loss did not improve from 0.32861\n",
      "Epoch 2471/4000\n",
      "25/25 - 0s - loss: 0.2779 - accuracy: 0.8573 - val_loss: 36.0522 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02471: val_loss did not improve from 0.32861\n",
      "Epoch 2472/4000\n",
      "25/25 - 0s - loss: 0.2717 - accuracy: 0.8625 - val_loss: 37.8409 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02472: val_loss did not improve from 0.32861\n",
      "Epoch 2473/4000\n",
      "25/25 - 0s - loss: 0.2642 - accuracy: 0.8755 - val_loss: 38.0468 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02473: val_loss did not improve from 0.32861\n",
      "Epoch 2474/4000\n",
      "25/25 - 0s - loss: 0.2592 - accuracy: 0.8729 - val_loss: 39.3852 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02474: val_loss did not improve from 0.32861\n",
      "Epoch 2475/4000\n",
      "25/25 - 0s - loss: 0.2618 - accuracy: 0.8690 - val_loss: 38.2548 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02475: val_loss did not improve from 0.32861\n",
      "Epoch 2476/4000\n",
      "25/25 - 0s - loss: 0.2698 - accuracy: 0.8664 - val_loss: 37.1475 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02476: val_loss did not improve from 0.32861\n",
      "Epoch 2477/4000\n",
      "25/25 - 0s - loss: 0.2552 - accuracy: 0.8768 - val_loss: 39.1346 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02477: val_loss did not improve from 0.32861\n",
      "Epoch 2478/4000\n",
      "25/25 - 0s - loss: 0.2550 - accuracy: 0.8677 - val_loss: 39.9114 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02478: val_loss did not improve from 0.32861\n",
      "Epoch 2479/4000\n",
      "25/25 - 0s - loss: 0.2597 - accuracy: 0.8716 - val_loss: 40.5726 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02479: val_loss did not improve from 0.32861\n",
      "Epoch 2480/4000\n",
      "25/25 - 0s - loss: 0.2692 - accuracy: 0.8794 - val_loss: 38.1985 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02480: val_loss did not improve from 0.32861\n",
      "Epoch 2481/4000\n",
      "25/25 - 0s - loss: 0.2590 - accuracy: 0.8729 - val_loss: 46.9362 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02481: val_loss did not improve from 0.32861\n",
      "Epoch 2482/4000\n",
      "25/25 - 0s - loss: 0.4189 - accuracy: 0.8677 - val_loss: 15.8183 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02482: val_loss did not improve from 0.32861\n",
      "Epoch 2483/4000\n",
      "25/25 - 0s - loss: 0.5776 - accuracy: 0.8197 - val_loss: 12.9441 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02483: val_loss did not improve from 0.32861\n",
      "Epoch 2484/4000\n",
      "25/25 - 0s - loss: 0.5626 - accuracy: 0.8405 - val_loss: 15.0163 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02484: val_loss did not improve from 0.32861\n",
      "Epoch 2485/4000\n",
      "25/25 - 0s - loss: 0.4176 - accuracy: 0.8210 - val_loss: 5.6252 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02485: val_loss did not improve from 0.32861\n",
      "Epoch 2486/4000\n",
      "25/25 - 0s - loss: 0.3760 - accuracy: 0.8418 - val_loss: 6.3010 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02486: val_loss did not improve from 0.32861\n",
      "Epoch 2487/4000\n",
      "25/25 - 0s - loss: 0.3170 - accuracy: 0.8521 - val_loss: 6.9060 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02487: val_loss did not improve from 0.32861\n",
      "Epoch 2488/4000\n",
      "25/25 - 0s - loss: 0.3101 - accuracy: 0.8547 - val_loss: 6.8827 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02488: val_loss did not improve from 0.32861\n",
      "Epoch 2489/4000\n",
      "25/25 - 0s - loss: 0.2999 - accuracy: 0.8703 - val_loss: 6.8736 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02489: val_loss did not improve from 0.32861\n",
      "Epoch 2490/4000\n",
      "25/25 - 0s - loss: 0.3060 - accuracy: 0.8677 - val_loss: 6.6784 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02490: val_loss did not improve from 0.32861\n",
      "Epoch 2491/4000\n",
      "25/25 - 0s - loss: 0.2938 - accuracy: 0.8677 - val_loss: 6.3387 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 02491: val_loss did not improve from 0.32861\n",
      "Epoch 2492/4000\n",
      "25/25 - 0s - loss: 0.3207 - accuracy: 0.8664 - val_loss: 5.7151 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02492: val_loss did not improve from 0.32861\n",
      "Epoch 2493/4000\n",
      "25/25 - 0s - loss: 0.2729 - accuracy: 0.8846 - val_loss: 6.1872 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02493: val_loss did not improve from 0.32861\n",
      "Epoch 2494/4000\n",
      "25/25 - 0s - loss: 0.2683 - accuracy: 0.8859 - val_loss: 6.6369 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02494: val_loss did not improve from 0.32861\n",
      "Epoch 2495/4000\n",
      "25/25 - 0s - loss: 0.2662 - accuracy: 0.8781 - val_loss: 6.6805 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02495: val_loss did not improve from 0.32861\n",
      "Epoch 2496/4000\n",
      "25/25 - 0s - loss: 0.2592 - accuracy: 0.8846 - val_loss: 7.1072 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02496: val_loss did not improve from 0.32861\n",
      "Epoch 2497/4000\n",
      "25/25 - 0s - loss: 0.2523 - accuracy: 0.8949 - val_loss: 7.0755 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02497: val_loss did not improve from 0.32861\n",
      "Epoch 2498/4000\n",
      "25/25 - 0s - loss: 0.2588 - accuracy: 0.8716 - val_loss: 6.9599 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02498: val_loss did not improve from 0.32861\n",
      "Epoch 2499/4000\n",
      "25/25 - 0s - loss: 0.2512 - accuracy: 0.8885 - val_loss: 7.0248 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02499: val_loss did not improve from 0.32861\n",
      "Epoch 2500/4000\n",
      "25/25 - 0s - loss: 0.2539 - accuracy: 0.8794 - val_loss: 7.3214 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02500: val_loss did not improve from 0.32861\n",
      "Epoch 2501/4000\n",
      "25/25 - 0s - loss: 0.2437 - accuracy: 0.8911 - val_loss: 7.4379 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02501: val_loss did not improve from 0.32861\n",
      "Epoch 2502/4000\n",
      "25/25 - 0s - loss: 0.2396 - accuracy: 0.8962 - val_loss: 7.4883 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02502: val_loss did not improve from 0.32861\n",
      "Epoch 2503/4000\n",
      "25/25 - 0s - loss: 0.2411 - accuracy: 0.8949 - val_loss: 7.6046 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02503: val_loss did not improve from 0.32861\n",
      "Epoch 2504/4000\n",
      "25/25 - 0s - loss: 0.2391 - accuracy: 0.8962 - val_loss: 7.5639 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02504: val_loss did not improve from 0.32861\n",
      "Epoch 2505/4000\n",
      "25/25 - 0s - loss: 0.2387 - accuracy: 0.8949 - val_loss: 7.6689 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02505: val_loss did not improve from 0.32861\n",
      "Epoch 2506/4000\n",
      "25/25 - 0s - loss: 0.2414 - accuracy: 0.8885 - val_loss: 7.6452 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02506: val_loss did not improve from 0.32861\n",
      "Epoch 2507/4000\n",
      "25/25 - 0s - loss: 0.2397 - accuracy: 0.8936 - val_loss: 7.8619 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02507: val_loss did not improve from 0.32861\n",
      "Epoch 2508/4000\n",
      "25/25 - 0s - loss: 0.2429 - accuracy: 0.8936 - val_loss: 7.8643 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02508: val_loss did not improve from 0.32861\n",
      "Epoch 2509/4000\n",
      "25/25 - 0s - loss: 0.2680 - accuracy: 0.8638 - val_loss: 7.7458 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02509: val_loss did not improve from 0.32861\n",
      "Epoch 2510/4000\n",
      "25/25 - 0s - loss: 0.2404 - accuracy: 0.8936 - val_loss: 8.0178 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02510: val_loss did not improve from 0.32861\n",
      "Epoch 2511/4000\n",
      "25/25 - 0s - loss: 0.2364 - accuracy: 0.8988 - val_loss: 8.1768 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02511: val_loss did not improve from 0.32861\n",
      "Epoch 2512/4000\n",
      "25/25 - 0s - loss: 0.2387 - accuracy: 0.8962 - val_loss: 7.6921 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02512: val_loss did not improve from 0.32861\n",
      "Epoch 2513/4000\n",
      "25/25 - 0s - loss: 0.2357 - accuracy: 0.8962 - val_loss: 7.5915 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02513: val_loss did not improve from 0.32861\n",
      "Epoch 2514/4000\n",
      "25/25 - 0s - loss: 0.2352 - accuracy: 0.8988 - val_loss: 7.7083 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02514: val_loss did not improve from 0.32861\n",
      "Epoch 2515/4000\n",
      "25/25 - 0s - loss: 0.2395 - accuracy: 0.8911 - val_loss: 8.0046 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02515: val_loss did not improve from 0.32861\n",
      "Epoch 2516/4000\n",
      "25/25 - 0s - loss: 0.2464 - accuracy: 0.8859 - val_loss: 7.7831 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02516: val_loss did not improve from 0.32861\n",
      "Epoch 2517/4000\n",
      "25/25 - 0s - loss: 0.2399 - accuracy: 0.8898 - val_loss: 7.7336 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02517: val_loss did not improve from 0.32861\n",
      "Epoch 2518/4000\n",
      "25/25 - 0s - loss: 0.2421 - accuracy: 0.8911 - val_loss: 7.7993 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02518: val_loss did not improve from 0.32861\n",
      "Epoch 2519/4000\n",
      "25/25 - 0s - loss: 0.2393 - accuracy: 0.8923 - val_loss: 8.8092 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02519: val_loss did not improve from 0.32861\n",
      "Epoch 2520/4000\n",
      "25/25 - 0s - loss: 0.3142 - accuracy: 0.8781 - val_loss: 8.8038 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02520: val_loss did not improve from 0.32861\n",
      "Epoch 2521/4000\n",
      "25/25 - 0s - loss: 0.2361 - accuracy: 0.8975 - val_loss: 8.3830 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02521: val_loss did not improve from 0.32861\n",
      "Epoch 2522/4000\n",
      "25/25 - 0s - loss: 0.2366 - accuracy: 0.8936 - val_loss: 8.4129 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02522: val_loss did not improve from 0.32861\n",
      "Epoch 2523/4000\n",
      "25/25 - 0s - loss: 0.2319 - accuracy: 0.8898 - val_loss: 8.6944 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02523: val_loss did not improve from 0.32861\n",
      "Epoch 2524/4000\n",
      "25/25 - 0s - loss: 0.2377 - accuracy: 0.8898 - val_loss: 8.6843 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02524: val_loss did not improve from 0.32861\n",
      "Epoch 2525/4000\n",
      "25/25 - 0s - loss: 0.2389 - accuracy: 0.8923 - val_loss: 8.7007 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02525: val_loss did not improve from 0.32861\n",
      "Epoch 2526/4000\n",
      "25/25 - 0s - loss: 0.2344 - accuracy: 0.8936 - val_loss: 8.7600 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02526: val_loss did not improve from 0.32861\n",
      "Epoch 2527/4000\n",
      "25/25 - 0s - loss: 0.2315 - accuracy: 0.8949 - val_loss: 8.9355 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02527: val_loss did not improve from 0.32861\n",
      "Epoch 2528/4000\n",
      "25/25 - 0s - loss: 0.2310 - accuracy: 0.8923 - val_loss: 9.0313 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02528: val_loss did not improve from 0.32861\n",
      "Epoch 2529/4000\n",
      "25/25 - 0s - loss: 0.2436 - accuracy: 0.8846 - val_loss: 9.2502 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02529: val_loss did not improve from 0.32861\n",
      "Epoch 2530/4000\n",
      "25/25 - 0s - loss: 0.2351 - accuracy: 0.8911 - val_loss: 9.4476 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02530: val_loss did not improve from 0.32861\n",
      "Epoch 2531/4000\n",
      "25/25 - 0s - loss: 0.2377 - accuracy: 0.8898 - val_loss: 9.2367 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02531: val_loss did not improve from 0.32861\n",
      "Epoch 2532/4000\n",
      "25/25 - 0s - loss: 0.2286 - accuracy: 0.8949 - val_loss: 9.2746 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02532: val_loss did not improve from 0.32861\n",
      "Epoch 2533/4000\n",
      "25/25 - 0s - loss: 0.2368 - accuracy: 0.8949 - val_loss: 9.1938 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02533: val_loss did not improve from 0.32861\n",
      "Epoch 2534/4000\n",
      "25/25 - 0s - loss: 0.2310 - accuracy: 0.8923 - val_loss: 9.2915 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02534: val_loss did not improve from 0.32861\n",
      "Epoch 2535/4000\n",
      "25/25 - 0s - loss: 0.2331 - accuracy: 0.8923 - val_loss: 9.1038 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02535: val_loss did not improve from 0.32861\n",
      "Epoch 2536/4000\n",
      "25/25 - 0s - loss: 0.2473 - accuracy: 0.8885 - val_loss: 9.5575 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02536: val_loss did not improve from 0.32861\n",
      "Epoch 2537/4000\n",
      "25/25 - 0s - loss: 0.2648 - accuracy: 0.8794 - val_loss: 11.3727 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02537: val_loss did not improve from 0.32861\n",
      "Epoch 2538/4000\n",
      "25/25 - 0s - loss: 0.5264 - accuracy: 0.8534 - val_loss: 3.4204 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02538: val_loss did not improve from 0.32861\n",
      "Epoch 2539/4000\n",
      "25/25 - 0s - loss: 0.6974 - accuracy: 0.8560 - val_loss: 4.9469 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02539: val_loss did not improve from 0.32861\n",
      "Epoch 2540/4000\n",
      "25/25 - 0s - loss: 0.3634 - accuracy: 0.8638 - val_loss: 6.9567 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02540: val_loss did not improve from 0.32861\n",
      "Epoch 2541/4000\n",
      "25/25 - 0s - loss: 0.3119 - accuracy: 0.8677 - val_loss: 7.6385 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02541: val_loss did not improve from 0.32861\n",
      "Epoch 2542/4000\n",
      "25/25 - 0s - loss: 0.2938 - accuracy: 0.8729 - val_loss: 8.1353 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02542: val_loss did not improve from 0.32861\n",
      "Epoch 2543/4000\n",
      "25/25 - 0s - loss: 0.2795 - accuracy: 0.8716 - val_loss: 8.6788 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02543: val_loss did not improve from 0.32861\n",
      "Epoch 2544/4000\n",
      "25/25 - 0s - loss: 0.2756 - accuracy: 0.8807 - val_loss: 8.5044 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02544: val_loss did not improve from 0.32861\n",
      "Epoch 2545/4000\n",
      "25/25 - 0s - loss: 0.2680 - accuracy: 0.8820 - val_loss: 8.5569 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02545: val_loss did not improve from 0.32861\n",
      "Epoch 2546/4000\n",
      "25/25 - 0s - loss: 0.2776 - accuracy: 0.8716 - val_loss: 8.7010 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02546: val_loss did not improve from 0.32861\n",
      "Epoch 2547/4000\n",
      "25/25 - 0s - loss: 0.2684 - accuracy: 0.8729 - val_loss: 8.6055 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02547: val_loss did not improve from 0.32861\n",
      "Epoch 2548/4000\n",
      "25/25 - 0s - loss: 0.2698 - accuracy: 0.8820 - val_loss: 8.5942 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02548: val_loss did not improve from 0.32861\n",
      "Epoch 2549/4000\n",
      "25/25 - 0s - loss: 0.2691 - accuracy: 0.8781 - val_loss: 8.5454 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02549: val_loss did not improve from 0.32861\n",
      "Epoch 2550/4000\n",
      "25/25 - 0s - loss: 0.2563 - accuracy: 0.8859 - val_loss: 8.6339 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02550: val_loss did not improve from 0.32861\n",
      "Epoch 2551/4000\n",
      "25/25 - 0s - loss: 0.2610 - accuracy: 0.8807 - val_loss: 8.6710 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02551: val_loss did not improve from 0.32861\n",
      "Epoch 2552/4000\n",
      "25/25 - 0s - loss: 0.2536 - accuracy: 0.8885 - val_loss: 8.6933 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02552: val_loss did not improve from 0.32861\n",
      "Epoch 2553/4000\n",
      "25/25 - 0s - loss: 0.2609 - accuracy: 0.8846 - val_loss: 8.6353 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02553: val_loss did not improve from 0.32861\n",
      "Epoch 2554/4000\n",
      "25/25 - 0s - loss: 0.2526 - accuracy: 0.8885 - val_loss: 8.6985 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02554: val_loss did not improve from 0.32861\n",
      "Epoch 2555/4000\n",
      "25/25 - 0s - loss: 0.2569 - accuracy: 0.8872 - val_loss: 8.6663 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02555: val_loss did not improve from 0.32861\n",
      "Epoch 2556/4000\n",
      "25/25 - 0s - loss: 0.2582 - accuracy: 0.8898 - val_loss: 9.1152 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02556: val_loss did not improve from 0.32861\n",
      "Epoch 2557/4000\n",
      "25/25 - 0s - loss: 0.2565 - accuracy: 0.8872 - val_loss: 9.3111 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02557: val_loss did not improve from 0.32861\n",
      "Epoch 2558/4000\n",
      "25/25 - 0s - loss: 0.2568 - accuracy: 0.8768 - val_loss: 9.1828 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02558: val_loss did not improve from 0.32861\n",
      "Epoch 2559/4000\n",
      "25/25 - 0s - loss: 0.2614 - accuracy: 0.8872 - val_loss: 9.0874 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02559: val_loss did not improve from 0.32861\n",
      "Epoch 2560/4000\n",
      "25/25 - 0s - loss: 0.2461 - accuracy: 0.8911 - val_loss: 9.1326 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02560: val_loss did not improve from 0.32861\n",
      "Epoch 2561/4000\n",
      "25/25 - 0s - loss: 0.2600 - accuracy: 0.8846 - val_loss: 9.1154 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02561: val_loss did not improve from 0.32861\n",
      "Epoch 2562/4000\n",
      "25/25 - 0s - loss: 0.2514 - accuracy: 0.8859 - val_loss: 8.9663 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02562: val_loss did not improve from 0.32861\n",
      "Epoch 2563/4000\n",
      "25/25 - 0s - loss: 0.2558 - accuracy: 0.8807 - val_loss: 9.0129 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02563: val_loss did not improve from 0.32861\n",
      "Epoch 2564/4000\n",
      "25/25 - 0s - loss: 0.2563 - accuracy: 0.8781 - val_loss: 8.9295 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02564: val_loss did not improve from 0.32861\n",
      "Epoch 2565/4000\n",
      "25/25 - 0s - loss: 0.2435 - accuracy: 0.8833 - val_loss: 9.0143 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02565: val_loss did not improve from 0.32861\n",
      "Epoch 2566/4000\n",
      "25/25 - 0s - loss: 0.2434 - accuracy: 0.8885 - val_loss: 9.0974 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02566: val_loss did not improve from 0.32861\n",
      "Epoch 2567/4000\n",
      "25/25 - 0s - loss: 0.2438 - accuracy: 0.8872 - val_loss: 8.9229 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02567: val_loss did not improve from 0.32861\n",
      "Epoch 2568/4000\n",
      "25/25 - 0s - loss: 0.2397 - accuracy: 0.8859 - val_loss: 8.9963 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02568: val_loss did not improve from 0.32861\n",
      "Epoch 2569/4000\n",
      "25/25 - 0s - loss: 0.2499 - accuracy: 0.8949 - val_loss: 9.1194 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02569: val_loss did not improve from 0.32861\n",
      "Epoch 2570/4000\n",
      "25/25 - 0s - loss: 0.2539 - accuracy: 0.8885 - val_loss: 9.1771 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02570: val_loss did not improve from 0.32861\n",
      "Epoch 2571/4000\n",
      "25/25 - 0s - loss: 0.2431 - accuracy: 0.8898 - val_loss: 9.2533 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02571: val_loss did not improve from 0.32861\n",
      "Epoch 2572/4000\n",
      "25/25 - 0s - loss: 0.2422 - accuracy: 0.8898 - val_loss: 9.3343 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02572: val_loss did not improve from 0.32861\n",
      "Epoch 2573/4000\n",
      "25/25 - 0s - loss: 0.2391 - accuracy: 0.8898 - val_loss: 9.2678 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02573: val_loss did not improve from 0.32861\n",
      "Epoch 2574/4000\n",
      "25/25 - 0s - loss: 0.2335 - accuracy: 0.8949 - val_loss: 9.2795 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02574: val_loss did not improve from 0.32861\n",
      "Epoch 2575/4000\n",
      "25/25 - 0s - loss: 0.2378 - accuracy: 0.8911 - val_loss: 9.4321 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02575: val_loss did not improve from 0.32861\n",
      "Epoch 2576/4000\n",
      "25/25 - 0s - loss: 0.2420 - accuracy: 0.8898 - val_loss: 9.3737 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02576: val_loss did not improve from 0.32861\n",
      "Epoch 2577/4000\n",
      "25/25 - 0s - loss: 0.2427 - accuracy: 0.8898 - val_loss: 9.3701 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02577: val_loss did not improve from 0.32861\n",
      "Epoch 2578/4000\n",
      "25/25 - 0s - loss: 0.2407 - accuracy: 0.8781 - val_loss: 9.1891 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02578: val_loss did not improve from 0.32861\n",
      "Epoch 2579/4000\n",
      "25/25 - 0s - loss: 0.3245 - accuracy: 0.8729 - val_loss: 8.2819 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02579: val_loss did not improve from 0.32861\n",
      "Epoch 2580/4000\n",
      "25/25 - 0s - loss: 0.2857 - accuracy: 0.8794 - val_loss: 7.4970 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02580: val_loss did not improve from 0.32861\n",
      "Epoch 2581/4000\n",
      "25/25 - 0s - loss: 0.2999 - accuracy: 0.8612 - val_loss: 7.4772 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02581: val_loss did not improve from 0.32861\n",
      "Epoch 2582/4000\n",
      "25/25 - 0s - loss: 0.2766 - accuracy: 0.8716 - val_loss: 7.4406 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02582: val_loss did not improve from 0.32861\n",
      "Epoch 2583/4000\n",
      "25/25 - 0s - loss: 0.2641 - accuracy: 0.8755 - val_loss: 7.5985 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02583: val_loss did not improve from 0.32861\n",
      "Epoch 2584/4000\n",
      "25/25 - 0s - loss: 0.2840 - accuracy: 0.8794 - val_loss: 7.6130 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02584: val_loss did not improve from 0.32861\n",
      "Epoch 2585/4000\n",
      "25/25 - 0s - loss: 0.2782 - accuracy: 0.8755 - val_loss: 7.5773 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02585: val_loss did not improve from 0.32861\n",
      "Epoch 2586/4000\n",
      "25/25 - 0s - loss: 0.2544 - accuracy: 0.8846 - val_loss: 7.5814 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02586: val_loss did not improve from 0.32861\n",
      "Epoch 2587/4000\n",
      "25/25 - 0s - loss: 0.2474 - accuracy: 0.8885 - val_loss: 7.6415 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02587: val_loss did not improve from 0.32861\n",
      "Epoch 2588/4000\n",
      "25/25 - 0s - loss: 0.2479 - accuracy: 0.8872 - val_loss: 7.7267 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02588: val_loss did not improve from 0.32861\n",
      "Epoch 2589/4000\n",
      "25/25 - 0s - loss: 0.2447 - accuracy: 0.8885 - val_loss: 7.7674 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02589: val_loss did not improve from 0.32861\n",
      "Epoch 2590/4000\n",
      "25/25 - 0s - loss: 0.2456 - accuracy: 0.8885 - val_loss: 7.7407 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02590: val_loss did not improve from 0.32861\n",
      "Epoch 2591/4000\n",
      "25/25 - 0s - loss: 0.2395 - accuracy: 0.8911 - val_loss: 7.7976 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02591: val_loss did not improve from 0.32861\n",
      "Epoch 2592/4000\n",
      "25/25 - 0s - loss: 0.2577 - accuracy: 0.8846 - val_loss: 7.7316 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02592: val_loss did not improve from 0.32861\n",
      "Epoch 2593/4000\n",
      "25/25 - 0s - loss: 0.2429 - accuracy: 0.8885 - val_loss: 7.8126 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02593: val_loss did not improve from 0.32861\n",
      "Epoch 2594/4000\n",
      "25/25 - 0s - loss: 0.2418 - accuracy: 0.8885 - val_loss: 7.8752 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02594: val_loss did not improve from 0.32861\n",
      "Epoch 2595/4000\n",
      "25/25 - 0s - loss: 0.2419 - accuracy: 0.8846 - val_loss: 8.0171 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02595: val_loss did not improve from 0.32861\n",
      "Epoch 2596/4000\n",
      "25/25 - 0s - loss: 0.2408 - accuracy: 0.8923 - val_loss: 7.8972 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02596: val_loss did not improve from 0.32861\n",
      "Epoch 2597/4000\n",
      "25/25 - 0s - loss: 0.2412 - accuracy: 0.8833 - val_loss: 7.9573 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02597: val_loss did not improve from 0.32861\n",
      "Epoch 2598/4000\n",
      "25/25 - 0s - loss: 0.2380 - accuracy: 0.8885 - val_loss: 8.0705 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02598: val_loss did not improve from 0.32861\n",
      "Epoch 2599/4000\n",
      "25/25 - 0s - loss: 0.2696 - accuracy: 0.8677 - val_loss: 8.2053 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02599: val_loss did not improve from 0.32861\n",
      "Epoch 2600/4000\n",
      "25/25 - 0s - loss: 0.2449 - accuracy: 0.8833 - val_loss: 8.3030 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02600: val_loss did not improve from 0.32861\n",
      "Epoch 2601/4000\n",
      "25/25 - 0s - loss: 0.2416 - accuracy: 0.8911 - val_loss: 8.1713 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02601: val_loss did not improve from 0.32861\n",
      "Epoch 2602/4000\n",
      "25/25 - 0s - loss: 0.2485 - accuracy: 0.8898 - val_loss: 8.5794 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02602: val_loss did not improve from 0.32861\n",
      "Epoch 2603/4000\n",
      "25/25 - 0s - loss: 0.2419 - accuracy: 0.8936 - val_loss: 8.4276 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02603: val_loss did not improve from 0.32861\n",
      "Epoch 2604/4000\n",
      "25/25 - 0s - loss: 0.3463 - accuracy: 0.8936 - val_loss: 5.8472 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 02604: val_loss did not improve from 0.32861\n",
      "Epoch 2605/4000\n",
      "25/25 - 0s - loss: 0.2645 - accuracy: 0.8833 - val_loss: 6.5427 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02605: val_loss did not improve from 0.32861\n",
      "Epoch 2606/4000\n",
      "25/25 - 0s - loss: 0.2706 - accuracy: 0.8755 - val_loss: 4.1722 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02606: val_loss did not improve from 0.32861\n",
      "Epoch 2607/4000\n",
      "25/25 - 0s - loss: 0.2608 - accuracy: 0.8833 - val_loss: 4.7534 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02607: val_loss did not improve from 0.32861\n",
      "Epoch 2608/4000\n",
      "25/25 - 0s - loss: 0.2585 - accuracy: 0.8742 - val_loss: 4.7979 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02608: val_loss did not improve from 0.32861\n",
      "Epoch 2609/4000\n",
      "25/25 - 0s - loss: 0.2453 - accuracy: 0.8768 - val_loss: 4.7231 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02609: val_loss did not improve from 0.32861\n",
      "Epoch 2610/4000\n",
      "25/25 - 0s - loss: 0.2465 - accuracy: 0.8923 - val_loss: 4.9399 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02610: val_loss did not improve from 0.32861\n",
      "Epoch 2611/4000\n",
      "25/25 - 0s - loss: 0.2422 - accuracy: 0.8833 - val_loss: 6.8124 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02611: val_loss did not improve from 0.32861\n",
      "Epoch 2612/4000\n",
      "25/25 - 0s - loss: 0.2457 - accuracy: 0.8781 - val_loss: 6.7968 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02612: val_loss did not improve from 0.32861\n",
      "Epoch 2613/4000\n",
      "25/25 - 0s - loss: 0.2808 - accuracy: 0.8703 - val_loss: 7.1987 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02613: val_loss did not improve from 0.32861\n",
      "Epoch 2614/4000\n",
      "25/25 - 0s - loss: 0.3053 - accuracy: 0.8664 - val_loss: 7.7632 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02614: val_loss did not improve from 0.32861\n",
      "Epoch 2615/4000\n",
      "25/25 - 0s - loss: 0.2840 - accuracy: 0.8703 - val_loss: 7.3896 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02615: val_loss did not improve from 0.32861\n",
      "Epoch 2616/4000\n",
      "25/25 - 0s - loss: 0.2725 - accuracy: 0.8755 - val_loss: 7.3397 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02616: val_loss did not improve from 0.32861\n",
      "Epoch 2617/4000\n",
      "25/25 - 0s - loss: 0.2608 - accuracy: 0.8755 - val_loss: 7.4092 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02617: val_loss did not improve from 0.32861\n",
      "Epoch 2618/4000\n",
      "25/25 - 0s - loss: 0.2522 - accuracy: 0.8768 - val_loss: 7.5247 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02618: val_loss did not improve from 0.32861\n",
      "Epoch 2619/4000\n",
      "25/25 - 0s - loss: 0.2549 - accuracy: 0.8742 - val_loss: 7.4812 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02619: val_loss did not improve from 0.32861\n",
      "Epoch 2620/4000\n",
      "25/25 - 0s - loss: 0.2616 - accuracy: 0.8742 - val_loss: 7.5783 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02620: val_loss did not improve from 0.32861\n",
      "Epoch 2621/4000\n",
      "25/25 - 0s - loss: 0.2605 - accuracy: 0.8768 - val_loss: 7.7770 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02621: val_loss did not improve from 0.32861\n",
      "Epoch 2622/4000\n",
      "25/25 - 0s - loss: 0.2566 - accuracy: 0.8768 - val_loss: 8.1602 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02622: val_loss did not improve from 0.32861\n",
      "Epoch 2623/4000\n",
      "25/25 - 0s - loss: 0.2476 - accuracy: 0.8794 - val_loss: 8.1078 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02623: val_loss did not improve from 0.32861\n",
      "Epoch 2624/4000\n",
      "25/25 - 0s - loss: 0.2498 - accuracy: 0.8807 - val_loss: 8.0046 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02624: val_loss did not improve from 0.32861\n",
      "Epoch 2625/4000\n",
      "25/25 - 0s - loss: 0.2506 - accuracy: 0.8794 - val_loss: 8.1691 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02625: val_loss did not improve from 0.32861\n",
      "Epoch 2626/4000\n",
      "25/25 - 0s - loss: 0.2499 - accuracy: 0.8716 - val_loss: 8.5097 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02626: val_loss did not improve from 0.32861\n",
      "Epoch 2627/4000\n",
      "25/25 - 0s - loss: 0.2526 - accuracy: 0.8742 - val_loss: 9.1342 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02627: val_loss did not improve from 0.32861\n",
      "Epoch 2628/4000\n",
      "25/25 - 0s - loss: 0.2511 - accuracy: 0.8729 - val_loss: 9.7955 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02628: val_loss did not improve from 0.32861\n",
      "Epoch 2629/4000\n",
      "25/25 - 0s - loss: 0.2380 - accuracy: 0.8859 - val_loss: 9.7909 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02629: val_loss did not improve from 0.32861\n",
      "Epoch 2630/4000\n",
      "25/25 - 0s - loss: 0.2439 - accuracy: 0.8807 - val_loss: 9.8627 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02630: val_loss did not improve from 0.32861\n",
      "Epoch 2631/4000\n",
      "25/25 - 0s - loss: 0.2513 - accuracy: 0.8755 - val_loss: 9.8713 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02631: val_loss did not improve from 0.32861\n",
      "Epoch 2632/4000\n",
      "25/25 - 0s - loss: 0.2431 - accuracy: 0.8716 - val_loss: 10.0043 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02632: val_loss did not improve from 0.32861\n",
      "Epoch 2633/4000\n",
      "25/25 - 0s - loss: 0.2415 - accuracy: 0.8781 - val_loss: 9.7379 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02633: val_loss did not improve from 0.32861\n",
      "Epoch 2634/4000\n",
      "25/25 - 0s - loss: 0.2424 - accuracy: 0.8833 - val_loss: 9.8048 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02634: val_loss did not improve from 0.32861\n",
      "Epoch 2635/4000\n",
      "25/25 - 0s - loss: 0.2414 - accuracy: 0.8898 - val_loss: 9.7740 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02635: val_loss did not improve from 0.32861\n",
      "Epoch 2636/4000\n",
      "25/25 - 0s - loss: 0.2477 - accuracy: 0.8716 - val_loss: 9.8772 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02636: val_loss did not improve from 0.32861\n",
      "Epoch 2637/4000\n",
      "25/25 - 0s - loss: 0.2367 - accuracy: 0.8794 - val_loss: 9.8865 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02637: val_loss did not improve from 0.32861\n",
      "Epoch 2638/4000\n",
      "25/25 - 0s - loss: 0.2405 - accuracy: 0.8833 - val_loss: 9.7947 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02638: val_loss did not improve from 0.32861\n",
      "Epoch 2639/4000\n",
      "25/25 - 0s - loss: 0.2408 - accuracy: 0.8742 - val_loss: 9.9146 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02639: val_loss did not improve from 0.32861\n",
      "Epoch 2640/4000\n",
      "25/25 - 0s - loss: 0.2372 - accuracy: 0.8794 - val_loss: 10.0477 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02640: val_loss did not improve from 0.32861\n",
      "Epoch 2641/4000\n",
      "25/25 - 0s - loss: 0.2455 - accuracy: 0.8846 - val_loss: 9.9764 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02641: val_loss did not improve from 0.32861\n",
      "Epoch 2642/4000\n",
      "25/25 - 0s - loss: 0.2437 - accuracy: 0.8781 - val_loss: 10.0052 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02642: val_loss did not improve from 0.32861\n",
      "Epoch 2643/4000\n",
      "25/25 - 0s - loss: 0.2440 - accuracy: 0.8716 - val_loss: 10.1510 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02643: val_loss did not improve from 0.32861\n",
      "Epoch 2644/4000\n",
      "25/25 - 0s - loss: 0.2396 - accuracy: 0.8781 - val_loss: 10.0487 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02644: val_loss did not improve from 0.32861\n",
      "Epoch 2645/4000\n",
      "25/25 - 0s - loss: 0.2579 - accuracy: 0.8703 - val_loss: 10.0946 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02645: val_loss did not improve from 0.32861\n",
      "Epoch 2646/4000\n",
      "25/25 - 0s - loss: 0.2422 - accuracy: 0.8768 - val_loss: 10.0239 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02646: val_loss did not improve from 0.32861\n",
      "Epoch 2647/4000\n",
      "25/25 - 0s - loss: 0.2356 - accuracy: 0.8807 - val_loss: 10.1089 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02647: val_loss did not improve from 0.32861\n",
      "Epoch 2648/4000\n",
      "25/25 - 0s - loss: 0.2379 - accuracy: 0.8872 - val_loss: 10.0186 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02648: val_loss did not improve from 0.32861\n",
      "Epoch 2649/4000\n",
      "25/25 - 0s - loss: 0.2437 - accuracy: 0.8768 - val_loss: 10.1263 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02649: val_loss did not improve from 0.32861\n",
      "Epoch 2650/4000\n",
      "25/25 - 0s - loss: 0.2413 - accuracy: 0.8729 - val_loss: 10.1719 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02650: val_loss did not improve from 0.32861\n",
      "Epoch 2651/4000\n",
      "25/25 - 0s - loss: 0.2413 - accuracy: 0.8833 - val_loss: 10.2207 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02651: val_loss did not improve from 0.32861\n",
      "Epoch 2652/4000\n",
      "25/25 - 0s - loss: 0.2410 - accuracy: 0.8807 - val_loss: 10.1211 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02652: val_loss did not improve from 0.32861\n",
      "Epoch 2653/4000\n",
      "25/25 - 0s - loss: 0.2351 - accuracy: 0.8820 - val_loss: 10.1964 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02653: val_loss did not improve from 0.32861\n",
      "Epoch 2654/4000\n",
      "25/25 - 0s - loss: 0.2485 - accuracy: 0.8742 - val_loss: 10.1061 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02654: val_loss did not improve from 0.32861\n",
      "Epoch 2655/4000\n",
      "25/25 - 0s - loss: 0.2394 - accuracy: 0.8794 - val_loss: 10.2227 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02655: val_loss did not improve from 0.32861\n",
      "Epoch 2656/4000\n",
      "25/25 - 0s - loss: 0.2429 - accuracy: 0.8768 - val_loss: 10.2483 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02656: val_loss did not improve from 0.32861\n",
      "Epoch 2657/4000\n",
      "25/25 - 0s - loss: 0.2451 - accuracy: 0.8794 - val_loss: 10.4462 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02657: val_loss did not improve from 0.32861\n",
      "Epoch 2658/4000\n",
      "25/25 - 0s - loss: 0.2637 - accuracy: 0.8690 - val_loss: 10.5572 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02658: val_loss did not improve from 0.32861\n",
      "Epoch 2659/4000\n",
      "25/25 - 0s - loss: 0.2537 - accuracy: 0.8794 - val_loss: 10.5953 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02659: val_loss did not improve from 0.32861\n",
      "Epoch 2660/4000\n",
      "25/25 - 0s - loss: 0.2525 - accuracy: 0.8781 - val_loss: 10.6028 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02660: val_loss did not improve from 0.32861\n",
      "Epoch 2661/4000\n",
      "25/25 - 0s - loss: 0.2510 - accuracy: 0.8833 - val_loss: 10.6215 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02661: val_loss did not improve from 0.32861\n",
      "Epoch 2662/4000\n",
      "25/25 - 0s - loss: 0.2522 - accuracy: 0.8794 - val_loss: 10.5727 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02662: val_loss did not improve from 0.32861\n",
      "Epoch 2663/4000\n",
      "25/25 - 0s - loss: 0.2551 - accuracy: 0.8859 - val_loss: 10.5379 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02663: val_loss did not improve from 0.32861\n",
      "Epoch 2664/4000\n",
      "25/25 - 0s - loss: 0.2508 - accuracy: 0.8755 - val_loss: 10.6057 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02664: val_loss did not improve from 0.32861\n",
      "Epoch 2665/4000\n",
      "25/25 - 0s - loss: 0.2701 - accuracy: 0.8781 - val_loss: 10.7133 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02665: val_loss did not improve from 0.32861\n",
      "Epoch 2666/4000\n",
      "25/25 - 0s - loss: 0.2510 - accuracy: 0.8807 - val_loss: 10.7274 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02666: val_loss did not improve from 0.32861\n",
      "Epoch 2667/4000\n",
      "25/25 - 0s - loss: 0.2546 - accuracy: 0.8742 - val_loss: 10.8030 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02667: val_loss did not improve from 0.32861\n",
      "Epoch 2668/4000\n",
      "25/25 - 0s - loss: 0.2565 - accuracy: 0.8742 - val_loss: 10.7889 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02668: val_loss did not improve from 0.32861\n",
      "Epoch 2669/4000\n",
      "25/25 - 0s - loss: 0.2538 - accuracy: 0.8755 - val_loss: 10.7884 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02669: val_loss did not improve from 0.32861\n",
      "Epoch 2670/4000\n",
      "25/25 - 0s - loss: 0.2503 - accuracy: 0.8833 - val_loss: 10.9145 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02670: val_loss did not improve from 0.32861\n",
      "Epoch 2671/4000\n",
      "25/25 - 0s - loss: 0.2543 - accuracy: 0.8872 - val_loss: 11.0467 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02671: val_loss did not improve from 0.32861\n",
      "Epoch 2672/4000\n",
      "25/25 - 0s - loss: 0.2520 - accuracy: 0.8820 - val_loss: 10.9612 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02672: val_loss did not improve from 0.32861\n",
      "Epoch 2673/4000\n",
      "25/25 - 0s - loss: 0.2548 - accuracy: 0.8677 - val_loss: 11.0774 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02673: val_loss did not improve from 0.32861\n",
      "Epoch 2674/4000\n",
      "25/25 - 0s - loss: 0.2751 - accuracy: 0.8677 - val_loss: 11.0592 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02674: val_loss did not improve from 0.32861\n",
      "Epoch 2675/4000\n",
      "25/25 - 0s - loss: 0.2585 - accuracy: 0.8729 - val_loss: 11.0005 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02675: val_loss did not improve from 0.32861\n",
      "Epoch 2676/4000\n",
      "25/25 - 0s - loss: 0.2522 - accuracy: 0.8794 - val_loss: 11.2098 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02676: val_loss did not improve from 0.32861\n",
      "Epoch 2677/4000\n",
      "25/25 - 0s - loss: 0.2540 - accuracy: 0.8742 - val_loss: 11.0559 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02677: val_loss did not improve from 0.32861\n",
      "Epoch 2678/4000\n",
      "25/25 - 0s - loss: 0.2494 - accuracy: 0.8768 - val_loss: 10.8767 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02678: val_loss did not improve from 0.32861\n",
      "Epoch 2679/4000\n",
      "25/25 - 0s - loss: 0.2607 - accuracy: 0.8703 - val_loss: 10.8048 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02679: val_loss did not improve from 0.32861\n",
      "Epoch 2680/4000\n",
      "25/25 - 0s - loss: 0.2518 - accuracy: 0.8794 - val_loss: 10.8943 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02680: val_loss did not improve from 0.32861\n",
      "Epoch 2681/4000\n",
      "25/25 - 0s - loss: 0.2538 - accuracy: 0.8794 - val_loss: 10.9208 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02681: val_loss did not improve from 0.32861\n",
      "Epoch 2682/4000\n",
      "25/25 - 0s - loss: 0.2548 - accuracy: 0.8807 - val_loss: 10.8713 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02682: val_loss did not improve from 0.32861\n",
      "Epoch 2683/4000\n",
      "25/25 - 0s - loss: 0.2512 - accuracy: 0.8794 - val_loss: 10.8881 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02683: val_loss did not improve from 0.32861\n",
      "Epoch 2684/4000\n",
      "25/25 - 0s - loss: 0.2486 - accuracy: 0.8794 - val_loss: 10.9252 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02684: val_loss did not improve from 0.32861\n",
      "Epoch 2685/4000\n",
      "25/25 - 0s - loss: 0.2569 - accuracy: 0.8729 - val_loss: 10.9091 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02685: val_loss did not improve from 0.32861\n",
      "Epoch 2686/4000\n",
      "25/25 - 0s - loss: 0.2505 - accuracy: 0.8794 - val_loss: 11.1383 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02686: val_loss did not improve from 0.32861\n",
      "Epoch 2687/4000\n",
      "25/25 - 0s - loss: 0.2502 - accuracy: 0.8755 - val_loss: 11.1687 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02687: val_loss did not improve from 0.32861\n",
      "Epoch 2688/4000\n",
      "25/25 - 0s - loss: 0.2505 - accuracy: 0.8794 - val_loss: 11.0643 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02688: val_loss did not improve from 0.32861\n",
      "Epoch 2689/4000\n",
      "25/25 - 0s - loss: 0.2631 - accuracy: 0.8703 - val_loss: 11.1594 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02689: val_loss did not improve from 0.32861\n",
      "Epoch 2690/4000\n",
      "25/25 - 0s - loss: 0.2563 - accuracy: 0.8729 - val_loss: 11.6928 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02690: val_loss did not improve from 0.32861\n",
      "Epoch 2691/4000\n",
      "25/25 - 0s - loss: 0.2484 - accuracy: 0.8781 - val_loss: 11.8611 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02691: val_loss did not improve from 0.32861\n",
      "Epoch 2692/4000\n",
      "25/25 - 1s - loss: 0.2644 - accuracy: 0.8716 - val_loss: 11.7724 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02692: val_loss did not improve from 0.32861\n",
      "Epoch 2693/4000\n",
      "25/25 - 0s - loss: 0.2655 - accuracy: 0.8729 - val_loss: 11.3216 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02693: val_loss did not improve from 0.32861\n",
      "Epoch 2694/4000\n",
      "25/25 - 0s - loss: 0.2528 - accuracy: 0.8755 - val_loss: 11.4175 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02694: val_loss did not improve from 0.32861\n",
      "Epoch 2695/4000\n",
      "25/25 - 0s - loss: 0.2479 - accuracy: 0.8846 - val_loss: 11.4552 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02695: val_loss did not improve from 0.32861\n",
      "Epoch 2696/4000\n",
      "25/25 - 0s - loss: 0.2489 - accuracy: 0.8781 - val_loss: 11.4676 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02696: val_loss did not improve from 0.32861\n",
      "Epoch 2697/4000\n",
      "25/25 - 0s - loss: 0.2532 - accuracy: 0.8794 - val_loss: 11.3814 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02697: val_loss did not improve from 0.32861\n",
      "Epoch 2698/4000\n",
      "25/25 - 0s - loss: 0.2512 - accuracy: 0.8768 - val_loss: 11.5138 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02698: val_loss did not improve from 0.32861\n",
      "Epoch 2699/4000\n",
      "25/25 - 0s - loss: 0.2480 - accuracy: 0.8807 - val_loss: 11.3933 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02699: val_loss did not improve from 0.32861\n",
      "Epoch 2700/4000\n",
      "25/25 - 0s - loss: 0.2486 - accuracy: 0.8820 - val_loss: 11.4366 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02700: val_loss did not improve from 0.32861\n",
      "Epoch 2701/4000\n",
      "25/25 - 0s - loss: 0.2486 - accuracy: 0.8833 - val_loss: 11.4162 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02701: val_loss did not improve from 0.32861\n",
      "Epoch 2702/4000\n",
      "25/25 - 0s - loss: 0.2516 - accuracy: 0.8755 - val_loss: 11.4241 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02702: val_loss did not improve from 0.32861\n",
      "Epoch 2703/4000\n",
      "25/25 - 0s - loss: 0.2404 - accuracy: 0.8898 - val_loss: 10.8957 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02703: val_loss did not improve from 0.32861\n",
      "Epoch 2704/4000\n",
      "25/25 - 0s - loss: 0.2355 - accuracy: 0.8975 - val_loss: 10.9792 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02704: val_loss did not improve from 0.32861\n",
      "Epoch 2705/4000\n",
      "25/25 - 0s - loss: 0.2449 - accuracy: 0.8859 - val_loss: 10.9155 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02705: val_loss did not improve from 0.32861\n",
      "Epoch 2706/4000\n",
      "25/25 - 0s - loss: 0.2365 - accuracy: 0.8911 - val_loss: 10.7853 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02706: val_loss did not improve from 0.32861\n",
      "Epoch 2707/4000\n",
      "25/25 - 0s - loss: 0.2438 - accuracy: 0.8885 - val_loss: 10.6037 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02707: val_loss did not improve from 0.32861\n",
      "Epoch 2708/4000\n",
      "25/25 - 0s - loss: 0.2404 - accuracy: 0.8936 - val_loss: 10.7282 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02708: val_loss did not improve from 0.32861\n",
      "Epoch 2709/4000\n",
      "25/25 - 0s - loss: 0.2498 - accuracy: 0.8781 - val_loss: 10.7763 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02709: val_loss did not improve from 0.32861\n",
      "Epoch 2710/4000\n",
      "25/25 - 0s - loss: 0.2434 - accuracy: 0.8846 - val_loss: 10.9248 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02710: val_loss did not improve from 0.32861\n",
      "Epoch 2711/4000\n",
      "25/25 - 0s - loss: 0.2554 - accuracy: 0.8833 - val_loss: 10.9428 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02711: val_loss did not improve from 0.32861\n",
      "Epoch 2712/4000\n",
      "25/25 - 0s - loss: 0.2430 - accuracy: 0.8898 - val_loss: 10.5258 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02712: val_loss did not improve from 0.32861\n",
      "Epoch 2713/4000\n",
      "25/25 - 0s - loss: 0.2440 - accuracy: 0.8768 - val_loss: 10.6551 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02713: val_loss did not improve from 0.32861\n",
      "Epoch 2714/4000\n",
      "25/25 - 0s - loss: 0.2368 - accuracy: 0.8885 - val_loss: 10.6795 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02714: val_loss did not improve from 0.32861\n",
      "Epoch 2715/4000\n",
      "25/25 - 0s - loss: 0.2393 - accuracy: 0.8859 - val_loss: 10.6132 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02715: val_loss did not improve from 0.32861\n",
      "Epoch 2716/4000\n",
      "25/25 - 0s - loss: 0.2355 - accuracy: 0.8859 - val_loss: 10.6247 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02716: val_loss did not improve from 0.32861\n",
      "Epoch 2717/4000\n",
      "25/25 - 0s - loss: 0.2409 - accuracy: 0.8768 - val_loss: 10.6670 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02717: val_loss did not improve from 0.32861\n",
      "Epoch 2718/4000\n",
      "25/25 - 0s - loss: 0.2401 - accuracy: 0.8898 - val_loss: 10.5415 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02718: val_loss did not improve from 0.32861\n",
      "Epoch 2719/4000\n",
      "25/25 - 0s - loss: 0.2378 - accuracy: 0.8872 - val_loss: 10.6425 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02719: val_loss did not improve from 0.32861\n",
      "Epoch 2720/4000\n",
      "25/25 - 0s - loss: 0.2356 - accuracy: 0.8885 - val_loss: 10.8238 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02720: val_loss did not improve from 0.32861\n",
      "Epoch 2721/4000\n",
      "25/25 - 0s - loss: 0.2366 - accuracy: 0.8885 - val_loss: 10.7756 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02721: val_loss did not improve from 0.32861\n",
      "Epoch 2722/4000\n",
      "25/25 - 0s - loss: 0.2365 - accuracy: 0.8872 - val_loss: 10.7558 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02722: val_loss did not improve from 0.32861\n",
      "Epoch 2723/4000\n",
      "25/25 - 0s - loss: 0.2473 - accuracy: 0.8833 - val_loss: 10.9283 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02723: val_loss did not improve from 0.32861\n",
      "Epoch 2724/4000\n",
      "25/25 - 0s - loss: 0.2491 - accuracy: 0.8820 - val_loss: 10.9111 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02724: val_loss did not improve from 0.32861\n",
      "Epoch 2725/4000\n",
      "25/25 - 0s - loss: 0.2450 - accuracy: 0.8911 - val_loss: 10.7618 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02725: val_loss did not improve from 0.32861\n",
      "Epoch 2726/4000\n",
      "25/25 - 0s - loss: 0.2446 - accuracy: 0.8794 - val_loss: 9.6956 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02726: val_loss did not improve from 0.32861\n",
      "Epoch 2727/4000\n",
      "25/25 - 0s - loss: 0.2576 - accuracy: 0.8846 - val_loss: 9.7399 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02727: val_loss did not improve from 0.32861\n",
      "Epoch 2728/4000\n",
      "25/25 - 0s - loss: 0.2489 - accuracy: 0.8885 - val_loss: 8.3406 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02728: val_loss did not improve from 0.32861\n",
      "Epoch 2729/4000\n",
      "25/25 - 0s - loss: 0.2411 - accuracy: 0.8872 - val_loss: 8.0952 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02729: val_loss did not improve from 0.32861\n",
      "Epoch 2730/4000\n",
      "25/25 - 0s - loss: 0.2373 - accuracy: 0.8885 - val_loss: 7.8801 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02730: val_loss did not improve from 0.32861\n",
      "Epoch 2731/4000\n",
      "25/25 - 0s - loss: 0.2419 - accuracy: 0.8923 - val_loss: 7.8127 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02731: val_loss did not improve from 0.32861\n",
      "Epoch 2732/4000\n",
      "25/25 - 0s - loss: 0.3458 - accuracy: 0.8677 - val_loss: 7.0825 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 02732: val_loss did not improve from 0.32861\n",
      "Epoch 2733/4000\n",
      "25/25 - 0s - loss: 0.3266 - accuracy: 0.8392 - val_loss: 9.6983 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02733: val_loss did not improve from 0.32861\n",
      "Epoch 2734/4000\n",
      "25/25 - 0s - loss: 0.2546 - accuracy: 0.8936 - val_loss: 9.7745 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02734: val_loss did not improve from 0.32861\n",
      "Epoch 2735/4000\n",
      "25/25 - 0s - loss: 0.7463 - accuracy: 0.8898 - val_loss: 10.4501 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 02735: val_loss did not improve from 0.32861\n",
      "Epoch 2736/4000\n",
      "25/25 - 0s - loss: 0.5078 - accuracy: 0.8301 - val_loss: 6.3237 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 02736: val_loss did not improve from 0.32861\n",
      "Epoch 2737/4000\n",
      "25/25 - 0s - loss: 0.4148 - accuracy: 0.8275 - val_loss: 7.8320 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 02737: val_loss did not improve from 0.32861\n",
      "Epoch 2738/4000\n",
      "25/25 - 0s - loss: 0.3306 - accuracy: 0.8599 - val_loss: 7.4488 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 02738: val_loss did not improve from 0.32861\n",
      "Epoch 2739/4000\n",
      "25/25 - 0s - loss: 0.3380 - accuracy: 0.8431 - val_loss: 5.2624 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 02739: val_loss did not improve from 0.32861\n",
      "Epoch 2740/4000\n",
      "25/25 - 0s - loss: 0.3575 - accuracy: 0.8314 - val_loss: 5.5503 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 02740: val_loss did not improve from 0.32861\n",
      "Epoch 2741/4000\n",
      "25/25 - 0s - loss: 0.3802 - accuracy: 0.8145 - val_loss: 4.0446 - val_accuracy: 0.7772\n",
      "\n",
      "Epoch 02741: val_loss did not improve from 0.32861\n",
      "Epoch 2742/4000\n",
      "25/25 - 0s - loss: 0.3430 - accuracy: 0.8210 - val_loss: 3.6157 - val_accuracy: 0.7617\n",
      "\n",
      "Epoch 02742: val_loss did not improve from 0.32861\n",
      "Epoch 2743/4000\n",
      "25/25 - 0s - loss: 0.3321 - accuracy: 0.8327 - val_loss: 3.6388 - val_accuracy: 0.7668\n",
      "\n",
      "Epoch 02743: val_loss did not improve from 0.32861\n",
      "Epoch 2744/4000\n",
      "25/25 - 0s - loss: 0.3327 - accuracy: 0.8275 - val_loss: 4.8876 - val_accuracy: 0.7668\n",
      "\n",
      "Epoch 02744: val_loss did not improve from 0.32861\n",
      "Epoch 2745/4000\n",
      "25/25 - 0s - loss: 0.3374 - accuracy: 0.8249 - val_loss: 2.9523 - val_accuracy: 0.7668\n",
      "\n",
      "Epoch 02745: val_loss did not improve from 0.32861\n",
      "Epoch 2746/4000\n",
      "25/25 - 0s - loss: 0.3196 - accuracy: 0.8275 - val_loss: 3.0328 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 02746: val_loss did not improve from 0.32861\n",
      "Epoch 2747/4000\n",
      "25/25 - 0s - loss: 0.3150 - accuracy: 0.8327 - val_loss: 3.0430 - val_accuracy: 0.7668\n",
      "\n",
      "Epoch 02747: val_loss did not improve from 0.32861\n",
      "Epoch 2748/4000\n",
      "25/25 - 0s - loss: 0.3110 - accuracy: 0.8405 - val_loss: 3.2856 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 02748: val_loss did not improve from 0.32861\n",
      "Epoch 2749/4000\n",
      "25/25 - 0s - loss: 0.3100 - accuracy: 0.8288 - val_loss: 3.2885 - val_accuracy: 0.7668\n",
      "\n",
      "Epoch 02749: val_loss did not improve from 0.32861\n",
      "Epoch 2750/4000\n",
      "25/25 - 0s - loss: 0.3111 - accuracy: 0.8340 - val_loss: 3.3916 - val_accuracy: 0.7668\n",
      "\n",
      "Epoch 02750: val_loss did not improve from 0.32861\n",
      "Epoch 2751/4000\n",
      "25/25 - 0s - loss: 0.3277 - accuracy: 0.8288 - val_loss: 3.4020 - val_accuracy: 0.7668\n",
      "\n",
      "Epoch 02751: val_loss did not improve from 0.32861\n",
      "Epoch 2752/4000\n",
      "25/25 - 0s - loss: 0.3200 - accuracy: 0.8262 - val_loss: 2.9806 - val_accuracy: 0.7565\n",
      "\n",
      "Epoch 02752: val_loss did not improve from 0.32861\n",
      "Epoch 2753/4000\n",
      "25/25 - 0s - loss: 0.3153 - accuracy: 0.8288 - val_loss: 2.9410 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 02753: val_loss did not improve from 0.32861\n",
      "Epoch 2754/4000\n",
      "25/25 - 0s - loss: 0.3118 - accuracy: 0.8418 - val_loss: 2.8814 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 02754: val_loss did not improve from 0.32861\n",
      "Epoch 2755/4000\n",
      "25/25 - 0s - loss: 0.3105 - accuracy: 0.8314 - val_loss: 2.8910 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 02755: val_loss did not improve from 0.32861\n",
      "Epoch 2756/4000\n",
      "25/25 - 0s - loss: 0.3326 - accuracy: 0.8470 - val_loss: 2.5194 - val_accuracy: 0.7772\n",
      "\n",
      "Epoch 02756: val_loss did not improve from 0.32861\n",
      "Epoch 2757/4000\n",
      "25/25 - 0s - loss: 0.3275 - accuracy: 0.8249 - val_loss: 2.7059 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 02757: val_loss did not improve from 0.32861\n",
      "Epoch 2758/4000\n",
      "25/25 - 0s - loss: 0.3236 - accuracy: 0.8106 - val_loss: 2.8768 - val_accuracy: 0.7668\n",
      "\n",
      "Epoch 02758: val_loss did not improve from 0.32861\n",
      "Epoch 2759/4000\n",
      "25/25 - 0s - loss: 0.3123 - accuracy: 0.8288 - val_loss: 4.0107 - val_accuracy: 0.7772\n",
      "\n",
      "Epoch 02759: val_loss did not improve from 0.32861\n",
      "Epoch 2760/4000\n",
      "25/25 - 0s - loss: 0.3086 - accuracy: 0.8327 - val_loss: 5.0996 - val_accuracy: 0.7772\n",
      "\n",
      "Epoch 02760: val_loss did not improve from 0.32861\n",
      "Epoch 2761/4000\n",
      "25/25 - 0s - loss: 0.3083 - accuracy: 0.8249 - val_loss: 6.3701 - val_accuracy: 0.7668\n",
      "\n",
      "Epoch 02761: val_loss did not improve from 0.32861\n",
      "Epoch 2762/4000\n",
      "25/25 - 0s - loss: 0.3149 - accuracy: 0.8405 - val_loss: 6.3860 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 02762: val_loss did not improve from 0.32861\n",
      "Epoch 2763/4000\n",
      "25/25 - 0s - loss: 0.3037 - accuracy: 0.8340 - val_loss: 6.4655 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 02763: val_loss did not improve from 0.32861\n",
      "Epoch 2764/4000\n",
      "25/25 - 0s - loss: 0.3002 - accuracy: 0.8366 - val_loss: 6.4990 - val_accuracy: 0.7772\n",
      "\n",
      "Epoch 02764: val_loss did not improve from 0.32861\n",
      "Epoch 2765/4000\n",
      "25/25 - 0s - loss: 0.3613 - accuracy: 0.8392 - val_loss: 5.3609 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 02765: val_loss did not improve from 0.32861\n",
      "Epoch 2766/4000\n",
      "25/25 - 0s - loss: 0.3329 - accuracy: 0.8392 - val_loss: 1.7263 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02766: val_loss did not improve from 0.32861\n",
      "Epoch 2767/4000\n",
      "25/25 - 0s - loss: 0.3190 - accuracy: 0.8340 - val_loss: 2.2255 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 02767: val_loss did not improve from 0.32861\n",
      "Epoch 2768/4000\n",
      "25/25 - 0s - loss: 0.3075 - accuracy: 0.8457 - val_loss: 2.4959 - val_accuracy: 0.7513\n",
      "\n",
      "Epoch 02768: val_loss did not improve from 0.32861\n",
      "Epoch 2769/4000\n",
      "25/25 - 0s - loss: 0.3001 - accuracy: 0.8534 - val_loss: 6.3440 - val_accuracy: 0.7617\n",
      "\n",
      "Epoch 02769: val_loss did not improve from 0.32861\n",
      "Epoch 2770/4000\n",
      "25/25 - 0s - loss: 0.3103 - accuracy: 0.8534 - val_loss: 5.6249 - val_accuracy: 0.7772\n",
      "\n",
      "Epoch 02770: val_loss did not improve from 0.32861\n",
      "Epoch 2771/4000\n",
      "25/25 - 0s - loss: 0.2976 - accuracy: 0.8664 - val_loss: 5.3657 - val_accuracy: 0.7772\n",
      "\n",
      "Epoch 02771: val_loss did not improve from 0.32861\n",
      "Epoch 2772/4000\n",
      "25/25 - 0s - loss: 0.2929 - accuracy: 0.8677 - val_loss: 4.5634 - val_accuracy: 0.7772\n",
      "\n",
      "Epoch 02772: val_loss did not improve from 0.32861\n",
      "Epoch 2773/4000\n",
      "25/25 - 0s - loss: 0.2879 - accuracy: 0.8690 - val_loss: 4.5546 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 02773: val_loss did not improve from 0.32861\n",
      "Epoch 2774/4000\n",
      "25/25 - 0s - loss: 0.2854 - accuracy: 0.8651 - val_loss: 5.2363 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02774: val_loss did not improve from 0.32861\n",
      "Epoch 2775/4000\n",
      "25/25 - 0s - loss: 0.2825 - accuracy: 0.8599 - val_loss: 5.1340 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 02775: val_loss did not improve from 0.32861\n",
      "Epoch 2776/4000\n",
      "25/25 - 0s - loss: 0.2875 - accuracy: 0.8651 - val_loss: 4.8669 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02776: val_loss did not improve from 0.32861\n",
      "Epoch 2777/4000\n",
      "25/25 - 0s - loss: 0.2846 - accuracy: 0.8638 - val_loss: 5.2087 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02777: val_loss did not improve from 0.32861\n",
      "Epoch 2778/4000\n",
      "25/25 - 0s - loss: 0.2918 - accuracy: 0.8573 - val_loss: 5.0006 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02778: val_loss did not improve from 0.32861\n",
      "Epoch 2779/4000\n",
      "25/25 - 0s - loss: 0.2856 - accuracy: 0.8612 - val_loss: 5.0260 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02779: val_loss did not improve from 0.32861\n",
      "Epoch 2780/4000\n",
      "25/25 - 0s - loss: 0.2808 - accuracy: 0.8651 - val_loss: 4.9629 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02780: val_loss did not improve from 0.32861\n",
      "Epoch 2781/4000\n",
      "25/25 - 0s - loss: 0.2786 - accuracy: 0.8729 - val_loss: 4.8266 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02781: val_loss did not improve from 0.32861\n",
      "Epoch 2782/4000\n",
      "25/25 - 0s - loss: 0.3026 - accuracy: 0.8599 - val_loss: 5.0540 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 02782: val_loss did not improve from 0.32861\n",
      "Epoch 2783/4000\n",
      "25/25 - 0s - loss: 0.3069 - accuracy: 0.8586 - val_loss: 5.3271 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02783: val_loss did not improve from 0.32861\n",
      "Epoch 2784/4000\n",
      "25/25 - 0s - loss: 0.2904 - accuracy: 0.8612 - val_loss: 5.7972 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02784: val_loss did not improve from 0.32861\n",
      "Epoch 2785/4000\n",
      "25/25 - 0s - loss: 0.3262 - accuracy: 0.8547 - val_loss: 8.0579 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 02785: val_loss did not improve from 0.32861\n",
      "Epoch 2786/4000\n",
      "25/25 - 0s - loss: 0.3342 - accuracy: 0.8405 - val_loss: 5.9036 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 02786: val_loss did not improve from 0.32861\n",
      "Epoch 2787/4000\n",
      "25/25 - 0s - loss: 0.2899 - accuracy: 0.8482 - val_loss: 5.5050 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02787: val_loss did not improve from 0.32861\n",
      "Epoch 2788/4000\n",
      "25/25 - 0s - loss: 0.2720 - accuracy: 0.8781 - val_loss: 5.4533 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02788: val_loss did not improve from 0.32861\n",
      "Epoch 2789/4000\n",
      "25/25 - 0s - loss: 0.2699 - accuracy: 0.8794 - val_loss: 5.4031 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02789: val_loss did not improve from 0.32861\n",
      "Epoch 2790/4000\n",
      "25/25 - 0s - loss: 0.2757 - accuracy: 0.8690 - val_loss: 5.4380 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02790: val_loss did not improve from 0.32861\n",
      "Epoch 2791/4000\n",
      "25/25 - 0s - loss: 0.2715 - accuracy: 0.8703 - val_loss: 5.3836 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02791: val_loss did not improve from 0.32861\n",
      "Epoch 2792/4000\n",
      "25/25 - 0s - loss: 0.2686 - accuracy: 0.8846 - val_loss: 5.1859 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02792: val_loss did not improve from 0.32861\n",
      "Epoch 2793/4000\n",
      "25/25 - 0s - loss: 0.2719 - accuracy: 0.8768 - val_loss: 5.2576 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02793: val_loss did not improve from 0.32861\n",
      "Epoch 2794/4000\n",
      "25/25 - 0s - loss: 0.2665 - accuracy: 0.8781 - val_loss: 5.3026 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02794: val_loss did not improve from 0.32861\n",
      "Epoch 2795/4000\n",
      "25/25 - 0s - loss: 0.2637 - accuracy: 0.8846 - val_loss: 5.3410 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02795: val_loss did not improve from 0.32861\n",
      "Epoch 2796/4000\n",
      "25/25 - 0s - loss: 0.2658 - accuracy: 0.8755 - val_loss: 5.3726 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02796: val_loss did not improve from 0.32861\n",
      "Epoch 2797/4000\n",
      "25/25 - 0s - loss: 0.2836 - accuracy: 0.8768 - val_loss: 5.4261 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02797: val_loss did not improve from 0.32861\n",
      "Epoch 2798/4000\n",
      "25/25 - 0s - loss: 0.2879 - accuracy: 0.8547 - val_loss: 5.5192 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 02798: val_loss did not improve from 0.32861\n",
      "Epoch 2799/4000\n",
      "25/25 - 0s - loss: 0.2905 - accuracy: 0.8846 - val_loss: 5.5001 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 02799: val_loss did not improve from 0.32861\n",
      "Epoch 2800/4000\n",
      "25/25 - 0s - loss: 0.2693 - accuracy: 0.8781 - val_loss: 5.8105 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 02800: val_loss did not improve from 0.32861\n",
      "Epoch 2801/4000\n",
      "25/25 - 0s - loss: 0.2762 - accuracy: 0.8742 - val_loss: 5.8822 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 02801: val_loss did not improve from 0.32861\n",
      "Epoch 2802/4000\n",
      "25/25 - 0s - loss: 0.2703 - accuracy: 0.8794 - val_loss: 5.8362 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 02802: val_loss did not improve from 0.32861\n",
      "Epoch 2803/4000\n",
      "25/25 - 0s - loss: 0.2564 - accuracy: 0.8923 - val_loss: 8.1091 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02803: val_loss did not improve from 0.32861\n",
      "Epoch 2804/4000\n",
      "25/25 - 0s - loss: 0.2528 - accuracy: 0.8911 - val_loss: 8.0530 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02804: val_loss did not improve from 0.32861\n",
      "Epoch 2805/4000\n",
      "25/25 - 0s - loss: 0.2605 - accuracy: 0.8820 - val_loss: 7.9237 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 02805: val_loss did not improve from 0.32861\n",
      "Epoch 2806/4000\n",
      "25/25 - 0s - loss: 0.3062 - accuracy: 0.8599 - val_loss: 9.2764 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 02806: val_loss did not improve from 0.32861\n",
      "Epoch 2807/4000\n",
      "25/25 - 0s - loss: 0.2747 - accuracy: 0.8949 - val_loss: 7.2221 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 02807: val_loss did not improve from 0.32861\n",
      "Epoch 2808/4000\n",
      "25/25 - 0s - loss: 0.2772 - accuracy: 0.8794 - val_loss: 7.9451 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 02808: val_loss did not improve from 0.32861\n",
      "Epoch 2809/4000\n",
      "25/25 - 0s - loss: 0.2539 - accuracy: 0.8859 - val_loss: 8.2027 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 02809: val_loss did not improve from 0.32861\n",
      "Epoch 2810/4000\n",
      "25/25 - 0s - loss: 0.2533 - accuracy: 0.8923 - val_loss: 8.3795 - val_accuracy: 0.7772\n",
      "\n",
      "Epoch 02810: val_loss did not improve from 0.32861\n",
      "Epoch 2811/4000\n",
      "25/25 - 0s - loss: 0.2498 - accuracy: 0.8911 - val_loss: 8.4125 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02811: val_loss did not improve from 0.32861\n",
      "Epoch 2812/4000\n",
      "25/25 - 0s - loss: 0.2572 - accuracy: 0.8911 - val_loss: 8.5781 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02812: val_loss did not improve from 0.32861\n",
      "Epoch 2813/4000\n",
      "25/25 - 0s - loss: 0.2431 - accuracy: 0.9001 - val_loss: 8.1973 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02813: val_loss did not improve from 0.32861\n",
      "Epoch 2814/4000\n",
      "25/25 - 0s - loss: 0.2389 - accuracy: 0.8936 - val_loss: 8.4136 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02814: val_loss did not improve from 0.32861\n",
      "Epoch 2815/4000\n",
      "25/25 - 0s - loss: 0.2400 - accuracy: 0.8949 - val_loss: 8.6615 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02815: val_loss did not improve from 0.32861\n",
      "Epoch 2816/4000\n",
      "25/25 - 0s - loss: 0.2385 - accuracy: 0.8962 - val_loss: 8.6940 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02816: val_loss did not improve from 0.32861\n",
      "Epoch 2817/4000\n",
      "25/25 - 0s - loss: 0.2444 - accuracy: 0.8923 - val_loss: 8.7534 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02817: val_loss did not improve from 0.32861\n",
      "Epoch 2818/4000\n",
      "25/25 - 0s - loss: 0.2395 - accuracy: 0.8911 - val_loss: 8.9122 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02818: val_loss did not improve from 0.32861\n",
      "Epoch 2819/4000\n",
      "25/25 - 0s - loss: 0.2391 - accuracy: 0.8911 - val_loss: 9.0666 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02819: val_loss did not improve from 0.32861\n",
      "Epoch 2820/4000\n",
      "25/25 - 0s - loss: 0.2385 - accuracy: 0.8936 - val_loss: 9.0725 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 02820: val_loss did not improve from 0.32861\n",
      "Epoch 2821/4000\n",
      "25/25 - 0s - loss: 0.2432 - accuracy: 0.8898 - val_loss: 9.0777 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02821: val_loss did not improve from 0.32861\n",
      "Epoch 2822/4000\n",
      "25/25 - 0s - loss: 0.2410 - accuracy: 0.8923 - val_loss: 9.3425 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02822: val_loss did not improve from 0.32861\n",
      "Epoch 2823/4000\n",
      "25/25 - 0s - loss: 0.2415 - accuracy: 0.8936 - val_loss: 9.4501 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02823: val_loss did not improve from 0.32861\n",
      "Epoch 2824/4000\n",
      "25/25 - 0s - loss: 0.2361 - accuracy: 0.9066 - val_loss: 8.8426 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 02824: val_loss did not improve from 0.32861\n",
      "Epoch 2825/4000\n",
      "25/25 - 0s - loss: 0.2606 - accuracy: 0.8911 - val_loss: 9.3487 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02825: val_loss did not improve from 0.32861\n",
      "Epoch 2826/4000\n",
      "25/25 - 0s - loss: 0.2776 - accuracy: 0.8781 - val_loss: 10.2836 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02826: val_loss did not improve from 0.32861\n",
      "Epoch 2827/4000\n",
      "25/25 - 0s - loss: 0.2591 - accuracy: 0.8833 - val_loss: 8.7692 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02827: val_loss did not improve from 0.32861\n",
      "Epoch 2828/4000\n",
      "25/25 - 0s - loss: 0.2553 - accuracy: 0.8846 - val_loss: 9.8497 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02828: val_loss did not improve from 0.32861\n",
      "Epoch 2829/4000\n",
      "25/25 - 0s - loss: 0.2585 - accuracy: 0.8885 - val_loss: 10.0084 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02829: val_loss did not improve from 0.32861\n",
      "Epoch 2830/4000\n",
      "25/25 - 0s - loss: 0.2518 - accuracy: 0.8898 - val_loss: 10.0533 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02830: val_loss did not improve from 0.32861\n",
      "Epoch 2831/4000\n",
      "25/25 - 0s - loss: 0.2511 - accuracy: 0.8846 - val_loss: 10.0484 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02831: val_loss did not improve from 0.32861\n",
      "Epoch 2832/4000\n",
      "25/25 - 0s - loss: 0.2529 - accuracy: 0.8898 - val_loss: 10.3677 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02832: val_loss did not improve from 0.32861\n",
      "Epoch 2833/4000\n",
      "25/25 - 0s - loss: 0.2605 - accuracy: 0.8833 - val_loss: 10.2802 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 02833: val_loss did not improve from 0.32861\n",
      "Epoch 2834/4000\n",
      "25/25 - 0s - loss: 0.2944 - accuracy: 0.8651 - val_loss: 10.1668 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 02834: val_loss did not improve from 0.32861\n",
      "Epoch 2835/4000\n",
      "25/25 - 0s - loss: 0.2760 - accuracy: 0.8923 - val_loss: 9.8512 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 02835: val_loss did not improve from 0.32861\n",
      "Epoch 2836/4000\n",
      "25/25 - 0s - loss: 0.2694 - accuracy: 0.8742 - val_loss: 10.9893 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02836: val_loss did not improve from 0.32861\n",
      "Epoch 2837/4000\n",
      "25/25 - 0s - loss: 0.2697 - accuracy: 0.8716 - val_loss: 8.6077 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02837: val_loss did not improve from 0.32861\n",
      "Epoch 2838/4000\n",
      "25/25 - 0s - loss: 0.2626 - accuracy: 0.8833 - val_loss: 8.4323 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 02838: val_loss did not improve from 0.32861\n",
      "Epoch 2839/4000\n",
      "25/25 - 0s - loss: 0.2462 - accuracy: 0.8936 - val_loss: 8.7516 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02839: val_loss did not improve from 0.32861\n",
      "Epoch 2840/4000\n",
      "25/25 - 0s - loss: 0.2462 - accuracy: 0.8988 - val_loss: 6.3135 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02840: val_loss did not improve from 0.32861\n",
      "Epoch 2841/4000\n",
      "25/25 - 0s - loss: 0.2919 - accuracy: 0.8742 - val_loss: 6.0586 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02841: val_loss did not improve from 0.32861\n",
      "Epoch 2842/4000\n",
      "25/25 - 0s - loss: 0.3408 - accuracy: 0.8560 - val_loss: 1.5595 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02842: val_loss did not improve from 0.32861\n",
      "Epoch 2843/4000\n",
      "25/25 - 0s - loss: 0.3302 - accuracy: 0.8638 - val_loss: 1.2829 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02843: val_loss did not improve from 0.32861\n",
      "Epoch 2844/4000\n",
      "25/25 - 0s - loss: 0.2706 - accuracy: 0.8807 - val_loss: 2.1274 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02844: val_loss did not improve from 0.32861\n",
      "Epoch 2845/4000\n",
      "25/25 - 0s - loss: 0.2634 - accuracy: 0.8781 - val_loss: 2.1846 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02845: val_loss did not improve from 0.32861\n",
      "Epoch 2846/4000\n",
      "25/25 - 0s - loss: 0.2663 - accuracy: 0.8807 - val_loss: 2.7191 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02846: val_loss did not improve from 0.32861\n",
      "Epoch 2847/4000\n",
      "25/25 - 0s - loss: 0.2593 - accuracy: 0.8833 - val_loss: 2.6834 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02847: val_loss did not improve from 0.32861\n",
      "Epoch 2848/4000\n",
      "25/25 - 0s - loss: 0.2594 - accuracy: 0.8794 - val_loss: 4.5180 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02848: val_loss did not improve from 0.32861\n",
      "Epoch 2849/4000\n",
      "25/25 - 0s - loss: 0.4923 - accuracy: 0.8768 - val_loss: 4.1929 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02849: val_loss did not improve from 0.32861\n",
      "Epoch 2850/4000\n",
      "25/25 - 0s - loss: 0.3458 - accuracy: 0.8521 - val_loss: 6.8879 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 02850: val_loss did not improve from 0.32861\n",
      "Epoch 2851/4000\n",
      "25/25 - 0s - loss: 0.3237 - accuracy: 0.8599 - val_loss: 5.7456 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02851: val_loss did not improve from 0.32861\n",
      "Epoch 2852/4000\n",
      "25/25 - 0s - loss: 0.2862 - accuracy: 0.8677 - val_loss: 6.1930 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02852: val_loss did not improve from 0.32861\n",
      "Epoch 2853/4000\n",
      "25/25 - 0s - loss: 0.3793 - accuracy: 0.8768 - val_loss: 4.6240 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 02853: val_loss did not improve from 0.32861\n",
      "Epoch 2854/4000\n",
      "25/25 - 0s - loss: 0.2728 - accuracy: 0.8742 - val_loss: 4.7152 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02854: val_loss did not improve from 0.32861\n",
      "Epoch 2855/4000\n",
      "25/25 - 0s - loss: 0.2661 - accuracy: 0.8820 - val_loss: 4.9229 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02855: val_loss did not improve from 0.32861\n",
      "Epoch 2856/4000\n",
      "25/25 - 0s - loss: 0.2623 - accuracy: 0.8846 - val_loss: 4.8922 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02856: val_loss did not improve from 0.32861\n",
      "Epoch 2857/4000\n",
      "25/25 - 0s - loss: 0.2566 - accuracy: 0.8872 - val_loss: 4.6206 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02857: val_loss did not improve from 0.32861\n",
      "Epoch 2858/4000\n",
      "25/25 - 0s - loss: 0.2726 - accuracy: 0.8690 - val_loss: 4.7343 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02858: val_loss did not improve from 0.32861\n",
      "Epoch 2859/4000\n",
      "25/25 - 0s - loss: 0.2495 - accuracy: 0.8923 - val_loss: 4.9501 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02859: val_loss did not improve from 0.32861\n",
      "Epoch 2860/4000\n",
      "25/25 - 0s - loss: 0.2711 - accuracy: 0.8781 - val_loss: 4.4677 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02860: val_loss did not improve from 0.32861\n",
      "Epoch 2861/4000\n",
      "25/25 - 0s - loss: 0.2826 - accuracy: 0.8716 - val_loss: 4.7705 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02861: val_loss did not improve from 0.32861\n",
      "Epoch 2862/4000\n",
      "25/25 - 0s - loss: 0.2556 - accuracy: 0.8911 - val_loss: 5.1267 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02862: val_loss did not improve from 0.32861\n",
      "Epoch 2863/4000\n",
      "25/25 - 0s - loss: 0.2533 - accuracy: 0.8962 - val_loss: 4.9424 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02863: val_loss did not improve from 0.32861\n",
      "Epoch 2864/4000\n",
      "25/25 - 0s - loss: 0.2603 - accuracy: 0.8911 - val_loss: 1.7523 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02864: val_loss did not improve from 0.32861\n",
      "Epoch 2865/4000\n",
      "25/25 - 0s - loss: 0.2724 - accuracy: 0.8716 - val_loss: 2.1067 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02865: val_loss did not improve from 0.32861\n",
      "Epoch 2866/4000\n",
      "25/25 - 0s - loss: 0.2630 - accuracy: 0.8833 - val_loss: 3.6394 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02866: val_loss did not improve from 0.32861\n",
      "Epoch 2867/4000\n",
      "25/25 - 0s - loss: 0.2650 - accuracy: 0.8859 - val_loss: 3.1270 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02867: val_loss did not improve from 0.32861\n",
      "Epoch 2868/4000\n",
      "25/25 - 0s - loss: 0.2943 - accuracy: 0.8599 - val_loss: 5.5407 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02868: val_loss did not improve from 0.32861\n",
      "Epoch 2869/4000\n",
      "25/25 - 0s - loss: 0.5110 - accuracy: 0.8703 - val_loss: 9.0398 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02869: val_loss did not improve from 0.32861\n",
      "Epoch 2870/4000\n",
      "25/25 - 0s - loss: 0.4011 - accuracy: 0.8716 - val_loss: 1.3336 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02870: val_loss did not improve from 0.32861\n",
      "Epoch 2871/4000\n",
      "25/25 - 0s - loss: 0.3428 - accuracy: 0.8573 - val_loss: 1.0246 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02871: val_loss did not improve from 0.32861\n",
      "Epoch 2872/4000\n",
      "25/25 - 0s - loss: 0.3041 - accuracy: 0.8677 - val_loss: 1.4992 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02872: val_loss did not improve from 0.32861\n",
      "Epoch 2873/4000\n",
      "25/25 - 0s - loss: 0.2871 - accuracy: 0.8846 - val_loss: 2.0537 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02873: val_loss did not improve from 0.32861\n",
      "Epoch 2874/4000\n",
      "25/25 - 0s - loss: 0.2779 - accuracy: 0.8807 - val_loss: 2.2438 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02874: val_loss did not improve from 0.32861\n",
      "Epoch 2875/4000\n",
      "25/25 - 0s - loss: 0.2790 - accuracy: 0.8846 - val_loss: 2.2958 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 02875: val_loss did not improve from 0.32861\n",
      "Epoch 2876/4000\n",
      "25/25 - 0s - loss: 0.2731 - accuracy: 0.8872 - val_loss: 2.4232 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02876: val_loss did not improve from 0.32861\n",
      "Epoch 2877/4000\n",
      "25/25 - 0s - loss: 0.2806 - accuracy: 0.8898 - val_loss: 2.4123 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02877: val_loss did not improve from 0.32861\n",
      "Epoch 2878/4000\n",
      "25/25 - 0s - loss: 0.2908 - accuracy: 0.8781 - val_loss: 2.5013 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02878: val_loss did not improve from 0.32861\n",
      "Epoch 2879/4000\n",
      "25/25 - 0s - loss: 0.2766 - accuracy: 0.8833 - val_loss: 2.3984 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02879: val_loss did not improve from 0.32861\n",
      "Epoch 2880/4000\n",
      "25/25 - 0s - loss: 0.2875 - accuracy: 0.8781 - val_loss: 2.3396 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02880: val_loss did not improve from 0.32861\n",
      "Epoch 2881/4000\n",
      "25/25 - 0s - loss: 0.2663 - accuracy: 0.8923 - val_loss: 2.4277 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02881: val_loss did not improve from 0.32861\n",
      "Epoch 2882/4000\n",
      "25/25 - 0s - loss: 0.2638 - accuracy: 0.8885 - val_loss: 2.3158 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02882: val_loss did not improve from 0.32861\n",
      "Epoch 2883/4000\n",
      "25/25 - 0s - loss: 0.2672 - accuracy: 0.8859 - val_loss: 2.3128 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02883: val_loss did not improve from 0.32861\n",
      "Epoch 2884/4000\n",
      "25/25 - 0s - loss: 0.2787 - accuracy: 0.8859 - val_loss: 2.3490 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02884: val_loss did not improve from 0.32861\n",
      "Epoch 2885/4000\n",
      "25/25 - 0s - loss: 0.2902 - accuracy: 0.8794 - val_loss: 2.1123 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02885: val_loss did not improve from 0.32861\n",
      "Epoch 2886/4000\n",
      "25/25 - 0s - loss: 0.2713 - accuracy: 0.8885 - val_loss: 2.1588 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02886: val_loss did not improve from 0.32861\n",
      "Epoch 2887/4000\n",
      "25/25 - 0s - loss: 0.2730 - accuracy: 0.8833 - val_loss: 2.3259 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02887: val_loss did not improve from 0.32861\n",
      "Epoch 2888/4000\n",
      "25/25 - 0s - loss: 0.2890 - accuracy: 0.8664 - val_loss: 2.5096 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02888: val_loss did not improve from 0.32861\n",
      "Epoch 2889/4000\n",
      "25/25 - 0s - loss: 0.2772 - accuracy: 0.8833 - val_loss: 2.8055 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 02889: val_loss did not improve from 0.32861\n",
      "Epoch 2890/4000\n",
      "25/25 - 0s - loss: 0.2745 - accuracy: 0.8859 - val_loss: 2.7877 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 02890: val_loss did not improve from 0.32861\n",
      "Epoch 2891/4000\n",
      "25/25 - 0s - loss: 0.2705 - accuracy: 0.8781 - val_loss: 2.9208 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02891: val_loss did not improve from 0.32861\n",
      "Epoch 2892/4000\n",
      "25/25 - 0s - loss: 0.2806 - accuracy: 0.8768 - val_loss: 2.9935 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02892: val_loss did not improve from 0.32861\n",
      "Epoch 2893/4000\n",
      "25/25 - 0s - loss: 0.2712 - accuracy: 0.8859 - val_loss: 2.8887 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 02893: val_loss did not improve from 0.32861\n",
      "Epoch 2894/4000\n",
      "25/25 - 0s - loss: 0.2811 - accuracy: 0.8729 - val_loss: 2.9890 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02894: val_loss did not improve from 0.32861\n",
      "Epoch 2895/4000\n",
      "25/25 - 0s - loss: 0.2670 - accuracy: 0.8781 - val_loss: 2.8889 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02895: val_loss did not improve from 0.32861\n",
      "Epoch 2896/4000\n",
      "25/25 - 0s - loss: 0.2591 - accuracy: 0.8911 - val_loss: 2.7602 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02896: val_loss did not improve from 0.32861\n",
      "Epoch 2897/4000\n",
      "25/25 - 0s - loss: 0.2566 - accuracy: 0.8872 - val_loss: 2.6996 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02897: val_loss did not improve from 0.32861\n",
      "Epoch 2898/4000\n",
      "25/25 - 0s - loss: 0.2593 - accuracy: 0.8923 - val_loss: 2.3418 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02898: val_loss did not improve from 0.32861\n",
      "Epoch 2899/4000\n",
      "25/25 - 0s - loss: 0.2737 - accuracy: 0.8872 - val_loss: 2.2909 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02899: val_loss did not improve from 0.32861\n",
      "Epoch 2900/4000\n",
      "25/25 - 0s - loss: 0.2602 - accuracy: 0.8846 - val_loss: 2.3980 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 02900: val_loss did not improve from 0.32861\n",
      "Epoch 2901/4000\n",
      "25/25 - 0s - loss: 0.2631 - accuracy: 0.8833 - val_loss: 2.3553 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02901: val_loss did not improve from 0.32861\n",
      "Epoch 2902/4000\n",
      "25/25 - 0s - loss: 0.2585 - accuracy: 0.8898 - val_loss: 2.5014 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02902: val_loss did not improve from 0.32861\n",
      "Epoch 2903/4000\n",
      "25/25 - 0s - loss: 0.2556 - accuracy: 0.8885 - val_loss: 2.7112 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 02903: val_loss did not improve from 0.32861\n",
      "Epoch 2904/4000\n",
      "25/25 - 0s - loss: 0.2642 - accuracy: 0.8872 - val_loss: 2.7291 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02904: val_loss did not improve from 0.32861\n",
      "Epoch 2905/4000\n",
      "25/25 - 0s - loss: 0.2525 - accuracy: 0.8898 - val_loss: 2.6620 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02905: val_loss did not improve from 0.32861\n",
      "Epoch 2906/4000\n",
      "25/25 - 0s - loss: 0.2596 - accuracy: 0.8820 - val_loss: 2.6125 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02906: val_loss did not improve from 0.32861\n",
      "Epoch 2907/4000\n",
      "25/25 - 0s - loss: 0.2572 - accuracy: 0.8911 - val_loss: 2.6476 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02907: val_loss did not improve from 0.32861\n",
      "Epoch 2908/4000\n",
      "25/25 - 0s - loss: 0.2606 - accuracy: 0.8911 - val_loss: 2.6073 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02908: val_loss did not improve from 0.32861\n",
      "Epoch 2909/4000\n",
      "25/25 - 0s - loss: 0.2588 - accuracy: 0.8872 - val_loss: 2.6090 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 02909: val_loss did not improve from 0.32861\n",
      "Epoch 2910/4000\n",
      "25/25 - 0s - loss: 0.2538 - accuracy: 0.8781 - val_loss: 2.4525 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02910: val_loss did not improve from 0.32861\n",
      "Epoch 2911/4000\n",
      "25/25 - 0s - loss: 0.2570 - accuracy: 0.8885 - val_loss: 2.3080 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02911: val_loss did not improve from 0.32861\n",
      "Epoch 2912/4000\n",
      "25/25 - 0s - loss: 0.2573 - accuracy: 0.8872 - val_loss: 2.3488 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02912: val_loss did not improve from 0.32861\n",
      "Epoch 2913/4000\n",
      "25/25 - 0s - loss: 0.2539 - accuracy: 0.8846 - val_loss: 2.4558 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02913: val_loss did not improve from 0.32861\n",
      "Epoch 2914/4000\n",
      "25/25 - 0s - loss: 0.2618 - accuracy: 0.8794 - val_loss: 2.5650 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02914: val_loss did not improve from 0.32861\n",
      "Epoch 2915/4000\n",
      "25/25 - 0s - loss: 0.2568 - accuracy: 0.8833 - val_loss: 2.4985 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02915: val_loss did not improve from 0.32861\n",
      "Epoch 2916/4000\n",
      "25/25 - 0s - loss: 0.2563 - accuracy: 0.8872 - val_loss: 2.4605 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02916: val_loss did not improve from 0.32861\n",
      "Epoch 2917/4000\n",
      "25/25 - 0s - loss: 0.2562 - accuracy: 0.8885 - val_loss: 2.3520 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02917: val_loss did not improve from 0.32861\n",
      "Epoch 2918/4000\n",
      "25/25 - 0s - loss: 0.2515 - accuracy: 0.8859 - val_loss: 2.3251 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02918: val_loss did not improve from 0.32861\n",
      "Epoch 2919/4000\n",
      "25/25 - 0s - loss: 0.2617 - accuracy: 0.8807 - val_loss: 2.5153 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02919: val_loss did not improve from 0.32861\n",
      "Epoch 2920/4000\n",
      "25/25 - 0s - loss: 0.2571 - accuracy: 0.8846 - val_loss: 2.6519 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02920: val_loss did not improve from 0.32861\n",
      "Epoch 2921/4000\n",
      "25/25 - 0s - loss: 0.2532 - accuracy: 0.8859 - val_loss: 2.5572 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02921: val_loss did not improve from 0.32861\n",
      "Epoch 2922/4000\n",
      "25/25 - 0s - loss: 0.2624 - accuracy: 0.8807 - val_loss: 2.7310 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02922: val_loss did not improve from 0.32861\n",
      "Epoch 2923/4000\n",
      "25/25 - 0s - loss: 0.2776 - accuracy: 0.8936 - val_loss: 2.0661 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02923: val_loss did not improve from 0.32861\n",
      "Epoch 2924/4000\n",
      "25/25 - 0s - loss: 0.2581 - accuracy: 0.8923 - val_loss: 2.6142 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02924: val_loss did not improve from 0.32861\n",
      "Epoch 2925/4000\n",
      "25/25 - 0s - loss: 0.2684 - accuracy: 0.8820 - val_loss: 2.6002 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02925: val_loss did not improve from 0.32861\n",
      "Epoch 2926/4000\n",
      "25/25 - 0s - loss: 0.2580 - accuracy: 0.8898 - val_loss: 2.9071 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02926: val_loss did not improve from 0.32861\n",
      "Epoch 2927/4000\n",
      "25/25 - 0s - loss: 0.2509 - accuracy: 0.8949 - val_loss: 3.1881 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02927: val_loss did not improve from 0.32861\n",
      "Epoch 2928/4000\n",
      "25/25 - 0s - loss: 0.2466 - accuracy: 0.8911 - val_loss: 3.5801 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02928: val_loss did not improve from 0.32861\n",
      "Epoch 2929/4000\n",
      "25/25 - 0s - loss: 0.2487 - accuracy: 0.8923 - val_loss: 3.5735 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02929: val_loss did not improve from 0.32861\n",
      "Epoch 2930/4000\n",
      "25/25 - 0s - loss: 0.3006 - accuracy: 0.8612 - val_loss: 4.4017 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02930: val_loss did not improve from 0.32861\n",
      "Epoch 2931/4000\n",
      "25/25 - 0s - loss: 0.2545 - accuracy: 0.8807 - val_loss: 4.6462 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02931: val_loss did not improve from 0.32861\n",
      "Epoch 2932/4000\n",
      "25/25 - 0s - loss: 0.2433 - accuracy: 0.8949 - val_loss: 4.7958 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02932: val_loss did not improve from 0.32861\n",
      "Epoch 2933/4000\n",
      "25/25 - 0s - loss: 0.2465 - accuracy: 0.8936 - val_loss: 5.0193 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02933: val_loss did not improve from 0.32861\n",
      "Epoch 2934/4000\n",
      "25/25 - 0s - loss: 0.2385 - accuracy: 0.8949 - val_loss: 5.2795 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02934: val_loss did not improve from 0.32861\n",
      "Epoch 2935/4000\n",
      "25/25 - 0s - loss: 0.2440 - accuracy: 0.8898 - val_loss: 4.9694 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02935: val_loss did not improve from 0.32861\n",
      "Epoch 2936/4000\n",
      "25/25 - 0s - loss: 0.2449 - accuracy: 0.8911 - val_loss: 4.8149 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02936: val_loss did not improve from 0.32861\n",
      "Epoch 2937/4000\n",
      "25/25 - 0s - loss: 0.2378 - accuracy: 0.8949 - val_loss: 4.7614 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02937: val_loss did not improve from 0.32861\n",
      "Epoch 2938/4000\n",
      "25/25 - 0s - loss: 0.2392 - accuracy: 0.8898 - val_loss: 4.9332 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02938: val_loss did not improve from 0.32861\n",
      "Epoch 2939/4000\n",
      "25/25 - 0s - loss: 0.2385 - accuracy: 0.8949 - val_loss: 4.8967 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02939: val_loss did not improve from 0.32861\n",
      "Epoch 2940/4000\n",
      "25/25 - 0s - loss: 0.2808 - accuracy: 0.8716 - val_loss: 5.0818 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02940: val_loss did not improve from 0.32861\n",
      "Epoch 2941/4000\n",
      "25/25 - 0s - loss: 0.2549 - accuracy: 0.8885 - val_loss: 4.9596 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02941: val_loss did not improve from 0.32861\n",
      "Epoch 2942/4000\n",
      "25/25 - 0s - loss: 0.2491 - accuracy: 0.8846 - val_loss: 4.6618 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02942: val_loss did not improve from 0.32861\n",
      "Epoch 2943/4000\n",
      "25/25 - 0s - loss: 0.2472 - accuracy: 0.8807 - val_loss: 4.2592 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02943: val_loss did not improve from 0.32861\n",
      "Epoch 2944/4000\n",
      "25/25 - 0s - loss: 0.2398 - accuracy: 0.8962 - val_loss: 4.5684 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02944: val_loss did not improve from 0.32861\n",
      "Epoch 2945/4000\n",
      "25/25 - 0s - loss: 0.2399 - accuracy: 0.8923 - val_loss: 4.6227 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02945: val_loss did not improve from 0.32861\n",
      "Epoch 2946/4000\n",
      "25/25 - 0s - loss: 0.2468 - accuracy: 0.8885 - val_loss: 4.6587 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02946: val_loss did not improve from 0.32861\n",
      "Epoch 2947/4000\n",
      "25/25 - 0s - loss: 0.2431 - accuracy: 0.8859 - val_loss: 4.9569 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02947: val_loss did not improve from 0.32861\n",
      "Epoch 2948/4000\n",
      "25/25 - 0s - loss: 0.2417 - accuracy: 0.9014 - val_loss: 5.3577 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02948: val_loss did not improve from 0.32861\n",
      "Epoch 2949/4000\n",
      "25/25 - 0s - loss: 0.2368 - accuracy: 0.8975 - val_loss: 5.6829 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02949: val_loss did not improve from 0.32861\n",
      "Epoch 2950/4000\n",
      "25/25 - 0s - loss: 0.2468 - accuracy: 0.8885 - val_loss: 5.7845 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02950: val_loss did not improve from 0.32861\n",
      "Epoch 2951/4000\n",
      "25/25 - 0s - loss: 0.2442 - accuracy: 0.8911 - val_loss: 5.8941 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02951: val_loss did not improve from 0.32861\n",
      "Epoch 2952/4000\n",
      "25/25 - 0s - loss: 0.2428 - accuracy: 0.8898 - val_loss: 5.8682 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02952: val_loss did not improve from 0.32861\n",
      "Epoch 2953/4000\n",
      "25/25 - 0s - loss: 0.2361 - accuracy: 0.9027 - val_loss: 5.8337 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02953: val_loss did not improve from 0.32861\n",
      "Epoch 2954/4000\n",
      "25/25 - 0s - loss: 0.2364 - accuracy: 0.8962 - val_loss: 5.9399 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02954: val_loss did not improve from 0.32861\n",
      "Epoch 2955/4000\n",
      "25/25 - 0s - loss: 0.2406 - accuracy: 0.8898 - val_loss: 5.9455 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02955: val_loss did not improve from 0.32861\n",
      "Epoch 2956/4000\n",
      "25/25 - 0s - loss: 0.2363 - accuracy: 0.8949 - val_loss: 5.8051 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02956: val_loss did not improve from 0.32861\n",
      "Epoch 2957/4000\n",
      "25/25 - 0s - loss: 0.2366 - accuracy: 0.8923 - val_loss: 6.1005 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02957: val_loss did not improve from 0.32861\n",
      "Epoch 2958/4000\n",
      "25/25 - 0s - loss: 0.2390 - accuracy: 0.8936 - val_loss: 5.7300 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02958: val_loss did not improve from 0.32861\n",
      "Epoch 2959/4000\n",
      "25/25 - 0s - loss: 0.2456 - accuracy: 0.8936 - val_loss: 5.5546 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02959: val_loss did not improve from 0.32861\n",
      "Epoch 2960/4000\n",
      "25/25 - 0s - loss: 0.2762 - accuracy: 0.8962 - val_loss: 5.8184 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02960: val_loss did not improve from 0.32861\n",
      "Epoch 2961/4000\n",
      "25/25 - 0s - loss: 0.2584 - accuracy: 0.8807 - val_loss: 5.8948 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02961: val_loss did not improve from 0.32861\n",
      "Epoch 2962/4000\n",
      "25/25 - 0s - loss: 0.2570 - accuracy: 0.8846 - val_loss: 6.0245 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02962: val_loss did not improve from 0.32861\n",
      "Epoch 2963/4000\n",
      "25/25 - 0s - loss: 0.2524 - accuracy: 0.8833 - val_loss: 6.1186 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02963: val_loss did not improve from 0.32861\n",
      "Epoch 2964/4000\n",
      "25/25 - 0s - loss: 0.2512 - accuracy: 0.8885 - val_loss: 5.8330 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02964: val_loss did not improve from 0.32861\n",
      "Epoch 2965/4000\n",
      "25/25 - 0s - loss: 0.2413 - accuracy: 0.8911 - val_loss: 6.0773 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02965: val_loss did not improve from 0.32861\n",
      "Epoch 2966/4000\n",
      "25/25 - 0s - loss: 0.2431 - accuracy: 0.8885 - val_loss: 6.0769 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02966: val_loss did not improve from 0.32861\n",
      "Epoch 2967/4000\n",
      "25/25 - 0s - loss: 0.2384 - accuracy: 0.8859 - val_loss: 6.6764 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02967: val_loss did not improve from 0.32861\n",
      "Epoch 2968/4000\n",
      "25/25 - 0s - loss: 0.2347 - accuracy: 0.8911 - val_loss: 7.3128 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02968: val_loss did not improve from 0.32861\n",
      "Epoch 2969/4000\n",
      "25/25 - 0s - loss: 0.2332 - accuracy: 0.8923 - val_loss: 7.3508 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02969: val_loss did not improve from 0.32861\n",
      "Epoch 2970/4000\n",
      "25/25 - 0s - loss: 0.2369 - accuracy: 0.8898 - val_loss: 7.5828 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02970: val_loss did not improve from 0.32861\n",
      "Epoch 2971/4000\n",
      "25/25 - 0s - loss: 0.2452 - accuracy: 0.8898 - val_loss: 7.7228 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02971: val_loss did not improve from 0.32861\n",
      "Epoch 2972/4000\n",
      "25/25 - 0s - loss: 0.2352 - accuracy: 0.8872 - val_loss: 7.8377 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02972: val_loss did not improve from 0.32861\n",
      "Epoch 2973/4000\n",
      "25/25 - 0s - loss: 0.2831 - accuracy: 0.8638 - val_loss: 6.6858 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02973: val_loss did not improve from 0.32861\n",
      "Epoch 2974/4000\n",
      "25/25 - 0s - loss: 0.3228 - accuracy: 0.8547 - val_loss: 6.7845 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02974: val_loss did not improve from 0.32861\n",
      "Epoch 2975/4000\n",
      "25/25 - 0s - loss: 0.2655 - accuracy: 0.8794 - val_loss: 7.6319 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02975: val_loss did not improve from 0.32861\n",
      "Epoch 2976/4000\n",
      "25/25 - 0s - loss: 0.2402 - accuracy: 0.8898 - val_loss: 8.4397 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02976: val_loss did not improve from 0.32861\n",
      "Epoch 2977/4000\n",
      "25/25 - 0s - loss: 0.2394 - accuracy: 0.8833 - val_loss: 8.4008 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02977: val_loss did not improve from 0.32861\n",
      "Epoch 2978/4000\n",
      "25/25 - 0s - loss: 0.2430 - accuracy: 0.8898 - val_loss: 8.4082 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02978: val_loss did not improve from 0.32861\n",
      "Epoch 2979/4000\n",
      "25/25 - 0s - loss: 0.2343 - accuracy: 0.8911 - val_loss: 8.5339 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02979: val_loss did not improve from 0.32861\n",
      "Epoch 2980/4000\n",
      "25/25 - 0s - loss: 0.2421 - accuracy: 0.8898 - val_loss: 8.1719 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02980: val_loss did not improve from 0.32861\n",
      "Epoch 2981/4000\n",
      "25/25 - 0s - loss: 0.2414 - accuracy: 0.8885 - val_loss: 8.9021 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02981: val_loss did not improve from 0.32861\n",
      "Epoch 2982/4000\n",
      "25/25 - 0s - loss: 0.2398 - accuracy: 0.8885 - val_loss: 8.9434 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02982: val_loss did not improve from 0.32861\n",
      "Epoch 2983/4000\n",
      "25/25 - 0s - loss: 0.2429 - accuracy: 0.8872 - val_loss: 7.5243 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02983: val_loss did not improve from 0.32861\n",
      "Epoch 2984/4000\n",
      "25/25 - 0s - loss: 0.2373 - accuracy: 0.8872 - val_loss: 7.7270 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02984: val_loss did not improve from 0.32861\n",
      "Epoch 2985/4000\n",
      "25/25 - 0s - loss: 0.2384 - accuracy: 0.8911 - val_loss: 8.0325 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02985: val_loss did not improve from 0.32861\n",
      "Epoch 2986/4000\n",
      "25/25 - 0s - loss: 0.2460 - accuracy: 0.8794 - val_loss: 8.3714 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02986: val_loss did not improve from 0.32861\n",
      "Epoch 2987/4000\n",
      "25/25 - 0s - loss: 0.2515 - accuracy: 0.8807 - val_loss: 8.5473 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02987: val_loss did not improve from 0.32861\n",
      "Epoch 2988/4000\n",
      "25/25 - 0s - loss: 0.2454 - accuracy: 0.8872 - val_loss: 8.7140 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02988: val_loss did not improve from 0.32861\n",
      "Epoch 2989/4000\n",
      "25/25 - 0s - loss: 0.2422 - accuracy: 0.8859 - val_loss: 8.7834 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02989: val_loss did not improve from 0.32861\n",
      "Epoch 2990/4000\n",
      "25/25 - 0s - loss: 0.3303 - accuracy: 0.8833 - val_loss: 9.5166 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02990: val_loss did not improve from 0.32861\n",
      "Epoch 2991/4000\n",
      "25/25 - 0s - loss: 0.2761 - accuracy: 0.8846 - val_loss: 4.3936 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02991: val_loss did not improve from 0.32861\n",
      "Epoch 2992/4000\n",
      "25/25 - 0s - loss: 0.2827 - accuracy: 0.8781 - val_loss: 5.5885 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02992: val_loss did not improve from 0.32861\n",
      "Epoch 2993/4000\n",
      "25/25 - 0s - loss: 0.2735 - accuracy: 0.8872 - val_loss: 9.0120 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02993: val_loss did not improve from 0.32861\n",
      "Epoch 2994/4000\n",
      "25/25 - 0s - loss: 0.3267 - accuracy: 0.8898 - val_loss: 9.2954 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02994: val_loss did not improve from 0.32861\n",
      "Epoch 2995/4000\n",
      "25/25 - 0s - loss: 0.2709 - accuracy: 0.8716 - val_loss: 9.4433 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02995: val_loss did not improve from 0.32861\n",
      "Epoch 2996/4000\n",
      "25/25 - 0s - loss: 0.2504 - accuracy: 0.8794 - val_loss: 9.2976 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02996: val_loss did not improve from 0.32861\n",
      "Epoch 2997/4000\n",
      "25/25 - 0s - loss: 0.2403 - accuracy: 0.8949 - val_loss: 9.6589 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02997: val_loss did not improve from 0.32861\n",
      "Epoch 2998/4000\n",
      "25/25 - 0s - loss: 0.2365 - accuracy: 0.8949 - val_loss: 9.7254 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02998: val_loss did not improve from 0.32861\n",
      "Epoch 2999/4000\n",
      "25/25 - 0s - loss: 0.2429 - accuracy: 0.8898 - val_loss: 9.9571 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02999: val_loss did not improve from 0.32861\n",
      "Epoch 3000/4000\n",
      "25/25 - 0s - loss: 0.2355 - accuracy: 0.8975 - val_loss: 10.2189 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03000: val_loss did not improve from 0.32861\n",
      "Epoch 3001/4000\n",
      "25/25 - 1s - loss: 0.2404 - accuracy: 0.8988 - val_loss: 9.8797 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03001: val_loss did not improve from 0.32861\n",
      "Epoch 3002/4000\n",
      "25/25 - 0s - loss: 0.2419 - accuracy: 0.8859 - val_loss: 10.2395 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03002: val_loss did not improve from 0.32861\n",
      "Epoch 3003/4000\n",
      "25/25 - 0s - loss: 0.2426 - accuracy: 0.8911 - val_loss: 10.3988 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03003: val_loss did not improve from 0.32861\n",
      "Epoch 3004/4000\n",
      "25/25 - 0s - loss: 0.2485 - accuracy: 0.8936 - val_loss: 10.3116 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 03004: val_loss did not improve from 0.32861\n",
      "Epoch 3005/4000\n",
      "25/25 - 0s - loss: 0.2335 - accuracy: 0.8949 - val_loss: 9.9637 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03005: val_loss did not improve from 0.32861\n",
      "Epoch 3006/4000\n",
      "25/25 - 0s - loss: 0.2377 - accuracy: 0.8898 - val_loss: 10.1850 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03006: val_loss did not improve from 0.32861\n",
      "Epoch 3007/4000\n",
      "25/25 - 0s - loss: 0.2384 - accuracy: 0.8949 - val_loss: 10.3262 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03007: val_loss did not improve from 0.32861\n",
      "Epoch 3008/4000\n",
      "25/25 - 0s - loss: 0.2322 - accuracy: 0.9001 - val_loss: 10.4368 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03008: val_loss did not improve from 0.32861\n",
      "Epoch 3009/4000\n",
      "25/25 - 0s - loss: 0.2378 - accuracy: 0.8949 - val_loss: 10.7949 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03009: val_loss did not improve from 0.32861\n",
      "Epoch 3010/4000\n",
      "25/25 - 0s - loss: 0.2350 - accuracy: 0.8923 - val_loss: 10.8454 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03010: val_loss did not improve from 0.32861\n",
      "Epoch 3011/4000\n",
      "25/25 - 0s - loss: 0.2429 - accuracy: 0.8872 - val_loss: 11.4770 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03011: val_loss did not improve from 0.32861\n",
      "Epoch 3012/4000\n",
      "25/25 - 0s - loss: 0.2708 - accuracy: 0.8885 - val_loss: 12.4103 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 03012: val_loss did not improve from 0.32861\n",
      "Epoch 3013/4000\n",
      "25/25 - 0s - loss: 0.2866 - accuracy: 0.8690 - val_loss: 11.7681 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03013: val_loss did not improve from 0.32861\n",
      "Epoch 3014/4000\n",
      "25/25 - 0s - loss: 0.2445 - accuracy: 0.8911 - val_loss: 10.2866 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03014: val_loss did not improve from 0.32861\n",
      "Epoch 3015/4000\n",
      "25/25 - 0s - loss: 0.2411 - accuracy: 0.8962 - val_loss: 10.8016 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03015: val_loss did not improve from 0.32861\n",
      "Epoch 3016/4000\n",
      "25/25 - 0s - loss: 0.2378 - accuracy: 0.8872 - val_loss: 10.8415 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03016: val_loss did not improve from 0.32861\n",
      "Epoch 3017/4000\n",
      "25/25 - 0s - loss: 0.2322 - accuracy: 0.8923 - val_loss: 11.2313 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03017: val_loss did not improve from 0.32861\n",
      "Epoch 3018/4000\n",
      "25/25 - 0s - loss: 0.2274 - accuracy: 0.9027 - val_loss: 11.5075 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03018: val_loss did not improve from 0.32861\n",
      "Epoch 3019/4000\n",
      "25/25 - 0s - loss: 0.2307 - accuracy: 0.9040 - val_loss: 11.4692 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03019: val_loss did not improve from 0.32861\n",
      "Epoch 3020/4000\n",
      "25/25 - 0s - loss: 0.2332 - accuracy: 0.8885 - val_loss: 11.5084 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03020: val_loss did not improve from 0.32861\n",
      "Epoch 3021/4000\n",
      "25/25 - 1s - loss: 0.2356 - accuracy: 0.8975 - val_loss: 11.6630 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03021: val_loss did not improve from 0.32861\n",
      "Epoch 3022/4000\n",
      "25/25 - 0s - loss: 0.2305 - accuracy: 0.8988 - val_loss: 12.0558 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03022: val_loss did not improve from 0.32861\n",
      "Epoch 3023/4000\n",
      "25/25 - 0s - loss: 0.2403 - accuracy: 0.8936 - val_loss: 12.9605 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03023: val_loss did not improve from 0.32861\n",
      "Epoch 3024/4000\n",
      "25/25 - 0s - loss: 0.2304 - accuracy: 0.8988 - val_loss: 12.8784 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03024: val_loss did not improve from 0.32861\n",
      "Epoch 3025/4000\n",
      "25/25 - 0s - loss: 0.2363 - accuracy: 0.8988 - val_loss: 12.5796 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03025: val_loss did not improve from 0.32861\n",
      "Epoch 3026/4000\n",
      "25/25 - 0s - loss: 0.2408 - accuracy: 0.8846 - val_loss: 12.6382 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03026: val_loss did not improve from 0.32861\n",
      "Epoch 3027/4000\n",
      "25/25 - 0s - loss: 0.2369 - accuracy: 0.8988 - val_loss: 12.8136 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03027: val_loss did not improve from 0.32861\n",
      "Epoch 3028/4000\n",
      "25/25 - 0s - loss: 0.2310 - accuracy: 0.9027 - val_loss: 12.7852 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03028: val_loss did not improve from 0.32861\n",
      "Epoch 3029/4000\n",
      "25/25 - 0s - loss: 0.2283 - accuracy: 0.8975 - val_loss: 12.8068 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03029: val_loss did not improve from 0.32861\n",
      "Epoch 3030/4000\n",
      "25/25 - 0s - loss: 0.2294 - accuracy: 0.8988 - val_loss: 12.7808 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03030: val_loss did not improve from 0.32861\n",
      "Epoch 3031/4000\n",
      "25/25 - 0s - loss: 0.2321 - accuracy: 0.9014 - val_loss: 12.4741 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03031: val_loss did not improve from 0.32861\n",
      "Epoch 3032/4000\n",
      "25/25 - 0s - loss: 0.2422 - accuracy: 0.8859 - val_loss: 12.2013 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03032: val_loss did not improve from 0.32861\n",
      "Epoch 3033/4000\n",
      "25/25 - 0s - loss: 0.2303 - accuracy: 0.8975 - val_loss: 12.0414 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03033: val_loss did not improve from 0.32861\n",
      "Epoch 3034/4000\n",
      "25/25 - 0s - loss: 0.2362 - accuracy: 0.8911 - val_loss: 11.9552 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03034: val_loss did not improve from 0.32861\n",
      "Epoch 3035/4000\n",
      "25/25 - 0s - loss: 0.2299 - accuracy: 0.9001 - val_loss: 12.1113 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03035: val_loss did not improve from 0.32861\n",
      "Epoch 3036/4000\n",
      "25/25 - 0s - loss: 0.2417 - accuracy: 0.8936 - val_loss: 12.1115 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03036: val_loss did not improve from 0.32861\n",
      "Epoch 3037/4000\n",
      "25/25 - 0s - loss: 0.2335 - accuracy: 0.8988 - val_loss: 11.8207 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03037: val_loss did not improve from 0.32861\n",
      "Epoch 3038/4000\n",
      "25/25 - 0s - loss: 0.2279 - accuracy: 0.8949 - val_loss: 11.9504 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03038: val_loss did not improve from 0.32861\n",
      "Epoch 3039/4000\n",
      "25/25 - 0s - loss: 0.2275 - accuracy: 0.8975 - val_loss: 11.9705 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03039: val_loss did not improve from 0.32861\n",
      "Epoch 3040/4000\n",
      "25/25 - 0s - loss: 0.2291 - accuracy: 0.9001 - val_loss: 12.1530 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03040: val_loss did not improve from 0.32861\n",
      "Epoch 3041/4000\n",
      "25/25 - 0s - loss: 0.2263 - accuracy: 0.9027 - val_loss: 12.2349 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03041: val_loss did not improve from 0.32861\n",
      "Epoch 3042/4000\n",
      "25/25 - 0s - loss: 0.2287 - accuracy: 0.8936 - val_loss: 11.8804 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03042: val_loss did not improve from 0.32861\n",
      "Epoch 3043/4000\n",
      "25/25 - 0s - loss: 0.2617 - accuracy: 0.8833 - val_loss: 11.5682 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03043: val_loss did not improve from 0.32861\n",
      "Epoch 3044/4000\n",
      "25/25 - 0s - loss: 0.2464 - accuracy: 0.8936 - val_loss: 12.2712 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03044: val_loss did not improve from 0.32861\n",
      "Epoch 3045/4000\n",
      "25/25 - 0s - loss: 0.2454 - accuracy: 0.8949 - val_loss: 13.1763 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03045: val_loss did not improve from 0.32861\n",
      "Epoch 3046/4000\n",
      "25/25 - 0s - loss: 0.2380 - accuracy: 0.8898 - val_loss: 12.8378 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03046: val_loss did not improve from 0.32861\n",
      "Epoch 3047/4000\n",
      "25/25 - 0s - loss: 0.2623 - accuracy: 0.8833 - val_loss: 12.7606 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03047: val_loss did not improve from 0.32861\n",
      "Epoch 3048/4000\n",
      "25/25 - 0s - loss: 0.2333 - accuracy: 0.8923 - val_loss: 12.9634 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03048: val_loss did not improve from 0.32861\n",
      "Epoch 3049/4000\n",
      "25/25 - 0s - loss: 0.2334 - accuracy: 0.8936 - val_loss: 13.1917 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03049: val_loss did not improve from 0.32861\n",
      "Epoch 3050/4000\n",
      "25/25 - 0s - loss: 0.2287 - accuracy: 0.9001 - val_loss: 13.2395 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03050: val_loss did not improve from 0.32861\n",
      "Epoch 3051/4000\n",
      "25/25 - 0s - loss: 0.2254 - accuracy: 0.9014 - val_loss: 13.1124 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03051: val_loss did not improve from 0.32861\n",
      "Epoch 3052/4000\n",
      "25/25 - 0s - loss: 0.2302 - accuracy: 0.9066 - val_loss: 13.0472 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 03052: val_loss did not improve from 0.32861\n",
      "Epoch 3053/4000\n",
      "25/25 - 0s - loss: 0.2248 - accuracy: 0.9040 - val_loss: 12.9602 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03053: val_loss did not improve from 0.32861\n",
      "Epoch 3054/4000\n",
      "25/25 - 0s - loss: 0.2378 - accuracy: 0.8975 - val_loss: 13.0256 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03054: val_loss did not improve from 0.32861\n",
      "Epoch 3055/4000\n",
      "25/25 - 0s - loss: 0.2286 - accuracy: 0.8975 - val_loss: 13.2180 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03055: val_loss did not improve from 0.32861\n",
      "Epoch 3056/4000\n",
      "25/25 - 0s - loss: 0.2357 - accuracy: 0.8885 - val_loss: 13.4271 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03056: val_loss did not improve from 0.32861\n",
      "Epoch 3057/4000\n",
      "25/25 - 0s - loss: 0.2265 - accuracy: 0.8988 - val_loss: 12.8520 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03057: val_loss did not improve from 0.32861\n",
      "Epoch 3058/4000\n",
      "25/25 - 0s - loss: 0.2262 - accuracy: 0.9001 - val_loss: 13.2393 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03058: val_loss did not improve from 0.32861\n",
      "Epoch 3059/4000\n",
      "25/25 - 0s - loss: 0.2306 - accuracy: 0.8885 - val_loss: 12.6344 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03059: val_loss did not improve from 0.32861\n",
      "Epoch 3060/4000\n",
      "25/25 - 0s - loss: 0.2289 - accuracy: 0.9014 - val_loss: 12.8352 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03060: val_loss did not improve from 0.32861\n",
      "Epoch 3061/4000\n",
      "25/25 - 0s - loss: 0.2255 - accuracy: 0.9014 - val_loss: 13.0048 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03061: val_loss did not improve from 0.32861\n",
      "Epoch 3062/4000\n",
      "25/25 - 0s - loss: 0.2242 - accuracy: 0.8988 - val_loss: 13.2369 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03062: val_loss did not improve from 0.32861\n",
      "Epoch 3063/4000\n",
      "25/25 - 0s - loss: 0.2404 - accuracy: 0.8911 - val_loss: 12.6799 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03063: val_loss did not improve from 0.32861\n",
      "Epoch 3064/4000\n",
      "25/25 - 0s - loss: 0.2317 - accuracy: 0.9040 - val_loss: 12.3674 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03064: val_loss did not improve from 0.32861\n",
      "Epoch 3065/4000\n",
      "25/25 - 0s - loss: 0.2692 - accuracy: 0.8716 - val_loss: 12.2136 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03065: val_loss did not improve from 0.32861\n",
      "Epoch 3066/4000\n",
      "25/25 - 0s - loss: 0.2398 - accuracy: 0.8807 - val_loss: 12.4681 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03066: val_loss did not improve from 0.32861\n",
      "Epoch 3067/4000\n",
      "25/25 - 0s - loss: 0.2393 - accuracy: 0.8898 - val_loss: 12.5898 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03067: val_loss did not improve from 0.32861\n",
      "Epoch 3068/4000\n",
      "25/25 - 0s - loss: 0.2322 - accuracy: 0.8988 - val_loss: 11.9611 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03068: val_loss did not improve from 0.32861\n",
      "Epoch 3069/4000\n",
      "25/25 - 0s - loss: 0.2324 - accuracy: 0.8949 - val_loss: 12.0447 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03069: val_loss did not improve from 0.32861\n",
      "Epoch 3070/4000\n",
      "25/25 - 0s - loss: 0.2297 - accuracy: 0.9014 - val_loss: 12.5081 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03070: val_loss did not improve from 0.32861\n",
      "Epoch 3071/4000\n",
      "25/25 - 0s - loss: 0.2304 - accuracy: 0.8975 - val_loss: 12.6871 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03071: val_loss did not improve from 0.32861\n",
      "Epoch 3072/4000\n",
      "25/25 - 0s - loss: 0.2282 - accuracy: 0.9027 - val_loss: 13.6799 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03072: val_loss did not improve from 0.32861\n",
      "Epoch 3073/4000\n",
      "25/25 - 0s - loss: 0.2481 - accuracy: 0.8911 - val_loss: 12.1413 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 03073: val_loss did not improve from 0.32861\n",
      "Epoch 3074/4000\n",
      "25/25 - 0s - loss: 0.2775 - accuracy: 0.8768 - val_loss: 11.3324 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03074: val_loss did not improve from 0.32861\n",
      "Epoch 3075/4000\n",
      "25/25 - 0s - loss: 0.3077 - accuracy: 0.8340 - val_loss: 12.0663 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03075: val_loss did not improve from 0.32861\n",
      "Epoch 3076/4000\n",
      "25/25 - 0s - loss: 0.2689 - accuracy: 0.8521 - val_loss: 11.3356 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03076: val_loss did not improve from 0.32861\n",
      "Epoch 3077/4000\n",
      "25/25 - 0s - loss: 0.2633 - accuracy: 0.8729 - val_loss: 12.0089 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03077: val_loss did not improve from 0.32861\n",
      "Epoch 3078/4000\n",
      "25/25 - 0s - loss: 0.3784 - accuracy: 0.8586 - val_loss: 9.6609 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 03078: val_loss did not improve from 0.32861\n",
      "Epoch 3079/4000\n",
      "25/25 - 0s - loss: 0.2707 - accuracy: 0.8833 - val_loss: 10.4633 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03079: val_loss did not improve from 0.32861\n",
      "Epoch 3080/4000\n",
      "25/25 - 0s - loss: 0.2928 - accuracy: 0.8651 - val_loss: 11.3383 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03080: val_loss did not improve from 0.32861\n",
      "Epoch 3081/4000\n",
      "25/25 - 0s - loss: 0.2703 - accuracy: 0.8755 - val_loss: 11.4055 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03081: val_loss did not improve from 0.32861\n",
      "Epoch 3082/4000\n",
      "25/25 - 0s - loss: 0.3021 - accuracy: 0.8690 - val_loss: 9.8517 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03082: val_loss did not improve from 0.32861\n",
      "Epoch 3083/4000\n",
      "25/25 - 0s - loss: 0.2967 - accuracy: 0.8547 - val_loss: 8.9061 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03083: val_loss did not improve from 0.32861\n",
      "Epoch 3084/4000\n",
      "25/25 - 0s - loss: 0.2770 - accuracy: 0.8651 - val_loss: 9.3796 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03084: val_loss did not improve from 0.32861\n",
      "Epoch 3085/4000\n",
      "25/25 - 0s - loss: 0.2574 - accuracy: 0.8911 - val_loss: 9.7758 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03085: val_loss did not improve from 0.32861\n",
      "Epoch 3086/4000\n",
      "25/25 - 0s - loss: 0.2564 - accuracy: 0.8807 - val_loss: 9.6351 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03086: val_loss did not improve from 0.32861\n",
      "Epoch 3087/4000\n",
      "25/25 - 0s - loss: 0.2456 - accuracy: 0.8898 - val_loss: 9.6410 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03087: val_loss did not improve from 0.32861\n",
      "Epoch 3088/4000\n",
      "25/25 - 0s - loss: 0.2480 - accuracy: 0.8898 - val_loss: 9.9310 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03088: val_loss did not improve from 0.32861\n",
      "Epoch 3089/4000\n",
      "25/25 - 0s - loss: 0.2427 - accuracy: 0.8949 - val_loss: 10.0731 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03089: val_loss did not improve from 0.32861\n",
      "Epoch 3090/4000\n",
      "25/25 - 0s - loss: 0.2429 - accuracy: 0.8898 - val_loss: 10.3194 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03090: val_loss did not improve from 0.32861\n",
      "Epoch 3091/4000\n",
      "25/25 - 0s - loss: 0.2437 - accuracy: 0.8923 - val_loss: 10.2702 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03091: val_loss did not improve from 0.32861\n",
      "Epoch 3092/4000\n",
      "25/25 - 0s - loss: 0.2462 - accuracy: 0.8949 - val_loss: 10.4239 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03092: val_loss did not improve from 0.32861\n",
      "Epoch 3093/4000\n",
      "25/25 - 0s - loss: 0.2422 - accuracy: 0.8936 - val_loss: 10.6909 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03093: val_loss did not improve from 0.32861\n",
      "Epoch 3094/4000\n",
      "25/25 - 0s - loss: 0.2522 - accuracy: 0.8807 - val_loss: 11.0164 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03094: val_loss did not improve from 0.32861\n",
      "Epoch 3095/4000\n",
      "25/25 - 0s - loss: 0.2422 - accuracy: 0.8911 - val_loss: 10.8559 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03095: val_loss did not improve from 0.32861\n",
      "Epoch 3096/4000\n",
      "25/25 - 0s - loss: 0.2459 - accuracy: 0.8898 - val_loss: 10.8540 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03096: val_loss did not improve from 0.32861\n",
      "Epoch 3097/4000\n",
      "25/25 - 0s - loss: 0.2434 - accuracy: 0.8988 - val_loss: 10.8353 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03097: val_loss did not improve from 0.32861\n",
      "Epoch 3098/4000\n",
      "25/25 - 0s - loss: 0.2445 - accuracy: 0.8911 - val_loss: 10.8484 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03098: val_loss did not improve from 0.32861\n",
      "Epoch 3099/4000\n",
      "25/25 - 0s - loss: 0.2446 - accuracy: 0.9014 - val_loss: 10.8690 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03099: val_loss did not improve from 0.32861\n",
      "Epoch 3100/4000\n",
      "25/25 - 0s - loss: 0.2444 - accuracy: 0.8911 - val_loss: 11.0148 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03100: val_loss did not improve from 0.32861\n",
      "Epoch 3101/4000\n",
      "25/25 - 0s - loss: 0.2448 - accuracy: 0.8949 - val_loss: 11.1307 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03101: val_loss did not improve from 0.32861\n",
      "Epoch 3102/4000\n",
      "25/25 - 0s - loss: 0.2407 - accuracy: 0.8975 - val_loss: 11.2949 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03102: val_loss did not improve from 0.32861\n",
      "Epoch 3103/4000\n",
      "25/25 - 0s - loss: 0.2474 - accuracy: 0.8846 - val_loss: 11.0704 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03103: val_loss did not improve from 0.32861\n",
      "Epoch 3104/4000\n",
      "25/25 - 0s - loss: 0.2476 - accuracy: 0.8846 - val_loss: 10.8478 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03104: val_loss did not improve from 0.32861\n",
      "Epoch 3105/4000\n",
      "25/25 - 0s - loss: 0.2465 - accuracy: 0.8898 - val_loss: 11.0144 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03105: val_loss did not improve from 0.32861\n",
      "Epoch 3106/4000\n",
      "25/25 - 0s - loss: 0.2434 - accuracy: 0.8923 - val_loss: 11.0999 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03106: val_loss did not improve from 0.32861\n",
      "Epoch 3107/4000\n",
      "25/25 - 0s - loss: 0.2442 - accuracy: 0.8846 - val_loss: 10.8403 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03107: val_loss did not improve from 0.32861\n",
      "Epoch 3108/4000\n",
      "25/25 - 0s - loss: 0.2457 - accuracy: 0.8936 - val_loss: 10.8603 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03108: val_loss did not improve from 0.32861\n",
      "Epoch 3109/4000\n",
      "25/25 - 0s - loss: 0.2507 - accuracy: 0.8898 - val_loss: 11.3570 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03109: val_loss did not improve from 0.32861\n",
      "Epoch 3110/4000\n",
      "25/25 - 0s - loss: 0.2534 - accuracy: 0.8807 - val_loss: 10.2817 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03110: val_loss did not improve from 0.32861\n",
      "Epoch 3111/4000\n",
      "25/25 - 0s - loss: 0.2687 - accuracy: 0.8794 - val_loss: 9.7648 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03111: val_loss did not improve from 0.32861\n",
      "Epoch 3112/4000\n",
      "25/25 - 0s - loss: 0.2744 - accuracy: 0.8677 - val_loss: 9.8481 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03112: val_loss did not improve from 0.32861\n",
      "Epoch 3113/4000\n",
      "25/25 - 0s - loss: 0.2537 - accuracy: 0.8988 - val_loss: 11.5708 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03113: val_loss did not improve from 0.32861\n",
      "Epoch 3114/4000\n",
      "25/25 - 0s - loss: 0.3091 - accuracy: 0.8586 - val_loss: 11.6125 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03114: val_loss did not improve from 0.32861\n",
      "Epoch 3115/4000\n",
      "25/25 - 0s - loss: 0.2596 - accuracy: 0.8807 - val_loss: 12.0525 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03115: val_loss did not improve from 0.32861\n",
      "Epoch 3116/4000\n",
      "25/25 - 0s - loss: 0.2453 - accuracy: 0.8988 - val_loss: 11.6300 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03116: val_loss did not improve from 0.32861\n",
      "Epoch 3117/4000\n",
      "25/25 - 0s - loss: 0.2417 - accuracy: 0.8923 - val_loss: 11.5484 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03117: val_loss did not improve from 0.32861\n",
      "Epoch 3118/4000\n",
      "25/25 - 0s - loss: 0.2464 - accuracy: 0.8833 - val_loss: 11.3922 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03118: val_loss did not improve from 0.32861\n",
      "Epoch 3119/4000\n",
      "25/25 - 0s - loss: 0.2419 - accuracy: 0.8911 - val_loss: 11.7803 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03119: val_loss did not improve from 0.32861\n",
      "Epoch 3120/4000\n",
      "25/25 - 0s - loss: 0.2398 - accuracy: 0.8962 - val_loss: 11.8047 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03120: val_loss did not improve from 0.32861\n",
      "Epoch 3121/4000\n",
      "25/25 - 0s - loss: 0.2382 - accuracy: 0.8962 - val_loss: 11.8620 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03121: val_loss did not improve from 0.32861\n",
      "Epoch 3122/4000\n",
      "25/25 - 0s - loss: 0.2403 - accuracy: 0.8936 - val_loss: 11.9566 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03122: val_loss did not improve from 0.32861\n",
      "Epoch 3123/4000\n",
      "25/25 - 0s - loss: 0.2457 - accuracy: 0.8833 - val_loss: 12.1472 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03123: val_loss did not improve from 0.32861\n",
      "Epoch 3124/4000\n",
      "25/25 - 0s - loss: 0.2450 - accuracy: 0.8911 - val_loss: 12.2171 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03124: val_loss did not improve from 0.32861\n",
      "Epoch 3125/4000\n",
      "25/25 - 0s - loss: 0.2386 - accuracy: 0.8923 - val_loss: 12.1392 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03125: val_loss did not improve from 0.32861\n",
      "Epoch 3126/4000\n",
      "25/25 - 0s - loss: 0.2560 - accuracy: 0.8872 - val_loss: 11.8802 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03126: val_loss did not improve from 0.32861\n",
      "Epoch 3127/4000\n",
      "25/25 - 0s - loss: 0.2396 - accuracy: 0.8962 - val_loss: 11.9632 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03127: val_loss did not improve from 0.32861\n",
      "Epoch 3128/4000\n",
      "25/25 - 0s - loss: 0.2479 - accuracy: 0.8833 - val_loss: 11.6311 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03128: val_loss did not improve from 0.32861\n",
      "Epoch 3129/4000\n",
      "25/25 - 0s - loss: 0.2450 - accuracy: 0.8859 - val_loss: 11.4207 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03129: val_loss did not improve from 0.32861\n",
      "Epoch 3130/4000\n",
      "25/25 - 0s - loss: 0.2561 - accuracy: 0.8911 - val_loss: 11.5442 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03130: val_loss did not improve from 0.32861\n",
      "Epoch 3131/4000\n",
      "25/25 - 0s - loss: 0.2581 - accuracy: 0.8781 - val_loss: 11.6079 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03131: val_loss did not improve from 0.32861\n",
      "Epoch 3132/4000\n",
      "25/25 - 0s - loss: 0.2460 - accuracy: 0.8949 - val_loss: 12.9190 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03132: val_loss did not improve from 0.32861\n",
      "Epoch 3133/4000\n",
      "25/25 - 0s - loss: 0.2544 - accuracy: 0.8859 - val_loss: 15.3573 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03133: val_loss did not improve from 0.32861\n",
      "Epoch 3134/4000\n",
      "25/25 - 0s - loss: 0.2528 - accuracy: 0.8859 - val_loss: 11.6659 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03134: val_loss did not improve from 0.32861\n",
      "Epoch 3135/4000\n",
      "25/25 - 0s - loss: 0.2404 - accuracy: 0.8911 - val_loss: 11.9870 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03135: val_loss did not improve from 0.32861\n",
      "Epoch 3136/4000\n",
      "25/25 - 0s - loss: 0.2412 - accuracy: 0.8911 - val_loss: 11.9698 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03136: val_loss did not improve from 0.32861\n",
      "Epoch 3137/4000\n",
      "25/25 - 0s - loss: 0.2420 - accuracy: 0.8923 - val_loss: 11.8160 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03137: val_loss did not improve from 0.32861\n",
      "Epoch 3138/4000\n",
      "25/25 - 0s - loss: 0.2749 - accuracy: 0.8833 - val_loss: 12.6446 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03138: val_loss did not improve from 0.32861\n",
      "Epoch 3139/4000\n",
      "25/25 - 0s - loss: 0.2531 - accuracy: 0.8872 - val_loss: 13.1012 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03139: val_loss did not improve from 0.32861\n",
      "Epoch 3140/4000\n",
      "25/25 - 0s - loss: 0.2464 - accuracy: 0.8794 - val_loss: 13.4291 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03140: val_loss did not improve from 0.32861\n",
      "Epoch 3141/4000\n",
      "25/25 - 0s - loss: 0.2844 - accuracy: 0.8690 - val_loss: 13.6984 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03141: val_loss did not improve from 0.32861\n",
      "Epoch 3142/4000\n",
      "25/25 - 0s - loss: 0.2494 - accuracy: 0.8923 - val_loss: 13.6934 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03142: val_loss did not improve from 0.32861\n",
      "Epoch 3143/4000\n",
      "25/25 - 0s - loss: 0.2590 - accuracy: 0.8807 - val_loss: 13.7333 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03143: val_loss did not improve from 0.32861\n",
      "Epoch 3144/4000\n",
      "25/25 - 0s - loss: 0.2436 - accuracy: 0.8885 - val_loss: 14.1473 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03144: val_loss did not improve from 0.32861\n",
      "Epoch 3145/4000\n",
      "25/25 - 0s - loss: 0.2759 - accuracy: 0.8846 - val_loss: 14.5143 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03145: val_loss did not improve from 0.32861\n",
      "Epoch 3146/4000\n",
      "25/25 - 0s - loss: 0.2996 - accuracy: 0.8677 - val_loss: 17.6284 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 03146: val_loss did not improve from 0.32861\n",
      "Epoch 3147/4000\n",
      "25/25 - 0s - loss: 0.4187 - accuracy: 0.8392 - val_loss: 19.4949 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03147: val_loss did not improve from 0.32861\n",
      "Epoch 3148/4000\n",
      "25/25 - 0s - loss: 0.3465 - accuracy: 0.8314 - val_loss: 20.3094 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 03148: val_loss did not improve from 0.32861\n",
      "Epoch 3149/4000\n",
      "25/25 - 0s - loss: 0.2972 - accuracy: 0.8586 - val_loss: 18.6714 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03149: val_loss did not improve from 0.32861\n",
      "Epoch 3150/4000\n",
      "25/25 - 0s - loss: 0.2828 - accuracy: 0.8703 - val_loss: 18.4400 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03150: val_loss did not improve from 0.32861\n",
      "Epoch 3151/4000\n",
      "25/25 - 0s - loss: 0.2859 - accuracy: 0.8833 - val_loss: 18.1924 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03151: val_loss did not improve from 0.32861\n",
      "Epoch 3152/4000\n",
      "25/25 - 0s - loss: 0.2787 - accuracy: 0.8729 - val_loss: 21.9477 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03152: val_loss did not improve from 0.32861\n",
      "Epoch 3153/4000\n",
      "25/25 - 0s - loss: 0.2881 - accuracy: 0.8638 - val_loss: 22.6683 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03153: val_loss did not improve from 0.32861\n",
      "Epoch 3154/4000\n",
      "25/25 - 0s - loss: 0.3016 - accuracy: 0.8534 - val_loss: 20.7346 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03154: val_loss did not improve from 0.32861\n",
      "Epoch 3155/4000\n",
      "25/25 - 0s - loss: 0.2786 - accuracy: 0.8742 - val_loss: 20.8818 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03155: val_loss did not improve from 0.32861\n",
      "Epoch 3156/4000\n",
      "25/25 - 0s - loss: 0.2578 - accuracy: 0.8872 - val_loss: 21.3527 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03156: val_loss did not improve from 0.32861\n",
      "Epoch 3157/4000\n",
      "25/25 - 0s - loss: 0.2701 - accuracy: 0.8820 - val_loss: 21.9695 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03157: val_loss did not improve from 0.32861\n",
      "Epoch 3158/4000\n",
      "25/25 - 0s - loss: 0.2550 - accuracy: 0.8885 - val_loss: 22.9923 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03158: val_loss did not improve from 0.32861\n",
      "Epoch 3159/4000\n",
      "25/25 - 0s - loss: 0.2514 - accuracy: 0.8885 - val_loss: 23.4144 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03159: val_loss did not improve from 0.32861\n",
      "Epoch 3160/4000\n",
      "25/25 - 0s - loss: 0.2471 - accuracy: 0.8949 - val_loss: 23.4768 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03160: val_loss did not improve from 0.32861\n",
      "Epoch 3161/4000\n",
      "25/25 - 0s - loss: 0.2952 - accuracy: 0.8612 - val_loss: 23.6833 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03161: val_loss did not improve from 0.32861\n",
      "Epoch 3162/4000\n",
      "25/25 - 0s - loss: 0.2817 - accuracy: 0.8703 - val_loss: 24.3192 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03162: val_loss did not improve from 0.32861\n",
      "Epoch 3163/4000\n",
      "25/25 - 0s - loss: 0.2579 - accuracy: 0.8807 - val_loss: 24.5234 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03163: val_loss did not improve from 0.32861\n",
      "Epoch 3164/4000\n",
      "25/25 - 0s - loss: 0.2550 - accuracy: 0.8885 - val_loss: 24.8704 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03164: val_loss did not improve from 0.32861\n",
      "Epoch 3165/4000\n",
      "25/25 - 0s - loss: 0.2494 - accuracy: 0.8898 - val_loss: 25.2807 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03165: val_loss did not improve from 0.32861\n",
      "Epoch 3166/4000\n",
      "25/25 - 0s - loss: 0.2533 - accuracy: 0.8794 - val_loss: 25.1291 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03166: val_loss did not improve from 0.32861\n",
      "Epoch 3167/4000\n",
      "25/25 - 0s - loss: 0.2502 - accuracy: 0.8846 - val_loss: 25.7801 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03167: val_loss did not improve from 0.32861\n",
      "Epoch 3168/4000\n",
      "25/25 - 0s - loss: 0.2513 - accuracy: 0.8923 - val_loss: 25.1480 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03168: val_loss did not improve from 0.32861\n",
      "Epoch 3169/4000\n",
      "25/25 - 0s - loss: 0.2500 - accuracy: 0.8898 - val_loss: 25.1547 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03169: val_loss did not improve from 0.32861\n",
      "Epoch 3170/4000\n",
      "25/25 - 0s - loss: 0.2499 - accuracy: 0.8885 - val_loss: 25.8188 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03170: val_loss did not improve from 0.32861\n",
      "Epoch 3171/4000\n",
      "25/25 - 0s - loss: 0.2460 - accuracy: 0.8872 - val_loss: 25.5004 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03171: val_loss did not improve from 0.32861\n",
      "Epoch 3172/4000\n",
      "25/25 - 0s - loss: 0.2473 - accuracy: 0.8885 - val_loss: 25.8255 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03172: val_loss did not improve from 0.32861\n",
      "Epoch 3173/4000\n",
      "25/25 - 0s - loss: 0.2446 - accuracy: 0.8949 - val_loss: 25.8277 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03173: val_loss did not improve from 0.32861\n",
      "Epoch 3174/4000\n",
      "25/25 - 0s - loss: 0.2474 - accuracy: 0.8898 - val_loss: 27.3915 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03174: val_loss did not improve from 0.32861\n",
      "Epoch 3175/4000\n",
      "25/25 - 0s - loss: 0.2548 - accuracy: 0.8846 - val_loss: 26.8119 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03175: val_loss did not improve from 0.32861\n",
      "Epoch 3176/4000\n",
      "25/25 - 0s - loss: 0.2443 - accuracy: 0.8975 - val_loss: 27.0040 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03176: val_loss did not improve from 0.32861\n",
      "Epoch 3177/4000\n",
      "25/25 - 0s - loss: 0.2441 - accuracy: 0.8949 - val_loss: 27.9226 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 03177: val_loss did not improve from 0.32861\n",
      "Epoch 3178/4000\n",
      "25/25 - 0s - loss: 0.2459 - accuracy: 0.8923 - val_loss: 28.4491 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03178: val_loss did not improve from 0.32861\n",
      "Epoch 3179/4000\n",
      "25/25 - 0s - loss: 0.2459 - accuracy: 0.8949 - val_loss: 27.4523 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03179: val_loss did not improve from 0.32861\n",
      "Epoch 3180/4000\n",
      "25/25 - 0s - loss: 0.2427 - accuracy: 0.8885 - val_loss: 28.1218 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03180: val_loss did not improve from 0.32861\n",
      "Epoch 3181/4000\n",
      "25/25 - 0s - loss: 0.3500 - accuracy: 0.8807 - val_loss: 19.6893 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03181: val_loss did not improve from 0.32861\n",
      "Epoch 3182/4000\n",
      "25/25 - 0s - loss: 0.2949 - accuracy: 0.8742 - val_loss: 8.8125 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03182: val_loss did not improve from 0.32861\n",
      "Epoch 3183/4000\n",
      "25/25 - 0s - loss: 0.2762 - accuracy: 0.8859 - val_loss: 4.9901 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03183: val_loss did not improve from 0.32861\n",
      "Epoch 3184/4000\n",
      "25/25 - 0s - loss: 0.2807 - accuracy: 0.8742 - val_loss: 4.3899 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03184: val_loss did not improve from 0.32861\n",
      "Epoch 3185/4000\n",
      "25/25 - 0s - loss: 0.2779 - accuracy: 0.8781 - val_loss: 4.7861 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03185: val_loss did not improve from 0.32861\n",
      "Epoch 3186/4000\n",
      "25/25 - 0s - loss: 0.2700 - accuracy: 0.8755 - val_loss: 5.7950 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03186: val_loss did not improve from 0.32861\n",
      "Epoch 3187/4000\n",
      "25/25 - 0s - loss: 0.2734 - accuracy: 0.8794 - val_loss: 4.9865 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03187: val_loss did not improve from 0.32861\n",
      "Epoch 3188/4000\n",
      "25/25 - 0s - loss: 0.2677 - accuracy: 0.8846 - val_loss: 4.4826 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03188: val_loss did not improve from 0.32861\n",
      "Epoch 3189/4000\n",
      "25/25 - 0s - loss: 0.2612 - accuracy: 0.8846 - val_loss: 4.5286 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03189: val_loss did not improve from 0.32861\n",
      "Epoch 3190/4000\n",
      "25/25 - 0s - loss: 0.2619 - accuracy: 0.8911 - val_loss: 4.7814 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03190: val_loss did not improve from 0.32861\n",
      "Epoch 3191/4000\n",
      "25/25 - 0s - loss: 0.2668 - accuracy: 0.8833 - val_loss: 5.1170 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03191: val_loss did not improve from 0.32861\n",
      "Epoch 3192/4000\n",
      "25/25 - 0s - loss: 0.2625 - accuracy: 0.8820 - val_loss: 5.0720 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03192: val_loss did not improve from 0.32861\n",
      "Epoch 3193/4000\n",
      "25/25 - 0s - loss: 0.2666 - accuracy: 0.8820 - val_loss: 6.0871 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03193: val_loss did not improve from 0.32861\n",
      "Epoch 3194/4000\n",
      "25/25 - 0s - loss: 0.3601 - accuracy: 0.8807 - val_loss: 6.3525 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 03194: val_loss did not improve from 0.32861\n",
      "Epoch 3195/4000\n",
      "25/25 - 0s - loss: 0.3703 - accuracy: 0.8534 - val_loss: 9.1675 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 03195: val_loss did not improve from 0.32861\n",
      "Epoch 3196/4000\n",
      "25/25 - 0s - loss: 0.3849 - accuracy: 0.8249 - val_loss: 31.5234 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 03196: val_loss did not improve from 0.32861\n",
      "Epoch 3197/4000\n",
      "25/25 - 0s - loss: 0.3199 - accuracy: 0.8262 - val_loss: 29.5976 - val_accuracy: 0.7772\n",
      "\n",
      "Epoch 03197: val_loss did not improve from 0.32861\n",
      "Epoch 3198/4000\n",
      "25/25 - 0s - loss: 0.2875 - accuracy: 0.8444 - val_loss: 29.9457 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03198: val_loss did not improve from 0.32861\n",
      "Epoch 3199/4000\n",
      "25/25 - 0s - loss: 0.2802 - accuracy: 0.8534 - val_loss: 28.9158 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03199: val_loss did not improve from 0.32861\n",
      "Epoch 3200/4000\n",
      "25/25 - 0s - loss: 0.2626 - accuracy: 0.8677 - val_loss: 27.3856 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03200: val_loss did not improve from 0.32861\n",
      "Epoch 3201/4000\n",
      "25/25 - 0s - loss: 0.2461 - accuracy: 0.9001 - val_loss: 27.1125 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03201: val_loss did not improve from 0.32861\n",
      "Epoch 3202/4000\n",
      "25/25 - 0s - loss: 0.2593 - accuracy: 0.8768 - val_loss: 28.7285 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03202: val_loss did not improve from 0.32861\n",
      "Epoch 3203/4000\n",
      "25/25 - 0s - loss: 0.2435 - accuracy: 0.8949 - val_loss: 28.8215 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03203: val_loss did not improve from 0.32861\n",
      "Epoch 3204/4000\n",
      "25/25 - 0s - loss: 0.2368 - accuracy: 0.8898 - val_loss: 28.5226 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03204: val_loss did not improve from 0.32861\n",
      "Epoch 3205/4000\n",
      "25/25 - 0s - loss: 0.2366 - accuracy: 0.8911 - val_loss: 28.3537 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03205: val_loss did not improve from 0.32861\n",
      "Epoch 3206/4000\n",
      "25/25 - 0s - loss: 0.2351 - accuracy: 0.8936 - val_loss: 27.3561 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03206: val_loss did not improve from 0.32861\n",
      "Epoch 3207/4000\n",
      "25/25 - 0s - loss: 0.2372 - accuracy: 0.8962 - val_loss: 27.1274 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03207: val_loss did not improve from 0.32861\n",
      "Epoch 3208/4000\n",
      "25/25 - 0s - loss: 0.2376 - accuracy: 0.8936 - val_loss: 27.7341 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03208: val_loss did not improve from 0.32861\n",
      "Epoch 3209/4000\n",
      "25/25 - 0s - loss: 0.2408 - accuracy: 0.8885 - val_loss: 27.7437 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03209: val_loss did not improve from 0.32861\n",
      "Epoch 3210/4000\n",
      "25/25 - 0s - loss: 0.2497 - accuracy: 0.8911 - val_loss: 27.5936 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03210: val_loss did not improve from 0.32861\n",
      "Epoch 3211/4000\n",
      "25/25 - 0s - loss: 0.2482 - accuracy: 0.8898 - val_loss: 32.2053 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03211: val_loss did not improve from 0.32861\n",
      "Epoch 3212/4000\n",
      "25/25 - 0s - loss: 0.2386 - accuracy: 0.8975 - val_loss: 29.5046 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03212: val_loss did not improve from 0.32861\n",
      "Epoch 3213/4000\n",
      "25/25 - 0s - loss: 0.2364 - accuracy: 0.8962 - val_loss: 29.2345 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03213: val_loss did not improve from 0.32861\n",
      "Epoch 3214/4000\n",
      "25/25 - 0s - loss: 0.2444 - accuracy: 0.8872 - val_loss: 29.6367 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03214: val_loss did not improve from 0.32861\n",
      "Epoch 3215/4000\n",
      "25/25 - 0s - loss: 0.2364 - accuracy: 0.8949 - val_loss: 29.7634 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03215: val_loss did not improve from 0.32861\n",
      "Epoch 3216/4000\n",
      "25/25 - 0s - loss: 0.2303 - accuracy: 0.9001 - val_loss: 29.8443 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03216: val_loss did not improve from 0.32861\n",
      "Epoch 3217/4000\n",
      "25/25 - 0s - loss: 0.2369 - accuracy: 0.8936 - val_loss: 29.7568 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03217: val_loss did not improve from 0.32861\n",
      "Epoch 3218/4000\n",
      "25/25 - 0s - loss: 0.2378 - accuracy: 0.8949 - val_loss: 30.5171 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03218: val_loss did not improve from 0.32861\n",
      "Epoch 3219/4000\n",
      "25/25 - 0s - loss: 0.2321 - accuracy: 0.8988 - val_loss: 30.5862 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03219: val_loss did not improve from 0.32861\n",
      "Epoch 3220/4000\n",
      "25/25 - 0s - loss: 0.2303 - accuracy: 0.9001 - val_loss: 30.2114 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03220: val_loss did not improve from 0.32861\n",
      "Epoch 3221/4000\n",
      "25/25 - 0s - loss: 0.2400 - accuracy: 0.8936 - val_loss: 30.4047 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03221: val_loss did not improve from 0.32861\n",
      "Epoch 3222/4000\n",
      "25/25 - 0s - loss: 0.2340 - accuracy: 0.9001 - val_loss: 30.8264 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03222: val_loss did not improve from 0.32861\n",
      "Epoch 3223/4000\n",
      "25/25 - 0s - loss: 0.2272 - accuracy: 0.9001 - val_loss: 32.1897 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03223: val_loss did not improve from 0.32861\n",
      "Epoch 3224/4000\n",
      "25/25 - 0s - loss: 0.2358 - accuracy: 0.8923 - val_loss: 31.2879 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03224: val_loss did not improve from 0.32861\n",
      "Epoch 3225/4000\n",
      "25/25 - 0s - loss: 0.2292 - accuracy: 0.9001 - val_loss: 31.5945 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03225: val_loss did not improve from 0.32861\n",
      "Epoch 3226/4000\n",
      "25/25 - 0s - loss: 0.2302 - accuracy: 0.8949 - val_loss: 31.8793 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03226: val_loss did not improve from 0.32861\n",
      "Epoch 3227/4000\n",
      "25/25 - 0s - loss: 0.2320 - accuracy: 0.8975 - val_loss: 31.8712 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03227: val_loss did not improve from 0.32861\n",
      "Epoch 3228/4000\n",
      "25/25 - 0s - loss: 0.2286 - accuracy: 0.9027 - val_loss: 32.7855 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03228: val_loss did not improve from 0.32861\n",
      "Epoch 3229/4000\n",
      "25/25 - 0s - loss: 0.2295 - accuracy: 0.9001 - val_loss: 32.9089 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03229: val_loss did not improve from 0.32861\n",
      "Epoch 3230/4000\n",
      "25/25 - 0s - loss: 0.2295 - accuracy: 0.9014 - val_loss: 33.0232 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03230: val_loss did not improve from 0.32861\n",
      "Epoch 3231/4000\n",
      "25/25 - 0s - loss: 0.2409 - accuracy: 0.8911 - val_loss: 32.3320 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03231: val_loss did not improve from 0.32861\n",
      "Epoch 3232/4000\n",
      "25/25 - 0s - loss: 0.2309 - accuracy: 0.9040 - val_loss: 30.7637 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03232: val_loss did not improve from 0.32861\n",
      "Epoch 3233/4000\n",
      "25/25 - 0s - loss: 0.2386 - accuracy: 0.8962 - val_loss: 29.9612 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03233: val_loss did not improve from 0.32861\n",
      "Epoch 3234/4000\n",
      "25/25 - 0s - loss: 0.2509 - accuracy: 0.8898 - val_loss: 22.2192 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03234: val_loss did not improve from 0.32861\n",
      "Epoch 3235/4000\n",
      "25/25 - 0s - loss: 0.2589 - accuracy: 0.8833 - val_loss: 20.9136 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03235: val_loss did not improve from 0.32861\n",
      "Epoch 3236/4000\n",
      "25/25 - 0s - loss: 0.2383 - accuracy: 0.9027 - val_loss: 20.8722 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03236: val_loss did not improve from 0.32861\n",
      "Epoch 3237/4000\n",
      "25/25 - 0s - loss: 0.2347 - accuracy: 0.8962 - val_loss: 22.4957 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03237: val_loss did not improve from 0.32861\n",
      "Epoch 3238/4000\n",
      "25/25 - 0s - loss: 0.2310 - accuracy: 0.9027 - val_loss: 22.6536 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03238: val_loss did not improve from 0.32861\n",
      "Epoch 3239/4000\n",
      "25/25 - 0s - loss: 0.2325 - accuracy: 0.9001 - val_loss: 22.7009 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03239: val_loss did not improve from 0.32861\n",
      "Epoch 3240/4000\n",
      "25/25 - 0s - loss: 0.2353 - accuracy: 0.8885 - val_loss: 22.4864 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03240: val_loss did not improve from 0.32861\n",
      "Epoch 3241/4000\n",
      "25/25 - 0s - loss: 0.2285 - accuracy: 0.8975 - val_loss: 22.5611 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03241: val_loss did not improve from 0.32861\n",
      "Epoch 3242/4000\n",
      "25/25 - 0s - loss: 0.2292 - accuracy: 0.8962 - val_loss: 22.4852 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03242: val_loss did not improve from 0.32861\n",
      "Epoch 3243/4000\n",
      "25/25 - 0s - loss: 0.2383 - accuracy: 0.8911 - val_loss: 23.0436 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03243: val_loss did not improve from 0.32861\n",
      "Epoch 3244/4000\n",
      "25/25 - 0s - loss: 0.2314 - accuracy: 0.9014 - val_loss: 23.8682 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03244: val_loss did not improve from 0.32861\n",
      "Epoch 3245/4000\n",
      "25/25 - 0s - loss: 0.2290 - accuracy: 0.9014 - val_loss: 23.6778 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03245: val_loss did not improve from 0.32861\n",
      "Epoch 3246/4000\n",
      "25/25 - 0s - loss: 0.2273 - accuracy: 0.8988 - val_loss: 24.0192 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03246: val_loss did not improve from 0.32861\n",
      "Epoch 3247/4000\n",
      "25/25 - 0s - loss: 0.2328 - accuracy: 0.8975 - val_loss: 25.2989 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03247: val_loss did not improve from 0.32861\n",
      "Epoch 3248/4000\n",
      "25/25 - 0s - loss: 0.2300 - accuracy: 0.8988 - val_loss: 24.2778 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03248: val_loss did not improve from 0.32861\n",
      "Epoch 3249/4000\n",
      "25/25 - 0s - loss: 0.2320 - accuracy: 0.8988 - val_loss: 24.3605 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03249: val_loss did not improve from 0.32861\n",
      "Epoch 3250/4000\n",
      "25/25 - 0s - loss: 0.2283 - accuracy: 0.8975 - val_loss: 24.5458 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03250: val_loss did not improve from 0.32861\n",
      "Epoch 3251/4000\n",
      "25/25 - 0s - loss: 0.2278 - accuracy: 0.9027 - val_loss: 24.8928 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03251: val_loss did not improve from 0.32861\n",
      "Epoch 3252/4000\n",
      "25/25 - 0s - loss: 0.2309 - accuracy: 0.9079 - val_loss: 24.9660 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03252: val_loss did not improve from 0.32861\n",
      "Epoch 3253/4000\n",
      "25/25 - 0s - loss: 0.2431 - accuracy: 0.8949 - val_loss: 24.7366 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03253: val_loss did not improve from 0.32861\n",
      "Epoch 3254/4000\n",
      "25/25 - 0s - loss: 0.2352 - accuracy: 0.8936 - val_loss: 25.7499 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03254: val_loss did not improve from 0.32861\n",
      "Epoch 3255/4000\n",
      "25/25 - 0s - loss: 0.2340 - accuracy: 0.9014 - val_loss: 24.1723 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03255: val_loss did not improve from 0.32861\n",
      "Epoch 3256/4000\n",
      "25/25 - 0s - loss: 0.2327 - accuracy: 0.8949 - val_loss: 25.1459 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03256: val_loss did not improve from 0.32861\n",
      "Epoch 3257/4000\n",
      "25/25 - 0s - loss: 0.2338 - accuracy: 0.8975 - val_loss: 26.0813 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03257: val_loss did not improve from 0.32861\n",
      "Epoch 3258/4000\n",
      "25/25 - 0s - loss: 0.2312 - accuracy: 0.8988 - val_loss: 26.7789 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03258: val_loss did not improve from 0.32861\n",
      "Epoch 3259/4000\n",
      "25/25 - 0s - loss: 0.2313 - accuracy: 0.9001 - val_loss: 26.9430 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03259: val_loss did not improve from 0.32861\n",
      "Epoch 3260/4000\n",
      "25/25 - 0s - loss: 0.2256 - accuracy: 0.9014 - val_loss: 27.1809 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03260: val_loss did not improve from 0.32861\n",
      "Epoch 3261/4000\n",
      "25/25 - 0s - loss: 0.2487 - accuracy: 0.8936 - val_loss: 28.9815 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03261: val_loss did not improve from 0.32861\n",
      "Epoch 3262/4000\n",
      "25/25 - 0s - loss: 0.2326 - accuracy: 0.8988 - val_loss: 28.1517 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03262: val_loss did not improve from 0.32861\n",
      "Epoch 3263/4000\n",
      "25/25 - 0s - loss: 0.2346 - accuracy: 0.8962 - val_loss: 27.9699 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03263: val_loss did not improve from 0.32861\n",
      "Epoch 3264/4000\n",
      "25/25 - 0s - loss: 0.2313 - accuracy: 0.9014 - val_loss: 28.4687 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03264: val_loss did not improve from 0.32861\n",
      "Epoch 3265/4000\n",
      "25/25 - 0s - loss: 0.2302 - accuracy: 0.8975 - val_loss: 28.1567 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03265: val_loss did not improve from 0.32861\n",
      "Epoch 3266/4000\n",
      "25/25 - 0s - loss: 0.2317 - accuracy: 0.8923 - val_loss: 26.4650 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03266: val_loss did not improve from 0.32861\n",
      "Epoch 3267/4000\n",
      "25/25 - 0s - loss: 0.2384 - accuracy: 0.8911 - val_loss: 27.4496 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03267: val_loss did not improve from 0.32861\n",
      "Epoch 3268/4000\n",
      "25/25 - 0s - loss: 0.2278 - accuracy: 0.9027 - val_loss: 27.6084 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03268: val_loss did not improve from 0.32861\n",
      "Epoch 3269/4000\n",
      "25/25 - 0s - loss: 0.2360 - accuracy: 0.8949 - val_loss: 28.1442 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03269: val_loss did not improve from 0.32861\n",
      "Epoch 3270/4000\n",
      "25/25 - 0s - loss: 0.2321 - accuracy: 0.8962 - val_loss: 28.5684 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03270: val_loss did not improve from 0.32861\n",
      "Epoch 3271/4000\n",
      "25/25 - 0s - loss: 0.2298 - accuracy: 0.9001 - val_loss: 28.8408 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03271: val_loss did not improve from 0.32861\n",
      "Epoch 3272/4000\n",
      "25/25 - 0s - loss: 0.2277 - accuracy: 0.8988 - val_loss: 28.6884 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03272: val_loss did not improve from 0.32861\n",
      "Epoch 3273/4000\n",
      "25/25 - 0s - loss: 0.2334 - accuracy: 0.8936 - val_loss: 28.6752 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03273: val_loss did not improve from 0.32861\n",
      "Epoch 3274/4000\n",
      "25/25 - 0s - loss: 0.2361 - accuracy: 0.8885 - val_loss: 30.6284 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03274: val_loss did not improve from 0.32861\n",
      "Epoch 3275/4000\n",
      "25/25 - 0s - loss: 0.2266 - accuracy: 0.8962 - val_loss: 30.3424 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03275: val_loss did not improve from 0.32861\n",
      "Epoch 3276/4000\n",
      "25/25 - 0s - loss: 0.2327 - accuracy: 0.8962 - val_loss: 28.8188 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03276: val_loss did not improve from 0.32861\n",
      "Epoch 3277/4000\n",
      "25/25 - 0s - loss: 0.2361 - accuracy: 0.8936 - val_loss: 26.7393 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03277: val_loss did not improve from 0.32861\n",
      "Epoch 3278/4000\n",
      "25/25 - 0s - loss: 0.2354 - accuracy: 0.9001 - val_loss: 28.0045 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03278: val_loss did not improve from 0.32861\n",
      "Epoch 3279/4000\n",
      "25/25 - 0s - loss: 0.2264 - accuracy: 0.9001 - val_loss: 27.8571 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03279: val_loss did not improve from 0.32861\n",
      "Epoch 3280/4000\n",
      "25/25 - 0s - loss: 0.2293 - accuracy: 0.8962 - val_loss: 28.8370 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03280: val_loss did not improve from 0.32861\n",
      "Epoch 3281/4000\n",
      "25/25 - 0s - loss: 0.2374 - accuracy: 0.8962 - val_loss: 28.8043 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03281: val_loss did not improve from 0.32861\n",
      "Epoch 3282/4000\n",
      "25/25 - 0s - loss: 0.2294 - accuracy: 0.9001 - val_loss: 29.9142 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03282: val_loss did not improve from 0.32861\n",
      "Epoch 3283/4000\n",
      "25/25 - 0s - loss: 0.2275 - accuracy: 0.9027 - val_loss: 30.2141 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03283: val_loss did not improve from 0.32861\n",
      "Epoch 3284/4000\n",
      "25/25 - 0s - loss: 0.2272 - accuracy: 0.8923 - val_loss: 29.9321 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03284: val_loss did not improve from 0.32861\n",
      "Epoch 3285/4000\n",
      "25/25 - 0s - loss: 0.2281 - accuracy: 0.8949 - val_loss: 30.9579 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03285: val_loss did not improve from 0.32861\n",
      "Epoch 3286/4000\n",
      "25/25 - 0s - loss: 0.2317 - accuracy: 0.8936 - val_loss: 32.4378 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03286: val_loss did not improve from 0.32861\n",
      "Epoch 3287/4000\n",
      "25/25 - 0s - loss: 0.2314 - accuracy: 0.9027 - val_loss: 32.2256 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03287: val_loss did not improve from 0.32861\n",
      "Epoch 3288/4000\n",
      "25/25 - 0s - loss: 0.2262 - accuracy: 0.8988 - val_loss: 31.5394 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03288: val_loss did not improve from 0.32861\n",
      "Epoch 3289/4000\n",
      "25/25 - 0s - loss: 0.2340 - accuracy: 0.8962 - val_loss: 31.3327 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03289: val_loss did not improve from 0.32861\n",
      "Epoch 3290/4000\n",
      "25/25 - 0s - loss: 0.2269 - accuracy: 0.9014 - val_loss: 30.9725 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03290: val_loss did not improve from 0.32861\n",
      "Epoch 3291/4000\n",
      "25/25 - 0s - loss: 0.2292 - accuracy: 0.8988 - val_loss: 31.5420 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03291: val_loss did not improve from 0.32861\n",
      "Epoch 3292/4000\n",
      "25/25 - 0s - loss: 0.2283 - accuracy: 0.9027 - val_loss: 32.8410 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03292: val_loss did not improve from 0.32861\n",
      "Epoch 3293/4000\n",
      "25/25 - 0s - loss: 0.2267 - accuracy: 0.9001 - val_loss: 33.1578 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03293: val_loss did not improve from 0.32861\n",
      "Epoch 3294/4000\n",
      "25/25 - 0s - loss: 0.2346 - accuracy: 0.9027 - val_loss: 32.6688 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03294: val_loss did not improve from 0.32861\n",
      "Epoch 3295/4000\n",
      "25/25 - 0s - loss: 0.2462 - accuracy: 0.8885 - val_loss: 30.5747 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03295: val_loss did not improve from 0.32861\n",
      "Epoch 3296/4000\n",
      "25/25 - 0s - loss: 0.2389 - accuracy: 0.8898 - val_loss: 31.7825 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03296: val_loss did not improve from 0.32861\n",
      "Epoch 3297/4000\n",
      "25/25 - 0s - loss: 0.2289 - accuracy: 0.9040 - val_loss: 32.4321 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03297: val_loss did not improve from 0.32861\n",
      "Epoch 3298/4000\n",
      "25/25 - 0s - loss: 0.2320 - accuracy: 0.8936 - val_loss: 31.4914 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03298: val_loss did not improve from 0.32861\n",
      "Epoch 3299/4000\n",
      "25/25 - 0s - loss: 0.2281 - accuracy: 0.8988 - val_loss: 32.8094 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03299: val_loss did not improve from 0.32861\n",
      "Epoch 3300/4000\n",
      "25/25 - 0s - loss: 0.2266 - accuracy: 0.9040 - val_loss: 32.5487 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03300: val_loss did not improve from 0.32861\n",
      "Epoch 3301/4000\n",
      "25/25 - 0s - loss: 0.2296 - accuracy: 0.9014 - val_loss: 32.2223 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03301: val_loss did not improve from 0.32861\n",
      "Epoch 3302/4000\n",
      "25/25 - 0s - loss: 0.2360 - accuracy: 0.8898 - val_loss: 31.9338 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03302: val_loss did not improve from 0.32861\n",
      "Epoch 3303/4000\n",
      "25/25 - 0s - loss: 0.2368 - accuracy: 0.9027 - val_loss: 32.0900 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03303: val_loss did not improve from 0.32861\n",
      "Epoch 3304/4000\n",
      "25/25 - 0s - loss: 0.2270 - accuracy: 0.9014 - val_loss: 32.2693 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03304: val_loss did not improve from 0.32861\n",
      "Epoch 3305/4000\n",
      "25/25 - 0s - loss: 0.2271 - accuracy: 0.9014 - val_loss: 31.4915 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03305: val_loss did not improve from 0.32861\n",
      "Epoch 3306/4000\n",
      "25/25 - 0s - loss: 0.2266 - accuracy: 0.9079 - val_loss: 32.2903 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03306: val_loss did not improve from 0.32861\n",
      "Epoch 3307/4000\n",
      "25/25 - 0s - loss: 0.2292 - accuracy: 0.9027 - val_loss: 30.4956 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03307: val_loss did not improve from 0.32861\n",
      "Epoch 3308/4000\n",
      "25/25 - 0s - loss: 0.2302 - accuracy: 0.9014 - val_loss: 30.4374 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03308: val_loss did not improve from 0.32861\n",
      "Epoch 3309/4000\n",
      "25/25 - 0s - loss: 0.2299 - accuracy: 0.8988 - val_loss: 29.9443 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03309: val_loss did not improve from 0.32861\n",
      "Epoch 3310/4000\n",
      "25/25 - 0s - loss: 0.2330 - accuracy: 0.8988 - val_loss: 30.8254 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03310: val_loss did not improve from 0.32861\n",
      "Epoch 3311/4000\n",
      "25/25 - 0s - loss: 0.2339 - accuracy: 0.8975 - val_loss: 30.9088 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03311: val_loss did not improve from 0.32861\n",
      "Epoch 3312/4000\n",
      "25/25 - 0s - loss: 0.2308 - accuracy: 0.8975 - val_loss: 31.4415 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03312: val_loss did not improve from 0.32861\n",
      "Epoch 3313/4000\n",
      "25/25 - 0s - loss: 0.2365 - accuracy: 0.8949 - val_loss: 30.0899 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03313: val_loss did not improve from 0.32861\n",
      "Epoch 3314/4000\n",
      "25/25 - 0s - loss: 0.2260 - accuracy: 0.9001 - val_loss: 29.8934 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03314: val_loss did not improve from 0.32861\n",
      "Epoch 3315/4000\n",
      "25/25 - 0s - loss: 0.2283 - accuracy: 0.9001 - val_loss: 31.6796 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03315: val_loss did not improve from 0.32861\n",
      "Epoch 3316/4000\n",
      "25/25 - 0s - loss: 0.2256 - accuracy: 0.9079 - val_loss: 31.6290 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03316: val_loss did not improve from 0.32861\n",
      "Epoch 3317/4000\n",
      "25/25 - 0s - loss: 0.2264 - accuracy: 0.9001 - val_loss: 31.9959 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03317: val_loss did not improve from 0.32861\n",
      "Epoch 3318/4000\n",
      "25/25 - 0s - loss: 0.2383 - accuracy: 0.8975 - val_loss: 32.2951 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03318: val_loss did not improve from 0.32861\n",
      "Epoch 3319/4000\n",
      "25/25 - 0s - loss: 0.2351 - accuracy: 0.8898 - val_loss: 31.5969 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03319: val_loss did not improve from 0.32861\n",
      "Epoch 3320/4000\n",
      "25/25 - 0s - loss: 0.2281 - accuracy: 0.8962 - val_loss: 31.4779 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03320: val_loss did not improve from 0.32861\n",
      "Epoch 3321/4000\n",
      "25/25 - 0s - loss: 0.2301 - accuracy: 0.8949 - val_loss: 31.1350 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03321: val_loss did not improve from 0.32861\n",
      "Epoch 3322/4000\n",
      "25/25 - 0s - loss: 0.2278 - accuracy: 0.9027 - val_loss: 29.7659 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03322: val_loss did not improve from 0.32861\n",
      "Epoch 3323/4000\n",
      "25/25 - 0s - loss: 0.2560 - accuracy: 0.8755 - val_loss: 31.6885 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03323: val_loss did not improve from 0.32861\n",
      "Epoch 3324/4000\n",
      "25/25 - 0s - loss: 0.2323 - accuracy: 0.9014 - val_loss: 31.4217 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03324: val_loss did not improve from 0.32861\n",
      "Epoch 3325/4000\n",
      "25/25 - 0s - loss: 0.2926 - accuracy: 0.8690 - val_loss: 28.6342 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03325: val_loss did not improve from 0.32861\n",
      "Epoch 3326/4000\n",
      "25/25 - 0s - loss: 0.2573 - accuracy: 0.8872 - val_loss: 28.1998 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03326: val_loss did not improve from 0.32861\n",
      "Epoch 3327/4000\n",
      "25/25 - 0s - loss: 0.2438 - accuracy: 0.8949 - val_loss: 28.2746 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03327: val_loss did not improve from 0.32861\n",
      "Epoch 3328/4000\n",
      "25/25 - 0s - loss: 0.2323 - accuracy: 0.8962 - val_loss: 29.5431 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03328: val_loss did not improve from 0.32861\n",
      "Epoch 3329/4000\n",
      "25/25 - 0s - loss: 0.2368 - accuracy: 0.8988 - val_loss: 28.2577 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03329: val_loss did not improve from 0.32861\n",
      "Epoch 3330/4000\n",
      "25/25 - 0s - loss: 0.2332 - accuracy: 0.8936 - val_loss: 29.7637 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03330: val_loss did not improve from 0.32861\n",
      "Epoch 3331/4000\n",
      "25/25 - 0s - loss: 0.2333 - accuracy: 0.8923 - val_loss: 30.3297 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03331: val_loss did not improve from 0.32861\n",
      "Epoch 3332/4000\n",
      "25/25 - 0s - loss: 0.2284 - accuracy: 0.9053 - val_loss: 30.6813 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03332: val_loss did not improve from 0.32861\n",
      "Epoch 3333/4000\n",
      "25/25 - 0s - loss: 0.2283 - accuracy: 0.8988 - val_loss: 29.9883 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03333: val_loss did not improve from 0.32861\n",
      "Epoch 3334/4000\n",
      "25/25 - 0s - loss: 0.2318 - accuracy: 0.9014 - val_loss: 30.0705 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03334: val_loss did not improve from 0.32861\n",
      "Epoch 3335/4000\n",
      "25/25 - 0s - loss: 0.2459 - accuracy: 0.8794 - val_loss: 31.4816 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03335: val_loss did not improve from 0.32861\n",
      "Epoch 3336/4000\n",
      "25/25 - 0s - loss: 0.2492 - accuracy: 0.8807 - val_loss: 32.4148 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03336: val_loss did not improve from 0.32861\n",
      "Epoch 3337/4000\n",
      "25/25 - 0s - loss: 0.2329 - accuracy: 0.8923 - val_loss: 33.3298 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03337: val_loss did not improve from 0.32861\n",
      "Epoch 3338/4000\n",
      "25/25 - 0s - loss: 0.2299 - accuracy: 0.8975 - val_loss: 32.5655 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03338: val_loss did not improve from 0.32861\n",
      "Epoch 3339/4000\n",
      "25/25 - 0s - loss: 0.2319 - accuracy: 0.9001 - val_loss: 32.2790 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03339: val_loss did not improve from 0.32861\n",
      "Epoch 3340/4000\n",
      "25/25 - 0s - loss: 0.2306 - accuracy: 0.8962 - val_loss: 31.7906 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03340: val_loss did not improve from 0.32861\n",
      "Epoch 3341/4000\n",
      "25/25 - 0s - loss: 0.2267 - accuracy: 0.9001 - val_loss: 31.6397 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03341: val_loss did not improve from 0.32861\n",
      "Epoch 3342/4000\n",
      "25/25 - 0s - loss: 0.2287 - accuracy: 0.8923 - val_loss: 32.0387 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03342: val_loss did not improve from 0.32861\n",
      "Epoch 3343/4000\n",
      "25/25 - 0s - loss: 0.2294 - accuracy: 0.8949 - val_loss: 31.9287 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03343: val_loss did not improve from 0.32861\n",
      "Epoch 3344/4000\n",
      "25/25 - 0s - loss: 0.2257 - accuracy: 0.9014 - val_loss: 29.6140 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03344: val_loss did not improve from 0.32861\n",
      "Epoch 3345/4000\n",
      "25/25 - 0s - loss: 0.2298 - accuracy: 0.8962 - val_loss: 28.4868 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03345: val_loss did not improve from 0.32861\n",
      "Epoch 3346/4000\n",
      "25/25 - 0s - loss: 0.2250 - accuracy: 0.9001 - val_loss: 29.0873 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03346: val_loss did not improve from 0.32861\n",
      "Epoch 3347/4000\n",
      "25/25 - 0s - loss: 0.2300 - accuracy: 0.9001 - val_loss: 28.7617 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03347: val_loss did not improve from 0.32861\n",
      "Epoch 3348/4000\n",
      "25/25 - 0s - loss: 0.2310 - accuracy: 0.8936 - val_loss: 38.3054 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03348: val_loss did not improve from 0.32861\n",
      "Epoch 3349/4000\n",
      "25/25 - 0s - loss: 0.2398 - accuracy: 0.8949 - val_loss: 40.2442 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03349: val_loss did not improve from 0.32861\n",
      "Epoch 3350/4000\n",
      "25/25 - 0s - loss: 0.2662 - accuracy: 0.8833 - val_loss: 39.6572 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03350: val_loss did not improve from 0.32861\n",
      "Epoch 3351/4000\n",
      "25/25 - 0s - loss: 0.2478 - accuracy: 0.8833 - val_loss: 35.4072 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03351: val_loss did not improve from 0.32861\n",
      "Epoch 3352/4000\n",
      "25/25 - 0s - loss: 0.2480 - accuracy: 0.8988 - val_loss: 21.9125 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03352: val_loss did not improve from 0.32861\n",
      "Epoch 3353/4000\n",
      "25/25 - 0s - loss: 0.6221 - accuracy: 0.9001 - val_loss: 14.8214 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03353: val_loss did not improve from 0.32861\n",
      "Epoch 3354/4000\n",
      "25/25 - 0s - loss: 0.6841 - accuracy: 0.8288 - val_loss: 4.5197 - val_accuracy: 0.7668\n",
      "\n",
      "Epoch 03354: val_loss did not improve from 0.32861\n",
      "Epoch 3355/4000\n",
      "25/25 - 0s - loss: 0.4516 - accuracy: 0.8158 - val_loss: 4.2763 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03355: val_loss did not improve from 0.32861\n",
      "Epoch 3356/4000\n",
      "25/25 - 0s - loss: 0.4048 - accuracy: 0.8379 - val_loss: 8.3497 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03356: val_loss did not improve from 0.32861\n",
      "Epoch 3357/4000\n",
      "25/25 - 0s - loss: 0.3585 - accuracy: 0.8521 - val_loss: 16.2497 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03357: val_loss did not improve from 0.32861\n",
      "Epoch 3358/4000\n",
      "25/25 - 0s - loss: 0.3307 - accuracy: 0.8690 - val_loss: 15.0066 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03358: val_loss did not improve from 0.32861\n",
      "Epoch 3359/4000\n",
      "25/25 - 0s - loss: 0.2930 - accuracy: 0.8742 - val_loss: 12.9840 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03359: val_loss did not improve from 0.32861\n",
      "Epoch 3360/4000\n",
      "25/25 - 0s - loss: 0.2963 - accuracy: 0.8755 - val_loss: 11.9651 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03360: val_loss did not improve from 0.32861\n",
      "Epoch 3361/4000\n",
      "25/25 - 0s - loss: 0.2945 - accuracy: 0.8716 - val_loss: 11.9660 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03361: val_loss did not improve from 0.32861\n",
      "Epoch 3362/4000\n",
      "25/25 - 0s - loss: 0.2910 - accuracy: 0.8703 - val_loss: 12.1640 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03362: val_loss did not improve from 0.32861\n",
      "Epoch 3363/4000\n",
      "25/25 - 0s - loss: 0.2919 - accuracy: 0.8586 - val_loss: 12.8313 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03363: val_loss did not improve from 0.32861\n",
      "Epoch 3364/4000\n",
      "25/25 - 0s - loss: 0.2848 - accuracy: 0.8807 - val_loss: 12.4651 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 03364: val_loss did not improve from 0.32861\n",
      "Epoch 3365/4000\n",
      "25/25 - 0s - loss: 0.2847 - accuracy: 0.8729 - val_loss: 12.2653 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03365: val_loss did not improve from 0.32861\n",
      "Epoch 3366/4000\n",
      "25/25 - 0s - loss: 0.2841 - accuracy: 0.8703 - val_loss: 13.0631 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03366: val_loss did not improve from 0.32861\n",
      "Epoch 3367/4000\n",
      "25/25 - 0s - loss: 0.2819 - accuracy: 0.8781 - val_loss: 13.0519 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03367: val_loss did not improve from 0.32861\n",
      "Epoch 3368/4000\n",
      "25/25 - 0s - loss: 0.2877 - accuracy: 0.8716 - val_loss: 12.7720 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 03368: val_loss did not improve from 0.32861\n",
      "Epoch 3369/4000\n",
      "25/25 - 0s - loss: 0.2798 - accuracy: 0.8833 - val_loss: 12.6504 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 03369: val_loss did not improve from 0.32861\n",
      "Epoch 3370/4000\n",
      "25/25 - 0s - loss: 0.2780 - accuracy: 0.8768 - val_loss: 13.0637 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03370: val_loss did not improve from 0.32861\n",
      "Epoch 3371/4000\n",
      "25/25 - 0s - loss: 0.2811 - accuracy: 0.8781 - val_loss: 13.0062 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 03371: val_loss did not improve from 0.32861\n",
      "Epoch 3372/4000\n",
      "25/25 - 0s - loss: 0.2654 - accuracy: 0.8820 - val_loss: 12.9472 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03372: val_loss did not improve from 0.32861\n",
      "Epoch 3373/4000\n",
      "25/25 - 0s - loss: 0.2686 - accuracy: 0.8846 - val_loss: 13.1593 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03373: val_loss did not improve from 0.32861\n",
      "Epoch 3374/4000\n",
      "25/25 - 0s - loss: 0.2648 - accuracy: 0.8833 - val_loss: 13.7539 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03374: val_loss did not improve from 0.32861\n",
      "Epoch 3375/4000\n",
      "25/25 - 0s - loss: 0.2657 - accuracy: 0.8898 - val_loss: 13.8918 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03375: val_loss did not improve from 0.32861\n",
      "Epoch 3376/4000\n",
      "25/25 - 0s - loss: 0.2850 - accuracy: 0.8820 - val_loss: 14.4675 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 03376: val_loss did not improve from 0.32861\n",
      "Epoch 3377/4000\n",
      "25/25 - 0s - loss: 0.2688 - accuracy: 0.8729 - val_loss: 14.4442 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03377: val_loss did not improve from 0.32861\n",
      "Epoch 3378/4000\n",
      "25/25 - 0s - loss: 0.3332 - accuracy: 0.8794 - val_loss: 12.2606 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 03378: val_loss did not improve from 0.32861\n",
      "Epoch 3379/4000\n",
      "25/25 - 0s - loss: 0.2671 - accuracy: 0.8833 - val_loss: 11.8171 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03379: val_loss did not improve from 0.32861\n",
      "Epoch 3380/4000\n",
      "25/25 - 0s - loss: 0.2656 - accuracy: 0.8755 - val_loss: 11.7581 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03380: val_loss did not improve from 0.32861\n",
      "Epoch 3381/4000\n",
      "25/25 - 0s - loss: 0.2653 - accuracy: 0.8898 - val_loss: 12.2595 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03381: val_loss did not improve from 0.32861\n",
      "Epoch 3382/4000\n",
      "25/25 - 0s - loss: 0.2659 - accuracy: 0.8781 - val_loss: 12.0759 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03382: val_loss did not improve from 0.32861\n",
      "Epoch 3383/4000\n",
      "25/25 - 0s - loss: 0.2633 - accuracy: 0.8885 - val_loss: 11.9098 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03383: val_loss did not improve from 0.32861\n",
      "Epoch 3384/4000\n",
      "25/25 - 0s - loss: 0.2810 - accuracy: 0.8755 - val_loss: 16.4105 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03384: val_loss did not improve from 0.32861\n",
      "Epoch 3385/4000\n",
      "25/25 - 0s - loss: 0.3167 - accuracy: 0.8418 - val_loss: 15.8130 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03385: val_loss did not improve from 0.32861\n",
      "Epoch 3386/4000\n",
      "25/25 - 0s - loss: 0.2859 - accuracy: 0.8690 - val_loss: 15.4187 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03386: val_loss did not improve from 0.32861\n",
      "Epoch 3387/4000\n",
      "25/25 - 0s - loss: 0.2773 - accuracy: 0.8820 - val_loss: 15.0925 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03387: val_loss did not improve from 0.32861\n",
      "Epoch 3388/4000\n",
      "25/25 - 0s - loss: 0.2993 - accuracy: 0.8794 - val_loss: 14.2113 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03388: val_loss did not improve from 0.32861\n",
      "Epoch 3389/4000\n",
      "25/25 - 0s - loss: 0.2723 - accuracy: 0.8833 - val_loss: 13.8322 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03389: val_loss did not improve from 0.32861\n",
      "Epoch 3390/4000\n",
      "25/25 - 0s - loss: 0.2902 - accuracy: 0.8651 - val_loss: 13.6783 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03390: val_loss did not improve from 0.32861\n",
      "Epoch 3391/4000\n",
      "25/25 - 0s - loss: 0.2802 - accuracy: 0.8703 - val_loss: 13.5942 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 03391: val_loss did not improve from 0.32861\n",
      "Epoch 3392/4000\n",
      "25/25 - 0s - loss: 0.2742 - accuracy: 0.8794 - val_loss: 15.6946 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03392: val_loss did not improve from 0.32861\n",
      "Epoch 3393/4000\n",
      "25/25 - 0s - loss: 0.2845 - accuracy: 0.8781 - val_loss: 15.2359 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03393: val_loss did not improve from 0.32861\n",
      "Epoch 3394/4000\n",
      "25/25 - 0s - loss: 0.2785 - accuracy: 0.8742 - val_loss: 14.9184 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03394: val_loss did not improve from 0.32861\n",
      "Epoch 3395/4000\n",
      "25/25 - 0s - loss: 0.2758 - accuracy: 0.8781 - val_loss: 14.9364 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03395: val_loss did not improve from 0.32861\n",
      "Epoch 3396/4000\n",
      "25/25 - 0s - loss: 0.2679 - accuracy: 0.8846 - val_loss: 14.8982 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03396: val_loss did not improve from 0.32861\n",
      "Epoch 3397/4000\n",
      "25/25 - 0s - loss: 0.2664 - accuracy: 0.8794 - val_loss: 15.0313 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03397: val_loss did not improve from 0.32861\n",
      "Epoch 3398/4000\n",
      "25/25 - 0s - loss: 0.2661 - accuracy: 0.8781 - val_loss: 14.7658 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03398: val_loss did not improve from 0.32861\n",
      "Epoch 3399/4000\n",
      "25/25 - 0s - loss: 0.2691 - accuracy: 0.8820 - val_loss: 14.8870 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03399: val_loss did not improve from 0.32861\n",
      "Epoch 3400/4000\n",
      "25/25 - 0s - loss: 0.2665 - accuracy: 0.8807 - val_loss: 14.7929 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03400: val_loss did not improve from 0.32861\n",
      "Epoch 3401/4000\n",
      "25/25 - 0s - loss: 0.2698 - accuracy: 0.8833 - val_loss: 14.7154 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03401: val_loss did not improve from 0.32861\n",
      "Epoch 3402/4000\n",
      "25/25 - 0s - loss: 0.2649 - accuracy: 0.8859 - val_loss: 14.7025 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03402: val_loss did not improve from 0.32861\n",
      "Epoch 3403/4000\n",
      "25/25 - 0s - loss: 0.2625 - accuracy: 0.8898 - val_loss: 14.7241 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03403: val_loss did not improve from 0.32861\n",
      "Epoch 3404/4000\n",
      "25/25 - 0s - loss: 0.2639 - accuracy: 0.8807 - val_loss: 14.4905 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03404: val_loss did not improve from 0.32861\n",
      "Epoch 3405/4000\n",
      "25/25 - 0s - loss: 0.2641 - accuracy: 0.8820 - val_loss: 14.3961 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03405: val_loss did not improve from 0.32861\n",
      "Epoch 3406/4000\n",
      "25/25 - 0s - loss: 0.2611 - accuracy: 0.8872 - val_loss: 14.4418 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03406: val_loss did not improve from 0.32861\n",
      "Epoch 3407/4000\n",
      "25/25 - 0s - loss: 0.2719 - accuracy: 0.8794 - val_loss: 14.4382 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03407: val_loss did not improve from 0.32861\n",
      "Epoch 3408/4000\n",
      "25/25 - 0s - loss: 0.2931 - accuracy: 0.8664 - val_loss: 13.9773 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03408: val_loss did not improve from 0.32861\n",
      "Epoch 3409/4000\n",
      "25/25 - 0s - loss: 0.2614 - accuracy: 0.8872 - val_loss: 13.7566 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03409: val_loss did not improve from 0.32861\n",
      "Epoch 3410/4000\n",
      "25/25 - 0s - loss: 0.2708 - accuracy: 0.8768 - val_loss: 13.5251 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03410: val_loss did not improve from 0.32861\n",
      "Epoch 3411/4000\n",
      "25/25 - 0s - loss: 0.2627 - accuracy: 0.8833 - val_loss: 13.8064 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03411: val_loss did not improve from 0.32861\n",
      "Epoch 3412/4000\n",
      "25/25 - 0s - loss: 0.2620 - accuracy: 0.8820 - val_loss: 14.1011 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03412: val_loss did not improve from 0.32861\n",
      "Epoch 3413/4000\n",
      "25/25 - 0s - loss: 0.2617 - accuracy: 0.8846 - val_loss: 14.2031 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03413: val_loss did not improve from 0.32861\n",
      "Epoch 3414/4000\n",
      "25/25 - 0s - loss: 0.2619 - accuracy: 0.8859 - val_loss: 14.0605 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03414: val_loss did not improve from 0.32861\n",
      "Epoch 3415/4000\n",
      "25/25 - 0s - loss: 0.2636 - accuracy: 0.8794 - val_loss: 14.1735 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03415: val_loss did not improve from 0.32861\n",
      "Epoch 3416/4000\n",
      "25/25 - 0s - loss: 0.2566 - accuracy: 0.8872 - val_loss: 14.4301 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03416: val_loss did not improve from 0.32861\n",
      "Epoch 3417/4000\n",
      "25/25 - 0s - loss: 0.2605 - accuracy: 0.8833 - val_loss: 14.2446 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03417: val_loss did not improve from 0.32861\n",
      "Epoch 3418/4000\n",
      "25/25 - 0s - loss: 0.2757 - accuracy: 0.8755 - val_loss: 14.1905 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03418: val_loss did not improve from 0.32861\n",
      "Epoch 3419/4000\n",
      "25/25 - 0s - loss: 0.2714 - accuracy: 0.8768 - val_loss: 14.1270 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03419: val_loss did not improve from 0.32861\n",
      "Epoch 3420/4000\n",
      "25/25 - 0s - loss: 0.2723 - accuracy: 0.8768 - val_loss: 14.4396 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03420: val_loss did not improve from 0.32861\n",
      "Epoch 3421/4000\n",
      "25/25 - 0s - loss: 0.2699 - accuracy: 0.8781 - val_loss: 14.4879 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03421: val_loss did not improve from 0.32861\n",
      "Epoch 3422/4000\n",
      "25/25 - 0s - loss: 0.2736 - accuracy: 0.8755 - val_loss: 14.4669 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03422: val_loss did not improve from 0.32861\n",
      "Epoch 3423/4000\n",
      "25/25 - 0s - loss: 0.2794 - accuracy: 0.8703 - val_loss: 16.4034 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03423: val_loss did not improve from 0.32861\n",
      "Epoch 3424/4000\n",
      "25/25 - 0s - loss: 0.4020 - accuracy: 0.8625 - val_loss: 10.8468 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 03424: val_loss did not improve from 0.32861\n",
      "Epoch 3425/4000\n",
      "25/25 - 0s - loss: 0.5222 - accuracy: 0.8716 - val_loss: 18.4964 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03425: val_loss did not improve from 0.32861\n",
      "Epoch 3426/4000\n",
      "25/25 - 0s - loss: 0.2889 - accuracy: 0.8690 - val_loss: 20.5111 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03426: val_loss did not improve from 0.32861\n",
      "Epoch 3427/4000\n",
      "25/25 - 0s - loss: 0.2686 - accuracy: 0.8846 - val_loss: 20.5664 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03427: val_loss did not improve from 0.32861\n",
      "Epoch 3428/4000\n",
      "25/25 - 0s - loss: 0.2776 - accuracy: 0.8846 - val_loss: 19.4290 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03428: val_loss did not improve from 0.32861\n",
      "Epoch 3429/4000\n",
      "25/25 - 0s - loss: 0.2692 - accuracy: 0.8755 - val_loss: 18.7979 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03429: val_loss did not improve from 0.32861\n",
      "Epoch 3430/4000\n",
      "25/25 - 0s - loss: 0.2633 - accuracy: 0.8872 - val_loss: 18.8265 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03430: val_loss did not improve from 0.32861\n",
      "Epoch 3431/4000\n",
      "25/25 - 0s - loss: 0.2652 - accuracy: 0.8794 - val_loss: 18.5331 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03431: val_loss did not improve from 0.32861\n",
      "Epoch 3432/4000\n",
      "25/25 - 0s - loss: 0.2638 - accuracy: 0.8820 - val_loss: 18.7130 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03432: val_loss did not improve from 0.32861\n",
      "Epoch 3433/4000\n",
      "25/25 - 0s - loss: 0.2635 - accuracy: 0.8846 - val_loss: 18.4569 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03433: val_loss did not improve from 0.32861\n",
      "Epoch 3434/4000\n",
      "25/25 - 0s - loss: 0.4307 - accuracy: 0.8418 - val_loss: 14.1301 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03434: val_loss did not improve from 0.32861\n",
      "Epoch 3435/4000\n",
      "25/25 - 0s - loss: 0.4053 - accuracy: 0.8716 - val_loss: 15.7720 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03435: val_loss did not improve from 0.32861\n",
      "Epoch 3436/4000\n",
      "25/25 - 0s - loss: 0.3501 - accuracy: 0.8703 - val_loss: 16.0992 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03436: val_loss did not improve from 0.32861\n",
      "Epoch 3437/4000\n",
      "25/25 - 0s - loss: 0.3320 - accuracy: 0.8677 - val_loss: 16.5419 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03437: val_loss did not improve from 0.32861\n",
      "Epoch 3438/4000\n",
      "25/25 - 0s - loss: 0.3096 - accuracy: 0.8729 - val_loss: 16.8258 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03438: val_loss did not improve from 0.32861\n",
      "Epoch 3439/4000\n",
      "25/25 - 0s - loss: 0.3525 - accuracy: 0.8677 - val_loss: 17.4358 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03439: val_loss did not improve from 0.32861\n",
      "Epoch 3440/4000\n",
      "25/25 - 0s - loss: 0.2901 - accuracy: 0.8742 - val_loss: 16.6826 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03440: val_loss did not improve from 0.32861\n",
      "Epoch 3441/4000\n",
      "25/25 - 0s - loss: 0.2767 - accuracy: 0.8846 - val_loss: 16.6800 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03441: val_loss did not improve from 0.32861\n",
      "Epoch 3442/4000\n",
      "25/25 - 0s - loss: 0.2763 - accuracy: 0.8859 - val_loss: 16.4270 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03442: val_loss did not improve from 0.32861\n",
      "Epoch 3443/4000\n",
      "25/25 - 0s - loss: 0.2988 - accuracy: 0.8690 - val_loss: 16.2819 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03443: val_loss did not improve from 0.32861\n",
      "Epoch 3444/4000\n",
      "25/25 - 0s - loss: 0.2772 - accuracy: 0.8885 - val_loss: 16.7036 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03444: val_loss did not improve from 0.32861\n",
      "Epoch 3445/4000\n",
      "25/25 - 0s - loss: 0.3495 - accuracy: 0.8534 - val_loss: 15.8588 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 03445: val_loss did not improve from 0.32861\n",
      "Epoch 3446/4000\n",
      "25/25 - 0s - loss: 0.2803 - accuracy: 0.8703 - val_loss: 14.4613 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03446: val_loss did not improve from 0.32861\n",
      "Epoch 3447/4000\n",
      "25/25 - 0s - loss: 0.2791 - accuracy: 0.8755 - val_loss: 14.7618 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03447: val_loss did not improve from 0.32861\n",
      "Epoch 3448/4000\n",
      "25/25 - 0s - loss: 0.2723 - accuracy: 0.8781 - val_loss: 11.9370 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03448: val_loss did not improve from 0.32861\n",
      "Epoch 3449/4000\n",
      "25/25 - 0s - loss: 0.2734 - accuracy: 0.8885 - val_loss: 12.8934 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03449: val_loss did not improve from 0.32861\n",
      "Epoch 3450/4000\n",
      "25/25 - 0s - loss: 0.3231 - accuracy: 0.8508 - val_loss: 13.3905 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03450: val_loss did not improve from 0.32861\n",
      "Epoch 3451/4000\n",
      "25/25 - 0s - loss: 0.2832 - accuracy: 0.8703 - val_loss: 14.1061 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03451: val_loss did not improve from 0.32861\n",
      "Epoch 3452/4000\n",
      "25/25 - 0s - loss: 0.2743 - accuracy: 0.8703 - val_loss: 14.1792 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03452: val_loss did not improve from 0.32861\n",
      "Epoch 3453/4000\n",
      "25/25 - 0s - loss: 0.2664 - accuracy: 0.8820 - val_loss: 14.2833 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03453: val_loss did not improve from 0.32861\n",
      "Epoch 3454/4000\n",
      "25/25 - 0s - loss: 0.2631 - accuracy: 0.8859 - val_loss: 14.3095 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03454: val_loss did not improve from 0.32861\n",
      "Epoch 3455/4000\n",
      "25/25 - 0s - loss: 0.2709 - accuracy: 0.8820 - val_loss: 14.6506 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03455: val_loss did not improve from 0.32861\n",
      "Epoch 3456/4000\n",
      "25/25 - 0s - loss: 0.2608 - accuracy: 0.8833 - val_loss: 14.6958 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03456: val_loss did not improve from 0.32861\n",
      "Epoch 3457/4000\n",
      "25/25 - 0s - loss: 0.2614 - accuracy: 0.8846 - val_loss: 14.8168 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03457: val_loss did not improve from 0.32861\n",
      "Epoch 3458/4000\n",
      "25/25 - 0s - loss: 0.2706 - accuracy: 0.8807 - val_loss: 15.0263 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03458: val_loss did not improve from 0.32861\n",
      "Epoch 3459/4000\n",
      "25/25 - 0s - loss: 0.2668 - accuracy: 0.8846 - val_loss: 14.6154 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03459: val_loss did not improve from 0.32861\n",
      "Epoch 3460/4000\n",
      "25/25 - 0s - loss: 0.2634 - accuracy: 0.8833 - val_loss: 14.8443 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03460: val_loss did not improve from 0.32861\n",
      "Epoch 3461/4000\n",
      "25/25 - 0s - loss: 0.2591 - accuracy: 0.8820 - val_loss: 15.7429 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03461: val_loss did not improve from 0.32861\n",
      "Epoch 3462/4000\n",
      "25/25 - 0s - loss: 0.2593 - accuracy: 0.8781 - val_loss: 15.8653 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03462: val_loss did not improve from 0.32861\n",
      "Epoch 3463/4000\n",
      "25/25 - 0s - loss: 0.2599 - accuracy: 0.8820 - val_loss: 16.0247 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03463: val_loss did not improve from 0.32861\n",
      "Epoch 3464/4000\n",
      "25/25 - 0s - loss: 0.2581 - accuracy: 0.8820 - val_loss: 16.3093 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03464: val_loss did not improve from 0.32861\n",
      "Epoch 3465/4000\n",
      "25/25 - 0s - loss: 0.2615 - accuracy: 0.8807 - val_loss: 16.3440 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03465: val_loss did not improve from 0.32861\n",
      "Epoch 3466/4000\n",
      "25/25 - 0s - loss: 0.2671 - accuracy: 0.8781 - val_loss: 16.3647 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03466: val_loss did not improve from 0.32861\n",
      "Epoch 3467/4000\n",
      "25/25 - 0s - loss: 0.2706 - accuracy: 0.8768 - val_loss: 16.1471 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03467: val_loss did not improve from 0.32861\n",
      "Epoch 3468/4000\n",
      "25/25 - 0s - loss: 0.2578 - accuracy: 0.8833 - val_loss: 16.1619 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03468: val_loss did not improve from 0.32861\n",
      "Epoch 3469/4000\n",
      "25/25 - 0s - loss: 0.2893 - accuracy: 0.8677 - val_loss: 16.2728 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03469: val_loss did not improve from 0.32861\n",
      "Epoch 3470/4000\n",
      "25/25 - 0s - loss: 0.2576 - accuracy: 0.8872 - val_loss: 16.6748 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03470: val_loss did not improve from 0.32861\n",
      "Epoch 3471/4000\n",
      "25/25 - 0s - loss: 0.2662 - accuracy: 0.8794 - val_loss: 16.3462 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03471: val_loss did not improve from 0.32861\n",
      "Epoch 3472/4000\n",
      "25/25 - 0s - loss: 0.2609 - accuracy: 0.8859 - val_loss: 16.6189 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03472: val_loss did not improve from 0.32861\n",
      "Epoch 3473/4000\n",
      "25/25 - 0s - loss: 0.2579 - accuracy: 0.8781 - val_loss: 16.9796 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03473: val_loss did not improve from 0.32861\n",
      "Epoch 3474/4000\n",
      "25/25 - 0s - loss: 0.2568 - accuracy: 0.8859 - val_loss: 17.1485 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03474: val_loss did not improve from 0.32861\n",
      "Epoch 3475/4000\n",
      "25/25 - 0s - loss: 0.2609 - accuracy: 0.8794 - val_loss: 17.6969 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03475: val_loss did not improve from 0.32861\n",
      "Epoch 3476/4000\n",
      "25/25 - 0s - loss: 0.2545 - accuracy: 0.8846 - val_loss: 17.7527 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03476: val_loss did not improve from 0.32861\n",
      "Epoch 3477/4000\n",
      "25/25 - 0s - loss: 0.2767 - accuracy: 0.8807 - val_loss: 17.7414 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03477: val_loss did not improve from 0.32861\n",
      "Epoch 3478/4000\n",
      "25/25 - 0s - loss: 0.2613 - accuracy: 0.8781 - val_loss: 17.5766 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03478: val_loss did not improve from 0.32861\n",
      "Epoch 3479/4000\n",
      "25/25 - 0s - loss: 0.2573 - accuracy: 0.8768 - val_loss: 17.8205 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03479: val_loss did not improve from 0.32861\n",
      "Epoch 3480/4000\n",
      "25/25 - 0s - loss: 0.2609 - accuracy: 0.8820 - val_loss: 18.0996 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03480: val_loss did not improve from 0.32861\n",
      "Epoch 3481/4000\n",
      "25/25 - 0s - loss: 0.2597 - accuracy: 0.8859 - val_loss: 18.1403 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03481: val_loss did not improve from 0.32861\n",
      "Epoch 3482/4000\n",
      "25/25 - 0s - loss: 0.2909 - accuracy: 0.8703 - val_loss: 17.9826 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03482: val_loss did not improve from 0.32861\n",
      "Epoch 3483/4000\n",
      "25/25 - 0s - loss: 0.2634 - accuracy: 0.8833 - val_loss: 18.3893 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03483: val_loss did not improve from 0.32861\n",
      "Epoch 3484/4000\n",
      "25/25 - 0s - loss: 0.2584 - accuracy: 0.8846 - val_loss: 18.7137 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03484: val_loss did not improve from 0.32861\n",
      "Epoch 3485/4000\n",
      "25/25 - 0s - loss: 0.2562 - accuracy: 0.8859 - val_loss: 18.9277 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03485: val_loss did not improve from 0.32861\n",
      "Epoch 3486/4000\n",
      "25/25 - 0s - loss: 0.2660 - accuracy: 0.8768 - val_loss: 19.2547 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03486: val_loss did not improve from 0.32861\n",
      "Epoch 3487/4000\n",
      "25/25 - 0s - loss: 0.2587 - accuracy: 0.8859 - val_loss: 19.3751 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03487: val_loss did not improve from 0.32861\n",
      "Epoch 3488/4000\n",
      "25/25 - 0s - loss: 0.2589 - accuracy: 0.8833 - val_loss: 19.6597 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03488: val_loss did not improve from 0.32861\n",
      "Epoch 3489/4000\n",
      "25/25 - 0s - loss: 0.2577 - accuracy: 0.8833 - val_loss: 20.0571 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03489: val_loss did not improve from 0.32861\n",
      "Epoch 3490/4000\n",
      "25/25 - 0s - loss: 0.2577 - accuracy: 0.8859 - val_loss: 20.3683 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03490: val_loss did not improve from 0.32861\n",
      "Epoch 3491/4000\n",
      "25/25 - 0s - loss: 0.2668 - accuracy: 0.8807 - val_loss: 19.8094 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03491: val_loss did not improve from 0.32861\n",
      "Epoch 3492/4000\n",
      "25/25 - 0s - loss: 0.2603 - accuracy: 0.8872 - val_loss: 20.0189 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03492: val_loss did not improve from 0.32861\n",
      "Epoch 3493/4000\n",
      "25/25 - 0s - loss: 0.2548 - accuracy: 0.8872 - val_loss: 20.4809 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03493: val_loss did not improve from 0.32861\n",
      "Epoch 3494/4000\n",
      "25/25 - 0s - loss: 0.2642 - accuracy: 0.8820 - val_loss: 22.7551 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03494: val_loss did not improve from 0.32861\n",
      "Epoch 3495/4000\n",
      "25/25 - 0s - loss: 0.2542 - accuracy: 0.8898 - val_loss: 23.2513 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03495: val_loss did not improve from 0.32861\n",
      "Epoch 3496/4000\n",
      "25/25 - 0s - loss: 0.2660 - accuracy: 0.8794 - val_loss: 23.2259 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03496: val_loss did not improve from 0.32861\n",
      "Epoch 3497/4000\n",
      "25/25 - 0s - loss: 0.2581 - accuracy: 0.8820 - val_loss: 23.3250 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03497: val_loss did not improve from 0.32861\n",
      "Epoch 3498/4000\n",
      "25/25 - 0s - loss: 0.2569 - accuracy: 0.8988 - val_loss: 23.4552 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03498: val_loss did not improve from 0.32861\n",
      "Epoch 3499/4000\n",
      "25/25 - 0s - loss: 0.2516 - accuracy: 0.8911 - val_loss: 23.6112 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03499: val_loss did not improve from 0.32861\n",
      "Epoch 3500/4000\n",
      "25/25 - 0s - loss: 0.2537 - accuracy: 0.8898 - val_loss: 23.5106 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03500: val_loss did not improve from 0.32861\n",
      "Epoch 3501/4000\n",
      "25/25 - 0s - loss: 0.2536 - accuracy: 0.8923 - val_loss: 24.0027 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03501: val_loss did not improve from 0.32861\n",
      "Epoch 3502/4000\n",
      "25/25 - 0s - loss: 0.2545 - accuracy: 0.8872 - val_loss: 24.5132 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03502: val_loss did not improve from 0.32861\n",
      "Epoch 3503/4000\n",
      "25/25 - 0s - loss: 0.2511 - accuracy: 0.8923 - val_loss: 24.3021 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03503: val_loss did not improve from 0.32861\n",
      "Epoch 3504/4000\n",
      "25/25 - 0s - loss: 0.2555 - accuracy: 0.8820 - val_loss: 23.6822 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03504: val_loss did not improve from 0.32861\n",
      "Epoch 3505/4000\n",
      "25/25 - 0s - loss: 0.2563 - accuracy: 0.8872 - val_loss: 23.9918 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03505: val_loss did not improve from 0.32861\n",
      "Epoch 3506/4000\n",
      "25/25 - 0s - loss: 0.2588 - accuracy: 0.8846 - val_loss: 23.5852 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03506: val_loss did not improve from 0.32861\n",
      "Epoch 3507/4000\n",
      "25/25 - 0s - loss: 0.2486 - accuracy: 0.8846 - val_loss: 23.5026 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03507: val_loss did not improve from 0.32861\n",
      "Epoch 3508/4000\n",
      "25/25 - 0s - loss: 0.2603 - accuracy: 0.8859 - val_loss: 23.8149 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03508: val_loss did not improve from 0.32861\n",
      "Epoch 3509/4000\n",
      "25/25 - 0s - loss: 0.2633 - accuracy: 0.8898 - val_loss: 24.4955 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03509: val_loss did not improve from 0.32861\n",
      "Epoch 3510/4000\n",
      "25/25 - 0s - loss: 0.2617 - accuracy: 0.8911 - val_loss: 24.4485 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03510: val_loss did not improve from 0.32861\n",
      "Epoch 3511/4000\n",
      "25/25 - 0s - loss: 0.2677 - accuracy: 0.8781 - val_loss: 23.1046 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03511: val_loss did not improve from 0.32861\n",
      "Epoch 3512/4000\n",
      "25/25 - 0s - loss: 0.2612 - accuracy: 0.8833 - val_loss: 23.3152 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03512: val_loss did not improve from 0.32861\n",
      "Epoch 3513/4000\n",
      "25/25 - 0s - loss: 0.2519 - accuracy: 0.8872 - val_loss: 23.5742 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03513: val_loss did not improve from 0.32861\n",
      "Epoch 3514/4000\n",
      "25/25 - 0s - loss: 0.2527 - accuracy: 0.8859 - val_loss: 23.6840 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03514: val_loss did not improve from 0.32861\n",
      "Epoch 3515/4000\n",
      "25/25 - 0s - loss: 0.2521 - accuracy: 0.8859 - val_loss: 24.0142 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03515: val_loss did not improve from 0.32861\n",
      "Epoch 3516/4000\n",
      "25/25 - 0s - loss: 0.2550 - accuracy: 0.8885 - val_loss: 24.4112 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03516: val_loss did not improve from 0.32861\n",
      "Epoch 3517/4000\n",
      "25/25 - 0s - loss: 0.2554 - accuracy: 0.8872 - val_loss: 24.5962 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03517: val_loss did not improve from 0.32861\n",
      "Epoch 3518/4000\n",
      "25/25 - 0s - loss: 0.2502 - accuracy: 0.8911 - val_loss: 23.3662 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03518: val_loss did not improve from 0.32861\n",
      "Epoch 3519/4000\n",
      "25/25 - 0s - loss: 0.2548 - accuracy: 0.8872 - val_loss: 23.4902 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03519: val_loss did not improve from 0.32861\n",
      "Epoch 3520/4000\n",
      "25/25 - 0s - loss: 0.2612 - accuracy: 0.8794 - val_loss: 23.5036 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03520: val_loss did not improve from 0.32861\n",
      "Epoch 3521/4000\n",
      "25/25 - 0s - loss: 0.2532 - accuracy: 0.8911 - val_loss: 23.8235 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03521: val_loss did not improve from 0.32861\n",
      "Epoch 3522/4000\n",
      "25/25 - 0s - loss: 0.2508 - accuracy: 0.8936 - val_loss: 23.9839 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03522: val_loss did not improve from 0.32861\n",
      "Epoch 3523/4000\n",
      "25/25 - 0s - loss: 0.2495 - accuracy: 0.8859 - val_loss: 23.8087 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03523: val_loss did not improve from 0.32861\n",
      "Epoch 3524/4000\n",
      "25/25 - 0s - loss: 0.2492 - accuracy: 0.8859 - val_loss: 24.3297 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03524: val_loss did not improve from 0.32861\n",
      "Epoch 3525/4000\n",
      "25/25 - 0s - loss: 0.2518 - accuracy: 0.8911 - val_loss: 24.5395 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03525: val_loss did not improve from 0.32861\n",
      "Epoch 3526/4000\n",
      "25/25 - 0s - loss: 0.2571 - accuracy: 0.8820 - val_loss: 25.0488 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03526: val_loss did not improve from 0.32861\n",
      "Epoch 3527/4000\n",
      "25/25 - 0s - loss: 0.2511 - accuracy: 0.8846 - val_loss: 25.1933 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03527: val_loss did not improve from 0.32861\n",
      "Epoch 3528/4000\n",
      "25/25 - 0s - loss: 0.2502 - accuracy: 0.8898 - val_loss: 25.3861 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03528: val_loss did not improve from 0.32861\n",
      "Epoch 3529/4000\n",
      "25/25 - 0s - loss: 0.2530 - accuracy: 0.8911 - val_loss: 25.4749 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03529: val_loss did not improve from 0.32861\n",
      "Epoch 3530/4000\n",
      "25/25 - 0s - loss: 0.2504 - accuracy: 0.8898 - val_loss: 26.9908 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03530: val_loss did not improve from 0.32861\n",
      "Epoch 3531/4000\n",
      "25/25 - 0s - loss: 0.2551 - accuracy: 0.8833 - val_loss: 25.9022 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03531: val_loss did not improve from 0.32861\n",
      "Epoch 3532/4000\n",
      "25/25 - 0s - loss: 0.2530 - accuracy: 0.8859 - val_loss: 26.0627 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03532: val_loss did not improve from 0.32861\n",
      "Epoch 3533/4000\n",
      "25/25 - 0s - loss: 0.2530 - accuracy: 0.8936 - val_loss: 25.9996 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03533: val_loss did not improve from 0.32861\n",
      "Epoch 3534/4000\n",
      "25/25 - 0s - loss: 0.2508 - accuracy: 0.8898 - val_loss: 26.3163 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03534: val_loss did not improve from 0.32861\n",
      "Epoch 3535/4000\n",
      "25/25 - 0s - loss: 0.2519 - accuracy: 0.8872 - val_loss: 25.4156 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03535: val_loss did not improve from 0.32861\n",
      "Epoch 3536/4000\n",
      "25/25 - 0s - loss: 0.2535 - accuracy: 0.8923 - val_loss: 25.4421 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03536: val_loss did not improve from 0.32861\n",
      "Epoch 3537/4000\n",
      "25/25 - 0s - loss: 0.2518 - accuracy: 0.8846 - val_loss: 25.9257 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03537: val_loss did not improve from 0.32861\n",
      "Epoch 3538/4000\n",
      "25/25 - 0s - loss: 0.2497 - accuracy: 0.8872 - val_loss: 26.0765 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03538: val_loss did not improve from 0.32861\n",
      "Epoch 3539/4000\n",
      "25/25 - 0s - loss: 0.2609 - accuracy: 0.8859 - val_loss: 25.2330 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03539: val_loss did not improve from 0.32861\n",
      "Epoch 3540/4000\n",
      "25/25 - 0s - loss: 0.2583 - accuracy: 0.8807 - val_loss: 24.7255 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03540: val_loss did not improve from 0.32861\n",
      "Epoch 3541/4000\n",
      "25/25 - 0s - loss: 0.2506 - accuracy: 0.8872 - val_loss: 24.9889 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03541: val_loss did not improve from 0.32861\n",
      "Epoch 3542/4000\n",
      "25/25 - 0s - loss: 0.2503 - accuracy: 0.8872 - val_loss: 25.1846 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03542: val_loss did not improve from 0.32861\n",
      "Epoch 3543/4000\n",
      "25/25 - 0s - loss: 0.2532 - accuracy: 0.8936 - val_loss: 25.3000 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03543: val_loss did not improve from 0.32861\n",
      "Epoch 3544/4000\n",
      "25/25 - 0s - loss: 0.2654 - accuracy: 0.8729 - val_loss: 23.6906 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03544: val_loss did not improve from 0.32861\n",
      "Epoch 3545/4000\n",
      "25/25 - 0s - loss: 0.2558 - accuracy: 0.8820 - val_loss: 23.9534 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03545: val_loss did not improve from 0.32861\n",
      "Epoch 3546/4000\n",
      "25/25 - 0s - loss: 0.2699 - accuracy: 0.8885 - val_loss: 24.3157 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03546: val_loss did not improve from 0.32861\n",
      "Epoch 3547/4000\n",
      "25/25 - 0s - loss: 0.2547 - accuracy: 0.8781 - val_loss: 24.8065 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03547: val_loss did not improve from 0.32861\n",
      "Epoch 3548/4000\n",
      "25/25 - 0s - loss: 0.2509 - accuracy: 0.8885 - val_loss: 25.3814 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03548: val_loss did not improve from 0.32861\n",
      "Epoch 3549/4000\n",
      "25/25 - 0s - loss: 0.2914 - accuracy: 0.8781 - val_loss: 24.0102 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03549: val_loss did not improve from 0.32861\n",
      "Epoch 3550/4000\n",
      "25/25 - 0s - loss: 0.2861 - accuracy: 0.8716 - val_loss: 24.0449 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03550: val_loss did not improve from 0.32861\n",
      "Epoch 3551/4000\n",
      "25/25 - 0s - loss: 0.2685 - accuracy: 0.8885 - val_loss: 25.0039 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03551: val_loss did not improve from 0.32861\n",
      "Epoch 3552/4000\n",
      "25/25 - 0s - loss: 0.2562 - accuracy: 0.8807 - val_loss: 25.4896 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03552: val_loss did not improve from 0.32861\n",
      "Epoch 3553/4000\n",
      "25/25 - 0s - loss: 0.2541 - accuracy: 0.8923 - val_loss: 25.5949 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03553: val_loss did not improve from 0.32861\n",
      "Epoch 3554/4000\n",
      "25/25 - 0s - loss: 0.2499 - accuracy: 0.8885 - val_loss: 26.4102 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03554: val_loss did not improve from 0.32861\n",
      "Epoch 3555/4000\n",
      "25/25 - 0s - loss: 0.2476 - accuracy: 0.8911 - val_loss: 26.4275 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03555: val_loss did not improve from 0.32861\n",
      "Epoch 3556/4000\n",
      "25/25 - 0s - loss: 0.2471 - accuracy: 0.8923 - val_loss: 26.4542 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03556: val_loss did not improve from 0.32861\n",
      "Epoch 3557/4000\n",
      "25/25 - 0s - loss: 0.2488 - accuracy: 0.8898 - val_loss: 26.2751 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03557: val_loss did not improve from 0.32861\n",
      "Epoch 3558/4000\n",
      "25/25 - 0s - loss: 0.2597 - accuracy: 0.8820 - val_loss: 26.1683 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03558: val_loss did not improve from 0.32861\n",
      "Epoch 3559/4000\n",
      "25/25 - 0s - loss: 0.2523 - accuracy: 0.8833 - val_loss: 26.2531 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 03559: val_loss did not improve from 0.32861\n",
      "Epoch 3560/4000\n",
      "25/25 - 0s - loss: 0.2518 - accuracy: 0.8872 - val_loss: 26.1977 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03560: val_loss did not improve from 0.32861\n",
      "Epoch 3561/4000\n",
      "25/25 - 0s - loss: 0.2473 - accuracy: 0.8988 - val_loss: 26.6604 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03561: val_loss did not improve from 0.32861\n",
      "Epoch 3562/4000\n",
      "25/25 - 0s - loss: 0.2550 - accuracy: 0.8833 - val_loss: 27.7528 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03562: val_loss did not improve from 0.32861\n",
      "Epoch 3563/4000\n",
      "25/25 - 0s - loss: 0.2444 - accuracy: 0.8936 - val_loss: 28.0027 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03563: val_loss did not improve from 0.32861\n",
      "Epoch 3564/4000\n",
      "25/25 - 0s - loss: 0.2515 - accuracy: 0.8859 - val_loss: 28.2783 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03564: val_loss did not improve from 0.32861\n",
      "Epoch 3565/4000\n",
      "25/25 - 0s - loss: 0.2474 - accuracy: 0.8846 - val_loss: 27.7401 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03565: val_loss did not improve from 0.32861\n",
      "Epoch 3566/4000\n",
      "25/25 - 0s - loss: 0.2468 - accuracy: 0.8923 - val_loss: 27.6141 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03566: val_loss did not improve from 0.32861\n",
      "Epoch 3567/4000\n",
      "25/25 - 0s - loss: 0.2423 - accuracy: 0.8872 - val_loss: 28.4625 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03567: val_loss did not improve from 0.32861\n",
      "Epoch 3568/4000\n",
      "25/25 - 0s - loss: 0.2410 - accuracy: 0.8962 - val_loss: 28.2750 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03568: val_loss did not improve from 0.32861\n",
      "Epoch 3569/4000\n",
      "25/25 - 0s - loss: 0.2431 - accuracy: 0.8936 - val_loss: 27.8787 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03569: val_loss did not improve from 0.32861\n",
      "Epoch 3570/4000\n",
      "25/25 - 0s - loss: 0.2472 - accuracy: 0.8820 - val_loss: 27.8902 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03570: val_loss did not improve from 0.32861\n",
      "Epoch 3571/4000\n",
      "25/25 - 0s - loss: 0.2422 - accuracy: 0.8936 - val_loss: 28.6568 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03571: val_loss did not improve from 0.32861\n",
      "Epoch 3572/4000\n",
      "25/25 - 0s - loss: 0.2403 - accuracy: 0.8872 - val_loss: 27.3122 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03572: val_loss did not improve from 0.32861\n",
      "Epoch 3573/4000\n",
      "25/25 - 0s - loss: 0.2452 - accuracy: 0.8911 - val_loss: 27.9028 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03573: val_loss did not improve from 0.32861\n",
      "Epoch 3574/4000\n",
      "25/25 - 0s - loss: 0.2440 - accuracy: 0.8936 - val_loss: 27.6733 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03574: val_loss did not improve from 0.32861\n",
      "Epoch 3575/4000\n",
      "25/25 - 0s - loss: 0.2412 - accuracy: 0.8949 - val_loss: 27.4821 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03575: val_loss did not improve from 0.32861\n",
      "Epoch 3576/4000\n",
      "25/25 - 0s - loss: 0.2462 - accuracy: 0.8898 - val_loss: 28.0771 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03576: val_loss did not improve from 0.32861\n",
      "Epoch 3577/4000\n",
      "25/25 - 0s - loss: 0.2421 - accuracy: 0.8923 - val_loss: 34.1838 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03577: val_loss did not improve from 0.32861\n",
      "Epoch 3578/4000\n",
      "25/25 - 0s - loss: 0.2454 - accuracy: 0.8923 - val_loss: 30.9774 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03578: val_loss did not improve from 0.32861\n",
      "Epoch 3579/4000\n",
      "25/25 - 0s - loss: 0.2407 - accuracy: 0.8923 - val_loss: 29.6075 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03579: val_loss did not improve from 0.32861\n",
      "Epoch 3580/4000\n",
      "25/25 - 0s - loss: 0.2519 - accuracy: 0.8923 - val_loss: 28.3115 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03580: val_loss did not improve from 0.32861\n",
      "Epoch 3581/4000\n",
      "25/25 - 0s - loss: 0.2440 - accuracy: 0.8846 - val_loss: 28.2400 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03581: val_loss did not improve from 0.32861\n",
      "Epoch 3582/4000\n",
      "25/25 - 0s - loss: 0.2436 - accuracy: 0.8872 - val_loss: 27.8689 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03582: val_loss did not improve from 0.32861\n",
      "Epoch 3583/4000\n",
      "25/25 - 0s - loss: 0.2444 - accuracy: 0.8936 - val_loss: 27.8768 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03583: val_loss did not improve from 0.32861\n",
      "Epoch 3584/4000\n",
      "25/25 - 0s - loss: 0.2397 - accuracy: 0.8911 - val_loss: 28.0830 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03584: val_loss did not improve from 0.32861\n",
      "Epoch 3585/4000\n",
      "25/25 - 0s - loss: 0.2418 - accuracy: 0.8846 - val_loss: 28.7200 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03585: val_loss did not improve from 0.32861\n",
      "Epoch 3586/4000\n",
      "25/25 - 0s - loss: 0.2444 - accuracy: 0.8898 - val_loss: 28.7422 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03586: val_loss did not improve from 0.32861\n",
      "Epoch 3587/4000\n",
      "25/25 - 0s - loss: 0.2452 - accuracy: 0.8911 - val_loss: 27.5406 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03587: val_loss did not improve from 0.32861\n",
      "Epoch 3588/4000\n",
      "25/25 - 0s - loss: 0.2430 - accuracy: 0.8936 - val_loss: 27.3692 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03588: val_loss did not improve from 0.32861\n",
      "Epoch 3589/4000\n",
      "25/25 - 0s - loss: 0.2463 - accuracy: 0.8820 - val_loss: 27.4784 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03589: val_loss did not improve from 0.32861\n",
      "Epoch 3590/4000\n",
      "25/25 - 0s - loss: 0.2462 - accuracy: 0.8923 - val_loss: 27.6367 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03590: val_loss did not improve from 0.32861\n",
      "Epoch 3591/4000\n",
      "25/25 - 0s - loss: 0.2381 - accuracy: 0.8949 - val_loss: 27.4994 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03591: val_loss did not improve from 0.32861\n",
      "Epoch 3592/4000\n",
      "25/25 - 0s - loss: 0.2457 - accuracy: 0.8898 - val_loss: 27.4501 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03592: val_loss did not improve from 0.32861\n",
      "Epoch 3593/4000\n",
      "25/25 - 0s - loss: 0.2463 - accuracy: 0.8923 - val_loss: 27.6302 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03593: val_loss did not improve from 0.32861\n",
      "Epoch 3594/4000\n",
      "25/25 - 0s - loss: 0.2426 - accuracy: 0.8872 - val_loss: 27.2575 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03594: val_loss did not improve from 0.32861\n",
      "Epoch 3595/4000\n",
      "25/25 - 0s - loss: 0.2418 - accuracy: 0.8898 - val_loss: 27.2929 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03595: val_loss did not improve from 0.32861\n",
      "Epoch 3596/4000\n",
      "25/25 - 0s - loss: 0.2396 - accuracy: 0.8923 - val_loss: 27.2585 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03596: val_loss did not improve from 0.32861\n",
      "Epoch 3597/4000\n",
      "25/25 - 0s - loss: 0.2406 - accuracy: 0.8923 - val_loss: 26.8073 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03597: val_loss did not improve from 0.32861\n",
      "Epoch 3598/4000\n",
      "25/25 - 0s - loss: 0.2533 - accuracy: 0.8846 - val_loss: 27.0600 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03598: val_loss did not improve from 0.32861\n",
      "Epoch 3599/4000\n",
      "25/25 - 0s - loss: 0.2411 - accuracy: 0.8885 - val_loss: 27.0904 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03599: val_loss did not improve from 0.32861\n",
      "Epoch 3600/4000\n",
      "25/25 - 0s - loss: 0.2399 - accuracy: 0.8975 - val_loss: 27.2947 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03600: val_loss did not improve from 0.32861\n",
      "Epoch 3601/4000\n",
      "25/25 - 0s - loss: 0.2386 - accuracy: 0.8923 - val_loss: 27.2909 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03601: val_loss did not improve from 0.32861\n",
      "Epoch 3602/4000\n",
      "25/25 - 0s - loss: 0.2497 - accuracy: 0.8872 - val_loss: 26.0458 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03602: val_loss did not improve from 0.32861\n",
      "Epoch 3603/4000\n",
      "25/25 - 0s - loss: 0.2402 - accuracy: 0.8872 - val_loss: 26.3262 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03603: val_loss did not improve from 0.32861\n",
      "Epoch 3604/4000\n",
      "25/25 - 0s - loss: 0.2826 - accuracy: 0.8898 - val_loss: 25.8636 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03604: val_loss did not improve from 0.32861\n",
      "Epoch 3605/4000\n",
      "25/25 - 0s - loss: 0.2911 - accuracy: 0.8664 - val_loss: 27.5720 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03605: val_loss did not improve from 0.32861\n",
      "Epoch 3606/4000\n",
      "25/25 - 0s - loss: 0.2655 - accuracy: 0.8807 - val_loss: 44.6138 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03606: val_loss did not improve from 0.32861\n",
      "Epoch 3607/4000\n",
      "25/25 - 0s - loss: 0.3877 - accuracy: 0.8846 - val_loss: 17.5212 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03607: val_loss did not improve from 0.32861\n",
      "Epoch 3608/4000\n",
      "25/25 - 0s - loss: 0.3295 - accuracy: 0.8677 - val_loss: 17.2558 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03608: val_loss did not improve from 0.32861\n",
      "Epoch 3609/4000\n",
      "25/25 - 0s - loss: 0.3028 - accuracy: 0.8729 - val_loss: 18.8491 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03609: val_loss did not improve from 0.32861\n",
      "Epoch 3610/4000\n",
      "25/25 - 0s - loss: 0.3120 - accuracy: 0.8612 - val_loss: 9.2553 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03610: val_loss did not improve from 0.32861\n",
      "Epoch 3611/4000\n",
      "25/25 - 0s - loss: 0.2839 - accuracy: 0.8716 - val_loss: 9.3931 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03611: val_loss did not improve from 0.32861\n",
      "Epoch 3612/4000\n",
      "25/25 - 0s - loss: 0.2860 - accuracy: 0.8703 - val_loss: 10.4918 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03612: val_loss did not improve from 0.32861\n",
      "Epoch 3613/4000\n",
      "25/25 - 0s - loss: 0.2877 - accuracy: 0.8794 - val_loss: 10.4739 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03613: val_loss did not improve from 0.32861\n",
      "Epoch 3614/4000\n",
      "25/25 - 0s - loss: 0.2762 - accuracy: 0.8742 - val_loss: 10.2410 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03614: val_loss did not improve from 0.32861\n",
      "Epoch 3615/4000\n",
      "25/25 - 0s - loss: 0.2747 - accuracy: 0.8833 - val_loss: 9.5876 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03615: val_loss did not improve from 0.32861\n",
      "Epoch 3616/4000\n",
      "25/25 - 0s - loss: 0.2727 - accuracy: 0.8781 - val_loss: 10.9681 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03616: val_loss did not improve from 0.32861\n",
      "Epoch 3617/4000\n",
      "25/25 - 0s - loss: 0.2841 - accuracy: 0.8794 - val_loss: 10.8204 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03617: val_loss did not improve from 0.32861\n",
      "Epoch 3618/4000\n",
      "25/25 - 0s - loss: 0.3694 - accuracy: 0.8833 - val_loss: 8.6470 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03618: val_loss did not improve from 0.32861\n",
      "Epoch 3619/4000\n",
      "25/25 - 0s - loss: 0.2523 - accuracy: 0.8833 - val_loss: 8.6934 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03619: val_loss did not improve from 0.32861\n",
      "Epoch 3620/4000\n",
      "25/25 - 0s - loss: 0.2747 - accuracy: 0.8768 - val_loss: 8.3372 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03620: val_loss did not improve from 0.32861\n",
      "Epoch 3621/4000\n",
      "25/25 - 0s - loss: 0.2559 - accuracy: 0.8872 - val_loss: 8.3712 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03621: val_loss did not improve from 0.32861\n",
      "Epoch 3622/4000\n",
      "25/25 - 0s - loss: 0.2678 - accuracy: 0.8846 - val_loss: 8.4603 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03622: val_loss did not improve from 0.32861\n",
      "Epoch 3623/4000\n",
      "25/25 - 0s - loss: 0.2619 - accuracy: 0.8859 - val_loss: 9.0703 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03623: val_loss did not improve from 0.32861\n",
      "Epoch 3624/4000\n",
      "25/25 - 0s - loss: 0.2773 - accuracy: 0.8807 - val_loss: 8.8952 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03624: val_loss did not improve from 0.32861\n",
      "Epoch 3625/4000\n",
      "25/25 - 0s - loss: 0.2626 - accuracy: 0.8820 - val_loss: 8.0401 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03625: val_loss did not improve from 0.32861\n",
      "Epoch 3626/4000\n",
      "25/25 - 0s - loss: 0.2424 - accuracy: 0.8936 - val_loss: 7.8782 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03626: val_loss did not improve from 0.32861\n",
      "Epoch 3627/4000\n",
      "25/25 - 0s - loss: 0.2566 - accuracy: 0.8755 - val_loss: 6.7949 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03627: val_loss did not improve from 0.32861\n",
      "Epoch 3628/4000\n",
      "25/25 - 0s - loss: 0.2603 - accuracy: 0.8742 - val_loss: 6.6012 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03628: val_loss did not improve from 0.32861\n",
      "Epoch 3629/4000\n",
      "25/25 - 0s - loss: 0.2569 - accuracy: 0.8820 - val_loss: 6.8220 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03629: val_loss did not improve from 0.32861\n",
      "Epoch 3630/4000\n",
      "25/25 - 0s - loss: 0.2446 - accuracy: 0.8846 - val_loss: 7.0092 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03630: val_loss did not improve from 0.32861\n",
      "Epoch 3631/4000\n",
      "25/25 - 0s - loss: 0.2555 - accuracy: 0.8768 - val_loss: 7.2346 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03631: val_loss did not improve from 0.32861\n",
      "Epoch 3632/4000\n",
      "25/25 - 0s - loss: 0.2608 - accuracy: 0.8690 - val_loss: 6.8590 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03632: val_loss did not improve from 0.32861\n",
      "Epoch 3633/4000\n",
      "25/25 - 0s - loss: 0.2416 - accuracy: 0.8936 - val_loss: 6.7109 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03633: val_loss did not improve from 0.32861\n",
      "Epoch 3634/4000\n",
      "25/25 - 0s - loss: 0.2499 - accuracy: 0.8872 - val_loss: 6.6989 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03634: val_loss did not improve from 0.32861\n",
      "Epoch 3635/4000\n",
      "25/25 - 0s - loss: 0.2444 - accuracy: 0.8859 - val_loss: 6.7986 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03635: val_loss did not improve from 0.32861\n",
      "Epoch 3636/4000\n",
      "25/25 - 0s - loss: 0.2424 - accuracy: 0.8936 - val_loss: 6.7694 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03636: val_loss did not improve from 0.32861\n",
      "Epoch 3637/4000\n",
      "25/25 - 0s - loss: 0.2446 - accuracy: 0.8898 - val_loss: 6.7050 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03637: val_loss did not improve from 0.32861\n",
      "Epoch 3638/4000\n",
      "25/25 - 0s - loss: 0.2446 - accuracy: 0.8859 - val_loss: 6.4692 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03638: val_loss did not improve from 0.32861\n",
      "Epoch 3639/4000\n",
      "25/25 - 0s - loss: 0.2390 - accuracy: 0.8872 - val_loss: 6.4262 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03639: val_loss did not improve from 0.32861\n",
      "Epoch 3640/4000\n",
      "25/25 - 0s - loss: 0.2403 - accuracy: 0.8923 - val_loss: 6.5406 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03640: val_loss did not improve from 0.32861\n",
      "Epoch 3641/4000\n",
      "25/25 - 0s - loss: 0.2391 - accuracy: 0.8923 - val_loss: 6.5544 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03641: val_loss did not improve from 0.32861\n",
      "Epoch 3642/4000\n",
      "25/25 - 0s - loss: 0.2406 - accuracy: 0.8949 - val_loss: 6.6537 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03642: val_loss did not improve from 0.32861\n",
      "Epoch 3643/4000\n",
      "25/25 - 0s - loss: 0.2472 - accuracy: 0.8859 - val_loss: 6.5737 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03643: val_loss did not improve from 0.32861\n",
      "Epoch 3644/4000\n",
      "25/25 - 0s - loss: 0.2373 - accuracy: 0.8911 - val_loss: 6.5021 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03644: val_loss did not improve from 0.32861\n",
      "Epoch 3645/4000\n",
      "25/25 - 0s - loss: 0.2420 - accuracy: 0.8781 - val_loss: 6.5754 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03645: val_loss did not improve from 0.32861\n",
      "Epoch 3646/4000\n",
      "25/25 - 0s - loss: 0.2664 - accuracy: 0.8729 - val_loss: 6.3237 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03646: val_loss did not improve from 0.32861\n",
      "Epoch 3647/4000\n",
      "25/25 - 0s - loss: 0.2490 - accuracy: 0.8936 - val_loss: 6.5379 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03647: val_loss did not improve from 0.32861\n",
      "Epoch 3648/4000\n",
      "25/25 - 0s - loss: 0.2410 - accuracy: 0.8885 - val_loss: 6.6769 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03648: val_loss did not improve from 0.32861\n",
      "Epoch 3649/4000\n",
      "25/25 - 0s - loss: 0.2482 - accuracy: 0.8846 - val_loss: 6.6393 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03649: val_loss did not improve from 0.32861\n",
      "Epoch 3650/4000\n",
      "25/25 - 1s - loss: 0.2421 - accuracy: 0.8911 - val_loss: 6.6775 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03650: val_loss did not improve from 0.32861\n",
      "Epoch 3651/4000\n",
      "25/25 - 0s - loss: 0.2415 - accuracy: 0.8833 - val_loss: 6.8038 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03651: val_loss did not improve from 0.32861\n",
      "Epoch 3652/4000\n",
      "25/25 - 0s - loss: 0.2422 - accuracy: 0.8833 - val_loss: 6.7456 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03652: val_loss did not improve from 0.32861\n",
      "Epoch 3653/4000\n",
      "25/25 - 0s - loss: 0.2440 - accuracy: 0.8885 - val_loss: 6.8885 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03653: val_loss did not improve from 0.32861\n",
      "Epoch 3654/4000\n",
      "25/25 - 0s - loss: 0.2431 - accuracy: 0.8859 - val_loss: 6.9677 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03654: val_loss did not improve from 0.32861\n",
      "Epoch 3655/4000\n",
      "25/25 - 0s - loss: 0.2369 - accuracy: 0.8898 - val_loss: 6.9201 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03655: val_loss did not improve from 0.32861\n",
      "Epoch 3656/4000\n",
      "25/25 - 0s - loss: 0.2430 - accuracy: 0.8962 - val_loss: 7.3245 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03656: val_loss did not improve from 0.32861\n",
      "Epoch 3657/4000\n",
      "25/25 - 0s - loss: 0.2701 - accuracy: 0.8768 - val_loss: 7.0215 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03657: val_loss did not improve from 0.32861\n",
      "Epoch 3658/4000\n",
      "25/25 - 0s - loss: 0.2476 - accuracy: 0.8872 - val_loss: 6.8527 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03658: val_loss did not improve from 0.32861\n",
      "Epoch 3659/4000\n",
      "25/25 - 1s - loss: 0.2449 - accuracy: 0.8794 - val_loss: 6.7751 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03659: val_loss did not improve from 0.32861\n",
      "Epoch 3660/4000\n",
      "25/25 - 0s - loss: 0.2393 - accuracy: 0.8885 - val_loss: 6.6894 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03660: val_loss did not improve from 0.32861\n",
      "Epoch 3661/4000\n",
      "25/25 - 0s - loss: 0.2425 - accuracy: 0.8923 - val_loss: 6.4386 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03661: val_loss did not improve from 0.32861\n",
      "Epoch 3662/4000\n",
      "25/25 - 0s - loss: 0.2509 - accuracy: 0.8859 - val_loss: 5.9666 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03662: val_loss did not improve from 0.32861\n",
      "Epoch 3663/4000\n",
      "25/25 - 0s - loss: 0.2387 - accuracy: 0.8885 - val_loss: 5.9648 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03663: val_loss did not improve from 0.32861\n",
      "Epoch 3664/4000\n",
      "25/25 - 0s - loss: 0.2446 - accuracy: 0.8936 - val_loss: 5.9630 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03664: val_loss did not improve from 0.32861\n",
      "Epoch 3665/4000\n",
      "25/25 - 0s - loss: 0.2393 - accuracy: 0.8923 - val_loss: 6.0257 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03665: val_loss did not improve from 0.32861\n",
      "Epoch 3666/4000\n",
      "25/25 - 0s - loss: 0.2461 - accuracy: 0.8872 - val_loss: 5.9181 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03666: val_loss did not improve from 0.32861\n",
      "Epoch 3667/4000\n",
      "25/25 - 0s - loss: 0.2348 - accuracy: 0.8898 - val_loss: 5.8835 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03667: val_loss did not improve from 0.32861\n",
      "Epoch 3668/4000\n",
      "25/25 - 0s - loss: 0.2412 - accuracy: 0.8923 - val_loss: 5.9260 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03668: val_loss did not improve from 0.32861\n",
      "Epoch 3669/4000\n",
      "25/25 - 0s - loss: 0.2380 - accuracy: 0.8936 - val_loss: 6.0755 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03669: val_loss did not improve from 0.32861\n",
      "Epoch 3670/4000\n",
      "25/25 - 0s - loss: 0.2569 - accuracy: 0.8911 - val_loss: 5.8314 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03670: val_loss did not improve from 0.32861\n",
      "Epoch 3671/4000\n",
      "25/25 - 0s - loss: 0.2437 - accuracy: 0.8936 - val_loss: 5.8117 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03671: val_loss did not improve from 0.32861\n",
      "Epoch 3672/4000\n",
      "25/25 - 0s - loss: 0.2410 - accuracy: 0.8859 - val_loss: 5.8718 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03672: val_loss did not improve from 0.32861\n",
      "Epoch 3673/4000\n",
      "25/25 - 0s - loss: 0.2413 - accuracy: 0.8898 - val_loss: 5.8734 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03673: val_loss did not improve from 0.32861\n",
      "Epoch 3674/4000\n",
      "25/25 - 0s - loss: 0.2557 - accuracy: 0.8768 - val_loss: 6.5242 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03674: val_loss did not improve from 0.32861\n",
      "Epoch 3675/4000\n",
      "25/25 - 0s - loss: 0.4260 - accuracy: 0.8885 - val_loss: 6.2951 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03675: val_loss did not improve from 0.32861\n",
      "Epoch 3676/4000\n",
      "25/25 - 0s - loss: 0.2560 - accuracy: 0.8755 - val_loss: 6.9755 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03676: val_loss did not improve from 0.32861\n",
      "Epoch 3677/4000\n",
      "25/25 - 0s - loss: 0.2540 - accuracy: 0.8885 - val_loss: 6.4036 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03677: val_loss did not improve from 0.32861\n",
      "Epoch 3678/4000\n",
      "25/25 - 0s - loss: 0.2595 - accuracy: 0.8794 - val_loss: 6.3573 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03678: val_loss did not improve from 0.32861\n",
      "Epoch 3679/4000\n",
      "25/25 - 0s - loss: 0.2396 - accuracy: 0.8859 - val_loss: 6.3619 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03679: val_loss did not improve from 0.32861\n",
      "Epoch 3680/4000\n",
      "25/25 - 0s - loss: 0.2440 - accuracy: 0.8885 - val_loss: 6.4009 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03680: val_loss did not improve from 0.32861\n",
      "Epoch 3681/4000\n",
      "25/25 - 0s - loss: 0.2393 - accuracy: 0.8911 - val_loss: 6.5073 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03681: val_loss did not improve from 0.32861\n",
      "Epoch 3682/4000\n",
      "25/25 - 0s - loss: 0.2532 - accuracy: 0.8794 - val_loss: 6.3455 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03682: val_loss did not improve from 0.32861\n",
      "Epoch 3683/4000\n",
      "25/25 - 0s - loss: 0.2384 - accuracy: 0.8885 - val_loss: 6.4518 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03683: val_loss did not improve from 0.32861\n",
      "Epoch 3684/4000\n",
      "25/25 - 0s - loss: 0.2430 - accuracy: 0.8781 - val_loss: 6.5862 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03684: val_loss did not improve from 0.32861\n",
      "Epoch 3685/4000\n",
      "25/25 - 0s - loss: 0.2435 - accuracy: 0.8846 - val_loss: 6.6481 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03685: val_loss did not improve from 0.32861\n",
      "Epoch 3686/4000\n",
      "25/25 - 0s - loss: 0.2418 - accuracy: 0.8911 - val_loss: 6.8746 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03686: val_loss did not improve from 0.32861\n",
      "Epoch 3687/4000\n",
      "25/25 - 0s - loss: 0.2385 - accuracy: 0.8898 - val_loss: 6.8647 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03687: val_loss did not improve from 0.32861\n",
      "Epoch 3688/4000\n",
      "25/25 - 0s - loss: 0.2384 - accuracy: 0.8988 - val_loss: 7.0778 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03688: val_loss did not improve from 0.32861\n",
      "Epoch 3689/4000\n",
      "25/25 - 0s - loss: 0.2376 - accuracy: 0.8885 - val_loss: 7.0902 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03689: val_loss did not improve from 0.32861\n",
      "Epoch 3690/4000\n",
      "25/25 - 0s - loss: 0.2366 - accuracy: 0.8936 - val_loss: 7.0128 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03690: val_loss did not improve from 0.32861\n",
      "Epoch 3691/4000\n",
      "25/25 - 0s - loss: 0.2352 - accuracy: 0.8885 - val_loss: 7.1350 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03691: val_loss did not improve from 0.32861\n",
      "Epoch 3692/4000\n",
      "25/25 - 0s - loss: 0.2383 - accuracy: 0.8923 - val_loss: 7.3077 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03692: val_loss did not improve from 0.32861\n",
      "Epoch 3693/4000\n",
      "25/25 - 0s - loss: 0.2444 - accuracy: 0.8936 - val_loss: 7.1177 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03693: val_loss did not improve from 0.32861\n",
      "Epoch 3694/4000\n",
      "25/25 - 0s - loss: 0.2367 - accuracy: 0.8949 - val_loss: 7.1269 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03694: val_loss did not improve from 0.32861\n",
      "Epoch 3695/4000\n",
      "25/25 - 0s - loss: 0.2352 - accuracy: 0.8911 - val_loss: 7.2143 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03695: val_loss did not improve from 0.32861\n",
      "Epoch 3696/4000\n",
      "25/25 - 0s - loss: 0.2382 - accuracy: 0.8923 - val_loss: 7.3377 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03696: val_loss did not improve from 0.32861\n",
      "Epoch 3697/4000\n",
      "25/25 - 0s - loss: 0.2481 - accuracy: 0.8936 - val_loss: 7.3033 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03697: val_loss did not improve from 0.32861\n",
      "Epoch 3698/4000\n",
      "25/25 - 0s - loss: 0.2363 - accuracy: 0.8949 - val_loss: 7.4085 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03698: val_loss did not improve from 0.32861\n",
      "Epoch 3699/4000\n",
      "25/25 - 0s - loss: 0.2449 - accuracy: 0.8885 - val_loss: 7.2866 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03699: val_loss did not improve from 0.32861\n",
      "Epoch 3700/4000\n",
      "25/25 - 0s - loss: 0.2736 - accuracy: 0.8677 - val_loss: 6.3171 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03700: val_loss did not improve from 0.32861\n",
      "Epoch 3701/4000\n",
      "25/25 - 0s - loss: 0.2502 - accuracy: 0.8885 - val_loss: 6.4438 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03701: val_loss did not improve from 0.32861\n",
      "Epoch 3702/4000\n",
      "25/25 - 0s - loss: 0.2413 - accuracy: 0.8872 - val_loss: 6.5088 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03702: val_loss did not improve from 0.32861\n",
      "Epoch 3703/4000\n",
      "25/25 - 0s - loss: 0.2616 - accuracy: 0.8781 - val_loss: 6.6525 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03703: val_loss did not improve from 0.32861\n",
      "Epoch 3704/4000\n",
      "25/25 - 0s - loss: 0.2782 - accuracy: 0.8794 - val_loss: 7.4439 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03704: val_loss did not improve from 0.32861\n",
      "Epoch 3705/4000\n",
      "25/25 - 0s - loss: 0.2569 - accuracy: 0.8923 - val_loss: 6.6147 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03705: val_loss did not improve from 0.32861\n",
      "Epoch 3706/4000\n",
      "25/25 - 0s - loss: 0.2458 - accuracy: 0.8911 - val_loss: 6.6424 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03706: val_loss did not improve from 0.32861\n",
      "Epoch 3707/4000\n",
      "25/25 - 0s - loss: 0.2438 - accuracy: 0.8820 - val_loss: 6.5407 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03707: val_loss did not improve from 0.32861\n",
      "Epoch 3708/4000\n",
      "25/25 - 0s - loss: 0.2677 - accuracy: 0.8768 - val_loss: 6.7193 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03708: val_loss did not improve from 0.32861\n",
      "Epoch 3709/4000\n",
      "25/25 - 0s - loss: 0.2414 - accuracy: 0.8820 - val_loss: 6.4099 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03709: val_loss did not improve from 0.32861\n",
      "Epoch 3710/4000\n",
      "25/25 - 0s - loss: 0.2387 - accuracy: 0.8898 - val_loss: 6.6375 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03710: val_loss did not improve from 0.32861\n",
      "Epoch 3711/4000\n",
      "25/25 - 0s - loss: 0.2361 - accuracy: 0.8936 - val_loss: 6.8122 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03711: val_loss did not improve from 0.32861\n",
      "Epoch 3712/4000\n",
      "25/25 - 0s - loss: 0.2379 - accuracy: 0.8949 - val_loss: 6.9141 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03712: val_loss did not improve from 0.32861\n",
      "Epoch 3713/4000\n",
      "25/25 - 0s - loss: 0.2433 - accuracy: 0.8936 - val_loss: 6.7292 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03713: val_loss did not improve from 0.32861\n",
      "Epoch 3714/4000\n",
      "25/25 - 0s - loss: 0.2398 - accuracy: 0.8911 - val_loss: 6.7453 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03714: val_loss did not improve from 0.32861\n",
      "Epoch 3715/4000\n",
      "25/25 - 0s - loss: 0.2359 - accuracy: 0.8923 - val_loss: 6.8780 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03715: val_loss did not improve from 0.32861\n",
      "Epoch 3716/4000\n",
      "25/25 - 0s - loss: 0.2460 - accuracy: 0.8833 - val_loss: 7.1814 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03716: val_loss did not improve from 0.32861\n",
      "Epoch 3717/4000\n",
      "25/25 - 0s - loss: 0.2397 - accuracy: 0.8872 - val_loss: 5.9136 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03717: val_loss did not improve from 0.32861\n",
      "Epoch 3718/4000\n",
      "25/25 - 0s - loss: 0.2503 - accuracy: 0.8820 - val_loss: 5.8460 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03718: val_loss did not improve from 0.32861\n",
      "Epoch 3719/4000\n",
      "25/25 - 0s - loss: 0.2446 - accuracy: 0.8936 - val_loss: 5.9442 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03719: val_loss did not improve from 0.32861\n",
      "Epoch 3720/4000\n",
      "25/25 - 0s - loss: 0.2426 - accuracy: 0.8923 - val_loss: 6.3549 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03720: val_loss did not improve from 0.32861\n",
      "Epoch 3721/4000\n",
      "25/25 - 0s - loss: 0.2431 - accuracy: 0.8885 - val_loss: 6.3075 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03721: val_loss did not improve from 0.32861\n",
      "Epoch 3722/4000\n",
      "25/25 - 0s - loss: 0.2380 - accuracy: 0.8872 - val_loss: 6.3836 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03722: val_loss did not improve from 0.32861\n",
      "Epoch 3723/4000\n",
      "25/25 - 0s - loss: 0.2476 - accuracy: 0.8833 - val_loss: 6.4327 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03723: val_loss did not improve from 0.32861\n",
      "Epoch 3724/4000\n",
      "25/25 - 0s - loss: 0.2392 - accuracy: 0.8949 - val_loss: 6.5835 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03724: val_loss did not improve from 0.32861\n",
      "Epoch 3725/4000\n",
      "25/25 - 0s - loss: 0.2403 - accuracy: 0.8859 - val_loss: 6.2246 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03725: val_loss did not improve from 0.32861\n",
      "Epoch 3726/4000\n",
      "25/25 - 0s - loss: 0.2377 - accuracy: 0.8923 - val_loss: 6.0587 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03726: val_loss did not improve from 0.32861\n",
      "Epoch 3727/4000\n",
      "25/25 - 0s - loss: 0.2408 - accuracy: 0.8885 - val_loss: 6.4209 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03727: val_loss did not improve from 0.32861\n",
      "Epoch 3728/4000\n",
      "25/25 - 0s - loss: 0.2375 - accuracy: 0.8923 - val_loss: 6.5637 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03728: val_loss did not improve from 0.32861\n",
      "Epoch 3729/4000\n",
      "25/25 - 0s - loss: 0.2467 - accuracy: 0.8872 - val_loss: 6.7852 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03729: val_loss did not improve from 0.32861\n",
      "Epoch 3730/4000\n",
      "25/25 - 0s - loss: 0.2411 - accuracy: 0.8859 - val_loss: 6.9022 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03730: val_loss did not improve from 0.32861\n",
      "Epoch 3731/4000\n",
      "25/25 - 0s - loss: 0.2415 - accuracy: 0.8949 - val_loss: 7.1475 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03731: val_loss did not improve from 0.32861\n",
      "Epoch 3732/4000\n",
      "25/25 - 0s - loss: 0.2417 - accuracy: 0.8846 - val_loss: 7.1369 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03732: val_loss did not improve from 0.32861\n",
      "Epoch 3733/4000\n",
      "25/25 - 0s - loss: 0.2354 - accuracy: 0.8975 - val_loss: 7.1716 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03733: val_loss did not improve from 0.32861\n",
      "Epoch 3734/4000\n",
      "25/25 - 0s - loss: 0.2364 - accuracy: 0.8962 - val_loss: 7.3581 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03734: val_loss did not improve from 0.32861\n",
      "Epoch 3735/4000\n",
      "25/25 - 0s - loss: 0.2458 - accuracy: 0.8833 - val_loss: 7.5025 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03735: val_loss did not improve from 0.32861\n",
      "Epoch 3736/4000\n",
      "25/25 - 0s - loss: 0.2352 - accuracy: 0.8885 - val_loss: 7.5374 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03736: val_loss did not improve from 0.32861\n",
      "Epoch 3737/4000\n",
      "25/25 - 0s - loss: 0.2399 - accuracy: 0.8923 - val_loss: 7.1985 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03737: val_loss did not improve from 0.32861\n",
      "Epoch 3738/4000\n",
      "25/25 - 0s - loss: 0.2379 - accuracy: 0.8936 - val_loss: 7.3800 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03738: val_loss did not improve from 0.32861\n",
      "Epoch 3739/4000\n",
      "25/25 - 0s - loss: 0.2426 - accuracy: 0.8885 - val_loss: 7.5917 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03739: val_loss did not improve from 0.32861\n",
      "Epoch 3740/4000\n",
      "25/25 - 0s - loss: 0.2390 - accuracy: 0.8872 - val_loss: 7.5554 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03740: val_loss did not improve from 0.32861\n",
      "Epoch 3741/4000\n",
      "25/25 - 0s - loss: 0.2365 - accuracy: 0.8872 - val_loss: 7.5475 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03741: val_loss did not improve from 0.32861\n",
      "Epoch 3742/4000\n",
      "25/25 - 0s - loss: 0.2378 - accuracy: 0.8923 - val_loss: 7.4518 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03742: val_loss did not improve from 0.32861\n",
      "Epoch 3743/4000\n",
      "25/25 - 0s - loss: 0.2372 - accuracy: 0.8962 - val_loss: 7.5577 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03743: val_loss did not improve from 0.32861\n",
      "Epoch 3744/4000\n",
      "25/25 - 0s - loss: 0.2374 - accuracy: 0.8962 - val_loss: 7.5794 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03744: val_loss did not improve from 0.32861\n",
      "Epoch 3745/4000\n",
      "25/25 - 0s - loss: 0.2386 - accuracy: 0.8936 - val_loss: 7.5999 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03745: val_loss did not improve from 0.32861\n",
      "Epoch 3746/4000\n",
      "25/25 - 0s - loss: 0.2395 - accuracy: 0.8923 - val_loss: 6.9647 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03746: val_loss did not improve from 0.32861\n",
      "Epoch 3747/4000\n",
      "25/25 - 0s - loss: 0.2473 - accuracy: 0.8898 - val_loss: 7.1898 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03747: val_loss did not improve from 0.32861\n",
      "Epoch 3748/4000\n",
      "25/25 - 0s - loss: 0.2471 - accuracy: 0.8859 - val_loss: 7.3835 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03748: val_loss did not improve from 0.32861\n",
      "Epoch 3749/4000\n",
      "25/25 - 0s - loss: 0.2379 - accuracy: 0.8911 - val_loss: 7.5319 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03749: val_loss did not improve from 0.32861\n",
      "Epoch 3750/4000\n",
      "25/25 - 0s - loss: 0.2437 - accuracy: 0.8742 - val_loss: 6.8337 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03750: val_loss did not improve from 0.32861\n",
      "Epoch 3751/4000\n",
      "25/25 - 0s - loss: 0.2355 - accuracy: 0.8872 - val_loss: 7.0918 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03751: val_loss did not improve from 0.32861\n",
      "Epoch 3752/4000\n",
      "25/25 - 0s - loss: 0.2509 - accuracy: 0.8885 - val_loss: 6.9665 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03752: val_loss did not improve from 0.32861\n",
      "Epoch 3753/4000\n",
      "25/25 - 0s - loss: 0.2431 - accuracy: 0.8911 - val_loss: 7.5116 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03753: val_loss did not improve from 0.32861\n",
      "Epoch 3754/4000\n",
      "25/25 - 0s - loss: 0.2381 - accuracy: 0.8988 - val_loss: 7.5944 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03754: val_loss did not improve from 0.32861\n",
      "Epoch 3755/4000\n",
      "25/25 - 0s - loss: 0.2441 - accuracy: 0.8911 - val_loss: 7.5536 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03755: val_loss did not improve from 0.32861\n",
      "Epoch 3756/4000\n",
      "25/25 - 0s - loss: 0.2431 - accuracy: 0.8859 - val_loss: 7.7120 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03756: val_loss did not improve from 0.32861\n",
      "Epoch 3757/4000\n",
      "25/25 - 0s - loss: 0.2408 - accuracy: 0.8859 - val_loss: 7.8314 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03757: val_loss did not improve from 0.32861\n",
      "Epoch 3758/4000\n",
      "25/25 - 0s - loss: 0.2401 - accuracy: 0.8859 - val_loss: 8.1384 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03758: val_loss did not improve from 0.32861\n",
      "Epoch 3759/4000\n",
      "25/25 - 0s - loss: 0.2405 - accuracy: 0.8872 - val_loss: 8.2545 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03759: val_loss did not improve from 0.32861\n",
      "Epoch 3760/4000\n",
      "25/25 - 0s - loss: 0.2384 - accuracy: 0.8898 - val_loss: 8.5674 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03760: val_loss did not improve from 0.32861\n",
      "Epoch 3761/4000\n",
      "25/25 - 0s - loss: 0.2446 - accuracy: 0.8872 - val_loss: 7.9322 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03761: val_loss did not improve from 0.32861\n",
      "Epoch 3762/4000\n",
      "25/25 - 0s - loss: 0.2422 - accuracy: 0.8898 - val_loss: 8.1283 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03762: val_loss did not improve from 0.32861\n",
      "Epoch 3763/4000\n",
      "25/25 - 0s - loss: 0.2365 - accuracy: 0.8898 - val_loss: 8.1432 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03763: val_loss did not improve from 0.32861\n",
      "Epoch 3764/4000\n",
      "25/25 - 0s - loss: 0.2381 - accuracy: 0.8923 - val_loss: 8.3472 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03764: val_loss did not improve from 0.32861\n",
      "Epoch 3765/4000\n",
      "25/25 - 0s - loss: 0.2454 - accuracy: 0.8872 - val_loss: 7.9908 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03765: val_loss did not improve from 0.32861\n",
      "Epoch 3766/4000\n",
      "25/25 - 0s - loss: 0.2376 - accuracy: 0.8962 - val_loss: 8.1459 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03766: val_loss did not improve from 0.32861\n",
      "Epoch 3767/4000\n",
      "25/25 - 0s - loss: 0.2463 - accuracy: 0.8936 - val_loss: 8.0408 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03767: val_loss did not improve from 0.32861\n",
      "Epoch 3768/4000\n",
      "25/25 - 0s - loss: 0.2423 - accuracy: 0.8859 - val_loss: 7.9152 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03768: val_loss did not improve from 0.32861\n",
      "Epoch 3769/4000\n",
      "25/25 - 0s - loss: 0.2381 - accuracy: 0.8885 - val_loss: 8.2475 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03769: val_loss did not improve from 0.32861\n",
      "Epoch 3770/4000\n",
      "25/25 - 0s - loss: 0.2416 - accuracy: 0.8898 - val_loss: 7.7272 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03770: val_loss did not improve from 0.32861\n",
      "Epoch 3771/4000\n",
      "25/25 - 0s - loss: 0.2357 - accuracy: 0.8936 - val_loss: 7.4262 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03771: val_loss did not improve from 0.32861\n",
      "Epoch 3772/4000\n",
      "25/25 - 0s - loss: 0.2437 - accuracy: 0.8820 - val_loss: 7.6908 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03772: val_loss did not improve from 0.32861\n",
      "Epoch 3773/4000\n",
      "25/25 - 0s - loss: 0.2390 - accuracy: 0.8923 - val_loss: 8.0141 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03773: val_loss did not improve from 0.32861\n",
      "Epoch 3774/4000\n",
      "25/25 - 0s - loss: 0.2416 - accuracy: 0.8898 - val_loss: 6.9625 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03774: val_loss did not improve from 0.32861\n",
      "Epoch 3775/4000\n",
      "25/25 - 0s - loss: 0.2418 - accuracy: 0.8872 - val_loss: 6.8383 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03775: val_loss did not improve from 0.32861\n",
      "Epoch 3776/4000\n",
      "25/25 - 0s - loss: 0.2435 - accuracy: 0.8911 - val_loss: 7.2503 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03776: val_loss did not improve from 0.32861\n",
      "Epoch 3777/4000\n",
      "25/25 - 0s - loss: 0.2428 - accuracy: 0.8898 - val_loss: 7.4759 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03777: val_loss did not improve from 0.32861\n",
      "Epoch 3778/4000\n",
      "25/25 - 0s - loss: 0.2428 - accuracy: 0.8898 - val_loss: 7.6568 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03778: val_loss did not improve from 0.32861\n",
      "Epoch 3779/4000\n",
      "25/25 - 0s - loss: 0.2460 - accuracy: 0.8833 - val_loss: 7.9419 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03779: val_loss did not improve from 0.32861\n",
      "Epoch 3780/4000\n",
      "25/25 - 0s - loss: 0.2451 - accuracy: 0.8742 - val_loss: 8.1282 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03780: val_loss did not improve from 0.32861\n",
      "Epoch 3781/4000\n",
      "25/25 - 0s - loss: 0.2575 - accuracy: 0.8820 - val_loss: 7.8566 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03781: val_loss did not improve from 0.32861\n",
      "Epoch 3782/4000\n",
      "25/25 - 0s - loss: 0.2682 - accuracy: 0.8716 - val_loss: 8.1095 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03782: val_loss did not improve from 0.32861\n",
      "Epoch 3783/4000\n",
      "25/25 - 0s - loss: 0.2575 - accuracy: 0.8820 - val_loss: 6.8225 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03783: val_loss did not improve from 0.32861\n",
      "Epoch 3784/4000\n",
      "25/25 - 0s - loss: 0.2384 - accuracy: 0.8820 - val_loss: 6.3568 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03784: val_loss did not improve from 0.32861\n",
      "Epoch 3785/4000\n",
      "25/25 - 0s - loss: 0.2414 - accuracy: 0.8885 - val_loss: 6.7881 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03785: val_loss did not improve from 0.32861\n",
      "Epoch 3786/4000\n",
      "25/25 - 0s - loss: 0.2430 - accuracy: 0.8833 - val_loss: 7.2970 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03786: val_loss did not improve from 0.32861\n",
      "Epoch 3787/4000\n",
      "25/25 - 0s - loss: 0.2431 - accuracy: 0.8872 - val_loss: 7.3235 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03787: val_loss did not improve from 0.32861\n",
      "Epoch 3788/4000\n",
      "25/25 - 0s - loss: 0.2478 - accuracy: 0.8807 - val_loss: 8.1395 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03788: val_loss did not improve from 0.32861\n",
      "Epoch 3789/4000\n",
      "25/25 - 0s - loss: 0.2467 - accuracy: 0.8911 - val_loss: 4.5608 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03789: val_loss did not improve from 0.32861\n",
      "Epoch 3790/4000\n",
      "25/25 - 0s - loss: 0.5334 - accuracy: 0.8314 - val_loss: 2.9895 - val_accuracy: 0.6995\n",
      "\n",
      "Epoch 03790: val_loss did not improve from 0.32861\n",
      "Epoch 3791/4000\n",
      "25/25 - 0s - loss: 0.6412 - accuracy: 0.7419 - val_loss: 4.1154 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03791: val_loss did not improve from 0.32861\n",
      "Epoch 3792/4000\n",
      "25/25 - 0s - loss: 0.5095 - accuracy: 0.7925 - val_loss: 2.5509 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 03792: val_loss did not improve from 0.32861\n",
      "Epoch 3793/4000\n",
      "25/25 - 0s - loss: 0.4596 - accuracy: 0.8158 - val_loss: 0.7650 - val_accuracy: 0.7668\n",
      "\n",
      "Epoch 03793: val_loss did not improve from 0.32861\n",
      "Epoch 3794/4000\n",
      "25/25 - 0s - loss: 0.3344 - accuracy: 0.8262 - val_loss: 0.6244 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 03794: val_loss did not improve from 0.32861\n",
      "Epoch 3795/4000\n",
      "25/25 - 0s - loss: 0.3594 - accuracy: 0.8327 - val_loss: 0.6599 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03795: val_loss did not improve from 0.32861\n",
      "Epoch 3796/4000\n",
      "25/25 - 0s - loss: 0.3253 - accuracy: 0.8327 - val_loss: 0.8836 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03796: val_loss did not improve from 0.32861\n",
      "Epoch 3797/4000\n",
      "25/25 - 0s - loss: 0.3382 - accuracy: 0.8288 - val_loss: 0.8330 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 03797: val_loss did not improve from 0.32861\n",
      "Epoch 3798/4000\n",
      "25/25 - 0s - loss: 0.3474 - accuracy: 0.8210 - val_loss: 1.0813 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03798: val_loss did not improve from 0.32861\n",
      "Epoch 3799/4000\n",
      "25/25 - 0s - loss: 0.3342 - accuracy: 0.8366 - val_loss: 1.8346 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 03799: val_loss did not improve from 0.32861\n",
      "Epoch 3800/4000\n",
      "25/25 - 0s - loss: 0.3826 - accuracy: 0.8249 - val_loss: 1.5131 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 03800: val_loss did not improve from 0.32861\n",
      "Epoch 3801/4000\n",
      "25/25 - 0s - loss: 0.3349 - accuracy: 0.8249 - val_loss: 1.4150 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 03801: val_loss did not improve from 0.32861\n",
      "Epoch 3802/4000\n",
      "25/25 - 0s - loss: 0.3132 - accuracy: 0.8288 - val_loss: 1.4702 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 03802: val_loss did not improve from 0.32861\n",
      "Epoch 3803/4000\n",
      "25/25 - 0s - loss: 0.3131 - accuracy: 0.8327 - val_loss: 1.5734 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03803: val_loss did not improve from 0.32861\n",
      "Epoch 3804/4000\n",
      "25/25 - 0s - loss: 0.3127 - accuracy: 0.8301 - val_loss: 1.8399 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 03804: val_loss did not improve from 0.32861\n",
      "Epoch 3805/4000\n",
      "25/25 - 0s - loss: 0.3041 - accuracy: 0.8392 - val_loss: 2.0640 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 03805: val_loss did not improve from 0.32861\n",
      "Epoch 3806/4000\n",
      "25/25 - 0s - loss: 0.3001 - accuracy: 0.8314 - val_loss: 2.0987 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03806: val_loss did not improve from 0.32861\n",
      "Epoch 3807/4000\n",
      "25/25 - 0s - loss: 0.2998 - accuracy: 0.8366 - val_loss: 2.1587 - val_accuracy: 0.7565\n",
      "\n",
      "Epoch 03807: val_loss did not improve from 0.32861\n",
      "Epoch 3808/4000\n",
      "25/25 - 0s - loss: 0.3015 - accuracy: 0.8405 - val_loss: 2.2015 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 03808: val_loss did not improve from 0.32861\n",
      "Epoch 3809/4000\n",
      "25/25 - 0s - loss: 0.3025 - accuracy: 0.8379 - val_loss: 2.1399 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 03809: val_loss did not improve from 0.32861\n",
      "Epoch 3810/4000\n",
      "25/25 - 0s - loss: 0.2972 - accuracy: 0.8379 - val_loss: 2.1472 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 03810: val_loss did not improve from 0.32861\n",
      "Epoch 3811/4000\n",
      "25/25 - 0s - loss: 0.2953 - accuracy: 0.8444 - val_loss: 2.2925 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 03811: val_loss did not improve from 0.32861\n",
      "Epoch 3812/4000\n",
      "25/25 - 0s - loss: 0.2925 - accuracy: 0.8327 - val_loss: 2.1886 - val_accuracy: 0.7772\n",
      "\n",
      "Epoch 03812: val_loss did not improve from 0.32861\n",
      "Epoch 3813/4000\n",
      "25/25 - 0s - loss: 0.2956 - accuracy: 0.8262 - val_loss: 2.2566 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03813: val_loss did not improve from 0.32861\n",
      "Epoch 3814/4000\n",
      "25/25 - 0s - loss: 0.3020 - accuracy: 0.8508 - val_loss: 2.4093 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 03814: val_loss did not improve from 0.32861\n",
      "Epoch 3815/4000\n",
      "25/25 - 0s - loss: 0.2901 - accuracy: 0.8405 - val_loss: 2.2036 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 03815: val_loss did not improve from 0.32861\n",
      "Epoch 3816/4000\n",
      "25/25 - 0s - loss: 0.2942 - accuracy: 0.8405 - val_loss: 2.6168 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 03816: val_loss did not improve from 0.32861\n",
      "Epoch 3817/4000\n",
      "25/25 - 0s - loss: 0.3228 - accuracy: 0.8353 - val_loss: 2.0892 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 03817: val_loss did not improve from 0.32861\n",
      "Epoch 3818/4000\n",
      "25/25 - 0s - loss: 0.3128 - accuracy: 0.8392 - val_loss: 2.1096 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 03818: val_loss did not improve from 0.32861\n",
      "Epoch 3819/4000\n",
      "25/25 - 0s - loss: 0.3185 - accuracy: 0.8197 - val_loss: 2.9724 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03819: val_loss did not improve from 0.32861\n",
      "Epoch 3820/4000\n",
      "25/25 - 0s - loss: 0.3055 - accuracy: 0.8444 - val_loss: 3.0076 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03820: val_loss did not improve from 0.32861\n",
      "Epoch 3821/4000\n",
      "25/25 - 0s - loss: 0.3421 - accuracy: 0.8158 - val_loss: 3.6143 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03821: val_loss did not improve from 0.32861\n",
      "Epoch 3822/4000\n",
      "25/25 - 0s - loss: 0.3018 - accuracy: 0.8366 - val_loss: 3.4448 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 03822: val_loss did not improve from 0.32861\n",
      "Epoch 3823/4000\n",
      "25/25 - 0s - loss: 0.3019 - accuracy: 0.8495 - val_loss: 2.9838 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03823: val_loss did not improve from 0.32861\n",
      "Epoch 3824/4000\n",
      "25/25 - 0s - loss: 0.3113 - accuracy: 0.8340 - val_loss: 3.2807 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03824: val_loss did not improve from 0.32861\n",
      "Epoch 3825/4000\n",
      "25/25 - 0s - loss: 0.2951 - accuracy: 0.8508 - val_loss: 3.2242 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03825: val_loss did not improve from 0.32861\n",
      "Epoch 3826/4000\n",
      "25/25 - 0s - loss: 0.3152 - accuracy: 0.8288 - val_loss: 3.2502 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03826: val_loss did not improve from 0.32861\n",
      "Epoch 3827/4000\n",
      "25/25 - 0s - loss: 0.3047 - accuracy: 0.8366 - val_loss: 3.2591 - val_accuracy: 0.7772\n",
      "\n",
      "Epoch 03827: val_loss did not improve from 0.32861\n",
      "Epoch 3828/4000\n",
      "25/25 - 0s - loss: 0.2995 - accuracy: 0.8379 - val_loss: 3.2517 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03828: val_loss did not improve from 0.32861\n",
      "Epoch 3829/4000\n",
      "25/25 - 0s - loss: 0.2989 - accuracy: 0.8366 - val_loss: 3.2603 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03829: val_loss did not improve from 0.32861\n",
      "Epoch 3830/4000\n",
      "25/25 - 0s - loss: 0.3010 - accuracy: 0.8418 - val_loss: 3.1176 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03830: val_loss did not improve from 0.32861\n",
      "Epoch 3831/4000\n",
      "25/25 - 0s - loss: 0.2948 - accuracy: 0.8262 - val_loss: 2.9550 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03831: val_loss did not improve from 0.32861\n",
      "Epoch 3832/4000\n",
      "25/25 - 0s - loss: 0.2974 - accuracy: 0.8314 - val_loss: 2.9724 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 03832: val_loss did not improve from 0.32861\n",
      "Epoch 3833/4000\n",
      "25/25 - 0s - loss: 0.3098 - accuracy: 0.8405 - val_loss: 2.9498 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03833: val_loss did not improve from 0.32861\n",
      "Epoch 3834/4000\n",
      "25/25 - 0s - loss: 0.3024 - accuracy: 0.8327 - val_loss: 2.7937 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03834: val_loss did not improve from 0.32861\n",
      "Epoch 3835/4000\n",
      "25/25 - 0s - loss: 0.2965 - accuracy: 0.8392 - val_loss: 2.8393 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 03835: val_loss did not improve from 0.32861\n",
      "Epoch 3836/4000\n",
      "25/25 - 0s - loss: 0.2981 - accuracy: 0.8327 - val_loss: 2.9531 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 03836: val_loss did not improve from 0.32861\n",
      "Epoch 3837/4000\n",
      "25/25 - 0s - loss: 0.3099 - accuracy: 0.8223 - val_loss: 2.9622 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03837: val_loss did not improve from 0.32861\n",
      "Epoch 3838/4000\n",
      "25/25 - 0s - loss: 0.2879 - accuracy: 0.8418 - val_loss: 2.9879 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03838: val_loss did not improve from 0.32861\n",
      "Epoch 3839/4000\n",
      "25/25 - 0s - loss: 0.2858 - accuracy: 0.8275 - val_loss: 2.9663 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03839: val_loss did not improve from 0.32861\n",
      "Epoch 3840/4000\n",
      "25/25 - 0s - loss: 0.2955 - accuracy: 0.8405 - val_loss: 3.0282 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03840: val_loss did not improve from 0.32861\n",
      "Epoch 3841/4000\n",
      "25/25 - 0s - loss: 0.2987 - accuracy: 0.8314 - val_loss: 3.4483 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03841: val_loss did not improve from 0.32861\n",
      "Epoch 3842/4000\n",
      "25/25 - 0s - loss: 0.2895 - accuracy: 0.8470 - val_loss: 3.7747 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03842: val_loss did not improve from 0.32861\n",
      "Epoch 3843/4000\n",
      "25/25 - 0s - loss: 0.2928 - accuracy: 0.8301 - val_loss: 4.1276 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03843: val_loss did not improve from 0.32861\n",
      "Epoch 3844/4000\n",
      "25/25 - 0s - loss: 0.2924 - accuracy: 0.8470 - val_loss: 3.9721 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03844: val_loss did not improve from 0.32861\n",
      "Epoch 3845/4000\n",
      "25/25 - 0s - loss: 0.2910 - accuracy: 0.8431 - val_loss: 4.0671 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03845: val_loss did not improve from 0.32861\n",
      "Epoch 3846/4000\n",
      "25/25 - 0s - loss: 0.2901 - accuracy: 0.8418 - val_loss: 4.2381 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03846: val_loss did not improve from 0.32861\n",
      "Epoch 3847/4000\n",
      "25/25 - 0s - loss: 0.2909 - accuracy: 0.8495 - val_loss: 4.0561 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03847: val_loss did not improve from 0.32861\n",
      "Epoch 3848/4000\n",
      "25/25 - 0s - loss: 0.2874 - accuracy: 0.8353 - val_loss: 4.1853 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03848: val_loss did not improve from 0.32861\n",
      "Epoch 3849/4000\n",
      "25/25 - 0s - loss: 0.2886 - accuracy: 0.8521 - val_loss: 4.2989 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03849: val_loss did not improve from 0.32861\n",
      "Epoch 3850/4000\n",
      "25/25 - 0s - loss: 0.2978 - accuracy: 0.8366 - val_loss: 4.2978 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03850: val_loss did not improve from 0.32861\n",
      "Epoch 3851/4000\n",
      "25/25 - 0s - loss: 0.2939 - accuracy: 0.8392 - val_loss: 4.3034 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03851: val_loss did not improve from 0.32861\n",
      "Epoch 3852/4000\n",
      "25/25 - 0s - loss: 0.2885 - accuracy: 0.8392 - val_loss: 4.1806 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03852: val_loss did not improve from 0.32861\n",
      "Epoch 3853/4000\n",
      "25/25 - 0s - loss: 0.2980 - accuracy: 0.8444 - val_loss: 4.4021 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03853: val_loss did not improve from 0.32861\n",
      "Epoch 3854/4000\n",
      "25/25 - 0s - loss: 0.2873 - accuracy: 0.8457 - val_loss: 4.3303 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03854: val_loss did not improve from 0.32861\n",
      "Epoch 3855/4000\n",
      "25/25 - 0s - loss: 0.3004 - accuracy: 0.8314 - val_loss: 4.3696 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03855: val_loss did not improve from 0.32861\n",
      "Epoch 3856/4000\n",
      "25/25 - 0s - loss: 0.3080 - accuracy: 0.8366 - val_loss: 4.1724 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03856: val_loss did not improve from 0.32861\n",
      "Epoch 3857/4000\n",
      "25/25 - 0s - loss: 0.2859 - accuracy: 0.8457 - val_loss: 4.3925 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03857: val_loss did not improve from 0.32861\n",
      "Epoch 3858/4000\n",
      "25/25 - 0s - loss: 0.2888 - accuracy: 0.8353 - val_loss: 4.6712 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03858: val_loss did not improve from 0.32861\n",
      "Epoch 3859/4000\n",
      "25/25 - 0s - loss: 0.2913 - accuracy: 0.8444 - val_loss: 4.3406 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03859: val_loss did not improve from 0.32861\n",
      "Epoch 3860/4000\n",
      "25/25 - 0s - loss: 0.2878 - accuracy: 0.8444 - val_loss: 4.5101 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03860: val_loss did not improve from 0.32861\n",
      "Epoch 3861/4000\n",
      "25/25 - 0s - loss: 0.3040 - accuracy: 0.8418 - val_loss: 4.6321 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03861: val_loss did not improve from 0.32861\n",
      "Epoch 3862/4000\n",
      "25/25 - 0s - loss: 0.2931 - accuracy: 0.8392 - val_loss: 4.7149 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03862: val_loss did not improve from 0.32861\n",
      "Epoch 3863/4000\n",
      "25/25 - 0s - loss: 0.2881 - accuracy: 0.8470 - val_loss: 4.4921 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03863: val_loss did not improve from 0.32861\n",
      "Epoch 3864/4000\n",
      "25/25 - 0s - loss: 0.2857 - accuracy: 0.8431 - val_loss: 4.4967 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03864: val_loss did not improve from 0.32861\n",
      "Epoch 3865/4000\n",
      "25/25 - 0s - loss: 0.2986 - accuracy: 0.8431 - val_loss: 4.5585 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03865: val_loss did not improve from 0.32861\n",
      "Epoch 3866/4000\n",
      "25/25 - 0s - loss: 0.3065 - accuracy: 0.8353 - val_loss: 4.1721 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03866: val_loss did not improve from 0.32861\n",
      "Epoch 3867/4000\n",
      "25/25 - 0s - loss: 0.2961 - accuracy: 0.8418 - val_loss: 4.1283 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03867: val_loss did not improve from 0.32861\n",
      "Epoch 3868/4000\n",
      "25/25 - 0s - loss: 0.2892 - accuracy: 0.8405 - val_loss: 3.9185 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03868: val_loss did not improve from 0.32861\n",
      "Epoch 3869/4000\n",
      "25/25 - 0s - loss: 0.2824 - accuracy: 0.8405 - val_loss: 4.2230 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03869: val_loss did not improve from 0.32861\n",
      "Epoch 3870/4000\n",
      "25/25 - 0s - loss: 0.2832 - accuracy: 0.8405 - val_loss: 4.4060 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03870: val_loss did not improve from 0.32861\n",
      "Epoch 3871/4000\n",
      "25/25 - 0s - loss: 0.2860 - accuracy: 0.8353 - val_loss: 4.4089 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03871: val_loss did not improve from 0.32861\n",
      "Epoch 3872/4000\n",
      "25/25 - 0s - loss: 0.2888 - accuracy: 0.8444 - val_loss: 4.5543 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03872: val_loss did not improve from 0.32861\n",
      "Epoch 3873/4000\n",
      "25/25 - 0s - loss: 0.2840 - accuracy: 0.8431 - val_loss: 4.6882 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03873: val_loss did not improve from 0.32861\n",
      "Epoch 3874/4000\n",
      "25/25 - 0s - loss: 0.2835 - accuracy: 0.8353 - val_loss: 4.7407 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03874: val_loss did not improve from 0.32861\n",
      "Epoch 3875/4000\n",
      "25/25 - 0s - loss: 0.2815 - accuracy: 0.8508 - val_loss: 4.4091 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03875: val_loss did not improve from 0.32861\n",
      "Epoch 3876/4000\n",
      "25/25 - 0s - loss: 0.2887 - accuracy: 0.8457 - val_loss: 4.5029 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03876: val_loss did not improve from 0.32861\n",
      "Epoch 3877/4000\n",
      "25/25 - 0s - loss: 0.2882 - accuracy: 0.8366 - val_loss: 4.6193 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03877: val_loss did not improve from 0.32861\n",
      "Epoch 3878/4000\n",
      "25/25 - 0s - loss: 0.2899 - accuracy: 0.8431 - val_loss: 4.6418 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03878: val_loss did not improve from 0.32861\n",
      "Epoch 3879/4000\n",
      "25/25 - 0s - loss: 0.2848 - accuracy: 0.8508 - val_loss: 4.8335 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03879: val_loss did not improve from 0.32861\n",
      "Epoch 3880/4000\n",
      "25/25 - 0s - loss: 0.2836 - accuracy: 0.8379 - val_loss: 4.9547 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03880: val_loss did not improve from 0.32861\n",
      "Epoch 3881/4000\n",
      "25/25 - 0s - loss: 0.2867 - accuracy: 0.8495 - val_loss: 5.1130 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03881: val_loss did not improve from 0.32861\n",
      "Epoch 3882/4000\n",
      "25/25 - 0s - loss: 0.3111 - accuracy: 0.8275 - val_loss: 4.8155 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03882: val_loss did not improve from 0.32861\n",
      "Epoch 3883/4000\n",
      "25/25 - 0s - loss: 0.2874 - accuracy: 0.8444 - val_loss: 5.0583 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03883: val_loss did not improve from 0.32861\n",
      "Epoch 3884/4000\n",
      "25/25 - 0s - loss: 0.2854 - accuracy: 0.8379 - val_loss: 5.0123 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03884: val_loss did not improve from 0.32861\n",
      "Epoch 3885/4000\n",
      "25/25 - 0s - loss: 0.2849 - accuracy: 0.8405 - val_loss: 5.1704 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03885: val_loss did not improve from 0.32861\n",
      "Epoch 3886/4000\n",
      "25/25 - 0s - loss: 0.2836 - accuracy: 0.8418 - val_loss: 5.3424 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03886: val_loss did not improve from 0.32861\n",
      "Epoch 3887/4000\n",
      "25/25 - 0s - loss: 0.2831 - accuracy: 0.8495 - val_loss: 5.4212 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03887: val_loss did not improve from 0.32861\n",
      "Epoch 3888/4000\n",
      "25/25 - 0s - loss: 0.2851 - accuracy: 0.8431 - val_loss: 5.5603 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03888: val_loss did not improve from 0.32861\n",
      "Epoch 3889/4000\n",
      "25/25 - 0s - loss: 0.2937 - accuracy: 0.8495 - val_loss: 6.6040 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03889: val_loss did not improve from 0.32861\n",
      "Epoch 3890/4000\n",
      "25/25 - 0s - loss: 0.2999 - accuracy: 0.8457 - val_loss: 7.5987 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03890: val_loss did not improve from 0.32861\n",
      "Epoch 3891/4000\n",
      "25/25 - 0s - loss: 0.2771 - accuracy: 0.8547 - val_loss: 7.5919 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03891: val_loss did not improve from 0.32861\n",
      "Epoch 3892/4000\n",
      "25/25 - 0s - loss: 0.2750 - accuracy: 0.8547 - val_loss: 7.4709 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03892: val_loss did not improve from 0.32861\n",
      "Epoch 3893/4000\n",
      "25/25 - 0s - loss: 0.2782 - accuracy: 0.8586 - val_loss: 7.3552 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03893: val_loss did not improve from 0.32861\n",
      "Epoch 3894/4000\n",
      "25/25 - 0s - loss: 0.2815 - accuracy: 0.8482 - val_loss: 7.3191 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03894: val_loss did not improve from 0.32861\n",
      "Epoch 3895/4000\n",
      "25/25 - 0s - loss: 0.2833 - accuracy: 0.8521 - val_loss: 7.3396 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03895: val_loss did not improve from 0.32861\n",
      "Epoch 3896/4000\n",
      "25/25 - 0s - loss: 0.2775 - accuracy: 0.8573 - val_loss: 7.3506 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03896: val_loss did not improve from 0.32861\n",
      "Epoch 3897/4000\n",
      "25/25 - 0s - loss: 0.2778 - accuracy: 0.8573 - val_loss: 7.5921 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03897: val_loss did not improve from 0.32861\n",
      "Epoch 3898/4000\n",
      "25/25 - 0s - loss: 0.2814 - accuracy: 0.8573 - val_loss: 7.9629 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03898: val_loss did not improve from 0.32861\n",
      "Epoch 3899/4000\n",
      "25/25 - 0s - loss: 0.2858 - accuracy: 0.8547 - val_loss: 7.4465 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03899: val_loss did not improve from 0.32861\n",
      "Epoch 3900/4000\n",
      "25/25 - 0s - loss: 0.3324 - accuracy: 0.8392 - val_loss: 7.7147 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 03900: val_loss did not improve from 0.32861\n",
      "Epoch 3901/4000\n",
      "25/25 - 0s - loss: 0.3170 - accuracy: 0.8353 - val_loss: 7.8829 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03901: val_loss did not improve from 0.32861\n",
      "Epoch 3902/4000\n",
      "25/25 - 0s - loss: 0.2929 - accuracy: 0.8495 - val_loss: 7.6481 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03902: val_loss did not improve from 0.32861\n",
      "Epoch 3903/4000\n",
      "25/25 - 0s - loss: 0.2810 - accuracy: 0.8482 - val_loss: 7.5679 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03903: val_loss did not improve from 0.32861\n",
      "Epoch 3904/4000\n",
      "25/25 - 0s - loss: 0.2776 - accuracy: 0.8444 - val_loss: 7.6424 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03904: val_loss did not improve from 0.32861\n",
      "Epoch 3905/4000\n",
      "25/25 - 0s - loss: 0.2707 - accuracy: 0.8457 - val_loss: 7.6250 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03905: val_loss did not improve from 0.32861\n",
      "Epoch 3906/4000\n",
      "25/25 - 0s - loss: 0.2880 - accuracy: 0.8431 - val_loss: 7.7708 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03906: val_loss did not improve from 0.32861\n",
      "Epoch 3907/4000\n",
      "25/25 - 0s - loss: 0.2891 - accuracy: 0.8508 - val_loss: 7.8093 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03907: val_loss did not improve from 0.32861\n",
      "Epoch 3908/4000\n",
      "25/25 - 0s - loss: 0.2676 - accuracy: 0.8573 - val_loss: 7.7647 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03908: val_loss did not improve from 0.32861\n",
      "Epoch 3909/4000\n",
      "25/25 - 0s - loss: 0.2700 - accuracy: 0.8612 - val_loss: 7.7851 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03909: val_loss did not improve from 0.32861\n",
      "Epoch 3910/4000\n",
      "25/25 - 0s - loss: 0.2668 - accuracy: 0.8547 - val_loss: 7.8984 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03910: val_loss did not improve from 0.32861\n",
      "Epoch 3911/4000\n",
      "25/25 - 0s - loss: 0.2835 - accuracy: 0.8431 - val_loss: 7.8262 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03911: val_loss did not improve from 0.32861\n",
      "Epoch 3912/4000\n",
      "25/25 - 0s - loss: 0.2698 - accuracy: 0.8612 - val_loss: 7.7329 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03912: val_loss did not improve from 0.32861\n",
      "Epoch 3913/4000\n",
      "25/25 - 0s - loss: 0.2697 - accuracy: 0.8586 - val_loss: 7.8101 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03913: val_loss did not improve from 0.32861\n",
      "Epoch 3914/4000\n",
      "25/25 - 0s - loss: 0.2668 - accuracy: 0.8534 - val_loss: 7.8064 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03914: val_loss did not improve from 0.32861\n",
      "Epoch 3915/4000\n",
      "25/25 - 0s - loss: 0.2778 - accuracy: 0.8560 - val_loss: 7.7930 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03915: val_loss did not improve from 0.32861\n",
      "Epoch 3916/4000\n",
      "25/25 - 0s - loss: 0.2708 - accuracy: 0.8534 - val_loss: 8.0390 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03916: val_loss did not improve from 0.32861\n",
      "Epoch 3917/4000\n",
      "25/25 - 0s - loss: 0.2888 - accuracy: 0.8392 - val_loss: 7.9178 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03917: val_loss did not improve from 0.32861\n",
      "Epoch 3918/4000\n",
      "25/25 - 0s - loss: 0.2776 - accuracy: 0.8457 - val_loss: 7.9097 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03918: val_loss did not improve from 0.32861\n",
      "Epoch 3919/4000\n",
      "25/25 - 0s - loss: 0.2760 - accuracy: 0.8508 - val_loss: 7.8888 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03919: val_loss did not improve from 0.32861\n",
      "Epoch 3920/4000\n",
      "25/25 - 0s - loss: 0.2658 - accuracy: 0.8534 - val_loss: 8.1223 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03920: val_loss did not improve from 0.32861\n",
      "Epoch 3921/4000\n",
      "25/25 - 0s - loss: 0.2720 - accuracy: 0.8547 - val_loss: 8.0244 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03921: val_loss did not improve from 0.32861\n",
      "Epoch 3922/4000\n",
      "25/25 - 0s - loss: 0.2673 - accuracy: 0.8560 - val_loss: 8.0335 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03922: val_loss did not improve from 0.32861\n",
      "Epoch 3923/4000\n",
      "25/25 - 0s - loss: 0.2765 - accuracy: 0.8495 - val_loss: 8.1995 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03923: val_loss did not improve from 0.32861\n",
      "Epoch 3924/4000\n",
      "25/25 - 0s - loss: 0.2654 - accuracy: 0.8612 - val_loss: 7.7634 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03924: val_loss did not improve from 0.32861\n",
      "Epoch 3925/4000\n",
      "25/25 - 0s - loss: 0.2748 - accuracy: 0.8586 - val_loss: 7.7703 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03925: val_loss did not improve from 0.32861\n",
      "Epoch 3926/4000\n",
      "25/25 - 0s - loss: 0.2811 - accuracy: 0.8327 - val_loss: 7.8578 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03926: val_loss did not improve from 0.32861\n",
      "Epoch 3927/4000\n",
      "25/25 - 0s - loss: 0.2734 - accuracy: 0.8482 - val_loss: 8.0106 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03927: val_loss did not improve from 0.32861\n",
      "Epoch 3928/4000\n",
      "25/25 - 0s - loss: 0.2657 - accuracy: 0.8573 - val_loss: 7.9978 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03928: val_loss did not improve from 0.32861\n",
      "Epoch 3929/4000\n",
      "25/25 - 0s - loss: 0.2771 - accuracy: 0.8508 - val_loss: 7.9475 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03929: val_loss did not improve from 0.32861\n",
      "Epoch 3930/4000\n",
      "25/25 - 0s - loss: 0.2684 - accuracy: 0.8495 - val_loss: 8.1223 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03930: val_loss did not improve from 0.32861\n",
      "Epoch 3931/4000\n",
      "25/25 - 0s - loss: 0.2735 - accuracy: 0.8534 - val_loss: 8.0929 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03931: val_loss did not improve from 0.32861\n",
      "Epoch 3932/4000\n",
      "25/25 - 0s - loss: 0.2688 - accuracy: 0.8534 - val_loss: 8.1646 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03932: val_loss did not improve from 0.32861\n",
      "Epoch 3933/4000\n",
      "25/25 - 0s - loss: 0.2648 - accuracy: 0.8625 - val_loss: 8.1977 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03933: val_loss did not improve from 0.32861\n",
      "Epoch 3934/4000\n",
      "25/25 - 0s - loss: 0.2715 - accuracy: 0.8534 - val_loss: 8.1038 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03934: val_loss did not improve from 0.32861\n",
      "Epoch 3935/4000\n",
      "25/25 - 0s - loss: 0.2659 - accuracy: 0.8573 - val_loss: 8.2326 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03935: val_loss did not improve from 0.32861\n",
      "Epoch 3936/4000\n",
      "25/25 - 0s - loss: 0.2704 - accuracy: 0.8508 - val_loss: 8.1267 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03936: val_loss did not improve from 0.32861\n",
      "Epoch 3937/4000\n",
      "25/25 - 0s - loss: 0.2672 - accuracy: 0.8560 - val_loss: 8.0702 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03937: val_loss did not improve from 0.32861\n",
      "Epoch 3938/4000\n",
      "25/25 - 1s - loss: 0.2703 - accuracy: 0.8508 - val_loss: 8.2875 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03938: val_loss did not improve from 0.32861\n",
      "Epoch 3939/4000\n",
      "25/25 - 0s - loss: 0.2742 - accuracy: 0.8612 - val_loss: 8.4894 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03939: val_loss did not improve from 0.32861\n",
      "Epoch 3940/4000\n",
      "25/25 - 0s - loss: 0.2753 - accuracy: 0.8495 - val_loss: 8.4504 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03940: val_loss did not improve from 0.32861\n",
      "Epoch 3941/4000\n",
      "25/25 - 0s - loss: 0.2847 - accuracy: 0.8534 - val_loss: 8.2518 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03941: val_loss did not improve from 0.32861\n",
      "Epoch 3942/4000\n",
      "25/25 - 0s - loss: 0.2779 - accuracy: 0.8482 - val_loss: 8.2839 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03942: val_loss did not improve from 0.32861\n",
      "Epoch 3943/4000\n",
      "25/25 - 0s - loss: 0.2701 - accuracy: 0.8495 - val_loss: 8.4742 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03943: val_loss did not improve from 0.32861\n",
      "Epoch 3944/4000\n",
      "25/25 - 0s - loss: 0.2828 - accuracy: 0.8457 - val_loss: 8.2935 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03944: val_loss did not improve from 0.32861\n",
      "Epoch 3945/4000\n",
      "25/25 - 0s - loss: 0.2704 - accuracy: 0.8625 - val_loss: 8.3774 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03945: val_loss did not improve from 0.32861\n",
      "Epoch 3946/4000\n",
      "25/25 - 0s - loss: 0.2695 - accuracy: 0.8573 - val_loss: 8.6377 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03946: val_loss did not improve from 0.32861\n",
      "Epoch 3947/4000\n",
      "25/25 - 0s - loss: 0.2787 - accuracy: 0.8547 - val_loss: 8.7627 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03947: val_loss did not improve from 0.32861\n",
      "Epoch 3948/4000\n",
      "25/25 - 0s - loss: 0.2729 - accuracy: 0.8560 - val_loss: 8.5565 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03948: val_loss did not improve from 0.32861\n",
      "Epoch 3949/4000\n",
      "25/25 - 0s - loss: 0.2695 - accuracy: 0.8495 - val_loss: 8.8036 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03949: val_loss did not improve from 0.32861\n",
      "Epoch 3950/4000\n",
      "25/25 - 0s - loss: 0.2811 - accuracy: 0.8418 - val_loss: 8.6451 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03950: val_loss did not improve from 0.32861\n",
      "Epoch 3951/4000\n",
      "25/25 - 0s - loss: 0.3360 - accuracy: 0.8418 - val_loss: 8.0298 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03951: val_loss did not improve from 0.32861\n",
      "Epoch 3952/4000\n",
      "25/25 - 0s - loss: 0.2856 - accuracy: 0.8431 - val_loss: 8.0462 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03952: val_loss did not improve from 0.32861\n",
      "Epoch 3953/4000\n",
      "25/25 - 0s - loss: 0.3057 - accuracy: 0.8573 - val_loss: 8.0307 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03953: val_loss did not improve from 0.32861\n",
      "Epoch 3954/4000\n",
      "25/25 - 0s - loss: 0.3044 - accuracy: 0.8470 - val_loss: 6.4709 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03954: val_loss did not improve from 0.32861\n",
      "Epoch 3955/4000\n",
      "25/25 - 0s - loss: 0.2879 - accuracy: 0.8444 - val_loss: 6.2723 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03955: val_loss did not improve from 0.32861\n",
      "Epoch 3956/4000\n",
      "25/25 - 0s - loss: 0.2798 - accuracy: 0.8599 - val_loss: 6.6185 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03956: val_loss did not improve from 0.32861\n",
      "Epoch 3957/4000\n",
      "25/25 - 0s - loss: 0.2830 - accuracy: 0.8703 - val_loss: 7.4561 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03957: val_loss did not improve from 0.32861\n",
      "Epoch 3958/4000\n",
      "25/25 - 0s - loss: 0.2755 - accuracy: 0.8729 - val_loss: 7.6656 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03958: val_loss did not improve from 0.32861\n",
      "Epoch 3959/4000\n",
      "25/25 - 0s - loss: 0.2750 - accuracy: 0.8625 - val_loss: 8.0863 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03959: val_loss did not improve from 0.32861\n",
      "Epoch 3960/4000\n",
      "25/25 - 0s - loss: 0.2829 - accuracy: 0.8457 - val_loss: 7.9419 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 03960: val_loss did not improve from 0.32861\n",
      "Epoch 3961/4000\n",
      "25/25 - 0s - loss: 0.2778 - accuracy: 0.8612 - val_loss: 8.0891 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03961: val_loss did not improve from 0.32861\n",
      "Epoch 3962/4000\n",
      "25/25 - 0s - loss: 0.2728 - accuracy: 0.8573 - val_loss: 8.1854 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03962: val_loss did not improve from 0.32861\n",
      "Epoch 3963/4000\n",
      "25/25 - 0s - loss: 0.2731 - accuracy: 0.8586 - val_loss: 8.2057 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03963: val_loss did not improve from 0.32861\n",
      "Epoch 3964/4000\n",
      "25/25 - 0s - loss: 0.2767 - accuracy: 0.8444 - val_loss: 8.2551 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03964: val_loss did not improve from 0.32861\n",
      "Epoch 3965/4000\n",
      "25/25 - 0s - loss: 0.2728 - accuracy: 0.8560 - val_loss: 8.1276 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03965: val_loss did not improve from 0.32861\n",
      "Epoch 3966/4000\n",
      "25/25 - 0s - loss: 0.2828 - accuracy: 0.8573 - val_loss: 7.9995 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03966: val_loss did not improve from 0.32861\n",
      "Epoch 3967/4000\n",
      "25/25 - 0s - loss: 0.2864 - accuracy: 0.8482 - val_loss: 8.1404 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03967: val_loss did not improve from 0.32861\n",
      "Epoch 3968/4000\n",
      "25/25 - 0s - loss: 0.2736 - accuracy: 0.8547 - val_loss: 8.0488 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03968: val_loss did not improve from 0.32861\n",
      "Epoch 3969/4000\n",
      "25/25 - 0s - loss: 0.2912 - accuracy: 0.8457 - val_loss: 8.2708 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03969: val_loss did not improve from 0.32861\n",
      "Epoch 3970/4000\n",
      "25/25 - 0s - loss: 0.2754 - accuracy: 0.8586 - val_loss: 8.3175 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03970: val_loss did not improve from 0.32861\n",
      "Epoch 3971/4000\n",
      "25/25 - 0s - loss: 0.2814 - accuracy: 0.8547 - val_loss: 8.1278 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03971: val_loss did not improve from 0.32861\n",
      "Epoch 3972/4000\n",
      "25/25 - 0s - loss: 0.2728 - accuracy: 0.8625 - val_loss: 8.2374 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03972: val_loss did not improve from 0.32861\n",
      "Epoch 3973/4000\n",
      "25/25 - 0s - loss: 0.2739 - accuracy: 0.8521 - val_loss: 8.2744 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03973: val_loss did not improve from 0.32861\n",
      "Epoch 3974/4000\n",
      "25/25 - 0s - loss: 0.2727 - accuracy: 0.8560 - val_loss: 8.1082 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03974: val_loss did not improve from 0.32861\n",
      "Epoch 3975/4000\n",
      "25/25 - 0s - loss: 0.2744 - accuracy: 0.8573 - val_loss: 8.2822 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03975: val_loss did not improve from 0.32861\n",
      "Epoch 3976/4000\n",
      "25/25 - 0s - loss: 0.2688 - accuracy: 0.8547 - val_loss: 8.4291 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03976: val_loss did not improve from 0.32861\n",
      "Epoch 3977/4000\n",
      "25/25 - 0s - loss: 0.2807 - accuracy: 0.8560 - val_loss: 8.0319 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03977: val_loss did not improve from 0.32861\n",
      "Epoch 3978/4000\n",
      "25/25 - 0s - loss: 0.2880 - accuracy: 0.8560 - val_loss: 7.2997 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03978: val_loss did not improve from 0.32861\n",
      "Epoch 3979/4000\n",
      "25/25 - 0s - loss: 0.2905 - accuracy: 0.8521 - val_loss: 7.7877 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03979: val_loss did not improve from 0.32861\n",
      "Epoch 3980/4000\n",
      "25/25 - 0s - loss: 0.3152 - accuracy: 0.8457 - val_loss: 7.7832 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 03980: val_loss did not improve from 0.32861\n",
      "Epoch 3981/4000\n",
      "25/25 - 0s - loss: 0.2991 - accuracy: 0.8457 - val_loss: 8.5423 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03981: val_loss did not improve from 0.32861\n",
      "Epoch 3982/4000\n",
      "25/25 - 0s - loss: 0.2886 - accuracy: 0.8573 - val_loss: 8.2698 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03982: val_loss did not improve from 0.32861\n",
      "Epoch 3983/4000\n",
      "25/25 - 0s - loss: 0.2940 - accuracy: 0.8547 - val_loss: 7.9757 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03983: val_loss did not improve from 0.32861\n",
      "Epoch 3984/4000\n",
      "25/25 - 0s - loss: 0.2830 - accuracy: 0.8560 - val_loss: 8.0302 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03984: val_loss did not improve from 0.32861\n",
      "Epoch 3985/4000\n",
      "25/25 - 0s - loss: 0.2761 - accuracy: 0.8586 - val_loss: 7.9977 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03985: val_loss did not improve from 0.32861\n",
      "Epoch 3986/4000\n",
      "25/25 - 0s - loss: 0.2742 - accuracy: 0.8521 - val_loss: 8.2549 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03986: val_loss did not improve from 0.32861\n",
      "Epoch 3987/4000\n",
      "25/25 - 0s - loss: 0.2778 - accuracy: 0.8521 - val_loss: 8.3240 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03987: val_loss did not improve from 0.32861\n",
      "Epoch 3988/4000\n",
      "25/25 - 0s - loss: 0.2716 - accuracy: 0.8586 - val_loss: 8.4220 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03988: val_loss did not improve from 0.32861\n",
      "Epoch 3989/4000\n",
      "25/25 - 0s - loss: 0.2762 - accuracy: 0.8405 - val_loss: 8.4917 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 03989: val_loss did not improve from 0.32861\n",
      "Epoch 3990/4000\n",
      "25/25 - 0s - loss: 0.2745 - accuracy: 0.8599 - val_loss: 8.7319 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03990: val_loss did not improve from 0.32861\n",
      "Epoch 3991/4000\n",
      "25/25 - 0s - loss: 0.2740 - accuracy: 0.8573 - val_loss: 8.7187 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03991: val_loss did not improve from 0.32861\n",
      "Epoch 3992/4000\n",
      "25/25 - 0s - loss: 0.2836 - accuracy: 0.8560 - val_loss: 8.7062 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03992: val_loss did not improve from 0.32861\n",
      "Epoch 3993/4000\n",
      "25/25 - 0s - loss: 0.2817 - accuracy: 0.8508 - val_loss: 9.1848 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03993: val_loss did not improve from 0.32861\n",
      "Epoch 3994/4000\n",
      "25/25 - 0s - loss: 0.2794 - accuracy: 0.8508 - val_loss: 8.9254 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03994: val_loss did not improve from 0.32861\n",
      "Epoch 3995/4000\n",
      "25/25 - 0s - loss: 0.2817 - accuracy: 0.8547 - val_loss: 8.9144 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 03995: val_loss did not improve from 0.32861\n",
      "Epoch 3996/4000\n",
      "25/25 - 0s - loss: 0.2942 - accuracy: 0.8392 - val_loss: 8.8843 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03996: val_loss did not improve from 0.32861\n",
      "Epoch 3997/4000\n",
      "25/25 - 0s - loss: 0.2731 - accuracy: 0.8547 - val_loss: 8.8950 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 03997: val_loss did not improve from 0.32861\n",
      "Epoch 3998/4000\n",
      "25/25 - 0s - loss: 0.2828 - accuracy: 0.8444 - val_loss: 8.6727 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 03998: val_loss did not improve from 0.32861\n",
      "Epoch 3999/4000\n",
      "25/25 - 0s - loss: 0.2800 - accuracy: 0.8521 - val_loss: 8.5905 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 03999: val_loss did not improve from 0.32861\n",
      "Epoch 4000/4000\n",
      "25/25 - 0s - loss: 0.2837 - accuracy: 0.8560 - val_loss: 8.7695 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 04000: val_loss did not improve from 0.32861\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                1024      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 8,547\n",
      "Trainable params: 8,547\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([      \n",
    "      tf.keras.layers.Dense(32, activation='relu'),\n",
    "      tf.keras.layers.Dense(32, activation='relu'),\n",
    "       tf.keras.layers.Dense(64, activation='relu'),\n",
    "      tf.keras.layers.Dense(64, activation='relu'),\n",
    "      tf.keras.layers.Dense(3)\n",
    "    ])\n",
    "learning_rate = 0.01\n",
    "batch_size = 32\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "metrics = ['accuracy']\n",
    "model_filename = 'models/model_4L_v2'\n",
    "model_l_v_e_filename = 'loss_vs_epochs_images/model_4L_v2_le.png'\n",
    "model_l_v_e_title = 'model_4L_v2'\n",
    "model_history_filename = 'history/history_model_4L_v2'\n",
    "\n",
    "model.compile(optimizer, loss_fn, metrics)\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(model_filename, monitor='val_loss', verbose=1,save_best_only=True, mode='min')\n",
    "model.fit(X_train, y_train, epochs = 4000,  validation_data=(X_test, y_test),batch_size = batch_size,callbacks=[checkpoint], verbose=2)\n",
    "model.summary()\n",
    "graph_loss_vs_epochs(model.history, model_l_v_e_filename, model_l_v_e_title)\n",
    "save_history(model_history_filename, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3286 - accuracy: 0.8394\n",
      "\n",
      "Test accuracy: 83.9%, test loss: 0.328615\n"
     ]
    }
   ],
   "source": [
    "best_m4L_v2 = load_model(model_filename)\n",
    "evaluate_model(best_m4L_v2, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241\n"
     ]
    }
   ],
   "source": [
    "test_ds_filename = '../test-ds.csv'\n",
    "output_filename_test_ds_labeled = 'test-ds-m4L_v2.csv'\n",
    "fill_test_ds_labels(model, test_ds_filename, output_filename_test_ds_labeled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: V3\n",
    "#### Model 4 consists in 4 hidden Dense layers:\n",
    "    learning_rate = 0.005\n",
    "    batch_size = 64\n",
    "    loss_fn = CategoricalCrossentropy\n",
    "    optimizer = Adam\n",
    "    Hidden layers:\n",
    "        1. units = 64, activation = relu\n",
    "        2. units = 64, activation = relu\n",
    "        3. units = 64, activation = relu\n",
    "        4. units = 64, activation = relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000\n",
      "13/13 - 2s - loss: 0.9005 - accuracy: 0.5901 - val_loss: 0.7715 - val_accuracy: 0.6684\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.77153, saving model to models\\model_4L_v3\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v3\\assets\n",
      "Epoch 2/3000\n",
      "13/13 - 0s - loss: 0.7902 - accuracy: 0.6628 - val_loss: 0.6970 - val_accuracy: 0.7306\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.77153 to 0.69697, saving model to models\\model_4L_v3\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v3\\assets\n",
      "Epoch 3/3000\n",
      "13/13 - 0s - loss: 0.6824 - accuracy: 0.6913 - val_loss: 0.6473 - val_accuracy: 0.7358\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.69697 to 0.64727, saving model to models\\model_4L_v3\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v3\\assets\n",
      "Epoch 4/3000\n",
      "13/13 - 0s - loss: 0.6584 - accuracy: 0.7263 - val_loss: 0.6167 - val_accuracy: 0.7461\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.64727 to 0.61666, saving model to models\\model_4L_v3\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v3\\assets\n",
      "Epoch 5/3000\n",
      "13/13 - 0s - loss: 0.5705 - accuracy: 0.7678 - val_loss: 0.5451 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.61666 to 0.54511, saving model to models\\model_4L_v3\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v3\\assets\n",
      "Epoch 6/3000\n",
      "13/13 - 0s - loss: 0.5295 - accuracy: 0.7717 - val_loss: 0.6165 - val_accuracy: 0.7513\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.54511\n",
      "Epoch 7/3000\n",
      "13/13 - 0s - loss: 0.5055 - accuracy: 0.7756 - val_loss: 0.5998 - val_accuracy: 0.7617\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.54511\n",
      "Epoch 8/3000\n",
      "13/13 - 0s - loss: 0.4575 - accuracy: 0.8054 - val_loss: 0.5445 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.54511 to 0.54454, saving model to models\\model_4L_v3\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v3\\assets\n",
      "Epoch 9/3000\n",
      "13/13 - 0s - loss: 0.4187 - accuracy: 0.8288 - val_loss: 0.5392 - val_accuracy: 0.7617\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.54454 to 0.53923, saving model to models\\model_4L_v3\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v3\\assets\n",
      "Epoch 10/3000\n",
      "13/13 - 0s - loss: 0.4324 - accuracy: 0.8210 - val_loss: 0.5731 - val_accuracy: 0.7461\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.53923\n",
      "Epoch 11/3000\n",
      "13/13 - 0s - loss: 0.3638 - accuracy: 0.8573 - val_loss: 0.5225 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.53923 to 0.52245, saving model to models\\model_4L_v3\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v3\\assets\n",
      "Epoch 12/3000\n",
      "13/13 - 0s - loss: 0.3693 - accuracy: 0.8470 - val_loss: 0.5040 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.52245 to 0.50400, saving model to models\\model_4L_v3\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v3\\assets\n",
      "Epoch 13/3000\n",
      "13/13 - 0s - loss: 0.3346 - accuracy: 0.8651 - val_loss: 0.5373 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.50400\n",
      "Epoch 14/3000\n",
      "13/13 - 0s - loss: 0.3288 - accuracy: 0.8495 - val_loss: 0.4705 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.50400 to 0.47050, saving model to models\\model_4L_v3\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v3\\assets\n",
      "Epoch 15/3000\n",
      "13/13 - 0s - loss: 0.3172 - accuracy: 0.8794 - val_loss: 0.5119 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.47050\n",
      "Epoch 16/3000\n",
      "13/13 - 0s - loss: 0.3467 - accuracy: 0.8340 - val_loss: 0.5044 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.47050\n",
      "Epoch 17/3000\n",
      "13/13 - 0s - loss: 0.3241 - accuracy: 0.8690 - val_loss: 0.5122 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.47050\n",
      "Epoch 18/3000\n",
      "13/13 - 0s - loss: 0.2965 - accuracy: 0.8703 - val_loss: 0.4697 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.47050 to 0.46974, saving model to models\\model_4L_v3\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v3\\assets\n",
      "Epoch 19/3000\n",
      "13/13 - 0s - loss: 0.3612 - accuracy: 0.8379 - val_loss: 0.4631 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.46974 to 0.46313, saving model to models\\model_4L_v3\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v3\\assets\n",
      "Epoch 20/3000\n",
      "13/13 - 0s - loss: 0.3467 - accuracy: 0.8638 - val_loss: 0.4676 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.46313\n",
      "Epoch 21/3000\n",
      "13/13 - 0s - loss: 0.3659 - accuracy: 0.8288 - val_loss: 0.4294 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.46313 to 0.42941, saving model to models\\model_4L_v3\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v3\\assets\n",
      "Epoch 22/3000\n",
      "13/13 - 0s - loss: 0.3064 - accuracy: 0.8742 - val_loss: 0.4325 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.42941\n",
      "Epoch 23/3000\n",
      "13/13 - 0s - loss: 0.2934 - accuracy: 0.8768 - val_loss: 0.5552 - val_accuracy: 0.7772\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.42941\n",
      "Epoch 24/3000\n",
      "13/13 - 0s - loss: 0.2793 - accuracy: 0.8690 - val_loss: 0.4299 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.42941\n",
      "Epoch 25/3000\n",
      "13/13 - 0s - loss: 0.2676 - accuracy: 0.8885 - val_loss: 0.4386 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.42941\n",
      "Epoch 26/3000\n",
      "13/13 - 0s - loss: 0.3356 - accuracy: 0.8846 - val_loss: 0.4755 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.42941\n",
      "Epoch 27/3000\n",
      "13/13 - 0s - loss: 0.2853 - accuracy: 0.8638 - val_loss: 0.5731 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.42941\n",
      "Epoch 28/3000\n",
      "13/13 - 0s - loss: 0.3436 - accuracy: 0.8781 - val_loss: 0.5025 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.42941\n",
      "Epoch 29/3000\n",
      "13/13 - 0s - loss: 0.2843 - accuracy: 0.8833 - val_loss: 0.4149 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.42941 to 0.41491, saving model to models\\model_4L_v3\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v3\\assets\n",
      "Epoch 30/3000\n",
      "13/13 - 0s - loss: 0.2660 - accuracy: 0.8846 - val_loss: 0.5294 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.41491\n",
      "Epoch 31/3000\n",
      "13/13 - 0s - loss: 0.2459 - accuracy: 0.8988 - val_loss: 0.4813 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.41491\n",
      "Epoch 32/3000\n",
      "13/13 - 0s - loss: 0.2445 - accuracy: 0.8846 - val_loss: 0.4946 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.41491\n",
      "Epoch 33/3000\n",
      "13/13 - 0s - loss: 0.2391 - accuracy: 0.8911 - val_loss: 0.4916 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.41491\n",
      "Epoch 34/3000\n",
      "13/13 - 0s - loss: 0.2340 - accuracy: 0.9001 - val_loss: 0.5340 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.41491\n",
      "Epoch 35/3000\n",
      "13/13 - 0s - loss: 0.2261 - accuracy: 0.8898 - val_loss: 0.4759 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.41491\n",
      "Epoch 36/3000\n",
      "13/13 - 0s - loss: 0.2614 - accuracy: 0.8729 - val_loss: 0.5748 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.41491\n",
      "Epoch 37/3000\n",
      "13/13 - 0s - loss: 0.2562 - accuracy: 0.8820 - val_loss: 0.5150 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.41491\n",
      "Epoch 38/3000\n",
      "13/13 - 0s - loss: 0.2429 - accuracy: 0.8949 - val_loss: 0.4921 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.41491\n",
      "Epoch 39/3000\n",
      "13/13 - 0s - loss: 0.2653 - accuracy: 0.8677 - val_loss: 0.5016 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.41491\n",
      "Epoch 40/3000\n",
      "13/13 - 0s - loss: 0.2474 - accuracy: 0.8794 - val_loss: 0.5140 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.41491\n",
      "Epoch 41/3000\n",
      "13/13 - 0s - loss: 0.2416 - accuracy: 0.8794 - val_loss: 0.4981 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.41491\n",
      "Epoch 42/3000\n",
      "13/13 - 0s - loss: 0.2220 - accuracy: 0.8923 - val_loss: 0.5224 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.41491\n",
      "Epoch 43/3000\n",
      "13/13 - 0s - loss: 0.2202 - accuracy: 0.9014 - val_loss: 0.5391 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.41491\n",
      "Epoch 44/3000\n",
      "13/13 - 0s - loss: 0.2444 - accuracy: 0.8820 - val_loss: 0.5242 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.41491\n",
      "Epoch 45/3000\n",
      "13/13 - 0s - loss: 0.2378 - accuracy: 0.8846 - val_loss: 0.4524 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.41491\n",
      "Epoch 46/3000\n",
      "13/13 - 0s - loss: 0.2303 - accuracy: 0.8898 - val_loss: 0.4841 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.41491\n",
      "Epoch 47/3000\n",
      "13/13 - 0s - loss: 0.2310 - accuracy: 0.8949 - val_loss: 0.4858 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.41491\n",
      "Epoch 48/3000\n",
      "13/13 - 0s - loss: 0.2783 - accuracy: 0.8729 - val_loss: 0.5480 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.41491\n",
      "Epoch 49/3000\n",
      "13/13 - 0s - loss: 0.2272 - accuracy: 0.8923 - val_loss: 0.5254 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.41491\n",
      "Epoch 50/3000\n",
      "13/13 - 0s - loss: 0.2322 - accuracy: 0.8988 - val_loss: 0.4613 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.41491\n",
      "Epoch 51/3000\n",
      "13/13 - 0s - loss: 0.2373 - accuracy: 0.8859 - val_loss: 0.5224 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.41491\n",
      "Epoch 52/3000\n",
      "13/13 - 0s - loss: 0.2278 - accuracy: 0.8911 - val_loss: 0.5035 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.41491\n",
      "Epoch 53/3000\n",
      "13/13 - 0s - loss: 0.2284 - accuracy: 0.8988 - val_loss: 0.4966 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.41491\n",
      "Epoch 54/3000\n",
      "13/13 - 0s - loss: 0.2208 - accuracy: 0.8988 - val_loss: 0.5490 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.41491\n",
      "Epoch 55/3000\n",
      "13/13 - 0s - loss: 0.2183 - accuracy: 0.8988 - val_loss: 0.5968 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.41491\n",
      "Epoch 56/3000\n",
      "13/13 - 0s - loss: 0.2239 - accuracy: 0.8975 - val_loss: 0.5313 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.41491\n",
      "Epoch 57/3000\n",
      "13/13 - 0s - loss: 0.2200 - accuracy: 0.9014 - val_loss: 0.5073 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.41491\n",
      "Epoch 58/3000\n",
      "13/13 - 0s - loss: 0.2162 - accuracy: 0.8975 - val_loss: 0.5367 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.41491\n",
      "Epoch 59/3000\n",
      "13/13 - 0s - loss: 0.2260 - accuracy: 0.8923 - val_loss: 0.5476 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.41491\n",
      "Epoch 60/3000\n",
      "13/13 - 0s - loss: 0.2357 - accuracy: 0.8911 - val_loss: 0.5210 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.41491\n",
      "Epoch 61/3000\n",
      "13/13 - 0s - loss: 0.2340 - accuracy: 0.8898 - val_loss: 0.5234 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.41491\n",
      "Epoch 62/3000\n",
      "13/13 - 0s - loss: 0.2194 - accuracy: 0.8936 - val_loss: 0.5251 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.41491\n",
      "Epoch 63/3000\n",
      "13/13 - 0s - loss: 0.2204 - accuracy: 0.8911 - val_loss: 0.5672 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.41491\n",
      "Epoch 64/3000\n",
      "13/13 - 0s - loss: 0.2139 - accuracy: 0.8911 - val_loss: 0.5377 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.41491\n",
      "Epoch 65/3000\n",
      "13/13 - 0s - loss: 0.2373 - accuracy: 0.8781 - val_loss: 0.4949 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.41491\n",
      "Epoch 66/3000\n",
      "13/13 - 0s - loss: 0.2268 - accuracy: 0.8949 - val_loss: 0.5804 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.41491\n",
      "Epoch 67/3000\n",
      "13/13 - 0s - loss: 0.2814 - accuracy: 0.8638 - val_loss: 0.4751 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.41491\n",
      "Epoch 68/3000\n",
      "13/13 - 0s - loss: 0.2739 - accuracy: 0.8729 - val_loss: 0.5664 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.41491\n",
      "Epoch 69/3000\n",
      "13/13 - 0s - loss: 0.2347 - accuracy: 0.8911 - val_loss: 0.5558 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.41491\n",
      "Epoch 70/3000\n",
      "13/13 - 0s - loss: 0.2265 - accuracy: 0.8936 - val_loss: 0.5509 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.41491\n",
      "Epoch 71/3000\n",
      "13/13 - 0s - loss: 0.2245 - accuracy: 0.8923 - val_loss: 0.5707 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.41491\n",
      "Epoch 72/3000\n",
      "13/13 - 0s - loss: 0.2272 - accuracy: 0.8962 - val_loss: 0.5322 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.41491\n",
      "Epoch 73/3000\n",
      "13/13 - 0s - loss: 0.2150 - accuracy: 0.8988 - val_loss: 0.5546 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.41491\n",
      "Epoch 74/3000\n",
      "13/13 - 0s - loss: 0.2161 - accuracy: 0.8962 - val_loss: 0.5505 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.41491\n",
      "Epoch 75/3000\n",
      "13/13 - 0s - loss: 0.2132 - accuracy: 0.8962 - val_loss: 0.5231 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.41491\n",
      "Epoch 76/3000\n",
      "13/13 - 0s - loss: 0.2117 - accuracy: 0.8949 - val_loss: 0.5318 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.41491\n",
      "Epoch 77/3000\n",
      "13/13 - 0s - loss: 0.2131 - accuracy: 0.8911 - val_loss: 0.5909 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.41491\n",
      "Epoch 78/3000\n",
      "13/13 - 0s - loss: 0.2173 - accuracy: 0.8936 - val_loss: 0.5632 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.41491\n",
      "Epoch 79/3000\n",
      "13/13 - 0s - loss: 0.2223 - accuracy: 0.8936 - val_loss: 0.5504 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.41491\n",
      "Epoch 80/3000\n",
      "13/13 - 0s - loss: 0.2211 - accuracy: 0.8755 - val_loss: 0.5843 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.41491\n",
      "Epoch 81/3000\n",
      "13/13 - 0s - loss: 0.2236 - accuracy: 0.8859 - val_loss: 0.5900 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.41491\n",
      "Epoch 82/3000\n",
      "13/13 - 0s - loss: 0.2163 - accuracy: 0.8975 - val_loss: 0.5985 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.41491\n",
      "Epoch 83/3000\n",
      "13/13 - 0s - loss: 0.2210 - accuracy: 0.9027 - val_loss: 0.5853 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.41491\n",
      "Epoch 84/3000\n",
      "13/13 - 0s - loss: 0.2133 - accuracy: 0.8975 - val_loss: 0.5833 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.41491\n",
      "Epoch 85/3000\n",
      "13/13 - 0s - loss: 0.2115 - accuracy: 0.9014 - val_loss: 0.5682 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.41491\n",
      "Epoch 86/3000\n",
      "13/13 - 0s - loss: 0.2124 - accuracy: 0.8988 - val_loss: 0.5695 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.41491\n",
      "Epoch 87/3000\n",
      "13/13 - 0s - loss: 0.2126 - accuracy: 0.9027 - val_loss: 0.5822 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.41491\n",
      "Epoch 88/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.8962 - val_loss: 0.5736 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.41491\n",
      "Epoch 89/3000\n",
      "13/13 - 0s - loss: 0.2076 - accuracy: 0.9014 - val_loss: 0.6285 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.41491\n",
      "Epoch 90/3000\n",
      "13/13 - 0s - loss: 0.2178 - accuracy: 0.9014 - val_loss: 0.5867 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.41491\n",
      "Epoch 91/3000\n",
      "13/13 - 0s - loss: 0.2180 - accuracy: 0.8962 - val_loss: 0.5037 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.41491\n",
      "Epoch 92/3000\n",
      "13/13 - 0s - loss: 0.2320 - accuracy: 0.8833 - val_loss: 0.4986 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.41491\n",
      "Epoch 93/3000\n",
      "13/13 - 0s - loss: 0.2315 - accuracy: 0.8936 - val_loss: 0.5417 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.41491\n",
      "Epoch 94/3000\n",
      "13/13 - 0s - loss: 0.2136 - accuracy: 0.8975 - val_loss: 0.5060 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.41491\n",
      "Epoch 95/3000\n",
      "13/13 - 0s - loss: 0.2121 - accuracy: 0.8975 - val_loss: 0.5210 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.41491\n",
      "Epoch 96/3000\n",
      "13/13 - 0s - loss: 0.2140 - accuracy: 0.9001 - val_loss: 0.5206 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.41491\n",
      "Epoch 97/3000\n",
      "13/13 - 0s - loss: 0.2151 - accuracy: 0.8962 - val_loss: 0.5286 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.41491\n",
      "Epoch 98/3000\n",
      "13/13 - 0s - loss: 0.2108 - accuracy: 0.8898 - val_loss: 0.5149 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.41491\n",
      "Epoch 99/3000\n",
      "13/13 - 0s - loss: 0.2407 - accuracy: 0.8807 - val_loss: 0.5469 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.41491\n",
      "Epoch 100/3000\n",
      "13/13 - 0s - loss: 0.2374 - accuracy: 0.8923 - val_loss: 0.6536 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.41491\n",
      "Epoch 101/3000\n",
      "13/13 - 0s - loss: 0.2870 - accuracy: 0.8742 - val_loss: 0.4973 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.41491\n",
      "Epoch 102/3000\n",
      "13/13 - 0s - loss: 0.2378 - accuracy: 0.8962 - val_loss: 0.5651 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.41491\n",
      "Epoch 103/3000\n",
      "13/13 - 0s - loss: 0.2398 - accuracy: 0.8936 - val_loss: 0.4939 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.41491\n",
      "Epoch 104/3000\n",
      "13/13 - 0s - loss: 0.2327 - accuracy: 0.8988 - val_loss: 0.5319 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.41491\n",
      "Epoch 105/3000\n",
      "13/13 - 0s - loss: 0.2196 - accuracy: 0.9014 - val_loss: 0.5431 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.41491\n",
      "Epoch 106/3000\n",
      "13/13 - 0s - loss: 0.2128 - accuracy: 0.9014 - val_loss: 0.6121 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.41491\n",
      "Epoch 107/3000\n",
      "13/13 - 0s - loss: 0.2194 - accuracy: 0.8911 - val_loss: 0.6019 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.41491\n",
      "Epoch 108/3000\n",
      "13/13 - 0s - loss: 0.2177 - accuracy: 0.8975 - val_loss: 0.5391 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.41491\n",
      "Epoch 109/3000\n",
      "13/13 - 0s - loss: 0.2150 - accuracy: 0.9014 - val_loss: 0.5531 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.41491\n",
      "Epoch 110/3000\n",
      "13/13 - 0s - loss: 0.2191 - accuracy: 0.9001 - val_loss: 0.5365 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.41491\n",
      "Epoch 111/3000\n",
      "13/13 - 0s - loss: 0.2113 - accuracy: 0.8962 - val_loss: 0.5717 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.41491\n",
      "Epoch 112/3000\n",
      "13/13 - 0s - loss: 0.2120 - accuracy: 0.8962 - val_loss: 0.5942 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.41491\n",
      "Epoch 113/3000\n",
      "13/13 - 0s - loss: 0.2180 - accuracy: 0.9027 - val_loss: 0.6153 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.41491\n",
      "Epoch 114/3000\n",
      "13/13 - 0s - loss: 0.2158 - accuracy: 0.9053 - val_loss: 0.5786 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.41491\n",
      "Epoch 115/3000\n",
      "13/13 - 0s - loss: 0.2103 - accuracy: 0.8988 - val_loss: 0.6575 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.41491\n",
      "Epoch 116/3000\n",
      "13/13 - 0s - loss: 0.2151 - accuracy: 0.9001 - val_loss: 0.6181 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.41491\n",
      "Epoch 117/3000\n",
      "13/13 - 0s - loss: 0.2131 - accuracy: 0.9040 - val_loss: 0.5122 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.41491\n",
      "Epoch 118/3000\n",
      "13/13 - 0s - loss: 0.2119 - accuracy: 0.8949 - val_loss: 0.5715 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.41491\n",
      "Epoch 119/3000\n",
      "13/13 - 0s - loss: 0.2148 - accuracy: 0.8988 - val_loss: 0.5840 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.41491\n",
      "Epoch 120/3000\n",
      "13/13 - 0s - loss: 0.2082 - accuracy: 0.8988 - val_loss: 0.6150 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.41491\n",
      "Epoch 121/3000\n",
      "13/13 - 0s - loss: 0.2224 - accuracy: 0.8975 - val_loss: 0.6331 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.41491\n",
      "Epoch 122/3000\n",
      "13/13 - 0s - loss: 0.2154 - accuracy: 0.8975 - val_loss: 0.6134 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.41491\n",
      "Epoch 123/3000\n",
      "13/13 - 0s - loss: 0.2124 - accuracy: 0.8962 - val_loss: 0.5715 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.41491\n",
      "Epoch 124/3000\n",
      "13/13 - 0s - loss: 0.2145 - accuracy: 0.8936 - val_loss: 0.5890 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.41491\n",
      "Epoch 125/3000\n",
      "13/13 - 0s - loss: 0.2165 - accuracy: 0.8988 - val_loss: 0.6132 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.41491\n",
      "Epoch 126/3000\n",
      "13/13 - 0s - loss: 0.2127 - accuracy: 0.8962 - val_loss: 0.5829 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.41491\n",
      "Epoch 127/3000\n",
      "13/13 - 0s - loss: 0.2132 - accuracy: 0.8975 - val_loss: 0.6265 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.41491\n",
      "Epoch 128/3000\n",
      "13/13 - 0s - loss: 0.2112 - accuracy: 0.8975 - val_loss: 0.5557 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.41491\n",
      "Epoch 129/3000\n",
      "13/13 - 0s - loss: 0.2154 - accuracy: 0.9001 - val_loss: 0.5398 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.41491\n",
      "Epoch 130/3000\n",
      "13/13 - 0s - loss: 0.2097 - accuracy: 0.8975 - val_loss: 0.5557 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.41491\n",
      "Epoch 131/3000\n",
      "13/13 - 0s - loss: 0.2093 - accuracy: 0.8962 - val_loss: 0.5795 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.41491\n",
      "Epoch 132/3000\n",
      "13/13 - 0s - loss: 0.2113 - accuracy: 0.8962 - val_loss: 0.5758 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.41491\n",
      "Epoch 133/3000\n",
      "13/13 - 0s - loss: 0.2078 - accuracy: 0.8975 - val_loss: 0.5559 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.41491\n",
      "Epoch 134/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.9040 - val_loss: 0.5411 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.41491\n",
      "Epoch 135/3000\n",
      "13/13 - 0s - loss: 0.2113 - accuracy: 0.8988 - val_loss: 0.5375 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.41491\n",
      "Epoch 136/3000\n",
      "13/13 - 0s - loss: 0.2064 - accuracy: 0.8988 - val_loss: 0.5624 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.41491\n",
      "Epoch 137/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.8949 - val_loss: 0.5500 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.41491\n",
      "Epoch 138/3000\n",
      "13/13 - 0s - loss: 0.2043 - accuracy: 0.9001 - val_loss: 0.5503 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.41491\n",
      "Epoch 139/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.9027 - val_loss: 0.5716 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.41491\n",
      "Epoch 140/3000\n",
      "13/13 - 0s - loss: 0.2033 - accuracy: 0.9027 - val_loss: 0.5725 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.41491\n",
      "Epoch 141/3000\n",
      "13/13 - 0s - loss: 0.2034 - accuracy: 0.9027 - val_loss: 0.5762 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.41491\n",
      "Epoch 142/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9014 - val_loss: 0.6000 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.41491\n",
      "Epoch 143/3000\n",
      "13/13 - 0s - loss: 0.2076 - accuracy: 0.9027 - val_loss: 0.6079 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.41491\n",
      "Epoch 144/3000\n",
      "13/13 - 0s - loss: 0.2080 - accuracy: 0.8962 - val_loss: 0.5802 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.41491\n",
      "Epoch 145/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.8975 - val_loss: 0.5894 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.41491\n",
      "Epoch 146/3000\n",
      "13/13 - 0s - loss: 0.2052 - accuracy: 0.8988 - val_loss: 0.5970 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.41491\n",
      "Epoch 147/3000\n",
      "13/13 - 0s - loss: 0.2070 - accuracy: 0.8885 - val_loss: 0.5873 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.41491\n",
      "Epoch 148/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.9001 - val_loss: 0.6095 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.41491\n",
      "Epoch 149/3000\n",
      "13/13 - 0s - loss: 0.2122 - accuracy: 0.8923 - val_loss: 0.5797 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.41491\n",
      "Epoch 150/3000\n",
      "13/13 - 0s - loss: 0.2112 - accuracy: 0.9001 - val_loss: 0.6006 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.41491\n",
      "Epoch 151/3000\n",
      "13/13 - 0s - loss: 0.2107 - accuracy: 0.8962 - val_loss: 0.5586 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.41491\n",
      "Epoch 152/3000\n",
      "13/13 - 0s - loss: 0.2091 - accuracy: 0.8962 - val_loss: 0.5863 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.41491\n",
      "Epoch 153/3000\n",
      "13/13 - 0s - loss: 0.2099 - accuracy: 0.8949 - val_loss: 0.5961 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.41491\n",
      "Epoch 154/3000\n",
      "13/13 - 0s - loss: 0.2097 - accuracy: 0.8975 - val_loss: 0.5900 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.41491\n",
      "Epoch 155/3000\n",
      "13/13 - 0s - loss: 0.2091 - accuracy: 0.8923 - val_loss: 0.5634 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.41491\n",
      "Epoch 156/3000\n",
      "13/13 - 0s - loss: 0.2209 - accuracy: 0.8911 - val_loss: 0.5558 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.41491\n",
      "Epoch 157/3000\n",
      "13/13 - 0s - loss: 0.2213 - accuracy: 0.8936 - val_loss: 0.6260 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.41491\n",
      "Epoch 158/3000\n",
      "13/13 - 0s - loss: 0.2151 - accuracy: 0.8949 - val_loss: 0.6141 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.41491\n",
      "Epoch 159/3000\n",
      "13/13 - 0s - loss: 0.2177 - accuracy: 0.8962 - val_loss: 0.5725 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.41491\n",
      "Epoch 160/3000\n",
      "13/13 - 0s - loss: 0.2101 - accuracy: 0.8962 - val_loss: 0.5726 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.41491\n",
      "Epoch 161/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.8975 - val_loss: 0.6091 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.41491\n",
      "Epoch 162/3000\n",
      "13/13 - 0s - loss: 0.2070 - accuracy: 0.9027 - val_loss: 0.6129 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.41491\n",
      "Epoch 163/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.9001 - val_loss: 0.6186 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.41491\n",
      "Epoch 164/3000\n",
      "13/13 - 0s - loss: 0.2064 - accuracy: 0.9001 - val_loss: 0.6036 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.41491\n",
      "Epoch 165/3000\n",
      "13/13 - 0s - loss: 0.2048 - accuracy: 0.9001 - val_loss: 0.6161 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.41491\n",
      "Epoch 166/3000\n",
      "13/13 - 0s - loss: 0.2097 - accuracy: 0.8949 - val_loss: 0.6394 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.41491\n",
      "Epoch 167/3000\n",
      "13/13 - 0s - loss: 0.2080 - accuracy: 0.8975 - val_loss: 0.6203 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.41491\n",
      "Epoch 168/3000\n",
      "13/13 - 0s - loss: 0.2120 - accuracy: 0.8962 - val_loss: 0.5954 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.41491\n",
      "Epoch 169/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.9001 - val_loss: 0.6029 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.41491\n",
      "Epoch 170/3000\n",
      "13/13 - 0s - loss: 0.2083 - accuracy: 0.8949 - val_loss: 0.6238 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.41491\n",
      "Epoch 171/3000\n",
      "13/13 - 0s - loss: 0.2070 - accuracy: 0.9014 - val_loss: 0.6147 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.41491\n",
      "Epoch 172/3000\n",
      "13/13 - 0s - loss: 0.2070 - accuracy: 0.9027 - val_loss: 0.5953 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.41491\n",
      "Epoch 173/3000\n",
      "13/13 - 0s - loss: 0.2066 - accuracy: 0.9027 - val_loss: 0.6206 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.41491\n",
      "Epoch 174/3000\n",
      "13/13 - 0s - loss: 0.2041 - accuracy: 0.9027 - val_loss: 0.6497 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.41491\n",
      "Epoch 175/3000\n",
      "13/13 - 0s - loss: 0.2073 - accuracy: 0.9014 - val_loss: 0.6229 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.41491\n",
      "Epoch 176/3000\n",
      "13/13 - 0s - loss: 0.2178 - accuracy: 0.8911 - val_loss: 0.6166 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.41491\n",
      "Epoch 177/3000\n",
      "13/13 - 0s - loss: 0.2127 - accuracy: 0.8949 - val_loss: 0.6113 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.41491\n",
      "Epoch 178/3000\n",
      "13/13 - 0s - loss: 0.2188 - accuracy: 0.8949 - val_loss: 0.6022 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.41491\n",
      "Epoch 179/3000\n",
      "13/13 - 0s - loss: 0.2086 - accuracy: 0.9001 - val_loss: 0.6248 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.41491\n",
      "Epoch 180/3000\n",
      "13/13 - 0s - loss: 0.2106 - accuracy: 0.8988 - val_loss: 0.6431 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.41491\n",
      "Epoch 181/3000\n",
      "13/13 - 0s - loss: 0.2108 - accuracy: 0.9027 - val_loss: 0.6141 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.41491\n",
      "Epoch 182/3000\n",
      "13/13 - 0s - loss: 0.2146 - accuracy: 0.8949 - val_loss: 0.6096 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.41491\n",
      "Epoch 183/3000\n",
      "13/13 - 0s - loss: 0.2120 - accuracy: 0.8975 - val_loss: 0.6123 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.41491\n",
      "Epoch 184/3000\n",
      "13/13 - 0s - loss: 0.2210 - accuracy: 0.8833 - val_loss: 0.6177 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.41491\n",
      "Epoch 185/3000\n",
      "13/13 - 0s - loss: 0.2200 - accuracy: 0.9001 - val_loss: 0.6597 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.41491\n",
      "Epoch 186/3000\n",
      "13/13 - 0s - loss: 0.2145 - accuracy: 0.9014 - val_loss: 0.7148 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.41491\n",
      "Epoch 187/3000\n",
      "13/13 - 0s - loss: 0.2077 - accuracy: 0.9027 - val_loss: 0.7762 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.41491\n",
      "Epoch 188/3000\n",
      "13/13 - 0s - loss: 0.2163 - accuracy: 0.8988 - val_loss: 0.7896 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.41491\n",
      "Epoch 189/3000\n",
      "13/13 - 0s - loss: 0.2112 - accuracy: 0.9001 - val_loss: 0.7813 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.41491\n",
      "Epoch 190/3000\n",
      "13/13 - 0s - loss: 0.2139 - accuracy: 0.9027 - val_loss: 0.7499 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.41491\n",
      "Epoch 191/3000\n",
      "13/13 - 0s - loss: 0.2104 - accuracy: 0.9014 - val_loss: 0.7480 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.41491\n",
      "Epoch 192/3000\n",
      "13/13 - 0s - loss: 0.2145 - accuracy: 0.8898 - val_loss: 0.7478 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.41491\n",
      "Epoch 193/3000\n",
      "13/13 - 0s - loss: 0.2199 - accuracy: 0.8833 - val_loss: 0.7687 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.41491\n",
      "Epoch 194/3000\n",
      "13/13 - 0s - loss: 0.2148 - accuracy: 0.8885 - val_loss: 0.7755 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.41491\n",
      "Epoch 195/3000\n",
      "13/13 - 0s - loss: 0.2098 - accuracy: 0.9001 - val_loss: 0.7464 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.41491\n",
      "Epoch 196/3000\n",
      "13/13 - 0s - loss: 0.2243 - accuracy: 0.8664 - val_loss: 0.6958 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.41491\n",
      "Epoch 197/3000\n",
      "13/13 - 0s - loss: 0.2211 - accuracy: 0.8716 - val_loss: 0.6570 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.41491\n",
      "Epoch 198/3000\n",
      "13/13 - 0s - loss: 0.2695 - accuracy: 0.8859 - val_loss: 0.7011 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.41491\n",
      "Epoch 199/3000\n",
      "13/13 - 0s - loss: 0.2617 - accuracy: 0.8807 - val_loss: 0.5916 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.41491\n",
      "Epoch 200/3000\n",
      "13/13 - 0s - loss: 0.2528 - accuracy: 0.8885 - val_loss: 0.6333 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.41491\n",
      "Epoch 201/3000\n",
      "13/13 - 0s - loss: 0.2459 - accuracy: 0.8885 - val_loss: 0.6519 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.41491\n",
      "Epoch 202/3000\n",
      "13/13 - 0s - loss: 0.2302 - accuracy: 0.8846 - val_loss: 0.6895 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.41491\n",
      "Epoch 203/3000\n",
      "13/13 - 0s - loss: 0.2267 - accuracy: 0.8859 - val_loss: 0.6545 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.41491\n",
      "Epoch 204/3000\n",
      "13/13 - 0s - loss: 0.2414 - accuracy: 0.8716 - val_loss: 0.6635 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.41491\n",
      "Epoch 205/3000\n",
      "13/13 - 0s - loss: 0.2281 - accuracy: 0.8872 - val_loss: 0.7157 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.41491\n",
      "Epoch 206/3000\n",
      "13/13 - 0s - loss: 0.2209 - accuracy: 0.8936 - val_loss: 0.7433 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.41491\n",
      "Epoch 207/3000\n",
      "13/13 - 0s - loss: 0.2409 - accuracy: 0.8781 - val_loss: 0.6016 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.41491\n",
      "Epoch 208/3000\n",
      "13/13 - 0s - loss: 0.2587 - accuracy: 0.8586 - val_loss: 0.6222 - val_accuracy: 0.7772\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.41491\n",
      "Epoch 209/3000\n",
      "13/13 - 0s - loss: 0.2565 - accuracy: 0.8612 - val_loss: 0.6311 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.41491\n",
      "Epoch 210/3000\n",
      "13/13 - 0s - loss: 0.2431 - accuracy: 0.8742 - val_loss: 0.5158 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.41491\n",
      "Epoch 211/3000\n",
      "13/13 - 0s - loss: 0.2408 - accuracy: 0.8872 - val_loss: 0.5091 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.41491\n",
      "Epoch 212/3000\n",
      "13/13 - 0s - loss: 0.2378 - accuracy: 0.8768 - val_loss: 0.5786 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.41491\n",
      "Epoch 213/3000\n",
      "13/13 - 0s - loss: 0.2222 - accuracy: 0.8820 - val_loss: 0.5896 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.41491\n",
      "Epoch 214/3000\n",
      "13/13 - 0s - loss: 0.2180 - accuracy: 0.8859 - val_loss: 0.5620 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.41491\n",
      "Epoch 215/3000\n",
      "13/13 - 0s - loss: 0.2217 - accuracy: 0.8872 - val_loss: 0.5405 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.41491\n",
      "Epoch 216/3000\n",
      "13/13 - 0s - loss: 0.2161 - accuracy: 0.8911 - val_loss: 0.5655 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.41491\n",
      "Epoch 217/3000\n",
      "13/13 - 0s - loss: 0.2146 - accuracy: 0.8898 - val_loss: 0.6246 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.41491\n",
      "Epoch 218/3000\n",
      "13/13 - 0s - loss: 0.2161 - accuracy: 0.8911 - val_loss: 0.6334 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.41491\n",
      "Epoch 219/3000\n",
      "13/13 - 0s - loss: 0.2121 - accuracy: 0.8936 - val_loss: 0.6185 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.41491\n",
      "Epoch 220/3000\n",
      "13/13 - 0s - loss: 0.2109 - accuracy: 0.8988 - val_loss: 0.6006 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.41491\n",
      "Epoch 221/3000\n",
      "13/13 - 0s - loss: 0.2108 - accuracy: 0.8988 - val_loss: 0.6165 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.41491\n",
      "Epoch 222/3000\n",
      "13/13 - 0s - loss: 0.2102 - accuracy: 0.8988 - val_loss: 0.6323 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.41491\n",
      "Epoch 223/3000\n",
      "13/13 - 0s - loss: 0.2195 - accuracy: 0.8962 - val_loss: 0.6794 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.41491\n",
      "Epoch 224/3000\n",
      "13/13 - 0s - loss: 0.2156 - accuracy: 0.8988 - val_loss: 0.5776 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.41491\n",
      "Epoch 225/3000\n",
      "13/13 - 0s - loss: 0.2141 - accuracy: 0.8936 - val_loss: 0.6348 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.41491\n",
      "Epoch 226/3000\n",
      "13/13 - 0s - loss: 0.2237 - accuracy: 0.8975 - val_loss: 0.6433 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.41491\n",
      "Epoch 227/3000\n",
      "13/13 - 0s - loss: 0.2249 - accuracy: 0.8911 - val_loss: 0.5443 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.41491\n",
      "Epoch 228/3000\n",
      "13/13 - 0s - loss: 0.2303 - accuracy: 0.8768 - val_loss: 0.5784 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.41491\n",
      "Epoch 229/3000\n",
      "13/13 - 0s - loss: 0.2285 - accuracy: 0.8651 - val_loss: 0.5493 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.41491\n",
      "Epoch 230/3000\n",
      "13/13 - 0s - loss: 0.2224 - accuracy: 0.8716 - val_loss: 0.6111 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.41491\n",
      "Epoch 231/3000\n",
      "13/13 - 0s - loss: 0.2211 - accuracy: 0.8936 - val_loss: 0.6231 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.41491\n",
      "Epoch 232/3000\n",
      "13/13 - 0s - loss: 0.2160 - accuracy: 0.8949 - val_loss: 0.6344 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.41491\n",
      "Epoch 233/3000\n",
      "13/13 - 0s - loss: 0.2300 - accuracy: 0.9001 - val_loss: 0.6708 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.41491\n",
      "Epoch 234/3000\n",
      "13/13 - 0s - loss: 0.2203 - accuracy: 0.8923 - val_loss: 0.6129 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.41491\n",
      "Epoch 235/3000\n",
      "13/13 - 0s - loss: 0.2180 - accuracy: 0.8911 - val_loss: 0.6234 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.41491\n",
      "Epoch 236/3000\n",
      "13/13 - 0s - loss: 0.2125 - accuracy: 0.8975 - val_loss: 0.6461 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.41491\n",
      "Epoch 237/3000\n",
      "13/13 - 0s - loss: 0.2171 - accuracy: 0.8936 - val_loss: 0.6529 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.41491\n",
      "Epoch 238/3000\n",
      "13/13 - 0s - loss: 0.2137 - accuracy: 0.9027 - val_loss: 0.6485 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.41491\n",
      "Epoch 239/3000\n",
      "13/13 - 0s - loss: 0.2138 - accuracy: 0.9014 - val_loss: 0.6966 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.41491\n",
      "Epoch 240/3000\n",
      "13/13 - 0s - loss: 0.2108 - accuracy: 0.9001 - val_loss: 0.7130 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.41491\n",
      "Epoch 241/3000\n",
      "13/13 - 0s - loss: 0.2085 - accuracy: 0.8988 - val_loss: 0.6841 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.41491\n",
      "Epoch 242/3000\n",
      "13/13 - 0s - loss: 0.2070 - accuracy: 0.9014 - val_loss: 0.6860 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.41491\n",
      "Epoch 243/3000\n",
      "13/13 - 0s - loss: 0.2066 - accuracy: 0.9027 - val_loss: 0.6982 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.41491\n",
      "Epoch 244/3000\n",
      "13/13 - 0s - loss: 0.2098 - accuracy: 0.9001 - val_loss: 0.6809 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.41491\n",
      "Epoch 245/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.9027 - val_loss: 0.7388 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.41491\n",
      "Epoch 246/3000\n",
      "13/13 - 0s - loss: 0.2109 - accuracy: 0.9027 - val_loss: 0.7417 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.41491\n",
      "Epoch 247/3000\n",
      "13/13 - 0s - loss: 0.2132 - accuracy: 0.9027 - val_loss: 0.6040 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.41491\n",
      "Epoch 248/3000\n",
      "13/13 - 0s - loss: 0.2196 - accuracy: 0.9001 - val_loss: 0.6410 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.41491\n",
      "Epoch 249/3000\n",
      "13/13 - 0s - loss: 0.2112 - accuracy: 0.8975 - val_loss: 0.7102 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.41491\n",
      "Epoch 250/3000\n",
      "13/13 - 0s - loss: 0.2161 - accuracy: 0.9001 - val_loss: 0.6843 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.41491\n",
      "Epoch 251/3000\n",
      "13/13 - 0s - loss: 0.2328 - accuracy: 0.8962 - val_loss: 0.5944 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.41491\n",
      "Epoch 252/3000\n",
      "13/13 - 0s - loss: 0.2148 - accuracy: 0.9001 - val_loss: 0.7117 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.41491\n",
      "Epoch 253/3000\n",
      "13/13 - 0s - loss: 0.2564 - accuracy: 0.8872 - val_loss: 0.8444 - val_accuracy: 0.7513\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.41491\n",
      "Epoch 254/3000\n",
      "13/13 - 0s - loss: 0.3947 - accuracy: 0.8262 - val_loss: 0.7488 - val_accuracy: 0.7668\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.41491\n",
      "Epoch 255/3000\n",
      "13/13 - 0s - loss: 0.3543 - accuracy: 0.8340 - val_loss: 0.6248 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.41491\n",
      "Epoch 256/3000\n",
      "13/13 - 0s - loss: 0.3285 - accuracy: 0.8470 - val_loss: 0.5583 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.41491\n",
      "Epoch 257/3000\n",
      "13/13 - 0s - loss: 0.2604 - accuracy: 0.8833 - val_loss: 0.6086 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.41491\n",
      "Epoch 258/3000\n",
      "13/13 - 0s - loss: 0.2323 - accuracy: 0.8898 - val_loss: 0.6498 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.41491\n",
      "Epoch 259/3000\n",
      "13/13 - 0s - loss: 0.2423 - accuracy: 0.8833 - val_loss: 0.6267 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.41491\n",
      "Epoch 260/3000\n",
      "13/13 - 0s - loss: 0.2259 - accuracy: 0.8898 - val_loss: 0.6619 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.41491\n",
      "Epoch 261/3000\n",
      "13/13 - 0s - loss: 0.2225 - accuracy: 0.9027 - val_loss: 0.6983 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.41491\n",
      "Epoch 262/3000\n",
      "13/13 - 0s - loss: 0.2166 - accuracy: 0.9027 - val_loss: 0.7422 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.41491\n",
      "Epoch 263/3000\n",
      "13/13 - 0s - loss: 0.2157 - accuracy: 0.9053 - val_loss: 0.7294 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.41491\n",
      "Epoch 264/3000\n",
      "13/13 - 0s - loss: 0.2140 - accuracy: 0.8988 - val_loss: 0.7537 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.41491\n",
      "Epoch 265/3000\n",
      "13/13 - 0s - loss: 0.2112 - accuracy: 0.9027 - val_loss: 0.7586 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.41491\n",
      "Epoch 266/3000\n",
      "13/13 - 0s - loss: 0.2089 - accuracy: 0.8962 - val_loss: 0.7797 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.41491\n",
      "Epoch 267/3000\n",
      "13/13 - 0s - loss: 0.2243 - accuracy: 0.8988 - val_loss: 0.7264 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.41491\n",
      "Epoch 268/3000\n",
      "13/13 - 0s - loss: 0.2206 - accuracy: 0.8962 - val_loss: 0.7438 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.41491\n",
      "Epoch 269/3000\n",
      "13/13 - 0s - loss: 0.2517 - accuracy: 0.8911 - val_loss: 0.7047 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.41491\n",
      "Epoch 270/3000\n",
      "13/13 - 0s - loss: 0.2385 - accuracy: 0.8923 - val_loss: 0.9113 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.41491\n",
      "Epoch 271/3000\n",
      "13/13 - 0s - loss: 0.2254 - accuracy: 0.8885 - val_loss: 0.8338 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.41491\n",
      "Epoch 272/3000\n",
      "13/13 - 0s - loss: 0.2291 - accuracy: 0.8923 - val_loss: 0.6812 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.41491\n",
      "Epoch 273/3000\n",
      "13/13 - 0s - loss: 0.2625 - accuracy: 0.8716 - val_loss: 0.6899 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.41491\n",
      "Epoch 274/3000\n",
      "13/13 - 0s - loss: 0.2469 - accuracy: 0.8431 - val_loss: 0.7268 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.41491\n",
      "Epoch 275/3000\n",
      "13/13 - 0s - loss: 0.2262 - accuracy: 0.8885 - val_loss: 0.7746 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.41491\n",
      "Epoch 276/3000\n",
      "13/13 - 0s - loss: 0.2231 - accuracy: 0.8820 - val_loss: 0.7808 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.41491\n",
      "Epoch 277/3000\n",
      "13/13 - 0s - loss: 0.2272 - accuracy: 0.8936 - val_loss: 0.7194 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.41491\n",
      "Epoch 278/3000\n",
      "13/13 - 0s - loss: 0.2268 - accuracy: 0.8898 - val_loss: 0.7775 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.41491\n",
      "Epoch 279/3000\n",
      "13/13 - 0s - loss: 0.2212 - accuracy: 0.8898 - val_loss: 0.8203 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.41491\n",
      "Epoch 280/3000\n",
      "13/13 - 0s - loss: 0.2159 - accuracy: 0.9014 - val_loss: 0.7991 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.41491\n",
      "Epoch 281/3000\n",
      "13/13 - 0s - loss: 0.2203 - accuracy: 0.8975 - val_loss: 0.8120 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.41491\n",
      "Epoch 282/3000\n",
      "13/13 - 0s - loss: 0.2150 - accuracy: 0.8859 - val_loss: 0.8610 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.41491\n",
      "Epoch 283/3000\n",
      "13/13 - 0s - loss: 0.2514 - accuracy: 0.8911 - val_loss: 0.8292 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.41491\n",
      "Epoch 284/3000\n",
      "13/13 - 0s - loss: 0.2373 - accuracy: 0.8923 - val_loss: 0.7296 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.41491\n",
      "Epoch 285/3000\n",
      "13/13 - 0s - loss: 0.2213 - accuracy: 0.8885 - val_loss: 0.7737 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.41491\n",
      "Epoch 286/3000\n",
      "13/13 - 0s - loss: 0.2224 - accuracy: 0.8988 - val_loss: 0.7875 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.41491\n",
      "Epoch 287/3000\n",
      "13/13 - 0s - loss: 0.2126 - accuracy: 0.8911 - val_loss: 0.7815 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.41491\n",
      "Epoch 288/3000\n",
      "13/13 - 0s - loss: 0.2104 - accuracy: 0.9014 - val_loss: 0.8337 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.41491\n",
      "Epoch 289/3000\n",
      "13/13 - 0s - loss: 0.2171 - accuracy: 0.8911 - val_loss: 0.8238 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.41491\n",
      "Epoch 290/3000\n",
      "13/13 - 0s - loss: 0.2132 - accuracy: 0.9001 - val_loss: 0.7974 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.41491\n",
      "Epoch 291/3000\n",
      "13/13 - 0s - loss: 0.2127 - accuracy: 0.9001 - val_loss: 0.8408 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.41491\n",
      "Epoch 292/3000\n",
      "13/13 - 0s - loss: 0.2088 - accuracy: 0.8988 - val_loss: 0.8710 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.41491\n",
      "Epoch 293/3000\n",
      "13/13 - 0s - loss: 0.2128 - accuracy: 0.8936 - val_loss: 0.8096 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.41491\n",
      "Epoch 294/3000\n",
      "13/13 - 0s - loss: 0.2101 - accuracy: 0.8885 - val_loss: 0.8467 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.41491\n",
      "Epoch 295/3000\n",
      "13/13 - 0s - loss: 0.2189 - accuracy: 0.8911 - val_loss: 0.8174 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.41491\n",
      "Epoch 296/3000\n",
      "13/13 - 0s - loss: 0.2641 - accuracy: 0.8742 - val_loss: 0.7337 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.41491\n",
      "Epoch 297/3000\n",
      "13/13 - 0s - loss: 0.2495 - accuracy: 0.8794 - val_loss: 1.0345 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.41491\n",
      "Epoch 298/3000\n",
      "13/13 - 0s - loss: 0.2594 - accuracy: 0.8923 - val_loss: 0.7403 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.41491\n",
      "Epoch 299/3000\n",
      "13/13 - 0s - loss: 0.2234 - accuracy: 0.8988 - val_loss: 0.7146 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.41491\n",
      "Epoch 300/3000\n",
      "13/13 - 0s - loss: 0.2168 - accuracy: 0.8962 - val_loss: 0.7836 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.41491\n",
      "Epoch 301/3000\n",
      "13/13 - 0s - loss: 0.2133 - accuracy: 0.8988 - val_loss: 0.8071 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.41491\n",
      "Epoch 302/3000\n",
      "13/13 - 0s - loss: 0.2163 - accuracy: 0.8988 - val_loss: 0.8471 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.41491\n",
      "Epoch 303/3000\n",
      "13/13 - 0s - loss: 0.2171 - accuracy: 0.8949 - val_loss: 0.8247 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.41491\n",
      "Epoch 304/3000\n",
      "13/13 - 0s - loss: 0.2499 - accuracy: 0.8911 - val_loss: 0.8276 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.41491\n",
      "Epoch 305/3000\n",
      "13/13 - 0s - loss: 0.2145 - accuracy: 0.8988 - val_loss: 0.8500 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.41491\n",
      "Epoch 306/3000\n",
      "13/13 - 0s - loss: 0.2124 - accuracy: 0.8988 - val_loss: 0.8452 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.41491\n",
      "Epoch 307/3000\n",
      "13/13 - 0s - loss: 0.2179 - accuracy: 0.9014 - val_loss: 0.8593 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.41491\n",
      "Epoch 308/3000\n",
      "13/13 - 0s - loss: 0.2121 - accuracy: 0.9014 - val_loss: 0.8288 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.41491\n",
      "Epoch 309/3000\n",
      "13/13 - 0s - loss: 0.2137 - accuracy: 0.9001 - val_loss: 0.8630 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.41491\n",
      "Epoch 310/3000\n",
      "13/13 - 0s - loss: 0.2108 - accuracy: 0.9014 - val_loss: 0.8338 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.41491\n",
      "Epoch 311/3000\n",
      "13/13 - 0s - loss: 0.2099 - accuracy: 0.9001 - val_loss: 0.8337 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.41491\n",
      "Epoch 312/3000\n",
      "13/13 - 0s - loss: 0.2107 - accuracy: 0.9001 - val_loss: 0.8292 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.41491\n",
      "Epoch 313/3000\n",
      "13/13 - 0s - loss: 0.2147 - accuracy: 0.8975 - val_loss: 0.8256 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.41491\n",
      "Epoch 314/3000\n",
      "13/13 - 0s - loss: 0.2121 - accuracy: 0.8975 - val_loss: 0.8465 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.41491\n",
      "Epoch 315/3000\n",
      "13/13 - 0s - loss: 0.2099 - accuracy: 0.8962 - val_loss: 0.8575 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.41491\n",
      "Epoch 316/3000\n",
      "13/13 - 0s - loss: 0.2112 - accuracy: 0.8975 - val_loss: 0.8592 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.41491\n",
      "Epoch 317/3000\n",
      "13/13 - 0s - loss: 0.2086 - accuracy: 0.8962 - val_loss: 0.9065 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.41491\n",
      "Epoch 318/3000\n",
      "13/13 - 0s - loss: 0.2086 - accuracy: 0.8949 - val_loss: 0.9213 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.41491\n",
      "Epoch 319/3000\n",
      "13/13 - 0s - loss: 0.2085 - accuracy: 0.8962 - val_loss: 0.9193 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.41491\n",
      "Epoch 320/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.8949 - val_loss: 0.9208 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.41491\n",
      "Epoch 321/3000\n",
      "13/13 - 0s - loss: 0.2085 - accuracy: 0.8949 - val_loss: 0.9368 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.41491\n",
      "Epoch 322/3000\n",
      "13/13 - 0s - loss: 0.2107 - accuracy: 0.8885 - val_loss: 0.9452 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.41491\n",
      "Epoch 323/3000\n",
      "13/13 - 0s - loss: 0.2113 - accuracy: 0.8988 - val_loss: 0.9289 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.41491\n",
      "Epoch 324/3000\n",
      "13/13 - 0s - loss: 0.2141 - accuracy: 0.9027 - val_loss: 0.9715 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.41491\n",
      "Epoch 325/3000\n",
      "13/13 - 0s - loss: 0.2077 - accuracy: 0.9014 - val_loss: 1.0342 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.41491\n",
      "Epoch 326/3000\n",
      "13/13 - 0s - loss: 0.2296 - accuracy: 0.8898 - val_loss: 0.8528 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.41491\n",
      "Epoch 327/3000\n",
      "13/13 - 0s - loss: 0.2564 - accuracy: 0.8936 - val_loss: 0.7316 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.41491\n",
      "Epoch 328/3000\n",
      "13/13 - 0s - loss: 0.2328 - accuracy: 0.8949 - val_loss: 0.8735 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.41491\n",
      "Epoch 329/3000\n",
      "13/13 - 0s - loss: 0.2282 - accuracy: 0.8975 - val_loss: 0.9372 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.41491\n",
      "Epoch 330/3000\n",
      "13/13 - 0s - loss: 0.2135 - accuracy: 0.8988 - val_loss: 0.9716 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.41491\n",
      "Epoch 331/3000\n",
      "13/13 - 0s - loss: 0.2069 - accuracy: 0.9027 - val_loss: 0.9589 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.41491\n",
      "Epoch 332/3000\n",
      "13/13 - 0s - loss: 0.2128 - accuracy: 0.9014 - val_loss: 0.9590 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.41491\n",
      "Epoch 333/3000\n",
      "13/13 - 0s - loss: 0.2122 - accuracy: 0.9014 - val_loss: 0.9780 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.41491\n",
      "Epoch 334/3000\n",
      "13/13 - 0s - loss: 0.2173 - accuracy: 0.8988 - val_loss: 1.0830 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.41491\n",
      "Epoch 335/3000\n",
      "13/13 - 0s - loss: 0.2219 - accuracy: 0.9053 - val_loss: 1.0423 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.41491\n",
      "Epoch 336/3000\n",
      "13/13 - 0s - loss: 0.2202 - accuracy: 0.9014 - val_loss: 0.9611 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.41491\n",
      "Epoch 337/3000\n",
      "13/13 - 0s - loss: 0.2235 - accuracy: 0.8820 - val_loss: 0.9534 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.41491\n",
      "Epoch 338/3000\n",
      "13/13 - 0s - loss: 0.2124 - accuracy: 0.9001 - val_loss: 0.9156 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.41491\n",
      "Epoch 339/3000\n",
      "13/13 - 0s - loss: 0.2065 - accuracy: 0.9027 - val_loss: 0.8931 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.41491\n",
      "Epoch 340/3000\n",
      "13/13 - 0s - loss: 0.2095 - accuracy: 0.9027 - val_loss: 0.8712 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.41491\n",
      "Epoch 341/3000\n",
      "13/13 - 0s - loss: 0.2241 - accuracy: 0.8911 - val_loss: 0.9749 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.41491\n",
      "Epoch 342/3000\n",
      "13/13 - 0s - loss: 0.2227 - accuracy: 0.8898 - val_loss: 0.9954 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.41491\n",
      "Epoch 343/3000\n",
      "13/13 - 0s - loss: 0.2183 - accuracy: 0.8949 - val_loss: 0.9064 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.41491\n",
      "Epoch 344/3000\n",
      "13/13 - 0s - loss: 0.2080 - accuracy: 0.8962 - val_loss: 0.8639 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.41491\n",
      "Epoch 345/3000\n",
      "13/13 - 0s - loss: 0.2115 - accuracy: 0.8911 - val_loss: 0.8655 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.41491\n",
      "Epoch 346/3000\n",
      "13/13 - 0s - loss: 0.2067 - accuracy: 0.8988 - val_loss: 0.9030 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.41491\n",
      "Epoch 347/3000\n",
      "13/13 - 0s - loss: 0.2077 - accuracy: 0.8936 - val_loss: 0.9291 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.41491\n",
      "Epoch 348/3000\n",
      "13/13 - 0s - loss: 0.2047 - accuracy: 0.9027 - val_loss: 0.9200 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.41491\n",
      "Epoch 349/3000\n",
      "13/13 - 0s - loss: 0.2048 - accuracy: 0.9014 - val_loss: 0.9310 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.41491\n",
      "Epoch 350/3000\n",
      "13/13 - 0s - loss: 0.2067 - accuracy: 0.8923 - val_loss: 0.9195 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.41491\n",
      "Epoch 351/3000\n",
      "13/13 - 0s - loss: 0.2161 - accuracy: 0.9014 - val_loss: 0.8379 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.41491\n",
      "Epoch 352/3000\n",
      "13/13 - 0s - loss: 0.2095 - accuracy: 0.8936 - val_loss: 0.8801 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.41491\n",
      "Epoch 353/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.8988 - val_loss: 0.9344 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.41491\n",
      "Epoch 354/3000\n",
      "13/13 - 0s - loss: 0.2086 - accuracy: 0.8962 - val_loss: 0.8979 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.41491\n",
      "Epoch 355/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.8975 - val_loss: 0.8933 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.41491\n",
      "Epoch 356/3000\n",
      "13/13 - 0s - loss: 0.2043 - accuracy: 0.9014 - val_loss: 0.9751 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.41491\n",
      "Epoch 357/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.9014 - val_loss: 1.0002 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.41491\n",
      "Epoch 358/3000\n",
      "13/13 - 0s - loss: 0.2141 - accuracy: 0.8949 - val_loss: 0.8901 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.41491\n",
      "Epoch 359/3000\n",
      "13/13 - 0s - loss: 0.2132 - accuracy: 0.8898 - val_loss: 0.9412 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.41491\n",
      "Epoch 360/3000\n",
      "13/13 - 0s - loss: 0.2078 - accuracy: 0.9001 - val_loss: 0.9318 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.41491\n",
      "Epoch 361/3000\n",
      "13/13 - 0s - loss: 0.2083 - accuracy: 0.9027 - val_loss: 0.9249 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.41491\n",
      "Epoch 362/3000\n",
      "13/13 - 0s - loss: 0.2045 - accuracy: 0.9040 - val_loss: 0.9497 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.41491\n",
      "Epoch 363/3000\n",
      "13/13 - 0s - loss: 0.2065 - accuracy: 0.9001 - val_loss: 0.9627 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 0.41491\n",
      "Epoch 364/3000\n",
      "13/13 - 0s - loss: 0.2046 - accuracy: 0.9027 - val_loss: 0.9466 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.41491\n",
      "Epoch 365/3000\n",
      "13/13 - 0s - loss: 0.2150 - accuracy: 0.8859 - val_loss: 0.8732 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.41491\n",
      "Epoch 366/3000\n",
      "13/13 - 0s - loss: 0.2191 - accuracy: 0.8885 - val_loss: 0.8888 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.41491\n",
      "Epoch 367/3000\n",
      "13/13 - 0s - loss: 0.2143 - accuracy: 0.8898 - val_loss: 0.8940 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.41491\n",
      "Epoch 368/3000\n",
      "13/13 - 0s - loss: 0.2429 - accuracy: 0.8988 - val_loss: 0.8976 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.41491\n",
      "Epoch 369/3000\n",
      "13/13 - 0s - loss: 0.2156 - accuracy: 0.8923 - val_loss: 0.9548 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.41491\n",
      "Epoch 370/3000\n",
      "13/13 - 0s - loss: 0.2107 - accuracy: 0.9040 - val_loss: 0.9774 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.41491\n",
      "Epoch 371/3000\n",
      "13/13 - 0s - loss: 0.2167 - accuracy: 0.8872 - val_loss: 0.9936 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.41491\n",
      "Epoch 372/3000\n",
      "13/13 - 0s - loss: 0.2172 - accuracy: 0.8898 - val_loss: 0.9688 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.41491\n",
      "Epoch 373/3000\n",
      "13/13 - 0s - loss: 0.2112 - accuracy: 0.9040 - val_loss: 0.9888 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.41491\n",
      "Epoch 374/3000\n",
      "13/13 - 0s - loss: 0.2134 - accuracy: 0.9001 - val_loss: 0.9978 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.41491\n",
      "Epoch 375/3000\n",
      "13/13 - 0s - loss: 0.2078 - accuracy: 0.9001 - val_loss: 1.0405 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.41491\n",
      "Epoch 376/3000\n",
      "13/13 - 0s - loss: 0.2076 - accuracy: 0.8975 - val_loss: 1.0292 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.41491\n",
      "Epoch 377/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.9014 - val_loss: 1.0173 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.41491\n",
      "Epoch 378/3000\n",
      "13/13 - 0s - loss: 0.2112 - accuracy: 0.9001 - val_loss: 1.0363 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.41491\n",
      "Epoch 379/3000\n",
      "13/13 - 0s - loss: 0.2083 - accuracy: 0.8975 - val_loss: 1.0247 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.41491\n",
      "Epoch 380/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.8962 - val_loss: 1.0181 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.41491\n",
      "Epoch 381/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.9014 - val_loss: 1.0115 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 0.41491\n",
      "Epoch 382/3000\n",
      "13/13 - 0s - loss: 0.2061 - accuracy: 0.9027 - val_loss: 1.0239 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 0.41491\n",
      "Epoch 383/3000\n",
      "13/13 - 0s - loss: 0.2061 - accuracy: 0.9027 - val_loss: 1.0408 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 0.41491\n",
      "Epoch 384/3000\n",
      "13/13 - 0s - loss: 0.2115 - accuracy: 0.8988 - val_loss: 1.0419 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 0.41491\n",
      "Epoch 385/3000\n",
      "13/13 - 0s - loss: 0.2163 - accuracy: 0.8988 - val_loss: 0.8909 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 0.41491\n",
      "Epoch 386/3000\n",
      "13/13 - 0s - loss: 0.2143 - accuracy: 0.8962 - val_loss: 0.9159 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.41491\n",
      "Epoch 387/3000\n",
      "13/13 - 0s - loss: 0.2117 - accuracy: 0.8962 - val_loss: 0.9350 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 0.41491\n",
      "Epoch 388/3000\n",
      "13/13 - 0s - loss: 0.2229 - accuracy: 0.8859 - val_loss: 0.9377 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.41491\n",
      "Epoch 389/3000\n",
      "13/13 - 0s - loss: 0.2537 - accuracy: 0.8560 - val_loss: 1.0782 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 0.41491\n",
      "Epoch 390/3000\n",
      "13/13 - 0s - loss: 0.2522 - accuracy: 0.8859 - val_loss: 1.1140 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.41491\n",
      "Epoch 391/3000\n",
      "13/13 - 0s - loss: 0.2295 - accuracy: 0.8975 - val_loss: 1.0540 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.41491\n",
      "Epoch 392/3000\n",
      "13/13 - 0s - loss: 0.2151 - accuracy: 0.8949 - val_loss: 1.1180 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.41491\n",
      "Epoch 393/3000\n",
      "13/13 - 0s - loss: 0.2137 - accuracy: 0.9001 - val_loss: 1.0926 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.41491\n",
      "Epoch 394/3000\n",
      "13/13 - 0s - loss: 0.2128 - accuracy: 0.8962 - val_loss: 1.0471 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 0.41491\n",
      "Epoch 395/3000\n",
      "13/13 - 0s - loss: 0.2058 - accuracy: 0.9014 - val_loss: 0.9806 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 0.41491\n",
      "Epoch 396/3000\n",
      "13/13 - 0s - loss: 0.2051 - accuracy: 0.9027 - val_loss: 0.9938 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 0.41491\n",
      "Epoch 397/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.9027 - val_loss: 0.9588 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.41491\n",
      "Epoch 398/3000\n",
      "13/13 - 0s - loss: 0.2085 - accuracy: 0.9001 - val_loss: 1.0155 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 0.41491\n",
      "Epoch 399/3000\n",
      "13/13 - 0s - loss: 0.2089 - accuracy: 0.8975 - val_loss: 1.0112 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 0.41491\n",
      "Epoch 400/3000\n",
      "13/13 - 0s - loss: 0.2069 - accuracy: 0.9014 - val_loss: 1.0240 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.41491\n",
      "Epoch 401/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.8988 - val_loss: 1.0038 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 0.41491\n",
      "Epoch 402/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.9014 - val_loss: 1.0137 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 0.41491\n",
      "Epoch 403/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.9027 - val_loss: 1.0515 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 0.41491\n",
      "Epoch 404/3000\n",
      "13/13 - 0s - loss: 0.2025 - accuracy: 0.9001 - val_loss: 1.0548 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 0.41491\n",
      "Epoch 405/3000\n",
      "13/13 - 0s - loss: 0.2051 - accuracy: 0.8975 - val_loss: 1.0840 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 0.41491\n",
      "Epoch 406/3000\n",
      "13/13 - 0s - loss: 0.2073 - accuracy: 0.8949 - val_loss: 0.9894 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 0.41491\n",
      "Epoch 407/3000\n",
      "13/13 - 0s - loss: 0.2027 - accuracy: 0.8975 - val_loss: 0.9642 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 0.41491\n",
      "Epoch 408/3000\n",
      "13/13 - 0s - loss: 0.2077 - accuracy: 0.9001 - val_loss: 1.0090 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 0.41491\n",
      "Epoch 409/3000\n",
      "13/13 - 0s - loss: 0.2048 - accuracy: 0.9040 - val_loss: 1.0096 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 0.41491\n",
      "Epoch 410/3000\n",
      "13/13 - 0s - loss: 0.2052 - accuracy: 0.9014 - val_loss: 0.9753 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 0.41491\n",
      "Epoch 411/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.9027 - val_loss: 1.0218 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 0.41491\n",
      "Epoch 412/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.8975 - val_loss: 1.0400 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 0.41491\n",
      "Epoch 413/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.9014 - val_loss: 1.0292 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 0.41491\n",
      "Epoch 414/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.9027 - val_loss: 1.0034 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 0.41491\n",
      "Epoch 415/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.9014 - val_loss: 1.0185 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 0.41491\n",
      "Epoch 416/3000\n",
      "13/13 - 0s - loss: 0.2065 - accuracy: 0.8975 - val_loss: 1.0220 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.41491\n",
      "Epoch 417/3000\n",
      "13/13 - 0s - loss: 0.2076 - accuracy: 0.8988 - val_loss: 1.0207 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.41491\n",
      "Epoch 418/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.8988 - val_loss: 1.0578 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 0.41491\n",
      "Epoch 419/3000\n",
      "13/13 - 0s - loss: 0.2202 - accuracy: 0.9014 - val_loss: 1.2760 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 0.41491\n",
      "Epoch 420/3000\n",
      "13/13 - 0s - loss: 0.2141 - accuracy: 0.9001 - val_loss: 1.2861 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 0.41491\n",
      "Epoch 421/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.9027 - val_loss: 1.2481 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 0.41491\n",
      "Epoch 422/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.9027 - val_loss: 1.2898 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 0.41491\n",
      "Epoch 423/3000\n",
      "13/13 - 0s - loss: 0.2041 - accuracy: 0.9027 - val_loss: 1.3080 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 0.41491\n",
      "Epoch 424/3000\n",
      "13/13 - 0s - loss: 0.2041 - accuracy: 0.8988 - val_loss: 1.3219 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 0.41491\n",
      "Epoch 425/3000\n",
      "13/13 - 0s - loss: 0.2119 - accuracy: 0.8949 - val_loss: 1.3580 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 0.41491\n",
      "Epoch 426/3000\n",
      "13/13 - 0s - loss: 0.2133 - accuracy: 0.8988 - val_loss: 1.1968 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 0.41491\n",
      "Epoch 427/3000\n",
      "13/13 - 0s - loss: 0.2064 - accuracy: 0.9001 - val_loss: 1.1196 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 0.41491\n",
      "Epoch 428/3000\n",
      "13/13 - 0s - loss: 0.2069 - accuracy: 0.9014 - val_loss: 1.1697 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 0.41491\n",
      "Epoch 429/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.9001 - val_loss: 1.1694 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 0.41491\n",
      "Epoch 430/3000\n",
      "13/13 - 0s - loss: 0.2041 - accuracy: 0.9027 - val_loss: 1.1274 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.41491\n",
      "Epoch 431/3000\n",
      "13/13 - 0s - loss: 0.2066 - accuracy: 0.8988 - val_loss: 1.1089 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 0.41491\n",
      "Epoch 432/3000\n",
      "13/13 - 0s - loss: 0.2087 - accuracy: 0.9014 - val_loss: 1.1297 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.41491\n",
      "Epoch 433/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.9027 - val_loss: 1.1549 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.41491\n",
      "Epoch 434/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.8962 - val_loss: 1.1534 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 0.41491\n",
      "Epoch 435/3000\n",
      "13/13 - 0s - loss: 0.2104 - accuracy: 0.9027 - val_loss: 1.1392 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 0.41491\n",
      "Epoch 436/3000\n",
      "13/13 - 0s - loss: 0.2135 - accuracy: 0.9027 - val_loss: 1.0983 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 0.41491\n",
      "Epoch 437/3000\n",
      "13/13 - 0s - loss: 0.2101 - accuracy: 0.8988 - val_loss: 1.1534 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 0.41491\n",
      "Epoch 438/3000\n",
      "13/13 - 0s - loss: 0.2070 - accuracy: 0.9027 - val_loss: 1.1840 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 0.41491\n",
      "Epoch 439/3000\n",
      "13/13 - 0s - loss: 0.2052 - accuracy: 0.9027 - val_loss: 1.1962 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 0.41491\n",
      "Epoch 440/3000\n",
      "13/13 - 0s - loss: 0.2067 - accuracy: 0.9027 - val_loss: 1.1900 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.41491\n",
      "Epoch 441/3000\n",
      "13/13 - 0s - loss: 0.2060 - accuracy: 0.9027 - val_loss: 1.1719 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 0.41491\n",
      "Epoch 442/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.9027 - val_loss: 1.1026 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.41491\n",
      "Epoch 443/3000\n",
      "13/13 - 0s - loss: 0.2080 - accuracy: 0.9027 - val_loss: 1.1134 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.41491\n",
      "Epoch 444/3000\n",
      "13/13 - 0s - loss: 0.2049 - accuracy: 0.9027 - val_loss: 1.1211 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.41491\n",
      "Epoch 445/3000\n",
      "13/13 - 0s - loss: 0.2121 - accuracy: 0.9027 - val_loss: 1.1624 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.41491\n",
      "Epoch 446/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.9014 - val_loss: 1.1422 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.41491\n",
      "Epoch 447/3000\n",
      "13/13 - 0s - loss: 0.2068 - accuracy: 0.9014 - val_loss: 1.1018 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 0.41491\n",
      "Epoch 448/3000\n",
      "13/13 - 0s - loss: 0.2101 - accuracy: 0.9001 - val_loss: 1.0947 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 0.41491\n",
      "Epoch 449/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.9001 - val_loss: 1.0726 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 0.41491\n",
      "Epoch 450/3000\n",
      "13/13 - 0s - loss: 0.2058 - accuracy: 0.8975 - val_loss: 1.0784 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 0.41491\n",
      "Epoch 451/3000\n",
      "13/13 - 0s - loss: 0.2124 - accuracy: 0.8962 - val_loss: 1.2413 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 0.41491\n",
      "Epoch 452/3000\n",
      "13/13 - 0s - loss: 0.2061 - accuracy: 0.9040 - val_loss: 1.3180 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 0.41491\n",
      "Epoch 453/3000\n",
      "13/13 - 0s - loss: 0.2104 - accuracy: 0.9040 - val_loss: 1.2973 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 0.41491\n",
      "Epoch 454/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.9014 - val_loss: 1.2913 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 0.41491\n",
      "Epoch 455/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.9014 - val_loss: 1.2274 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 0.41491\n",
      "Epoch 456/3000\n",
      "13/13 - 0s - loss: 0.2191 - accuracy: 0.8872 - val_loss: 1.2335 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.41491\n",
      "Epoch 457/3000\n",
      "13/13 - 0s - loss: 0.2095 - accuracy: 0.8949 - val_loss: 1.1039 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 0.41491\n",
      "Epoch 458/3000\n",
      "13/13 - 0s - loss: 0.2077 - accuracy: 0.9014 - val_loss: 1.2006 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 0.41491\n",
      "Epoch 459/3000\n",
      "13/13 - 0s - loss: 0.2041 - accuracy: 0.8975 - val_loss: 1.2404 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 0.41491\n",
      "Epoch 460/3000\n",
      "13/13 - 0s - loss: 0.2048 - accuracy: 0.9027 - val_loss: 1.3066 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 0.41491\n",
      "Epoch 461/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.9014 - val_loss: 1.2992 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 0.41491\n",
      "Epoch 462/3000\n",
      "13/13 - 0s - loss: 0.2059 - accuracy: 0.8975 - val_loss: 1.3168 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 0.41491\n",
      "Epoch 463/3000\n",
      "13/13 - 0s - loss: 0.2034 - accuracy: 0.9001 - val_loss: 1.3147 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 0.41491\n",
      "Epoch 464/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.9014 - val_loss: 1.2328 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 0.41491\n",
      "Epoch 465/3000\n",
      "13/13 - 0s - loss: 0.2032 - accuracy: 0.8962 - val_loss: 1.1524 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 0.41491\n",
      "Epoch 466/3000\n",
      "13/13 - 0s - loss: 0.2043 - accuracy: 0.8988 - val_loss: 1.1401 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 0.41491\n",
      "Epoch 467/3000\n",
      "13/13 - 0s - loss: 0.2139 - accuracy: 0.8988 - val_loss: 1.0550 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.41491\n",
      "Epoch 468/3000\n",
      "13/13 - 0s - loss: 0.2252 - accuracy: 0.8833 - val_loss: 1.1631 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 0.41491\n",
      "Epoch 469/3000\n",
      "13/13 - 0s - loss: 0.2244 - accuracy: 0.8936 - val_loss: 1.0270 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 0.41491\n",
      "Epoch 470/3000\n",
      "13/13 - 0s - loss: 0.2337 - accuracy: 0.8846 - val_loss: 1.1888 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.41491\n",
      "Epoch 471/3000\n",
      "13/13 - 0s - loss: 0.2277 - accuracy: 0.8936 - val_loss: 0.9498 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 0.41491\n",
      "Epoch 472/3000\n",
      "13/13 - 0s - loss: 0.2144 - accuracy: 0.8975 - val_loss: 1.0998 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.41491\n",
      "Epoch 473/3000\n",
      "13/13 - 0s - loss: 0.2129 - accuracy: 0.8975 - val_loss: 1.2613 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 0.41491\n",
      "Epoch 474/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.8975 - val_loss: 1.2616 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 0.41491\n",
      "Epoch 475/3000\n",
      "13/13 - 0s - loss: 0.2051 - accuracy: 0.9027 - val_loss: 1.0623 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.41491\n",
      "Epoch 476/3000\n",
      "13/13 - 0s - loss: 0.2040 - accuracy: 0.9040 - val_loss: 1.0351 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 0.41491\n",
      "Epoch 477/3000\n",
      "13/13 - 0s - loss: 0.2045 - accuracy: 0.8962 - val_loss: 1.0813 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 0.41491\n",
      "Epoch 478/3000\n",
      "13/13 - 0s - loss: 0.2045 - accuracy: 0.8975 - val_loss: 1.0802 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 0.41491\n",
      "Epoch 479/3000\n",
      "13/13 - 0s - loss: 0.2070 - accuracy: 0.9014 - val_loss: 1.0074 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 0.41491\n",
      "Epoch 480/3000\n",
      "13/13 - 0s - loss: 0.2067 - accuracy: 0.8988 - val_loss: 0.9819 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.41491\n",
      "Epoch 481/3000\n",
      "13/13 - 0s - loss: 0.2094 - accuracy: 0.9066 - val_loss: 0.9425 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 0.41491\n",
      "Epoch 482/3000\n",
      "13/13 - 0s - loss: 0.2067 - accuracy: 0.8949 - val_loss: 0.9450 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 0.41491\n",
      "Epoch 483/3000\n",
      "13/13 - 0s - loss: 0.2089 - accuracy: 0.9001 - val_loss: 0.9345 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 0.41491\n",
      "Epoch 484/3000\n",
      "13/13 - 0s - loss: 0.2043 - accuracy: 0.9027 - val_loss: 0.9491 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.41491\n",
      "Epoch 485/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.9027 - val_loss: 0.9586 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 0.41491\n",
      "Epoch 486/3000\n",
      "13/13 - 0s - loss: 0.2040 - accuracy: 0.9053 - val_loss: 0.9630 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.41491\n",
      "Epoch 487/3000\n",
      "13/13 - 0s - loss: 0.2039 - accuracy: 0.8988 - val_loss: 0.9213 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.41491\n",
      "Epoch 488/3000\n",
      "13/13 - 0s - loss: 0.2097 - accuracy: 0.9001 - val_loss: 0.8695 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 0.41491\n",
      "Epoch 489/3000\n",
      "13/13 - 0s - loss: 0.2088 - accuracy: 0.8988 - val_loss: 0.7945 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 0.41491\n",
      "Epoch 490/3000\n",
      "13/13 - 0s - loss: 0.2043 - accuracy: 0.8988 - val_loss: 0.8917 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.41491\n",
      "Epoch 491/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.8962 - val_loss: 0.9648 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 0.41491\n",
      "Epoch 492/3000\n",
      "13/13 - 0s - loss: 0.2083 - accuracy: 0.9001 - val_loss: 0.9238 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 0.41491\n",
      "Epoch 493/3000\n",
      "13/13 - 0s - loss: 0.2117 - accuracy: 0.8988 - val_loss: 0.9341 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 0.41491\n",
      "Epoch 494/3000\n",
      "13/13 - 0s - loss: 0.2077 - accuracy: 0.9001 - val_loss: 0.9353 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 0.41491\n",
      "Epoch 495/3000\n",
      "13/13 - 0s - loss: 0.2087 - accuracy: 0.8949 - val_loss: 0.9851 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.41491\n",
      "Epoch 496/3000\n",
      "13/13 - 0s - loss: 0.2080 - accuracy: 0.9027 - val_loss: 1.0303 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.41491\n",
      "Epoch 497/3000\n",
      "13/13 - 0s - loss: 0.2047 - accuracy: 0.9014 - val_loss: 1.0312 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 0.41491\n",
      "Epoch 498/3000\n",
      "13/13 - 0s - loss: 0.2043 - accuracy: 0.9027 - val_loss: 1.0161 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 0.41491\n",
      "Epoch 499/3000\n",
      "13/13 - 0s - loss: 0.2116 - accuracy: 0.8975 - val_loss: 1.0157 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 0.41491\n",
      "Epoch 500/3000\n",
      "13/13 - 0s - loss: 0.2048 - accuracy: 0.9014 - val_loss: 1.0017 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.41491\n",
      "Epoch 501/3000\n",
      "13/13 - 0s - loss: 0.2134 - accuracy: 0.8962 - val_loss: 0.9690 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 0.41491\n",
      "Epoch 502/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.8988 - val_loss: 1.0692 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 0.41491\n",
      "Epoch 503/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.9027 - val_loss: 1.1099 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 0.41491\n",
      "Epoch 504/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.8962 - val_loss: 1.1257 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 0.41491\n",
      "Epoch 505/3000\n",
      "13/13 - 0s - loss: 0.2026 - accuracy: 0.9027 - val_loss: 1.1429 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 0.41491\n",
      "Epoch 506/3000\n",
      "13/13 - 0s - loss: 0.2024 - accuracy: 0.8988 - val_loss: 1.1867 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 0.41491\n",
      "Epoch 507/3000\n",
      "13/13 - 0s - loss: 0.2028 - accuracy: 0.9001 - val_loss: 1.2018 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 0.41491\n",
      "Epoch 508/3000\n",
      "13/13 - 0s - loss: 0.2026 - accuracy: 0.9027 - val_loss: 1.2054 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 0.41491\n",
      "Epoch 509/3000\n",
      "13/13 - 0s - loss: 0.2059 - accuracy: 0.9014 - val_loss: 1.2088 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 0.41491\n",
      "Epoch 510/3000\n",
      "13/13 - 0s - loss: 0.2061 - accuracy: 0.9014 - val_loss: 1.2509 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 0.41491\n",
      "Epoch 511/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9027 - val_loss: 1.2347 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 0.41491\n",
      "Epoch 512/3000\n",
      "13/13 - 0s - loss: 0.2076 - accuracy: 0.8988 - val_loss: 1.2175 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 0.41491\n",
      "Epoch 513/3000\n",
      "13/13 - 0s - loss: 0.2080 - accuracy: 0.8988 - val_loss: 1.2179 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 0.41491\n",
      "Epoch 514/3000\n",
      "13/13 - 0s - loss: 0.2056 - accuracy: 0.8988 - val_loss: 1.1443 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 0.41491\n",
      "Epoch 515/3000\n",
      "13/13 - 0s - loss: 0.2039 - accuracy: 0.9027 - val_loss: 1.1516 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 0.41491\n",
      "Epoch 516/3000\n",
      "13/13 - 0s - loss: 0.2036 - accuracy: 0.9040 - val_loss: 1.1874 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 0.41491\n",
      "Epoch 517/3000\n",
      "13/13 - 0s - loss: 0.2092 - accuracy: 0.9001 - val_loss: 1.2335 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 0.41491\n",
      "Epoch 518/3000\n",
      "13/13 - 0s - loss: 0.2085 - accuracy: 0.8975 - val_loss: 1.2241 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 0.41491\n",
      "Epoch 519/3000\n",
      "13/13 - 0s - loss: 0.2060 - accuracy: 0.8975 - val_loss: 1.2054 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 0.41491\n",
      "Epoch 520/3000\n",
      "13/13 - 0s - loss: 0.2068 - accuracy: 0.8949 - val_loss: 1.2424 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 0.41491\n",
      "Epoch 521/3000\n",
      "13/13 - 0s - loss: 0.2056 - accuracy: 0.9001 - val_loss: 1.2192 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 0.41491\n",
      "Epoch 522/3000\n",
      "13/13 - 0s - loss: 0.2046 - accuracy: 0.8949 - val_loss: 1.2024 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 0.41491\n",
      "Epoch 523/3000\n",
      "13/13 - 0s - loss: 0.2038 - accuracy: 0.8988 - val_loss: 1.1665 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 0.41491\n",
      "Epoch 524/3000\n",
      "13/13 - 0s - loss: 0.2117 - accuracy: 0.8923 - val_loss: 0.9885 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 0.41491\n",
      "Epoch 525/3000\n",
      "13/13 - 0s - loss: 0.2116 - accuracy: 0.8936 - val_loss: 1.2144 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 0.41491\n",
      "Epoch 526/3000\n",
      "13/13 - 0s - loss: 0.2326 - accuracy: 0.8975 - val_loss: 1.0696 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 0.41491\n",
      "Epoch 527/3000\n",
      "13/13 - 0s - loss: 0.2142 - accuracy: 0.9001 - val_loss: 1.0305 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 0.41491\n",
      "Epoch 528/3000\n",
      "13/13 - 0s - loss: 0.2095 - accuracy: 0.8962 - val_loss: 1.0671 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 0.41491\n",
      "Epoch 529/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.8949 - val_loss: 1.1075 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 0.41491\n",
      "Epoch 530/3000\n",
      "13/13 - 0s - loss: 0.2102 - accuracy: 0.8975 - val_loss: 1.1344 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 0.41491\n",
      "Epoch 531/3000\n",
      "13/13 - 0s - loss: 0.2119 - accuracy: 0.8975 - val_loss: 1.1133 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 0.41491\n",
      "Epoch 532/3000\n",
      "13/13 - 0s - loss: 0.2065 - accuracy: 0.9001 - val_loss: 1.1272 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 0.41491\n",
      "Epoch 533/3000\n",
      "13/13 - 0s - loss: 0.2098 - accuracy: 0.9001 - val_loss: 1.1347 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 0.41491\n",
      "Epoch 534/3000\n",
      "13/13 - 0s - loss: 0.2117 - accuracy: 0.9001 - val_loss: 1.1773 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 0.41491\n",
      "Epoch 535/3000\n",
      "13/13 - 0s - loss: 0.2077 - accuracy: 0.9014 - val_loss: 1.1833 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 0.41491\n",
      "Epoch 536/3000\n",
      "13/13 - 0s - loss: 0.2088 - accuracy: 0.8975 - val_loss: 1.1724 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 0.41491\n",
      "Epoch 537/3000\n",
      "13/13 - 0s - loss: 0.2144 - accuracy: 0.8898 - val_loss: 1.0881 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 0.41491\n",
      "Epoch 538/3000\n",
      "13/13 - 0s - loss: 0.2194 - accuracy: 0.8885 - val_loss: 1.1213 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 0.41491\n",
      "Epoch 539/3000\n",
      "13/13 - 0s - loss: 0.2210 - accuracy: 0.8949 - val_loss: 0.9653 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 0.41491\n",
      "Epoch 540/3000\n",
      "13/13 - 0s - loss: 0.2486 - accuracy: 0.8911 - val_loss: 1.1214 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 0.41491\n",
      "Epoch 541/3000\n",
      "13/13 - 0s - loss: 0.2360 - accuracy: 0.8872 - val_loss: 0.8294 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 0.41491\n",
      "Epoch 542/3000\n",
      "13/13 - 0s - loss: 0.2756 - accuracy: 0.8677 - val_loss: 1.8852 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 0.41491\n",
      "Epoch 543/3000\n",
      "13/13 - 0s - loss: 0.3186 - accuracy: 0.8742 - val_loss: 0.4946 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 0.41491\n",
      "Epoch 544/3000\n",
      "13/13 - 0s - loss: 0.2741 - accuracy: 0.8898 - val_loss: 0.6984 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 0.41491\n",
      "Epoch 545/3000\n",
      "13/13 - 0s - loss: 0.2446 - accuracy: 0.8833 - val_loss: 0.6695 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 0.41491\n",
      "Epoch 546/3000\n",
      "13/13 - 0s - loss: 0.2843 - accuracy: 0.8898 - val_loss: 0.6311 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 0.41491\n",
      "Epoch 547/3000\n",
      "13/13 - 0s - loss: 0.2308 - accuracy: 0.8898 - val_loss: 0.7853 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 0.41491\n",
      "Epoch 548/3000\n",
      "13/13 - 0s - loss: 0.2270 - accuracy: 0.8846 - val_loss: 0.7360 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 0.41491\n",
      "Epoch 549/3000\n",
      "13/13 - 0s - loss: 0.2184 - accuracy: 0.8898 - val_loss: 0.7393 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 0.41491\n",
      "Epoch 550/3000\n",
      "13/13 - 0s - loss: 0.2162 - accuracy: 0.8923 - val_loss: 0.7345 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 0.41491\n",
      "Epoch 551/3000\n",
      "13/13 - 0s - loss: 0.2166 - accuracy: 0.8923 - val_loss: 0.7028 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00551: val_loss did not improve from 0.41491\n",
      "Epoch 552/3000\n",
      "13/13 - 0s - loss: 0.2198 - accuracy: 0.8898 - val_loss: 0.6857 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00552: val_loss did not improve from 0.41491\n",
      "Epoch 553/3000\n",
      "13/13 - 0s - loss: 0.2137 - accuracy: 0.8911 - val_loss: 0.7092 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00553: val_loss did not improve from 0.41491\n",
      "Epoch 554/3000\n",
      "13/13 - 0s - loss: 0.2210 - accuracy: 0.8949 - val_loss: 0.6540 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00554: val_loss did not improve from 0.41491\n",
      "Epoch 555/3000\n",
      "13/13 - 0s - loss: 0.2561 - accuracy: 0.8949 - val_loss: 0.5776 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00555: val_loss did not improve from 0.41491\n",
      "Epoch 556/3000\n",
      "13/13 - 0s - loss: 0.2330 - accuracy: 0.8859 - val_loss: 0.5791 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00556: val_loss did not improve from 0.41491\n",
      "Epoch 557/3000\n",
      "13/13 - 0s - loss: 0.2132 - accuracy: 0.8988 - val_loss: 0.6394 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00557: val_loss did not improve from 0.41491\n",
      "Epoch 558/3000\n",
      "13/13 - 0s - loss: 0.2170 - accuracy: 0.9014 - val_loss: 0.6946 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00558: val_loss did not improve from 0.41491\n",
      "Epoch 559/3000\n",
      "13/13 - 0s - loss: 0.2146 - accuracy: 0.9001 - val_loss: 0.7184 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00559: val_loss did not improve from 0.41491\n",
      "Epoch 560/3000\n",
      "13/13 - 0s - loss: 0.2144 - accuracy: 0.9001 - val_loss: 0.6488 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 0.41491\n",
      "Epoch 561/3000\n",
      "13/13 - 0s - loss: 0.2124 - accuracy: 0.9027 - val_loss: 0.6183 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00561: val_loss did not improve from 0.41491\n",
      "Epoch 562/3000\n",
      "13/13 - 0s - loss: 0.2094 - accuracy: 0.9027 - val_loss: 0.6058 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00562: val_loss did not improve from 0.41491\n",
      "Epoch 563/3000\n",
      "13/13 - 0s - loss: 0.2061 - accuracy: 0.9027 - val_loss: 0.6002 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00563: val_loss did not improve from 0.41491\n",
      "Epoch 564/3000\n",
      "13/13 - 0s - loss: 0.2093 - accuracy: 0.9027 - val_loss: 0.6320 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00564: val_loss did not improve from 0.41491\n",
      "Epoch 565/3000\n",
      "13/13 - 0s - loss: 0.2100 - accuracy: 0.9027 - val_loss: 0.7027 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00565: val_loss did not improve from 0.41491\n",
      "Epoch 566/3000\n",
      "13/13 - 0s - loss: 0.2064 - accuracy: 0.9014 - val_loss: 0.7011 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00566: val_loss did not improve from 0.41491\n",
      "Epoch 567/3000\n",
      "13/13 - 0s - loss: 0.2056 - accuracy: 0.9027 - val_loss: 0.6799 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00567: val_loss did not improve from 0.41491\n",
      "Epoch 568/3000\n",
      "13/13 - 0s - loss: 0.2053 - accuracy: 0.8988 - val_loss: 0.6539 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00568: val_loss did not improve from 0.41491\n",
      "Epoch 569/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.9001 - val_loss: 0.6735 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00569: val_loss did not improve from 0.41491\n",
      "Epoch 570/3000\n",
      "13/13 - 0s - loss: 0.2096 - accuracy: 0.9014 - val_loss: 0.7153 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00570: val_loss did not improve from 0.41491\n",
      "Epoch 571/3000\n",
      "13/13 - 0s - loss: 0.2065 - accuracy: 0.9027 - val_loss: 0.7042 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00571: val_loss did not improve from 0.41491\n",
      "Epoch 572/3000\n",
      "13/13 - 0s - loss: 0.2039 - accuracy: 0.9027 - val_loss: 0.7046 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00572: val_loss did not improve from 0.41491\n",
      "Epoch 573/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.9040 - val_loss: 0.6633 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00573: val_loss did not improve from 0.41491\n",
      "Epoch 574/3000\n",
      "13/13 - 0s - loss: 0.2139 - accuracy: 0.8949 - val_loss: 0.5990 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00574: val_loss did not improve from 0.41491\n",
      "Epoch 575/3000\n",
      "13/13 - 0s - loss: 0.2190 - accuracy: 0.9001 - val_loss: 0.5389 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00575: val_loss did not improve from 0.41491\n",
      "Epoch 576/3000\n",
      "13/13 - 0s - loss: 0.2173 - accuracy: 0.8936 - val_loss: 0.5362 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00576: val_loss did not improve from 0.41491\n",
      "Epoch 577/3000\n",
      "13/13 - 0s - loss: 0.2093 - accuracy: 0.9027 - val_loss: 0.5731 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00577: val_loss did not improve from 0.41491\n",
      "Epoch 578/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.8988 - val_loss: 0.6027 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00578: val_loss did not improve from 0.41491\n",
      "Epoch 579/3000\n",
      "13/13 - 0s - loss: 0.2109 - accuracy: 0.9027 - val_loss: 0.6095 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00579: val_loss did not improve from 0.41491\n",
      "Epoch 580/3000\n",
      "13/13 - 0s - loss: 0.2083 - accuracy: 0.8962 - val_loss: 0.6002 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00580: val_loss did not improve from 0.41491\n",
      "Epoch 581/3000\n",
      "13/13 - 0s - loss: 0.2124 - accuracy: 0.8975 - val_loss: 0.6096 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00581: val_loss did not improve from 0.41491\n",
      "Epoch 582/3000\n",
      "13/13 - 0s - loss: 0.2109 - accuracy: 0.8988 - val_loss: 0.5993 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00582: val_loss did not improve from 0.41491\n",
      "Epoch 583/3000\n",
      "13/13 - 0s - loss: 0.2077 - accuracy: 0.9001 - val_loss: 0.6049 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00583: val_loss did not improve from 0.41491\n",
      "Epoch 584/3000\n",
      "13/13 - 0s - loss: 0.2100 - accuracy: 0.8949 - val_loss: 0.5847 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00584: val_loss did not improve from 0.41491\n",
      "Epoch 585/3000\n",
      "13/13 - 0s - loss: 0.2083 - accuracy: 0.9027 - val_loss: 0.6569 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00585: val_loss did not improve from 0.41491\n",
      "Epoch 586/3000\n",
      "13/13 - 0s - loss: 0.2096 - accuracy: 0.9014 - val_loss: 0.6804 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00586: val_loss did not improve from 0.41491\n",
      "Epoch 587/3000\n",
      "13/13 - 0s - loss: 0.2097 - accuracy: 0.9014 - val_loss: 0.6672 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00587: val_loss did not improve from 0.41491\n",
      "Epoch 588/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.9027 - val_loss: 0.6258 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00588: val_loss did not improve from 0.41491\n",
      "Epoch 589/3000\n",
      "13/13 - 0s - loss: 0.2082 - accuracy: 0.9027 - val_loss: 0.6490 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00589: val_loss did not improve from 0.41491\n",
      "Epoch 590/3000\n",
      "13/13 - 0s - loss: 0.2089 - accuracy: 0.9014 - val_loss: 0.6557 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00590: val_loss did not improve from 0.41491\n",
      "Epoch 591/3000\n",
      "13/13 - 0s - loss: 0.2069 - accuracy: 0.9014 - val_loss: 0.6529 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00591: val_loss did not improve from 0.41491\n",
      "Epoch 592/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.9014 - val_loss: 0.6369 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00592: val_loss did not improve from 0.41491\n",
      "Epoch 593/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.9014 - val_loss: 0.6356 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00593: val_loss did not improve from 0.41491\n",
      "Epoch 594/3000\n",
      "13/13 - 0s - loss: 0.2049 - accuracy: 0.9014 - val_loss: 0.6368 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00594: val_loss did not improve from 0.41491\n",
      "Epoch 595/3000\n",
      "13/13 - 0s - loss: 0.2053 - accuracy: 0.9027 - val_loss: 0.6503 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00595: val_loss did not improve from 0.41491\n",
      "Epoch 596/3000\n",
      "13/13 - 0s - loss: 0.2125 - accuracy: 0.8923 - val_loss: 0.6225 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00596: val_loss did not improve from 0.41491\n",
      "Epoch 597/3000\n",
      "13/13 - 0s - loss: 0.2207 - accuracy: 0.8923 - val_loss: 0.6034 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00597: val_loss did not improve from 0.41491\n",
      "Epoch 598/3000\n",
      "13/13 - 0s - loss: 0.2170 - accuracy: 0.8975 - val_loss: 0.6677 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00598: val_loss did not improve from 0.41491\n",
      "Epoch 599/3000\n",
      "13/13 - 0s - loss: 0.2109 - accuracy: 0.8975 - val_loss: 0.6579 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00599: val_loss did not improve from 0.41491\n",
      "Epoch 600/3000\n",
      "13/13 - 0s - loss: 0.2115 - accuracy: 0.9001 - val_loss: 0.6605 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00600: val_loss did not improve from 0.41491\n",
      "Epoch 601/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.9014 - val_loss: 0.6727 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00601: val_loss did not improve from 0.41491\n",
      "Epoch 602/3000\n",
      "13/13 - 0s - loss: 0.2068 - accuracy: 0.9040 - val_loss: 0.6731 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00602: val_loss did not improve from 0.41491\n",
      "Epoch 603/3000\n",
      "13/13 - 0s - loss: 0.2121 - accuracy: 0.8962 - val_loss: 0.6276 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00603: val_loss did not improve from 0.41491\n",
      "Epoch 604/3000\n",
      "13/13 - 0s - loss: 0.2144 - accuracy: 0.8936 - val_loss: 0.6070 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00604: val_loss did not improve from 0.41491\n",
      "Epoch 605/3000\n",
      "13/13 - 0s - loss: 0.2143 - accuracy: 0.9001 - val_loss: 0.6017 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00605: val_loss did not improve from 0.41491\n",
      "Epoch 606/3000\n",
      "13/13 - 0s - loss: 0.2136 - accuracy: 0.8949 - val_loss: 0.6071 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00606: val_loss did not improve from 0.41491\n",
      "Epoch 607/3000\n",
      "13/13 - 0s - loss: 0.2107 - accuracy: 0.8988 - val_loss: 0.5973 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00607: val_loss did not improve from 0.41491\n",
      "Epoch 608/3000\n",
      "13/13 - 0s - loss: 0.2162 - accuracy: 0.8911 - val_loss: 0.5808 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00608: val_loss did not improve from 0.41491\n",
      "Epoch 609/3000\n",
      "13/13 - 0s - loss: 0.2125 - accuracy: 0.8936 - val_loss: 0.5960 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00609: val_loss did not improve from 0.41491\n",
      "Epoch 610/3000\n",
      "13/13 - 0s - loss: 0.2120 - accuracy: 0.8936 - val_loss: 0.5701 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00610: val_loss did not improve from 0.41491\n",
      "Epoch 611/3000\n",
      "13/13 - 0s - loss: 0.2141 - accuracy: 0.8885 - val_loss: 0.5871 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00611: val_loss did not improve from 0.41491\n",
      "Epoch 612/3000\n",
      "13/13 - 0s - loss: 0.2114 - accuracy: 0.8911 - val_loss: 0.6187 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00612: val_loss did not improve from 0.41491\n",
      "Epoch 613/3000\n",
      "13/13 - 0s - loss: 0.2109 - accuracy: 0.8949 - val_loss: 0.6094 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00613: val_loss did not improve from 0.41491\n",
      "Epoch 614/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.8949 - val_loss: 0.6144 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00614: val_loss did not improve from 0.41491\n",
      "Epoch 615/3000\n",
      "13/13 - 0s - loss: 0.2141 - accuracy: 0.8911 - val_loss: 0.6250 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00615: val_loss did not improve from 0.41491\n",
      "Epoch 616/3000\n",
      "13/13 - 0s - loss: 0.2077 - accuracy: 0.8898 - val_loss: 0.6072 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00616: val_loss did not improve from 0.41491\n",
      "Epoch 617/3000\n",
      "13/13 - 0s - loss: 0.2107 - accuracy: 0.9027 - val_loss: 0.5658 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00617: val_loss did not improve from 0.41491\n",
      "Epoch 618/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.9027 - val_loss: 0.5634 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00618: val_loss did not improve from 0.41491\n",
      "Epoch 619/3000\n",
      "13/13 - 0s - loss: 0.2069 - accuracy: 0.9001 - val_loss: 0.5576 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00619: val_loss did not improve from 0.41491\n",
      "Epoch 620/3000\n",
      "13/13 - 0s - loss: 0.2122 - accuracy: 0.8962 - val_loss: 0.5037 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00620: val_loss did not improve from 0.41491\n",
      "Epoch 621/3000\n",
      "13/13 - 0s - loss: 0.2152 - accuracy: 0.8923 - val_loss: 0.6816 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00621: val_loss did not improve from 0.41491\n",
      "Epoch 622/3000\n",
      "13/13 - 0s - loss: 0.2555 - accuracy: 0.8807 - val_loss: 0.3851 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00622: val_loss improved from 0.41491 to 0.38514, saving model to models\\model_4L_v3\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v3\\assets\n",
      "Epoch 623/3000\n",
      "13/13 - 0s - loss: 0.2404 - accuracy: 0.8898 - val_loss: 0.5674 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00623: val_loss did not improve from 0.38514\n",
      "Epoch 624/3000\n",
      "13/13 - 0s - loss: 0.2354 - accuracy: 0.8833 - val_loss: 0.4911 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00624: val_loss did not improve from 0.38514\n",
      "Epoch 625/3000\n",
      "13/13 - 0s - loss: 0.2312 - accuracy: 0.8962 - val_loss: 0.5049 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00625: val_loss did not improve from 0.38514\n",
      "Epoch 626/3000\n",
      "13/13 - 0s - loss: 0.2288 - accuracy: 0.8885 - val_loss: 0.5427 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00626: val_loss did not improve from 0.38514\n",
      "Epoch 627/3000\n",
      "13/13 - 0s - loss: 0.2401 - accuracy: 0.8962 - val_loss: 0.6042 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00627: val_loss did not improve from 0.38514\n",
      "Epoch 628/3000\n",
      "13/13 - 0s - loss: 0.2175 - accuracy: 0.8846 - val_loss: 0.7055 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00628: val_loss did not improve from 0.38514\n",
      "Epoch 629/3000\n",
      "13/13 - 0s - loss: 0.2257 - accuracy: 0.8988 - val_loss: 0.5681 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00629: val_loss did not improve from 0.38514\n",
      "Epoch 630/3000\n",
      "13/13 - 0s - loss: 0.2163 - accuracy: 0.9027 - val_loss: 0.6397 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00630: val_loss did not improve from 0.38514\n",
      "Epoch 631/3000\n",
      "13/13 - 1s - loss: 0.2109 - accuracy: 0.9001 - val_loss: 0.6823 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00631: val_loss did not improve from 0.38514\n",
      "Epoch 632/3000\n",
      "13/13 - 1s - loss: 0.2092 - accuracy: 0.9001 - val_loss: 0.6729 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00632: val_loss did not improve from 0.38514\n",
      "Epoch 633/3000\n",
      "13/13 - 0s - loss: 0.2113 - accuracy: 0.9014 - val_loss: 0.6659 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00633: val_loss did not improve from 0.38514\n",
      "Epoch 634/3000\n",
      "13/13 - 0s - loss: 0.2120 - accuracy: 0.8962 - val_loss: 0.6757 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00634: val_loss did not improve from 0.38514\n",
      "Epoch 635/3000\n",
      "13/13 - 0s - loss: 0.2092 - accuracy: 0.8988 - val_loss: 0.7133 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00635: val_loss did not improve from 0.38514\n",
      "Epoch 636/3000\n",
      "13/13 - 0s - loss: 0.2101 - accuracy: 0.8975 - val_loss: 0.7314 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00636: val_loss did not improve from 0.38514\n",
      "Epoch 637/3000\n",
      "13/13 - 0s - loss: 0.2095 - accuracy: 0.9014 - val_loss: 0.7806 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00637: val_loss did not improve from 0.38514\n",
      "Epoch 638/3000\n",
      "13/13 - 0s - loss: 0.2101 - accuracy: 0.9014 - val_loss: 0.8022 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00638: val_loss did not improve from 0.38514\n",
      "Epoch 639/3000\n",
      "13/13 - 0s - loss: 0.2086 - accuracy: 0.9027 - val_loss: 0.7943 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00639: val_loss did not improve from 0.38514\n",
      "Epoch 640/3000\n",
      "13/13 - 0s - loss: 0.2120 - accuracy: 0.8988 - val_loss: 0.6964 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00640: val_loss did not improve from 0.38514\n",
      "Epoch 641/3000\n",
      "13/13 - 0s - loss: 0.2077 - accuracy: 0.9027 - val_loss: 0.6838 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00641: val_loss did not improve from 0.38514\n",
      "Epoch 642/3000\n",
      "13/13 - 0s - loss: 0.2070 - accuracy: 0.8936 - val_loss: 0.6960 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00642: val_loss did not improve from 0.38514\n",
      "Epoch 643/3000\n",
      "13/13 - 0s - loss: 0.2070 - accuracy: 0.9001 - val_loss: 0.6810 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00643: val_loss did not improve from 0.38514\n",
      "Epoch 644/3000\n",
      "13/13 - 0s - loss: 0.2088 - accuracy: 0.8988 - val_loss: 0.6960 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00644: val_loss did not improve from 0.38514\n",
      "Epoch 645/3000\n",
      "13/13 - 0s - loss: 0.2088 - accuracy: 0.8988 - val_loss: 0.7163 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00645: val_loss did not improve from 0.38514\n",
      "Epoch 646/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.9040 - val_loss: 0.7142 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00646: val_loss did not improve from 0.38514\n",
      "Epoch 647/3000\n",
      "13/13 - 0s - loss: 0.2069 - accuracy: 0.9001 - val_loss: 0.7340 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00647: val_loss did not improve from 0.38514\n",
      "Epoch 648/3000\n",
      "13/13 - 0s - loss: 0.2119 - accuracy: 0.9027 - val_loss: 0.7996 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00648: val_loss did not improve from 0.38514\n",
      "Epoch 649/3000\n",
      "13/13 - 0s - loss: 0.2095 - accuracy: 0.9014 - val_loss: 0.7854 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00649: val_loss did not improve from 0.38514\n",
      "Epoch 650/3000\n",
      "13/13 - 0s - loss: 0.2061 - accuracy: 0.9001 - val_loss: 0.7657 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00650: val_loss did not improve from 0.38514\n",
      "Epoch 651/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.9014 - val_loss: 0.7845 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00651: val_loss did not improve from 0.38514\n",
      "Epoch 652/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.9027 - val_loss: 0.8000 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00652: val_loss did not improve from 0.38514\n",
      "Epoch 653/3000\n",
      "13/13 - 0s - loss: 0.2038 - accuracy: 0.9014 - val_loss: 0.8104 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00653: val_loss did not improve from 0.38514\n",
      "Epoch 654/3000\n",
      "13/13 - 0s - loss: 0.2041 - accuracy: 0.9014 - val_loss: 0.8053 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00654: val_loss did not improve from 0.38514\n",
      "Epoch 655/3000\n",
      "13/13 - 0s - loss: 0.2053 - accuracy: 0.8962 - val_loss: 0.8066 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00655: val_loss did not improve from 0.38514\n",
      "Epoch 656/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.8962 - val_loss: 0.7874 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00656: val_loss did not improve from 0.38514\n",
      "Epoch 657/3000\n",
      "13/13 - 0s - loss: 0.2124 - accuracy: 0.8962 - val_loss: 0.8377 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00657: val_loss did not improve from 0.38514\n",
      "Epoch 658/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.8962 - val_loss: 0.8908 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00658: val_loss did not improve from 0.38514\n",
      "Epoch 659/3000\n",
      "13/13 - 0s - loss: 0.2171 - accuracy: 0.8936 - val_loss: 0.8716 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00659: val_loss did not improve from 0.38514\n",
      "Epoch 660/3000\n",
      "13/13 - 0s - loss: 0.2102 - accuracy: 0.9014 - val_loss: 0.8595 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00660: val_loss did not improve from 0.38514\n",
      "Epoch 661/3000\n",
      "13/13 - 0s - loss: 0.2165 - accuracy: 0.8962 - val_loss: 0.8243 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00661: val_loss did not improve from 0.38514\n",
      "Epoch 662/3000\n",
      "13/13 - 0s - loss: 0.2118 - accuracy: 0.8988 - val_loss: 0.7914 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00662: val_loss did not improve from 0.38514\n",
      "Epoch 663/3000\n",
      "13/13 - 0s - loss: 0.2146 - accuracy: 0.8936 - val_loss: 0.7786 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00663: val_loss did not improve from 0.38514\n",
      "Epoch 664/3000\n",
      "13/13 - 0s - loss: 0.2147 - accuracy: 0.8936 - val_loss: 0.7637 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00664: val_loss did not improve from 0.38514\n",
      "Epoch 665/3000\n",
      "13/13 - 0s - loss: 0.2124 - accuracy: 0.8988 - val_loss: 0.8095 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00665: val_loss did not improve from 0.38514\n",
      "Epoch 666/3000\n",
      "13/13 - 0s - loss: 0.2105 - accuracy: 0.8988 - val_loss: 0.8122 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00666: val_loss did not improve from 0.38514\n",
      "Epoch 667/3000\n",
      "13/13 - 0s - loss: 0.2094 - accuracy: 0.8975 - val_loss: 0.7971 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00667: val_loss did not improve from 0.38514\n",
      "Epoch 668/3000\n",
      "13/13 - 0s - loss: 0.2157 - accuracy: 0.8988 - val_loss: 0.7754 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00668: val_loss did not improve from 0.38514\n",
      "Epoch 669/3000\n",
      "13/13 - 0s - loss: 0.2190 - accuracy: 0.8988 - val_loss: 0.7706 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00669: val_loss did not improve from 0.38514\n",
      "Epoch 670/3000\n",
      "13/13 - 0s - loss: 0.2099 - accuracy: 0.8988 - val_loss: 0.8009 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00670: val_loss did not improve from 0.38514\n",
      "Epoch 671/3000\n",
      "13/13 - 0s - loss: 0.2106 - accuracy: 0.9014 - val_loss: 0.8969 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00671: val_loss did not improve from 0.38514\n",
      "Epoch 672/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.9001 - val_loss: 0.9264 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00672: val_loss did not improve from 0.38514\n",
      "Epoch 673/3000\n",
      "13/13 - 0s - loss: 0.2201 - accuracy: 0.8988 - val_loss: 0.6651 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00673: val_loss did not improve from 0.38514\n",
      "Epoch 674/3000\n",
      "13/13 - 0s - loss: 0.2313 - accuracy: 0.8923 - val_loss: 0.6760 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00674: val_loss did not improve from 0.38514\n",
      "Epoch 675/3000\n",
      "13/13 - 0s - loss: 0.2384 - accuracy: 0.9014 - val_loss: 0.7073 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00675: val_loss did not improve from 0.38514\n",
      "Epoch 676/3000\n",
      "13/13 - 0s - loss: 0.2484 - accuracy: 0.8898 - val_loss: 0.8367 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00676: val_loss did not improve from 0.38514\n",
      "Epoch 677/3000\n",
      "13/13 - 0s - loss: 0.2270 - accuracy: 0.8962 - val_loss: 0.7108 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00677: val_loss did not improve from 0.38514\n",
      "Epoch 678/3000\n",
      "13/13 - 0s - loss: 0.2239 - accuracy: 0.8923 - val_loss: 0.6499 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00678: val_loss did not improve from 0.38514\n",
      "Epoch 679/3000\n",
      "13/13 - 0s - loss: 0.2103 - accuracy: 0.8988 - val_loss: 0.7346 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00679: val_loss did not improve from 0.38514\n",
      "Epoch 680/3000\n",
      "13/13 - 0s - loss: 0.2103 - accuracy: 0.8949 - val_loss: 0.7758 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00680: val_loss did not improve from 0.38514\n",
      "Epoch 681/3000\n",
      "13/13 - 0s - loss: 0.2132 - accuracy: 0.9027 - val_loss: 0.7409 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00681: val_loss did not improve from 0.38514\n",
      "Epoch 682/3000\n",
      "13/13 - 0s - loss: 0.2059 - accuracy: 0.8988 - val_loss: 0.7072 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00682: val_loss did not improve from 0.38514\n",
      "Epoch 683/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.9027 - val_loss: 0.7337 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00683: val_loss did not improve from 0.38514\n",
      "Epoch 684/3000\n",
      "13/13 - 0s - loss: 0.2034 - accuracy: 0.8975 - val_loss: 0.7578 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00684: val_loss did not improve from 0.38514\n",
      "Epoch 685/3000\n",
      "13/13 - 0s - loss: 0.2094 - accuracy: 0.9014 - val_loss: 0.7651 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00685: val_loss did not improve from 0.38514\n",
      "Epoch 686/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.8936 - val_loss: 0.7750 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00686: val_loss did not improve from 0.38514\n",
      "Epoch 687/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.8988 - val_loss: 0.7676 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00687: val_loss did not improve from 0.38514\n",
      "Epoch 688/3000\n",
      "13/13 - 0s - loss: 0.2065 - accuracy: 0.9014 - val_loss: 0.7764 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00688: val_loss did not improve from 0.38514\n",
      "Epoch 689/3000\n",
      "13/13 - 0s - loss: 0.2066 - accuracy: 0.9027 - val_loss: 0.7893 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00689: val_loss did not improve from 0.38514\n",
      "Epoch 690/3000\n",
      "13/13 - 0s - loss: 0.2061 - accuracy: 0.9014 - val_loss: 0.8145 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00690: val_loss did not improve from 0.38514\n",
      "Epoch 691/3000\n",
      "13/13 - 0s - loss: 0.2060 - accuracy: 0.8936 - val_loss: 0.8282 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00691: val_loss did not improve from 0.38514\n",
      "Epoch 692/3000\n",
      "13/13 - 0s - loss: 0.2051 - accuracy: 0.9027 - val_loss: 0.8593 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00692: val_loss did not improve from 0.38514\n",
      "Epoch 693/3000\n",
      "13/13 - 0s - loss: 0.2058 - accuracy: 0.9027 - val_loss: 0.8677 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00693: val_loss did not improve from 0.38514\n",
      "Epoch 694/3000\n",
      "13/13 - 0s - loss: 0.2056 - accuracy: 0.9027 - val_loss: 0.8392 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00694: val_loss did not improve from 0.38514\n",
      "Epoch 695/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.9014 - val_loss: 0.8402 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00695: val_loss did not improve from 0.38514\n",
      "Epoch 696/3000\n",
      "13/13 - 0s - loss: 0.2058 - accuracy: 0.9014 - val_loss: 0.8428 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00696: val_loss did not improve from 0.38514\n",
      "Epoch 697/3000\n",
      "13/13 - 0s - loss: 0.2047 - accuracy: 0.8962 - val_loss: 0.8416 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00697: val_loss did not improve from 0.38514\n",
      "Epoch 698/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.9014 - val_loss: 0.8459 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00698: val_loss did not improve from 0.38514\n",
      "Epoch 699/3000\n",
      "13/13 - 0s - loss: 0.2041 - accuracy: 0.8975 - val_loss: 0.8548 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00699: val_loss did not improve from 0.38514\n",
      "Epoch 700/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.8962 - val_loss: 0.8583 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00700: val_loss did not improve from 0.38514\n",
      "Epoch 701/3000\n",
      "13/13 - 0s - loss: 0.2043 - accuracy: 0.9027 - val_loss: 0.8504 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00701: val_loss did not improve from 0.38514\n",
      "Epoch 702/3000\n",
      "13/13 - 0s - loss: 0.2032 - accuracy: 0.9014 - val_loss: 0.8503 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00702: val_loss did not improve from 0.38514\n",
      "Epoch 703/3000\n",
      "13/13 - 0s - loss: 0.2064 - accuracy: 0.9027 - val_loss: 0.8460 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00703: val_loss did not improve from 0.38514\n",
      "Epoch 704/3000\n",
      "13/13 - 0s - loss: 0.2092 - accuracy: 0.9040 - val_loss: 0.8331 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00704: val_loss did not improve from 0.38514\n",
      "Epoch 705/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.9027 - val_loss: 0.8048 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00705: val_loss did not improve from 0.38514\n",
      "Epoch 706/3000\n",
      "13/13 - 0s - loss: 0.2066 - accuracy: 0.9001 - val_loss: 0.8095 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00706: val_loss did not improve from 0.38514\n",
      "Epoch 707/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.9014 - val_loss: 0.8360 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00707: val_loss did not improve from 0.38514\n",
      "Epoch 708/3000\n",
      "13/13 - 0s - loss: 0.2051 - accuracy: 0.9027 - val_loss: 0.8518 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00708: val_loss did not improve from 0.38514\n",
      "Epoch 709/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.9027 - val_loss: 0.8537 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00709: val_loss did not improve from 0.38514\n",
      "Epoch 710/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.9001 - val_loss: 0.8371 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00710: val_loss did not improve from 0.38514\n",
      "Epoch 711/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.9027 - val_loss: 0.8182 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00711: val_loss did not improve from 0.38514\n",
      "Epoch 712/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.8975 - val_loss: 0.8150 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00712: val_loss did not improve from 0.38514\n",
      "Epoch 713/3000\n",
      "13/13 - 0s - loss: 0.2128 - accuracy: 0.8962 - val_loss: 0.8450 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00713: val_loss did not improve from 0.38514\n",
      "Epoch 714/3000\n",
      "13/13 - 0s - loss: 0.2078 - accuracy: 0.9014 - val_loss: 0.8760 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00714: val_loss did not improve from 0.38514\n",
      "Epoch 715/3000\n",
      "13/13 - 0s - loss: 0.2225 - accuracy: 0.8898 - val_loss: 0.8601 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00715: val_loss did not improve from 0.38514\n",
      "Epoch 716/3000\n",
      "13/13 - 0s - loss: 0.2069 - accuracy: 0.9001 - val_loss: 0.8556 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00716: val_loss did not improve from 0.38514\n",
      "Epoch 717/3000\n",
      "13/13 - 0s - loss: 0.2080 - accuracy: 0.9014 - val_loss: 0.9145 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00717: val_loss did not improve from 0.38514\n",
      "Epoch 718/3000\n",
      "13/13 - 0s - loss: 0.2059 - accuracy: 0.9027 - val_loss: 0.8418 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00718: val_loss did not improve from 0.38514\n",
      "Epoch 719/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9027 - val_loss: 0.8052 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00719: val_loss did not improve from 0.38514\n",
      "Epoch 720/3000\n",
      "13/13 - 0s - loss: 0.2041 - accuracy: 0.8988 - val_loss: 0.8154 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00720: val_loss did not improve from 0.38514\n",
      "Epoch 721/3000\n",
      "13/13 - 0s - loss: 0.2031 - accuracy: 0.8988 - val_loss: 0.8103 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00721: val_loss did not improve from 0.38514\n",
      "Epoch 722/3000\n",
      "13/13 - 0s - loss: 0.2032 - accuracy: 0.9001 - val_loss: 0.8063 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00722: val_loss did not improve from 0.38514\n",
      "Epoch 723/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9014 - val_loss: 0.8200 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00723: val_loss did not improve from 0.38514\n",
      "Epoch 724/3000\n",
      "13/13 - 0s - loss: 0.2022 - accuracy: 0.9014 - val_loss: 0.8430 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00724: val_loss did not improve from 0.38514\n",
      "Epoch 725/3000\n",
      "13/13 - 0s - loss: 0.2032 - accuracy: 0.9027 - val_loss: 0.8533 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00725: val_loss did not improve from 0.38514\n",
      "Epoch 726/3000\n",
      "13/13 - 0s - loss: 0.2053 - accuracy: 0.8975 - val_loss: 0.8818 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00726: val_loss did not improve from 0.38514\n",
      "Epoch 727/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.8988 - val_loss: 0.9055 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00727: val_loss did not improve from 0.38514\n",
      "Epoch 728/3000\n",
      "13/13 - 0s - loss: 0.2048 - accuracy: 0.8975 - val_loss: 0.8936 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00728: val_loss did not improve from 0.38514\n",
      "Epoch 729/3000\n",
      "13/13 - 0s - loss: 0.2048 - accuracy: 0.8975 - val_loss: 0.9003 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00729: val_loss did not improve from 0.38514\n",
      "Epoch 730/3000\n",
      "13/13 - 0s - loss: 0.2039 - accuracy: 0.8975 - val_loss: 0.8925 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00730: val_loss did not improve from 0.38514\n",
      "Epoch 731/3000\n",
      "13/13 - 0s - loss: 0.2029 - accuracy: 0.8949 - val_loss: 0.8806 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00731: val_loss did not improve from 0.38514\n",
      "Epoch 732/3000\n",
      "13/13 - 0s - loss: 0.2045 - accuracy: 0.8962 - val_loss: 0.8840 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00732: val_loss did not improve from 0.38514\n",
      "Epoch 733/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.8923 - val_loss: 0.8927 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00733: val_loss did not improve from 0.38514\n",
      "Epoch 734/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9027 - val_loss: 0.9000 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00734: val_loss did not improve from 0.38514\n",
      "Epoch 735/3000\n",
      "13/13 - 0s - loss: 0.2183 - accuracy: 0.9014 - val_loss: 1.4763 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00735: val_loss did not improve from 0.38514\n",
      "Epoch 736/3000\n",
      "13/13 - 0s - loss: 0.2633 - accuracy: 0.8923 - val_loss: 1.3941 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00736: val_loss did not improve from 0.38514\n",
      "Epoch 737/3000\n",
      "13/13 - 0s - loss: 0.2725 - accuracy: 0.8898 - val_loss: 0.8746 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 00737: val_loss did not improve from 0.38514\n",
      "Epoch 738/3000\n",
      "13/13 - 0s - loss: 0.2559 - accuracy: 0.8911 - val_loss: 0.6639 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00738: val_loss did not improve from 0.38514\n",
      "Epoch 739/3000\n",
      "13/13 - 0s - loss: 0.2272 - accuracy: 0.8988 - val_loss: 0.7202 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00739: val_loss did not improve from 0.38514\n",
      "Epoch 740/3000\n",
      "13/13 - 0s - loss: 0.2182 - accuracy: 0.8949 - val_loss: 0.7847 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00740: val_loss did not improve from 0.38514\n",
      "Epoch 741/3000\n",
      "13/13 - 0s - loss: 0.2153 - accuracy: 0.8936 - val_loss: 0.7958 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00741: val_loss did not improve from 0.38514\n",
      "Epoch 742/3000\n",
      "13/13 - 0s - loss: 0.2089 - accuracy: 0.8936 - val_loss: 0.8011 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00742: val_loss did not improve from 0.38514\n",
      "Epoch 743/3000\n",
      "13/13 - 0s - loss: 0.2155 - accuracy: 0.8949 - val_loss: 0.8504 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00743: val_loss did not improve from 0.38514\n",
      "Epoch 744/3000\n",
      "13/13 - 0s - loss: 0.2068 - accuracy: 0.8988 - val_loss: 0.8661 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00744: val_loss did not improve from 0.38514\n",
      "Epoch 745/3000\n",
      "13/13 - 0s - loss: 0.2194 - accuracy: 0.8975 - val_loss: 0.8308 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00745: val_loss did not improve from 0.38514\n",
      "Epoch 746/3000\n",
      "13/13 - 0s - loss: 0.2096 - accuracy: 0.8962 - val_loss: 0.7990 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00746: val_loss did not improve from 0.38514\n",
      "Epoch 747/3000\n",
      "13/13 - 0s - loss: 0.2070 - accuracy: 0.8988 - val_loss: 0.8505 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00747: val_loss did not improve from 0.38514\n",
      "Epoch 748/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.8962 - val_loss: 0.8887 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00748: val_loss did not improve from 0.38514\n",
      "Epoch 749/3000\n",
      "13/13 - 0s - loss: 0.2156 - accuracy: 0.8936 - val_loss: 0.8407 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00749: val_loss did not improve from 0.38514\n",
      "Epoch 750/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.9001 - val_loss: 0.8387 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00750: val_loss did not improve from 0.38514\n",
      "Epoch 751/3000\n",
      "13/13 - 0s - loss: 0.2098 - accuracy: 0.9001 - val_loss: 0.8764 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00751: val_loss did not improve from 0.38514\n",
      "Epoch 752/3000\n",
      "13/13 - 0s - loss: 0.2067 - accuracy: 0.9027 - val_loss: 0.8927 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00752: val_loss did not improve from 0.38514\n",
      "Epoch 753/3000\n",
      "13/13 - 0s - loss: 0.2085 - accuracy: 0.9014 - val_loss: 0.9347 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00753: val_loss did not improve from 0.38514\n",
      "Epoch 754/3000\n",
      "13/13 - 0s - loss: 0.2060 - accuracy: 0.9014 - val_loss: 0.9357 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00754: val_loss did not improve from 0.38514\n",
      "Epoch 755/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9014 - val_loss: 0.9505 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00755: val_loss did not improve from 0.38514\n",
      "Epoch 756/3000\n",
      "13/13 - 0s - loss: 0.2020 - accuracy: 0.9027 - val_loss: 0.9562 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00756: val_loss did not improve from 0.38514\n",
      "Epoch 757/3000\n",
      "13/13 - 0s - loss: 0.2034 - accuracy: 0.8988 - val_loss: 0.9616 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00757: val_loss did not improve from 0.38514\n",
      "Epoch 758/3000\n",
      "13/13 - 0s - loss: 0.2025 - accuracy: 0.9014 - val_loss: 1.0067 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00758: val_loss did not improve from 0.38514\n",
      "Epoch 759/3000\n",
      "13/13 - 0s - loss: 0.2036 - accuracy: 0.8962 - val_loss: 1.0193 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00759: val_loss did not improve from 0.38514\n",
      "Epoch 760/3000\n",
      "13/13 - 0s - loss: 0.2021 - accuracy: 0.9027 - val_loss: 0.9950 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00760: val_loss did not improve from 0.38514\n",
      "Epoch 761/3000\n",
      "13/13 - 0s - loss: 0.2046 - accuracy: 0.9001 - val_loss: 1.0619 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00761: val_loss did not improve from 0.38514\n",
      "Epoch 762/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.9014 - val_loss: 1.0639 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00762: val_loss did not improve from 0.38514\n",
      "Epoch 763/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9027 - val_loss: 1.0374 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00763: val_loss did not improve from 0.38514\n",
      "Epoch 764/3000\n",
      "13/13 - 0s - loss: 0.2019 - accuracy: 0.9014 - val_loss: 1.0247 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00764: val_loss did not improve from 0.38514\n",
      "Epoch 765/3000\n",
      "13/13 - 0s - loss: 0.2031 - accuracy: 0.9027 - val_loss: 1.0143 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00765: val_loss did not improve from 0.38514\n",
      "Epoch 766/3000\n",
      "13/13 - 0s - loss: 0.2029 - accuracy: 0.9014 - val_loss: 1.0372 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00766: val_loss did not improve from 0.38514\n",
      "Epoch 767/3000\n",
      "13/13 - 0s - loss: 0.2020 - accuracy: 0.8988 - val_loss: 1.0333 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00767: val_loss did not improve from 0.38514\n",
      "Epoch 768/3000\n",
      "13/13 - 0s - loss: 0.2021 - accuracy: 0.8988 - val_loss: 1.0374 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00768: val_loss did not improve from 0.38514\n",
      "Epoch 769/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9027 - val_loss: 1.0972 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00769: val_loss did not improve from 0.38514\n",
      "Epoch 770/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.8975 - val_loss: 1.0742 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00770: val_loss did not improve from 0.38514\n",
      "Epoch 771/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.9053 - val_loss: 1.0520 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00771: val_loss did not improve from 0.38514\n",
      "Epoch 772/3000\n",
      "13/13 - 0s - loss: 0.2030 - accuracy: 0.8988 - val_loss: 1.0279 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00772: val_loss did not improve from 0.38514\n",
      "Epoch 773/3000\n",
      "13/13 - 0s - loss: 0.2026 - accuracy: 0.9027 - val_loss: 1.0187 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00773: val_loss did not improve from 0.38514\n",
      "Epoch 774/3000\n",
      "13/13 - 0s - loss: 0.2077 - accuracy: 0.9027 - val_loss: 0.9651 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00774: val_loss did not improve from 0.38514\n",
      "Epoch 775/3000\n",
      "13/13 - 0s - loss: 0.2069 - accuracy: 0.8975 - val_loss: 0.9726 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00775: val_loss did not improve from 0.38514\n",
      "Epoch 776/3000\n",
      "13/13 - 0s - loss: 0.2087 - accuracy: 0.9014 - val_loss: 1.0391 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00776: val_loss did not improve from 0.38514\n",
      "Epoch 777/3000\n",
      "13/13 - 0s - loss: 0.2169 - accuracy: 0.8962 - val_loss: 1.0679 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00777: val_loss did not improve from 0.38514\n",
      "Epoch 778/3000\n",
      "13/13 - 0s - loss: 0.2131 - accuracy: 0.8975 - val_loss: 1.0411 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00778: val_loss did not improve from 0.38514\n",
      "Epoch 779/3000\n",
      "13/13 - 0s - loss: 0.2102 - accuracy: 0.8962 - val_loss: 1.0292 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00779: val_loss did not improve from 0.38514\n",
      "Epoch 780/3000\n",
      "13/13 - 0s - loss: 0.2088 - accuracy: 0.8962 - val_loss: 1.0555 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00780: val_loss did not improve from 0.38514\n",
      "Epoch 781/3000\n",
      "13/13 - 0s - loss: 0.2182 - accuracy: 0.8962 - val_loss: 1.0177 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00781: val_loss did not improve from 0.38514\n",
      "Epoch 782/3000\n",
      "13/13 - 0s - loss: 0.2078 - accuracy: 0.8949 - val_loss: 0.8613 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00782: val_loss did not improve from 0.38514\n",
      "Epoch 783/3000\n",
      "13/13 - 0s - loss: 0.2070 - accuracy: 0.8962 - val_loss: 0.8613 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00783: val_loss did not improve from 0.38514\n",
      "Epoch 784/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9001 - val_loss: 0.8902 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00784: val_loss did not improve from 0.38514\n",
      "Epoch 785/3000\n",
      "13/13 - 0s - loss: 0.2059 - accuracy: 0.9040 - val_loss: 0.9018 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00785: val_loss did not improve from 0.38514\n",
      "Epoch 786/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.9027 - val_loss: 0.8824 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00786: val_loss did not improve from 0.38514\n",
      "Epoch 787/3000\n",
      "13/13 - 0s - loss: 0.2066 - accuracy: 0.9027 - val_loss: 0.9083 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00787: val_loss did not improve from 0.38514\n",
      "Epoch 788/3000\n",
      "13/13 - 0s - loss: 0.2080 - accuracy: 0.9014 - val_loss: 0.9717 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00788: val_loss did not improve from 0.38514\n",
      "Epoch 789/3000\n",
      "13/13 - 0s - loss: 0.2147 - accuracy: 0.8911 - val_loss: 0.8931 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00789: val_loss did not improve from 0.38514\n",
      "Epoch 790/3000\n",
      "13/13 - 0s - loss: 0.2108 - accuracy: 0.8923 - val_loss: 0.8973 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00790: val_loss did not improve from 0.38514\n",
      "Epoch 791/3000\n",
      "13/13 - 0s - loss: 0.2056 - accuracy: 0.9001 - val_loss: 0.9187 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00791: val_loss did not improve from 0.38514\n",
      "Epoch 792/3000\n",
      "13/13 - 0s - loss: 0.2060 - accuracy: 0.9027 - val_loss: 0.9286 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00792: val_loss did not improve from 0.38514\n",
      "Epoch 793/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9014 - val_loss: 0.8926 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00793: val_loss did not improve from 0.38514\n",
      "Epoch 794/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.8975 - val_loss: 0.9055 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00794: val_loss did not improve from 0.38514\n",
      "Epoch 795/3000\n",
      "13/13 - 0s - loss: 0.2040 - accuracy: 0.9040 - val_loss: 0.8842 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00795: val_loss did not improve from 0.38514\n",
      "Epoch 796/3000\n",
      "13/13 - 0s - loss: 0.2040 - accuracy: 0.9014 - val_loss: 0.8949 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00796: val_loss did not improve from 0.38514\n",
      "Epoch 797/3000\n",
      "13/13 - 0s - loss: 0.2041 - accuracy: 0.9027 - val_loss: 0.8948 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00797: val_loss did not improve from 0.38514\n",
      "Epoch 798/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.9027 - val_loss: 0.8388 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00798: val_loss did not improve from 0.38514\n",
      "Epoch 799/3000\n",
      "13/13 - 0s - loss: 0.2067 - accuracy: 0.9027 - val_loss: 0.8633 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00799: val_loss did not improve from 0.38514\n",
      "Epoch 800/3000\n",
      "13/13 - 0s - loss: 0.2040 - accuracy: 0.9027 - val_loss: 0.8820 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00800: val_loss did not improve from 0.38514\n",
      "Epoch 801/3000\n",
      "13/13 - 0s - loss: 0.2047 - accuracy: 0.9027 - val_loss: 0.8961 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00801: val_loss did not improve from 0.38514\n",
      "Epoch 802/3000\n",
      "13/13 - 0s - loss: 0.2038 - accuracy: 0.9027 - val_loss: 0.9052 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00802: val_loss did not improve from 0.38514\n",
      "Epoch 803/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9027 - val_loss: 0.9052 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00803: val_loss did not improve from 0.38514\n",
      "Epoch 804/3000\n",
      "13/13 - 0s - loss: 0.2024 - accuracy: 0.9027 - val_loss: 0.8836 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00804: val_loss did not improve from 0.38514\n",
      "Epoch 805/3000\n",
      "13/13 - 0s - loss: 0.2041 - accuracy: 0.9040 - val_loss: 0.8751 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00805: val_loss did not improve from 0.38514\n",
      "Epoch 806/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9027 - val_loss: 0.9034 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00806: val_loss did not improve from 0.38514\n",
      "Epoch 807/3000\n",
      "13/13 - 0s - loss: 0.2048 - accuracy: 0.8975 - val_loss: 0.9229 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00807: val_loss did not improve from 0.38514\n",
      "Epoch 808/3000\n",
      "13/13 - 0s - loss: 0.2046 - accuracy: 0.8988 - val_loss: 0.9012 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00808: val_loss did not improve from 0.38514\n",
      "Epoch 809/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.8988 - val_loss: 0.9061 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00809: val_loss did not improve from 0.38514\n",
      "Epoch 810/3000\n",
      "13/13 - 0s - loss: 0.2105 - accuracy: 0.8975 - val_loss: 0.9232 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00810: val_loss did not improve from 0.38514\n",
      "Epoch 811/3000\n",
      "13/13 - 0s - loss: 0.2099 - accuracy: 0.8949 - val_loss: 0.9317 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00811: val_loss did not improve from 0.38514\n",
      "Epoch 812/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.8988 - val_loss: 0.9172 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00812: val_loss did not improve from 0.38514\n",
      "Epoch 813/3000\n",
      "13/13 - 0s - loss: 0.2029 - accuracy: 0.9001 - val_loss: 0.9114 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00813: val_loss did not improve from 0.38514\n",
      "Epoch 814/3000\n",
      "13/13 - 0s - loss: 0.2025 - accuracy: 0.9027 - val_loss: 0.9186 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00814: val_loss did not improve from 0.38514\n",
      "Epoch 815/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.8975 - val_loss: 0.9306 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00815: val_loss did not improve from 0.38514\n",
      "Epoch 816/3000\n",
      "13/13 - 0s - loss: 0.2021 - accuracy: 0.9053 - val_loss: 0.9188 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00816: val_loss did not improve from 0.38514\n",
      "Epoch 817/3000\n",
      "13/13 - 0s - loss: 0.2021 - accuracy: 0.9027 - val_loss: 0.9307 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00817: val_loss did not improve from 0.38514\n",
      "Epoch 818/3000\n",
      "13/13 - 0s - loss: 0.2022 - accuracy: 0.9027 - val_loss: 0.9494 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00818: val_loss did not improve from 0.38514\n",
      "Epoch 819/3000\n",
      "13/13 - 0s - loss: 0.2023 - accuracy: 0.9027 - val_loss: 0.9673 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00819: val_loss did not improve from 0.38514\n",
      "Epoch 820/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9027 - val_loss: 0.9513 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00820: val_loss did not improve from 0.38514\n",
      "Epoch 821/3000\n",
      "13/13 - 0s - loss: 0.2022 - accuracy: 0.9027 - val_loss: 0.9385 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00821: val_loss did not improve from 0.38514\n",
      "Epoch 822/3000\n",
      "13/13 - 0s - loss: 0.2024 - accuracy: 0.9001 - val_loss: 0.9421 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00822: val_loss did not improve from 0.38514\n",
      "Epoch 823/3000\n",
      "13/13 - 0s - loss: 0.2023 - accuracy: 0.9014 - val_loss: 0.9405 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00823: val_loss did not improve from 0.38514\n",
      "Epoch 824/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.8936 - val_loss: 0.9725 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00824: val_loss did not improve from 0.38514\n",
      "Epoch 825/3000\n",
      "13/13 - 0s - loss: 0.2036 - accuracy: 0.8988 - val_loss: 0.9691 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00825: val_loss did not improve from 0.38514\n",
      "Epoch 826/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.8988 - val_loss: 0.9434 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00826: val_loss did not improve from 0.38514\n",
      "Epoch 827/3000\n",
      "13/13 - 0s - loss: 0.2091 - accuracy: 0.8988 - val_loss: 0.9609 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00827: val_loss did not improve from 0.38514\n",
      "Epoch 828/3000\n",
      "13/13 - 0s - loss: 0.2056 - accuracy: 0.9001 - val_loss: 1.0051 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00828: val_loss did not improve from 0.38514\n",
      "Epoch 829/3000\n",
      "13/13 - 0s - loss: 0.2052 - accuracy: 0.9014 - val_loss: 1.0182 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00829: val_loss did not improve from 0.38514\n",
      "Epoch 830/3000\n",
      "13/13 - 0s - loss: 0.2027 - accuracy: 0.8988 - val_loss: 1.0183 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00830: val_loss did not improve from 0.38514\n",
      "Epoch 831/3000\n",
      "13/13 - 0s - loss: 0.2034 - accuracy: 0.9001 - val_loss: 1.0066 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00831: val_loss did not improve from 0.38514\n",
      "Epoch 832/3000\n",
      "13/13 - 0s - loss: 0.2031 - accuracy: 0.8988 - val_loss: 0.9998 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00832: val_loss did not improve from 0.38514\n",
      "Epoch 833/3000\n",
      "13/13 - 0s - loss: 0.2016 - accuracy: 0.8988 - val_loss: 1.0150 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00833: val_loss did not improve from 0.38514\n",
      "Epoch 834/3000\n",
      "13/13 - 0s - loss: 0.2030 - accuracy: 0.9014 - val_loss: 1.0284 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00834: val_loss did not improve from 0.38514\n",
      "Epoch 835/3000\n",
      "13/13 - 0s - loss: 0.2024 - accuracy: 0.9027 - val_loss: 1.0226 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00835: val_loss did not improve from 0.38514\n",
      "Epoch 836/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.9027 - val_loss: 1.0000 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00836: val_loss did not improve from 0.38514\n",
      "Epoch 837/3000\n",
      "13/13 - 0s - loss: 0.2031 - accuracy: 0.9014 - val_loss: 1.0255 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00837: val_loss did not improve from 0.38514\n",
      "Epoch 838/3000\n",
      "13/13 - 0s - loss: 0.2048 - accuracy: 0.9040 - val_loss: 1.0994 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00838: val_loss did not improve from 0.38514\n",
      "Epoch 839/3000\n",
      "13/13 - 0s - loss: 0.2011 - accuracy: 0.9040 - val_loss: 1.0554 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00839: val_loss did not improve from 0.38514\n",
      "Epoch 840/3000\n",
      "13/13 - 0s - loss: 0.2026 - accuracy: 0.9027 - val_loss: 1.0536 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00840: val_loss did not improve from 0.38514\n",
      "Epoch 841/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9014 - val_loss: 1.0481 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00841: val_loss did not improve from 0.38514\n",
      "Epoch 842/3000\n",
      "13/13 - 0s - loss: 0.2027 - accuracy: 0.9027 - val_loss: 1.0686 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00842: val_loss did not improve from 0.38514\n",
      "Epoch 843/3000\n",
      "13/13 - 0s - loss: 0.2031 - accuracy: 0.9027 - val_loss: 1.0693 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00843: val_loss did not improve from 0.38514\n",
      "Epoch 844/3000\n",
      "13/13 - 0s - loss: 0.2031 - accuracy: 0.9027 - val_loss: 1.0629 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00844: val_loss did not improve from 0.38514\n",
      "Epoch 845/3000\n",
      "13/13 - 0s - loss: 0.2036 - accuracy: 0.9027 - val_loss: 1.0694 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00845: val_loss did not improve from 0.38514\n",
      "Epoch 846/3000\n",
      "13/13 - 0s - loss: 0.2032 - accuracy: 0.9014 - val_loss: 1.0858 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00846: val_loss did not improve from 0.38514\n",
      "Epoch 847/3000\n",
      "13/13 - 0s - loss: 0.2024 - accuracy: 0.9001 - val_loss: 1.0860 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00847: val_loss did not improve from 0.38514\n",
      "Epoch 848/3000\n",
      "13/13 - 0s - loss: 0.2017 - accuracy: 0.9014 - val_loss: 1.1004 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00848: val_loss did not improve from 0.38514\n",
      "Epoch 849/3000\n",
      "13/13 - 0s - loss: 0.2022 - accuracy: 0.9014 - val_loss: 1.0758 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00849: val_loss did not improve from 0.38514\n",
      "Epoch 850/3000\n",
      "13/13 - 0s - loss: 0.2018 - accuracy: 0.9027 - val_loss: 1.0991 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00850: val_loss did not improve from 0.38514\n",
      "Epoch 851/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.9001 - val_loss: 1.0983 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00851: val_loss did not improve from 0.38514\n",
      "Epoch 852/3000\n",
      "13/13 - 0s - loss: 0.2043 - accuracy: 0.9014 - val_loss: 1.1087 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00852: val_loss did not improve from 0.38514\n",
      "Epoch 853/3000\n",
      "13/13 - 0s - loss: 0.2026 - accuracy: 0.9027 - val_loss: 1.0849 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00853: val_loss did not improve from 0.38514\n",
      "Epoch 854/3000\n",
      "13/13 - 0s - loss: 0.2019 - accuracy: 0.9014 - val_loss: 1.0858 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00854: val_loss did not improve from 0.38514\n",
      "Epoch 855/3000\n",
      "13/13 - 0s - loss: 0.2027 - accuracy: 0.9027 - val_loss: 1.0777 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00855: val_loss did not improve from 0.38514\n",
      "Epoch 856/3000\n",
      "13/13 - 0s - loss: 0.2027 - accuracy: 0.9027 - val_loss: 1.0789 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00856: val_loss did not improve from 0.38514\n",
      "Epoch 857/3000\n",
      "13/13 - 0s - loss: 0.2020 - accuracy: 0.9001 - val_loss: 1.0796 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00857: val_loss did not improve from 0.38514\n",
      "Epoch 858/3000\n",
      "13/13 - 0s - loss: 0.2015 - accuracy: 0.8988 - val_loss: 1.0675 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00858: val_loss did not improve from 0.38514\n",
      "Epoch 859/3000\n",
      "13/13 - 0s - loss: 0.2030 - accuracy: 0.9014 - val_loss: 1.0400 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00859: val_loss did not improve from 0.38514\n",
      "Epoch 860/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9027 - val_loss: 1.0217 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00860: val_loss did not improve from 0.38514\n",
      "Epoch 861/3000\n",
      "13/13 - 0s - loss: 0.2030 - accuracy: 0.9040 - val_loss: 1.0238 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00861: val_loss did not improve from 0.38514\n",
      "Epoch 862/3000\n",
      "13/13 - 0s - loss: 0.2015 - accuracy: 0.9040 - val_loss: 1.0292 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00862: val_loss did not improve from 0.38514\n",
      "Epoch 863/3000\n",
      "13/13 - 0s - loss: 0.2023 - accuracy: 0.9027 - val_loss: 1.0395 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00863: val_loss did not improve from 0.38514\n",
      "Epoch 864/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9040 - val_loss: 1.0940 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00864: val_loss did not improve from 0.38514\n",
      "Epoch 865/3000\n",
      "13/13 - 0s - loss: 0.2046 - accuracy: 0.8988 - val_loss: 1.0757 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00865: val_loss did not improve from 0.38514\n",
      "Epoch 866/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.9014 - val_loss: 1.0819 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00866: val_loss did not improve from 0.38514\n",
      "Epoch 867/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.9001 - val_loss: 1.0688 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00867: val_loss did not improve from 0.38514\n",
      "Epoch 868/3000\n",
      "13/13 - 0s - loss: 0.2051 - accuracy: 0.9027 - val_loss: 1.1280 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00868: val_loss did not improve from 0.38514\n",
      "Epoch 869/3000\n",
      "13/13 - 0s - loss: 0.2076 - accuracy: 0.9014 - val_loss: 1.1731 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00869: val_loss did not improve from 0.38514\n",
      "Epoch 870/3000\n",
      "13/13 - 0s - loss: 0.2066 - accuracy: 0.9014 - val_loss: 1.2294 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00870: val_loss did not improve from 0.38514\n",
      "Epoch 871/3000\n",
      "13/13 - 0s - loss: 0.2045 - accuracy: 0.9027 - val_loss: 1.2151 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00871: val_loss did not improve from 0.38514\n",
      "Epoch 872/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9027 - val_loss: 1.2386 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00872: val_loss did not improve from 0.38514\n",
      "Epoch 873/3000\n",
      "13/13 - 0s - loss: 0.2033 - accuracy: 0.9001 - val_loss: 1.2220 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00873: val_loss did not improve from 0.38514\n",
      "Epoch 874/3000\n",
      "13/13 - 0s - loss: 0.2031 - accuracy: 0.9014 - val_loss: 1.2169 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00874: val_loss did not improve from 0.38514\n",
      "Epoch 875/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9027 - val_loss: 1.2199 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00875: val_loss did not improve from 0.38514\n",
      "Epoch 876/3000\n",
      "13/13 - 0s - loss: 0.2032 - accuracy: 0.9027 - val_loss: 1.1895 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00876: val_loss did not improve from 0.38514\n",
      "Epoch 877/3000\n",
      "13/13 - 0s - loss: 0.2020 - accuracy: 0.8988 - val_loss: 1.1903 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00877: val_loss did not improve from 0.38514\n",
      "Epoch 878/3000\n",
      "13/13 - 0s - loss: 0.2045 - accuracy: 0.9014 - val_loss: 1.2217 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00878: val_loss did not improve from 0.38514\n",
      "Epoch 879/3000\n",
      "13/13 - 0s - loss: 0.2045 - accuracy: 0.9027 - val_loss: 1.2106 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00879: val_loss did not improve from 0.38514\n",
      "Epoch 880/3000\n",
      "13/13 - 0s - loss: 0.2028 - accuracy: 0.9001 - val_loss: 1.2246 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00880: val_loss did not improve from 0.38514\n",
      "Epoch 881/3000\n",
      "13/13 - 0s - loss: 0.2034 - accuracy: 0.9027 - val_loss: 1.2150 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00881: val_loss did not improve from 0.38514\n",
      "Epoch 882/3000\n",
      "13/13 - 0s - loss: 0.2026 - accuracy: 0.9027 - val_loss: 1.2161 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00882: val_loss did not improve from 0.38514\n",
      "Epoch 883/3000\n",
      "13/13 - 0s - loss: 0.2023 - accuracy: 0.9027 - val_loss: 1.2196 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00883: val_loss did not improve from 0.38514\n",
      "Epoch 884/3000\n",
      "13/13 - 0s - loss: 0.2023 - accuracy: 0.9014 - val_loss: 1.2077 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00884: val_loss did not improve from 0.38514\n",
      "Epoch 885/3000\n",
      "13/13 - 0s - loss: 0.2026 - accuracy: 0.9027 - val_loss: 1.1972 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00885: val_loss did not improve from 0.38514\n",
      "Epoch 886/3000\n",
      "13/13 - 0s - loss: 0.2025 - accuracy: 0.9027 - val_loss: 1.1918 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00886: val_loss did not improve from 0.38514\n",
      "Epoch 887/3000\n",
      "13/13 - 0s - loss: 0.2038 - accuracy: 0.9014 - val_loss: 1.2078 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00887: val_loss did not improve from 0.38514\n",
      "Epoch 888/3000\n",
      "13/13 - 0s - loss: 0.2023 - accuracy: 0.9027 - val_loss: 1.1954 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00888: val_loss did not improve from 0.38514\n",
      "Epoch 889/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.9027 - val_loss: 1.2124 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00889: val_loss did not improve from 0.38514\n",
      "Epoch 890/3000\n",
      "13/13 - 0s - loss: 0.2023 - accuracy: 0.9027 - val_loss: 1.1921 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00890: val_loss did not improve from 0.38514\n",
      "Epoch 891/3000\n",
      "13/13 - 0s - loss: 0.2024 - accuracy: 0.9027 - val_loss: 1.1780 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00891: val_loss did not improve from 0.38514\n",
      "Epoch 892/3000\n",
      "13/13 - 0s - loss: 0.2014 - accuracy: 0.9027 - val_loss: 1.1724 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00892: val_loss did not improve from 0.38514\n",
      "Epoch 893/3000\n",
      "13/13 - 0s - loss: 0.2040 - accuracy: 0.9040 - val_loss: 1.1321 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00893: val_loss did not improve from 0.38514\n",
      "Epoch 894/3000\n",
      "13/13 - 0s - loss: 0.2029 - accuracy: 0.9040 - val_loss: 1.1442 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00894: val_loss did not improve from 0.38514\n",
      "Epoch 895/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.9014 - val_loss: 1.1395 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00895: val_loss did not improve from 0.38514\n",
      "Epoch 896/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.8988 - val_loss: 1.1385 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00896: val_loss did not improve from 0.38514\n",
      "Epoch 897/3000\n",
      "13/13 - 0s - loss: 0.2276 - accuracy: 0.8936 - val_loss: 1.0036 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00897: val_loss did not improve from 0.38514\n",
      "Epoch 898/3000\n",
      "13/13 - 0s - loss: 0.2384 - accuracy: 0.8898 - val_loss: 1.1200 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00898: val_loss did not improve from 0.38514\n",
      "Epoch 899/3000\n",
      "13/13 - 0s - loss: 0.2279 - accuracy: 0.8962 - val_loss: 1.1400 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00899: val_loss did not improve from 0.38514\n",
      "Epoch 900/3000\n",
      "13/13 - 0s - loss: 0.2177 - accuracy: 0.8923 - val_loss: 1.1142 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00900: val_loss did not improve from 0.38514\n",
      "Epoch 901/3000\n",
      "13/13 - 0s - loss: 0.2151 - accuracy: 0.8962 - val_loss: 1.0415 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00901: val_loss did not improve from 0.38514\n",
      "Epoch 902/3000\n",
      "13/13 - 0s - loss: 0.2452 - accuracy: 0.8975 - val_loss: 0.8624 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00902: val_loss did not improve from 0.38514\n",
      "Epoch 903/3000\n",
      "13/13 - 0s - loss: 0.2314 - accuracy: 0.8833 - val_loss: 0.7802 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00903: val_loss did not improve from 0.38514\n",
      "Epoch 904/3000\n",
      "13/13 - 0s - loss: 0.2192 - accuracy: 0.8885 - val_loss: 0.8478 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00904: val_loss did not improve from 0.38514\n",
      "Epoch 905/3000\n",
      "13/13 - 0s - loss: 0.2146 - accuracy: 0.8936 - val_loss: 0.8988 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00905: val_loss did not improve from 0.38514\n",
      "Epoch 906/3000\n",
      "13/13 - 0s - loss: 0.2131 - accuracy: 0.8975 - val_loss: 0.9271 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00906: val_loss did not improve from 0.38514\n",
      "Epoch 907/3000\n",
      "13/13 - 0s - loss: 0.2269 - accuracy: 0.8975 - val_loss: 0.8350 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00907: val_loss did not improve from 0.38514\n",
      "Epoch 908/3000\n",
      "13/13 - 0s - loss: 0.2652 - accuracy: 0.8911 - val_loss: 0.7360 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00908: val_loss did not improve from 0.38514\n",
      "Epoch 909/3000\n",
      "13/13 - 0s - loss: 0.2439 - accuracy: 0.8872 - val_loss: 0.8030 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00909: val_loss did not improve from 0.38514\n",
      "Epoch 910/3000\n",
      "13/13 - 0s - loss: 0.2328 - accuracy: 0.8872 - val_loss: 0.9259 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00910: val_loss did not improve from 0.38514\n",
      "Epoch 911/3000\n",
      "13/13 - 0s - loss: 0.2729 - accuracy: 0.8872 - val_loss: 0.6456 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00911: val_loss did not improve from 0.38514\n",
      "Epoch 912/3000\n",
      "13/13 - 0s - loss: 0.2613 - accuracy: 0.8768 - val_loss: 0.7043 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00912: val_loss did not improve from 0.38514\n",
      "Epoch 913/3000\n",
      "13/13 - 0s - loss: 0.2214 - accuracy: 0.8962 - val_loss: 0.8132 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00913: val_loss did not improve from 0.38514\n",
      "Epoch 914/3000\n",
      "13/13 - 0s - loss: 0.2125 - accuracy: 0.8975 - val_loss: 0.8893 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00914: val_loss did not improve from 0.38514\n",
      "Epoch 915/3000\n",
      "13/13 - 0s - loss: 0.2139 - accuracy: 0.9001 - val_loss: 0.9297 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00915: val_loss did not improve from 0.38514\n",
      "Epoch 916/3000\n",
      "13/13 - 0s - loss: 0.2191 - accuracy: 0.9001 - val_loss: 0.9247 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00916: val_loss did not improve from 0.38514\n",
      "Epoch 917/3000\n",
      "13/13 - 0s - loss: 0.2086 - accuracy: 0.8949 - val_loss: 0.9482 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00917: val_loss did not improve from 0.38514\n",
      "Epoch 918/3000\n",
      "13/13 - 0s - loss: 0.2080 - accuracy: 0.8975 - val_loss: 0.9674 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00918: val_loss did not improve from 0.38514\n",
      "Epoch 919/3000\n",
      "13/13 - 0s - loss: 0.2086 - accuracy: 0.9014 - val_loss: 1.0035 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00919: val_loss did not improve from 0.38514\n",
      "Epoch 920/3000\n",
      "13/13 - 0s - loss: 0.2077 - accuracy: 0.9014 - val_loss: 0.9715 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00920: val_loss did not improve from 0.38514\n",
      "Epoch 921/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.8975 - val_loss: 0.9958 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00921: val_loss did not improve from 0.38514\n",
      "Epoch 922/3000\n",
      "13/13 - 0s - loss: 0.2086 - accuracy: 0.8949 - val_loss: 1.0282 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00922: val_loss did not improve from 0.38514\n",
      "Epoch 923/3000\n",
      "13/13 - 0s - loss: 0.2064 - accuracy: 0.9014 - val_loss: 1.0129 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00923: val_loss did not improve from 0.38514\n",
      "Epoch 924/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.9014 - val_loss: 0.9484 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00924: val_loss did not improve from 0.38514\n",
      "Epoch 925/3000\n",
      "13/13 - 0s - loss: 0.2038 - accuracy: 0.9014 - val_loss: 0.9644 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00925: val_loss did not improve from 0.38514\n",
      "Epoch 926/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.8975 - val_loss: 0.9589 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00926: val_loss did not improve from 0.38514\n",
      "Epoch 927/3000\n",
      "13/13 - 0s - loss: 0.2077 - accuracy: 0.8975 - val_loss: 0.9165 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00927: val_loss did not improve from 0.38514\n",
      "Epoch 928/3000\n",
      "13/13 - 0s - loss: 0.2068 - accuracy: 0.9001 - val_loss: 0.9261 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00928: val_loss did not improve from 0.38514\n",
      "Epoch 929/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.8988 - val_loss: 0.9224 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00929: val_loss did not improve from 0.38514\n",
      "Epoch 930/3000\n",
      "13/13 - 0s - loss: 0.2034 - accuracy: 0.9014 - val_loss: 0.9546 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00930: val_loss did not improve from 0.38514\n",
      "Epoch 931/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.9001 - val_loss: 0.9946 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00931: val_loss did not improve from 0.38514\n",
      "Epoch 932/3000\n",
      "13/13 - 0s - loss: 0.2102 - accuracy: 0.8949 - val_loss: 0.9317 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00932: val_loss did not improve from 0.38514\n",
      "Epoch 933/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.9001 - val_loss: 0.9377 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00933: val_loss did not improve from 0.38514\n",
      "Epoch 934/3000\n",
      "13/13 - 0s - loss: 0.2110 - accuracy: 0.8988 - val_loss: 0.9720 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00934: val_loss did not improve from 0.38514\n",
      "Epoch 935/3000\n",
      "13/13 - 0s - loss: 0.2070 - accuracy: 0.9014 - val_loss: 1.0242 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00935: val_loss did not improve from 0.38514\n",
      "Epoch 936/3000\n",
      "13/13 - 0s - loss: 0.2066 - accuracy: 0.8975 - val_loss: 1.0532 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00936: val_loss did not improve from 0.38514\n",
      "Epoch 937/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.9014 - val_loss: 1.0714 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00937: val_loss did not improve from 0.38514\n",
      "Epoch 938/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.8949 - val_loss: 1.0624 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00938: val_loss did not improve from 0.38514\n",
      "Epoch 939/3000\n",
      "13/13 - 0s - loss: 0.2043 - accuracy: 0.8988 - val_loss: 1.0903 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00939: val_loss did not improve from 0.38514\n",
      "Epoch 940/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.9001 - val_loss: 1.0989 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00940: val_loss did not improve from 0.38514\n",
      "Epoch 941/3000\n",
      "13/13 - 0s - loss: 0.2105 - accuracy: 0.8975 - val_loss: 1.0900 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00941: val_loss did not improve from 0.38514\n",
      "Epoch 942/3000\n",
      "13/13 - 0s - loss: 0.2092 - accuracy: 0.8911 - val_loss: 1.1044 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00942: val_loss did not improve from 0.38514\n",
      "Epoch 943/3000\n",
      "13/13 - 0s - loss: 0.2102 - accuracy: 0.8975 - val_loss: 1.0890 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00943: val_loss did not improve from 0.38514\n",
      "Epoch 944/3000\n",
      "13/13 - 0s - loss: 0.2068 - accuracy: 0.9014 - val_loss: 1.1089 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00944: val_loss did not improve from 0.38514\n",
      "Epoch 945/3000\n",
      "13/13 - 0s - loss: 0.2069 - accuracy: 0.9027 - val_loss: 1.0876 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00945: val_loss did not improve from 0.38514\n",
      "Epoch 946/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.9027 - val_loss: 1.0997 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00946: val_loss did not improve from 0.38514\n",
      "Epoch 947/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.8988 - val_loss: 1.1061 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00947: val_loss did not improve from 0.38514\n",
      "Epoch 948/3000\n",
      "13/13 - 0s - loss: 0.2066 - accuracy: 0.8988 - val_loss: 1.0697 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00948: val_loss did not improve from 0.38514\n",
      "Epoch 949/3000\n",
      "13/13 - 0s - loss: 0.2034 - accuracy: 0.9014 - val_loss: 1.0518 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00949: val_loss did not improve from 0.38514\n",
      "Epoch 950/3000\n",
      "13/13 - 0s - loss: 0.2041 - accuracy: 0.9001 - val_loss: 1.0758 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00950: val_loss did not improve from 0.38514\n",
      "Epoch 951/3000\n",
      "13/13 - 0s - loss: 0.2038 - accuracy: 0.9014 - val_loss: 1.0796 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00951: val_loss did not improve from 0.38514\n",
      "Epoch 952/3000\n",
      "13/13 - 0s - loss: 0.2034 - accuracy: 0.9027 - val_loss: 1.0916 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00952: val_loss did not improve from 0.38514\n",
      "Epoch 953/3000\n",
      "13/13 - 0s - loss: 0.2056 - accuracy: 0.9014 - val_loss: 1.1106 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00953: val_loss did not improve from 0.38514\n",
      "Epoch 954/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.9001 - val_loss: 1.1546 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00954: val_loss did not improve from 0.38514\n",
      "Epoch 955/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.9027 - val_loss: 1.1345 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00955: val_loss did not improve from 0.38514\n",
      "Epoch 956/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.9014 - val_loss: 1.1595 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00956: val_loss did not improve from 0.38514\n",
      "Epoch 957/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.9027 - val_loss: 1.1281 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00957: val_loss did not improve from 0.38514\n",
      "Epoch 958/3000\n",
      "13/13 - 0s - loss: 0.2065 - accuracy: 0.8988 - val_loss: 1.1092 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00958: val_loss did not improve from 0.38514\n",
      "Epoch 959/3000\n",
      "13/13 - 0s - loss: 0.2034 - accuracy: 0.9027 - val_loss: 1.1370 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00959: val_loss did not improve from 0.38514\n",
      "Epoch 960/3000\n",
      "13/13 - 0s - loss: 0.2030 - accuracy: 0.8988 - val_loss: 1.1167 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00960: val_loss did not improve from 0.38514\n",
      "Epoch 961/3000\n",
      "13/13 - 0s - loss: 0.2020 - accuracy: 0.9027 - val_loss: 1.0446 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00961: val_loss did not improve from 0.38514\n",
      "Epoch 962/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.8988 - val_loss: 1.0058 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00962: val_loss did not improve from 0.38514\n",
      "Epoch 963/3000\n",
      "13/13 - 0s - loss: 0.2096 - accuracy: 0.8988 - val_loss: 0.9796 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00963: val_loss did not improve from 0.38514\n",
      "Epoch 964/3000\n",
      "13/13 - 0s - loss: 0.2097 - accuracy: 0.9014 - val_loss: 0.9918 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00964: val_loss did not improve from 0.38514\n",
      "Epoch 965/3000\n",
      "13/13 - 0s - loss: 0.2135 - accuracy: 0.9014 - val_loss: 0.8767 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00965: val_loss did not improve from 0.38514\n",
      "Epoch 966/3000\n",
      "13/13 - 0s - loss: 0.2073 - accuracy: 0.9001 - val_loss: 0.8820 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00966: val_loss did not improve from 0.38514\n",
      "Epoch 967/3000\n",
      "13/13 - 0s - loss: 0.2082 - accuracy: 0.8975 - val_loss: 0.9180 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00967: val_loss did not improve from 0.38514\n",
      "Epoch 968/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.9014 - val_loss: 0.9581 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00968: val_loss did not improve from 0.38514\n",
      "Epoch 969/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.8975 - val_loss: 0.9719 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00969: val_loss did not improve from 0.38514\n",
      "Epoch 970/3000\n",
      "13/13 - 0s - loss: 0.2067 - accuracy: 0.9040 - val_loss: 0.9469 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00970: val_loss did not improve from 0.38514\n",
      "Epoch 971/3000\n",
      "13/13 - 0s - loss: 0.2108 - accuracy: 0.8975 - val_loss: 0.9397 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00971: val_loss did not improve from 0.38514\n",
      "Epoch 972/3000\n",
      "13/13 - 0s - loss: 0.2052 - accuracy: 0.9001 - val_loss: 0.9243 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00972: val_loss did not improve from 0.38514\n",
      "Epoch 973/3000\n",
      "13/13 - 0s - loss: 0.2165 - accuracy: 0.9014 - val_loss: 0.9835 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00973: val_loss did not improve from 0.38514\n",
      "Epoch 974/3000\n",
      "13/13 - 0s - loss: 0.2426 - accuracy: 0.8872 - val_loss: 0.8414 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00974: val_loss did not improve from 0.38514\n",
      "Epoch 975/3000\n",
      "13/13 - 0s - loss: 0.2269 - accuracy: 0.9014 - val_loss: 0.8694 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00975: val_loss did not improve from 0.38514\n",
      "Epoch 976/3000\n",
      "13/13 - 0s - loss: 0.2374 - accuracy: 0.8859 - val_loss: 0.6081 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00976: val_loss did not improve from 0.38514\n",
      "Epoch 977/3000\n",
      "13/13 - 0s - loss: 0.2288 - accuracy: 0.8988 - val_loss: 0.7378 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00977: val_loss did not improve from 0.38514\n",
      "Epoch 978/3000\n",
      "13/13 - 0s - loss: 0.2109 - accuracy: 0.8949 - val_loss: 0.7844 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00978: val_loss did not improve from 0.38514\n",
      "Epoch 979/3000\n",
      "13/13 - 0s - loss: 0.2098 - accuracy: 0.9001 - val_loss: 0.8457 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00979: val_loss did not improve from 0.38514\n",
      "Epoch 980/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.9001 - val_loss: 0.9248 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00980: val_loss did not improve from 0.38514\n",
      "Epoch 981/3000\n",
      "13/13 - 0s - loss: 0.2058 - accuracy: 0.9027 - val_loss: 0.9363 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00981: val_loss did not improve from 0.38514\n",
      "Epoch 982/3000\n",
      "13/13 - 0s - loss: 0.2052 - accuracy: 0.9001 - val_loss: 0.9031 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00982: val_loss did not improve from 0.38514\n",
      "Epoch 983/3000\n",
      "13/13 - 0s - loss: 0.2051 - accuracy: 0.8988 - val_loss: 0.9005 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00983: val_loss did not improve from 0.38514\n",
      "Epoch 984/3000\n",
      "13/13 - 0s - loss: 0.2083 - accuracy: 0.9014 - val_loss: 0.8939 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00984: val_loss did not improve from 0.38514\n",
      "Epoch 985/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.8975 - val_loss: 0.8842 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00985: val_loss did not improve from 0.38514\n",
      "Epoch 986/3000\n",
      "13/13 - 0s - loss: 0.2045 - accuracy: 0.9014 - val_loss: 0.8714 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00986: val_loss did not improve from 0.38514\n",
      "Epoch 987/3000\n",
      "13/13 - 0s - loss: 0.2058 - accuracy: 0.9027 - val_loss: 0.8680 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00987: val_loss did not improve from 0.38514\n",
      "Epoch 988/3000\n",
      "13/13 - 0s - loss: 0.2066 - accuracy: 0.9001 - val_loss: 0.8915 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00988: val_loss did not improve from 0.38514\n",
      "Epoch 989/3000\n",
      "13/13 - 0s - loss: 0.2058 - accuracy: 0.8988 - val_loss: 0.9183 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00989: val_loss did not improve from 0.38514\n",
      "Epoch 990/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.8962 - val_loss: 0.9328 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00990: val_loss did not improve from 0.38514\n",
      "Epoch 991/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.9053 - val_loss: 0.8688 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00991: val_loss did not improve from 0.38514\n",
      "Epoch 992/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.9014 - val_loss: 0.8634 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00992: val_loss did not improve from 0.38514\n",
      "Epoch 993/3000\n",
      "13/13 - 0s - loss: 0.2066 - accuracy: 0.8975 - val_loss: 0.9187 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00993: val_loss did not improve from 0.38514\n",
      "Epoch 994/3000\n",
      "13/13 - 0s - loss: 0.2036 - accuracy: 0.9014 - val_loss: 1.0600 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00994: val_loss did not improve from 0.38514\n",
      "Epoch 995/3000\n",
      "13/13 - 0s - loss: 0.2141 - accuracy: 0.9001 - val_loss: 0.8811 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00995: val_loss did not improve from 0.38514\n",
      "Epoch 996/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.9027 - val_loss: 0.9484 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00996: val_loss did not improve from 0.38514\n",
      "Epoch 997/3000\n",
      "13/13 - 0s - loss: 0.2124 - accuracy: 0.9027 - val_loss: 0.9344 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00997: val_loss did not improve from 0.38514\n",
      "Epoch 998/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.9027 - val_loss: 0.9100 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00998: val_loss did not improve from 0.38514\n",
      "Epoch 999/3000\n",
      "13/13 - 0s - loss: 0.2109 - accuracy: 0.9027 - val_loss: 0.9438 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00999: val_loss did not improve from 0.38514\n",
      "Epoch 1000/3000\n",
      "13/13 - 0s - loss: 0.2098 - accuracy: 0.9027 - val_loss: 0.9383 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01000: val_loss did not improve from 0.38514\n",
      "Epoch 1001/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.9027 - val_loss: 0.9330 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01001: val_loss did not improve from 0.38514\n",
      "Epoch 1002/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.9001 - val_loss: 0.9880 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01002: val_loss did not improve from 0.38514\n",
      "Epoch 1003/3000\n",
      "13/13 - 0s - loss: 0.2052 - accuracy: 0.9014 - val_loss: 0.9499 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01003: val_loss did not improve from 0.38514\n",
      "Epoch 1004/3000\n",
      "13/13 - 0s - loss: 0.2026 - accuracy: 0.9014 - val_loss: 0.9602 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01004: val_loss did not improve from 0.38514\n",
      "Epoch 1005/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.9001 - val_loss: 0.9721 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01005: val_loss did not improve from 0.38514\n",
      "Epoch 1006/3000\n",
      "13/13 - 0s - loss: 0.2041 - accuracy: 0.8975 - val_loss: 0.9596 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01006: val_loss did not improve from 0.38514\n",
      "Epoch 1007/3000\n",
      "13/13 - 0s - loss: 0.2030 - accuracy: 0.9027 - val_loss: 0.9575 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01007: val_loss did not improve from 0.38514\n",
      "Epoch 1008/3000\n",
      "13/13 - 0s - loss: 0.2041 - accuracy: 0.8988 - val_loss: 0.9744 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01008: val_loss did not improve from 0.38514\n",
      "Epoch 1009/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.9027 - val_loss: 0.9740 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01009: val_loss did not improve from 0.38514\n",
      "Epoch 1010/3000\n",
      "13/13 - 0s - loss: 0.2031 - accuracy: 0.9027 - val_loss: 0.9793 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01010: val_loss did not improve from 0.38514\n",
      "Epoch 1011/3000\n",
      "13/13 - 0s - loss: 0.2026 - accuracy: 0.9027 - val_loss: 0.9871 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01011: val_loss did not improve from 0.38514\n",
      "Epoch 1012/3000\n",
      "13/13 - 0s - loss: 0.2023 - accuracy: 0.9027 - val_loss: 1.0187 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01012: val_loss did not improve from 0.38514\n",
      "Epoch 1013/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.9001 - val_loss: 1.0360 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01013: val_loss did not improve from 0.38514\n",
      "Epoch 1014/3000\n",
      "13/13 - 0s - loss: 0.2049 - accuracy: 0.9001 - val_loss: 1.0506 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01014: val_loss did not improve from 0.38514\n",
      "Epoch 1015/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.8975 - val_loss: 1.0151 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01015: val_loss did not improve from 0.38514\n",
      "Epoch 1016/3000\n",
      "13/13 - 0s - loss: 0.2093 - accuracy: 0.9014 - val_loss: 0.9583 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01016: val_loss did not improve from 0.38514\n",
      "Epoch 1017/3000\n",
      "13/13 - 0s - loss: 0.2064 - accuracy: 0.8962 - val_loss: 0.8994 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01017: val_loss did not improve from 0.38514\n",
      "Epoch 1018/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.8975 - val_loss: 0.8930 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01018: val_loss did not improve from 0.38514\n",
      "Epoch 1019/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.8975 - val_loss: 0.9376 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01019: val_loss did not improve from 0.38514\n",
      "Epoch 1020/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.8962 - val_loss: 0.9704 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01020: val_loss did not improve from 0.38514\n",
      "Epoch 1021/3000\n",
      "13/13 - 0s - loss: 0.2102 - accuracy: 0.8923 - val_loss: 0.9602 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01021: val_loss did not improve from 0.38514\n",
      "Epoch 1022/3000\n",
      "13/13 - 0s - loss: 0.2085 - accuracy: 0.8936 - val_loss: 0.9517 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01022: val_loss did not improve from 0.38514\n",
      "Epoch 1023/3000\n",
      "13/13 - 0s - loss: 0.2049 - accuracy: 0.9001 - val_loss: 0.9565 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01023: val_loss did not improve from 0.38514\n",
      "Epoch 1024/3000\n",
      "13/13 - 0s - loss: 0.2036 - accuracy: 0.9014 - val_loss: 0.9737 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01024: val_loss did not improve from 0.38514\n",
      "Epoch 1025/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9027 - val_loss: 0.9699 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01025: val_loss did not improve from 0.38514\n",
      "Epoch 1026/3000\n",
      "13/13 - 0s - loss: 0.2126 - accuracy: 0.8988 - val_loss: 0.9656 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01026: val_loss did not improve from 0.38514\n",
      "Epoch 1027/3000\n",
      "13/13 - 0s - loss: 0.2126 - accuracy: 0.9040 - val_loss: 0.8334 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01027: val_loss did not improve from 0.38514\n",
      "Epoch 1028/3000\n",
      "13/13 - 0s - loss: 0.2065 - accuracy: 0.9001 - val_loss: 0.8134 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01028: val_loss did not improve from 0.38514\n",
      "Epoch 1029/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.9040 - val_loss: 0.8810 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01029: val_loss did not improve from 0.38514\n",
      "Epoch 1030/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.9014 - val_loss: 0.9164 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01030: val_loss did not improve from 0.38514\n",
      "Epoch 1031/3000\n",
      "13/13 - 0s - loss: 0.2039 - accuracy: 0.9014 - val_loss: 0.9119 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01031: val_loss did not improve from 0.38514\n",
      "Epoch 1032/3000\n",
      "13/13 - 0s - loss: 0.2070 - accuracy: 0.9001 - val_loss: 0.9200 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01032: val_loss did not improve from 0.38514\n",
      "Epoch 1033/3000\n",
      "13/13 - 0s - loss: 0.2087 - accuracy: 0.9001 - val_loss: 0.9794 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01033: val_loss did not improve from 0.38514\n",
      "Epoch 1034/3000\n",
      "13/13 - 0s - loss: 0.2078 - accuracy: 0.9001 - val_loss: 0.9645 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01034: val_loss did not improve from 0.38514\n",
      "Epoch 1035/3000\n",
      "13/13 - 0s - loss: 0.2150 - accuracy: 0.9014 - val_loss: 0.8500 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01035: val_loss did not improve from 0.38514\n",
      "Epoch 1036/3000\n",
      "13/13 - 0s - loss: 0.2105 - accuracy: 0.9001 - val_loss: 0.7858 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01036: val_loss did not improve from 0.38514\n",
      "Epoch 1037/3000\n",
      "13/13 - 0s - loss: 0.2080 - accuracy: 0.9001 - val_loss: 0.7895 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01037: val_loss did not improve from 0.38514\n",
      "Epoch 1038/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.9027 - val_loss: 0.8291 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01038: val_loss did not improve from 0.38514\n",
      "Epoch 1039/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.9027 - val_loss: 0.8438 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01039: val_loss did not improve from 0.38514\n",
      "Epoch 1040/3000\n",
      "13/13 - 0s - loss: 0.2046 - accuracy: 0.9027 - val_loss: 0.8595 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01040: val_loss did not improve from 0.38514\n",
      "Epoch 1041/3000\n",
      "13/13 - 0s - loss: 0.2262 - accuracy: 0.9001 - val_loss: 0.8978 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01041: val_loss did not improve from 0.38514\n",
      "Epoch 1042/3000\n",
      "13/13 - 1s - loss: 0.2217 - accuracy: 0.8975 - val_loss: 1.0022 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01042: val_loss did not improve from 0.38514\n",
      "Epoch 1043/3000\n",
      "13/13 - 0s - loss: 0.2094 - accuracy: 0.8975 - val_loss: 1.0336 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01043: val_loss did not improve from 0.38514\n",
      "Epoch 1044/3000\n",
      "13/13 - 0s - loss: 0.2080 - accuracy: 0.8988 - val_loss: 1.1009 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01044: val_loss did not improve from 0.38514\n",
      "Epoch 1045/3000\n",
      "13/13 - 0s - loss: 0.2155 - accuracy: 0.9027 - val_loss: 0.9870 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01045: val_loss did not improve from 0.38514\n",
      "Epoch 1046/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.9014 - val_loss: 0.8020 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01046: val_loss did not improve from 0.38514\n",
      "Epoch 1047/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.8975 - val_loss: 0.8557 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01047: val_loss did not improve from 0.38514\n",
      "Epoch 1048/3000\n",
      "13/13 - 0s - loss: 0.2073 - accuracy: 0.9001 - val_loss: 0.9116 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01048: val_loss did not improve from 0.38514\n",
      "Epoch 1049/3000\n",
      "13/13 - 0s - loss: 0.2056 - accuracy: 0.9014 - val_loss: 0.9577 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01049: val_loss did not improve from 0.38514\n",
      "Epoch 1050/3000\n",
      "13/13 - 0s - loss: 0.2051 - accuracy: 0.9027 - val_loss: 0.9288 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01050: val_loss did not improve from 0.38514\n",
      "Epoch 1051/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9027 - val_loss: 0.9630 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01051: val_loss did not improve from 0.38514\n",
      "Epoch 1052/3000\n",
      "13/13 - 0s - loss: 0.2024 - accuracy: 0.8988 - val_loss: 0.9677 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01052: val_loss did not improve from 0.38514\n",
      "Epoch 1053/3000\n",
      "13/13 - 0s - loss: 0.2026 - accuracy: 0.9027 - val_loss: 0.9486 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01053: val_loss did not improve from 0.38514\n",
      "Epoch 1054/3000\n",
      "13/13 - 0s - loss: 0.2032 - accuracy: 0.9001 - val_loss: 0.9578 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01054: val_loss did not improve from 0.38514\n",
      "Epoch 1055/3000\n",
      "13/13 - 0s - loss: 0.2038 - accuracy: 0.9001 - val_loss: 0.9902 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01055: val_loss did not improve from 0.38514\n",
      "Epoch 1056/3000\n",
      "13/13 - 0s - loss: 0.2043 - accuracy: 0.9014 - val_loss: 1.0200 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01056: val_loss did not improve from 0.38514\n",
      "Epoch 1057/3000\n",
      "13/13 - 0s - loss: 0.2047 - accuracy: 0.9001 - val_loss: 1.0063 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01057: val_loss did not improve from 0.38514\n",
      "Epoch 1058/3000\n",
      "13/13 - 0s - loss: 0.2040 - accuracy: 0.8975 - val_loss: 0.9807 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01058: val_loss did not improve from 0.38514\n",
      "Epoch 1059/3000\n",
      "13/13 - 0s - loss: 0.2030 - accuracy: 0.9014 - val_loss: 0.9789 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01059: val_loss did not improve from 0.38514\n",
      "Epoch 1060/3000\n",
      "13/13 - 0s - loss: 0.2030 - accuracy: 0.9014 - val_loss: 0.9764 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01060: val_loss did not improve from 0.38514\n",
      "Epoch 1061/3000\n",
      "13/13 - 0s - loss: 0.2027 - accuracy: 0.9014 - val_loss: 0.9833 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01061: val_loss did not improve from 0.38514\n",
      "Epoch 1062/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9027 - val_loss: 0.9860 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01062: val_loss did not improve from 0.38514\n",
      "Epoch 1063/3000\n",
      "13/13 - 0s - loss: 0.2033 - accuracy: 0.8975 - val_loss: 1.0004 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01063: val_loss did not improve from 0.38514\n",
      "Epoch 1064/3000\n",
      "13/13 - 0s - loss: 0.2021 - accuracy: 0.9001 - val_loss: 1.0184 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01064: val_loss did not improve from 0.38514\n",
      "Epoch 1065/3000\n",
      "13/13 - 0s - loss: 0.2026 - accuracy: 0.8988 - val_loss: 1.0240 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01065: val_loss did not improve from 0.38514\n",
      "Epoch 1066/3000\n",
      "13/13 - 0s - loss: 0.2025 - accuracy: 0.9001 - val_loss: 1.0294 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01066: val_loss did not improve from 0.38514\n",
      "Epoch 1067/3000\n",
      "13/13 - 0s - loss: 0.2036 - accuracy: 0.9027 - val_loss: 1.0487 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01067: val_loss did not improve from 0.38514\n",
      "Epoch 1068/3000\n",
      "13/13 - 0s - loss: 0.2043 - accuracy: 0.9014 - val_loss: 1.0309 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01068: val_loss did not improve from 0.38514\n",
      "Epoch 1069/3000\n",
      "13/13 - 0s - loss: 0.2029 - accuracy: 0.9001 - val_loss: 1.0220 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01069: val_loss did not improve from 0.38514\n",
      "Epoch 1070/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.9027 - val_loss: 1.0672 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01070: val_loss did not improve from 0.38514\n",
      "Epoch 1071/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.9014 - val_loss: 1.0923 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01071: val_loss did not improve from 0.38514\n",
      "Epoch 1072/3000\n",
      "13/13 - 0s - loss: 0.2044 - accuracy: 0.9027 - val_loss: 1.1181 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01072: val_loss did not improve from 0.38514\n",
      "Epoch 1073/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9027 - val_loss: 1.1355 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01073: val_loss did not improve from 0.38514\n",
      "Epoch 1074/3000\n",
      "13/13 - 0s - loss: 0.2046 - accuracy: 0.9027 - val_loss: 1.1576 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01074: val_loss did not improve from 0.38514\n",
      "Epoch 1075/3000\n",
      "13/13 - 0s - loss: 0.2022 - accuracy: 0.9040 - val_loss: 1.1408 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01075: val_loss did not improve from 0.38514\n",
      "Epoch 1076/3000\n",
      "13/13 - 0s - loss: 0.2029 - accuracy: 0.9001 - val_loss: 1.1605 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01076: val_loss did not improve from 0.38514\n",
      "Epoch 1077/3000\n",
      "13/13 - 0s - loss: 0.2026 - accuracy: 0.9014 - val_loss: 1.1469 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01077: val_loss did not improve from 0.38514\n",
      "Epoch 1078/3000\n",
      "13/13 - 0s - loss: 0.2025 - accuracy: 0.9014 - val_loss: 1.1424 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01078: val_loss did not improve from 0.38514\n",
      "Epoch 1079/3000\n",
      "13/13 - 0s - loss: 0.2078 - accuracy: 0.9027 - val_loss: 1.0411 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01079: val_loss did not improve from 0.38514\n",
      "Epoch 1080/3000\n",
      "13/13 - 0s - loss: 0.2136 - accuracy: 0.8885 - val_loss: 1.1201 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01080: val_loss did not improve from 0.38514\n",
      "Epoch 1081/3000\n",
      "13/13 - 0s - loss: 0.2060 - accuracy: 0.9014 - val_loss: 1.1640 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01081: val_loss did not improve from 0.38514\n",
      "Epoch 1082/3000\n",
      "13/13 - 0s - loss: 0.2065 - accuracy: 0.9014 - val_loss: 1.1668 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01082: val_loss did not improve from 0.38514\n",
      "Epoch 1083/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.9014 - val_loss: 1.2085 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01083: val_loss did not improve from 0.38514\n",
      "Epoch 1084/3000\n",
      "13/13 - 0s - loss: 0.2039 - accuracy: 0.9014 - val_loss: 1.2245 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01084: val_loss did not improve from 0.38514\n",
      "Epoch 1085/3000\n",
      "13/13 - 0s - loss: 0.2028 - accuracy: 0.9014 - val_loss: 1.2161 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01085: val_loss did not improve from 0.38514\n",
      "Epoch 1086/3000\n",
      "13/13 - 0s - loss: 0.2039 - accuracy: 0.9001 - val_loss: 1.1803 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01086: val_loss did not improve from 0.38514\n",
      "Epoch 1087/3000\n",
      "13/13 - 0s - loss: 0.2039 - accuracy: 0.9014 - val_loss: 1.1827 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01087: val_loss did not improve from 0.38514\n",
      "Epoch 1088/3000\n",
      "13/13 - 0s - loss: 0.2052 - accuracy: 0.8988 - val_loss: 1.1947 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01088: val_loss did not improve from 0.38514\n",
      "Epoch 1089/3000\n",
      "13/13 - 0s - loss: 0.2192 - accuracy: 0.8988 - val_loss: 1.0887 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01089: val_loss did not improve from 0.38514\n",
      "Epoch 1090/3000\n",
      "13/13 - 0s - loss: 0.2034 - accuracy: 0.9001 - val_loss: 1.0011 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01090: val_loss did not improve from 0.38514\n",
      "Epoch 1091/3000\n",
      "13/13 - 0s - loss: 0.2052 - accuracy: 0.9001 - val_loss: 1.0337 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01091: val_loss did not improve from 0.38514\n",
      "Epoch 1092/3000\n",
      "13/13 - 0s - loss: 0.2053 - accuracy: 0.9001 - val_loss: 1.0655 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01092: val_loss did not improve from 0.38514\n",
      "Epoch 1093/3000\n",
      "13/13 - 0s - loss: 0.2041 - accuracy: 0.9027 - val_loss: 1.0410 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01093: val_loss did not improve from 0.38514\n",
      "Epoch 1094/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.9027 - val_loss: 1.0566 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01094: val_loss did not improve from 0.38514\n",
      "Epoch 1095/3000\n",
      "13/13 - 0s - loss: 0.2058 - accuracy: 0.9027 - val_loss: 1.0664 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01095: val_loss did not improve from 0.38514\n",
      "Epoch 1096/3000\n",
      "13/13 - 0s - loss: 0.2032 - accuracy: 0.9027 - val_loss: 1.0622 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01096: val_loss did not improve from 0.38514\n",
      "Epoch 1097/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9027 - val_loss: 1.0678 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01097: val_loss did not improve from 0.38514\n",
      "Epoch 1098/3000\n",
      "13/13 - 0s - loss: 0.2087 - accuracy: 0.8988 - val_loss: 1.0840 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01098: val_loss did not improve from 0.38514\n",
      "Epoch 1099/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.8936 - val_loss: 1.0851 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01099: val_loss did not improve from 0.38514\n",
      "Epoch 1100/3000\n",
      "13/13 - 0s - loss: 0.2047 - accuracy: 0.8923 - val_loss: 1.1123 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01100: val_loss did not improve from 0.38514\n",
      "Epoch 1101/3000\n",
      "13/13 - 0s - loss: 0.2043 - accuracy: 0.8962 - val_loss: 1.1531 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01101: val_loss did not improve from 0.38514\n",
      "Epoch 1102/3000\n",
      "13/13 - 0s - loss: 0.2049 - accuracy: 0.8988 - val_loss: 1.1022 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01102: val_loss did not improve from 0.38514\n",
      "Epoch 1103/3000\n",
      "13/13 - 0s - loss: 0.2034 - accuracy: 0.9027 - val_loss: 1.0857 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01103: val_loss did not improve from 0.38514\n",
      "Epoch 1104/3000\n",
      "13/13 - 0s - loss: 0.2022 - accuracy: 0.9014 - val_loss: 1.1030 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01104: val_loss did not improve from 0.38514\n",
      "Epoch 1105/3000\n",
      "13/13 - 0s - loss: 0.2025 - accuracy: 0.9027 - val_loss: 1.1046 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01105: val_loss did not improve from 0.38514\n",
      "Epoch 1106/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9027 - val_loss: 1.1187 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01106: val_loss did not improve from 0.38514\n",
      "Epoch 1107/3000\n",
      "13/13 - 0s - loss: 0.2039 - accuracy: 0.9001 - val_loss: 1.1200 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01107: val_loss did not improve from 0.38514\n",
      "Epoch 1108/3000\n",
      "13/13 - 0s - loss: 0.2020 - accuracy: 0.9027 - val_loss: 1.1237 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01108: val_loss did not improve from 0.38514\n",
      "Epoch 1109/3000\n",
      "13/13 - 0s - loss: 0.2016 - accuracy: 0.9027 - val_loss: 1.1101 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01109: val_loss did not improve from 0.38514\n",
      "Epoch 1110/3000\n",
      "13/13 - 0s - loss: 0.2030 - accuracy: 0.9014 - val_loss: 1.1139 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01110: val_loss did not improve from 0.38514\n",
      "Epoch 1111/3000\n",
      "13/13 - 0s - loss: 0.2036 - accuracy: 0.9027 - val_loss: 1.1177 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01111: val_loss did not improve from 0.38514\n",
      "Epoch 1112/3000\n",
      "13/13 - 0s - loss: 0.2022 - accuracy: 0.9027 - val_loss: 1.1295 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01112: val_loss did not improve from 0.38514\n",
      "Epoch 1113/3000\n",
      "13/13 - 0s - loss: 0.2051 - accuracy: 0.8988 - val_loss: 1.1336 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01113: val_loss did not improve from 0.38514\n",
      "Epoch 1114/3000\n",
      "13/13 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 1.0861 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01114: val_loss did not improve from 0.38514\n",
      "Epoch 1115/3000\n",
      "13/13 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 1.0950 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01115: val_loss did not improve from 0.38514\n",
      "Epoch 1116/3000\n",
      "13/13 - 0s - loss: 0.2017 - accuracy: 0.9014 - val_loss: 1.0930 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01116: val_loss did not improve from 0.38514\n",
      "Epoch 1117/3000\n",
      "13/13 - 0s - loss: 0.2021 - accuracy: 0.9014 - val_loss: 1.1124 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01117: val_loss did not improve from 0.38514\n",
      "Epoch 1118/3000\n",
      "13/13 - 0s - loss: 0.2028 - accuracy: 0.8988 - val_loss: 1.1115 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01118: val_loss did not improve from 0.38514\n",
      "Epoch 1119/3000\n",
      "13/13 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 1.1084 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01119: val_loss did not improve from 0.38514\n",
      "Epoch 1120/3000\n",
      "13/13 - 0s - loss: 0.2016 - accuracy: 0.9027 - val_loss: 1.0939 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01120: val_loss did not improve from 0.38514\n",
      "Epoch 1121/3000\n",
      "13/13 - 0s - loss: 0.2014 - accuracy: 0.9014 - val_loss: 1.0883 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01121: val_loss did not improve from 0.38514\n",
      "Epoch 1122/3000\n",
      "13/13 - 0s - loss: 0.2012 - accuracy: 0.9014 - val_loss: 1.0917 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01122: val_loss did not improve from 0.38514\n",
      "Epoch 1123/3000\n",
      "13/13 - 0s - loss: 0.2018 - accuracy: 0.9027 - val_loss: 1.1042 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01123: val_loss did not improve from 0.38514\n",
      "Epoch 1124/3000\n",
      "13/13 - 0s - loss: 0.2022 - accuracy: 0.9040 - val_loss: 1.0896 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01124: val_loss did not improve from 0.38514\n",
      "Epoch 1125/3000\n",
      "13/13 - 0s - loss: 0.2017 - accuracy: 0.9001 - val_loss: 1.0948 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01125: val_loss did not improve from 0.38514\n",
      "Epoch 1126/3000\n",
      "13/13 - 0s - loss: 0.2010 - accuracy: 0.9014 - val_loss: 1.1078 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01126: val_loss did not improve from 0.38514\n",
      "Epoch 1127/3000\n",
      "13/13 - 0s - loss: 0.2020 - accuracy: 0.9040 - val_loss: 1.1097 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01127: val_loss did not improve from 0.38514\n",
      "Epoch 1128/3000\n",
      "13/13 - 0s - loss: 0.2016 - accuracy: 0.9001 - val_loss: 1.1310 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01128: val_loss did not improve from 0.38514\n",
      "Epoch 1129/3000\n",
      "13/13 - 0s - loss: 0.2026 - accuracy: 0.9001 - val_loss: 1.1791 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01129: val_loss did not improve from 0.38514\n",
      "Epoch 1130/3000\n",
      "13/13 - 0s - loss: 0.2060 - accuracy: 0.9014 - val_loss: 1.0489 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01130: val_loss did not improve from 0.38514\n",
      "Epoch 1131/3000\n",
      "13/13 - 0s - loss: 0.2032 - accuracy: 0.9027 - val_loss: 0.9262 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01131: val_loss did not improve from 0.38514\n",
      "Epoch 1132/3000\n",
      "13/13 - 0s - loss: 0.2022 - accuracy: 0.9027 - val_loss: 0.9169 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01132: val_loss did not improve from 0.38514\n",
      "Epoch 1133/3000\n",
      "13/13 - 0s - loss: 0.2016 - accuracy: 0.9027 - val_loss: 0.9180 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01133: val_loss did not improve from 0.38514\n",
      "Epoch 1134/3000\n",
      "13/13 - 0s - loss: 0.2025 - accuracy: 0.9027 - val_loss: 0.8970 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01134: val_loss did not improve from 0.38514\n",
      "Epoch 1135/3000\n",
      "13/13 - 0s - loss: 0.2030 - accuracy: 0.9040 - val_loss: 0.9391 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01135: val_loss did not improve from 0.38514\n",
      "Epoch 1136/3000\n",
      "13/13 - 0s - loss: 0.2020 - accuracy: 0.9014 - val_loss: 0.9847 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01136: val_loss did not improve from 0.38514\n",
      "Epoch 1137/3000\n",
      "13/13 - 0s - loss: 0.2026 - accuracy: 0.9027 - val_loss: 1.0318 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01137: val_loss did not improve from 0.38514\n",
      "Epoch 1138/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.9001 - val_loss: 0.9617 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01138: val_loss did not improve from 0.38514\n",
      "Epoch 1139/3000\n",
      "13/13 - 0s - loss: 0.2454 - accuracy: 0.8962 - val_loss: 0.9191 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01139: val_loss did not improve from 0.38514\n",
      "Epoch 1140/3000\n",
      "13/13 - 0s - loss: 0.2165 - accuracy: 0.8923 - val_loss: 0.7481 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01140: val_loss did not improve from 0.38514\n",
      "Epoch 1141/3000\n",
      "13/13 - 0s - loss: 0.2324 - accuracy: 0.9014 - val_loss: 0.5887 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01141: val_loss did not improve from 0.38514\n",
      "Epoch 1142/3000\n",
      "13/13 - 0s - loss: 0.2329 - accuracy: 0.9001 - val_loss: 0.6107 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01142: val_loss did not improve from 0.38514\n",
      "Epoch 1143/3000\n",
      "13/13 - 0s - loss: 0.2100 - accuracy: 0.9014 - val_loss: 0.5850 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01143: val_loss did not improve from 0.38514\n",
      "Epoch 1144/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.9001 - val_loss: 0.6507 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01144: val_loss did not improve from 0.38514\n",
      "Epoch 1145/3000\n",
      "13/13 - 0s - loss: 0.2154 - accuracy: 0.8911 - val_loss: 0.6110 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01145: val_loss did not improve from 0.38514\n",
      "Epoch 1146/3000\n",
      "13/13 - 0s - loss: 0.2095 - accuracy: 0.8988 - val_loss: 0.7448 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01146: val_loss did not improve from 0.38514\n",
      "Epoch 1147/3000\n",
      "13/13 - 0s - loss: 0.2310 - accuracy: 0.9014 - val_loss: 0.7550 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01147: val_loss did not improve from 0.38514\n",
      "Epoch 1148/3000\n",
      "13/13 - 0s - loss: 0.2152 - accuracy: 0.8911 - val_loss: 0.6528 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01148: val_loss did not improve from 0.38514\n",
      "Epoch 1149/3000\n",
      "13/13 - 0s - loss: 0.2100 - accuracy: 0.8975 - val_loss: 0.7967 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01149: val_loss did not improve from 0.38514\n",
      "Epoch 1150/3000\n",
      "13/13 - 0s - loss: 0.2098 - accuracy: 0.9001 - val_loss: 0.8565 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01150: val_loss did not improve from 0.38514\n",
      "Epoch 1151/3000\n",
      "13/13 - 0s - loss: 0.2087 - accuracy: 0.9014 - val_loss: 0.8618 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01151: val_loss did not improve from 0.38514\n",
      "Epoch 1152/3000\n",
      "13/13 - 0s - loss: 0.2067 - accuracy: 0.9027 - val_loss: 0.8564 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01152: val_loss did not improve from 0.38514\n",
      "Epoch 1153/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.9001 - val_loss: 0.8648 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01153: val_loss did not improve from 0.38514\n",
      "Epoch 1154/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.8975 - val_loss: 0.8728 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01154: val_loss did not improve from 0.38514\n",
      "Epoch 1155/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.8975 - val_loss: 0.8845 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01155: val_loss did not improve from 0.38514\n",
      "Epoch 1156/3000\n",
      "13/13 - 0s - loss: 0.2069 - accuracy: 0.8962 - val_loss: 0.9101 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01156: val_loss did not improve from 0.38514\n",
      "Epoch 1157/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.8975 - val_loss: 0.9222 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01157: val_loss did not improve from 0.38514\n",
      "Epoch 1158/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.8898 - val_loss: 0.9039 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01158: val_loss did not improve from 0.38514\n",
      "Epoch 1159/3000\n",
      "13/13 - 0s - loss: 0.2190 - accuracy: 0.9014 - val_loss: 0.9567 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01159: val_loss did not improve from 0.38514\n",
      "Epoch 1160/3000\n",
      "13/13 - 0s - loss: 0.2200 - accuracy: 0.8988 - val_loss: 0.9742 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01160: val_loss did not improve from 0.38514\n",
      "Epoch 1161/3000\n",
      "13/13 - 0s - loss: 0.2907 - accuracy: 0.8975 - val_loss: 1.0247 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01161: val_loss did not improve from 0.38514\n",
      "Epoch 1162/3000\n",
      "13/13 - 0s - loss: 0.2439 - accuracy: 0.8859 - val_loss: 0.7534 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01162: val_loss did not improve from 0.38514\n",
      "Epoch 1163/3000\n",
      "13/13 - 0s - loss: 0.2642 - accuracy: 0.8911 - val_loss: 0.9501 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01163: val_loss did not improve from 0.38514\n",
      "Epoch 1164/3000\n",
      "13/13 - 0s - loss: 0.2458 - accuracy: 0.8962 - val_loss: 0.7634 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01164: val_loss did not improve from 0.38514\n",
      "Epoch 1165/3000\n",
      "13/13 - 0s - loss: 0.2787 - accuracy: 0.8872 - val_loss: 0.6316 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01165: val_loss did not improve from 0.38514\n",
      "Epoch 1166/3000\n",
      "13/13 - 0s - loss: 0.2207 - accuracy: 0.9014 - val_loss: 0.7264 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01166: val_loss did not improve from 0.38514\n",
      "Epoch 1167/3000\n",
      "13/13 - 0s - loss: 0.2330 - accuracy: 0.8859 - val_loss: 0.7624 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01167: val_loss did not improve from 0.38514\n",
      "Epoch 1168/3000\n",
      "13/13 - 0s - loss: 0.2250 - accuracy: 0.8962 - val_loss: 0.8765 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01168: val_loss did not improve from 0.38514\n",
      "Epoch 1169/3000\n",
      "13/13 - 0s - loss: 0.2148 - accuracy: 0.9014 - val_loss: 0.8558 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01169: val_loss did not improve from 0.38514\n",
      "Epoch 1170/3000\n",
      "13/13 - 0s - loss: 0.2112 - accuracy: 0.8988 - val_loss: 0.8021 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01170: val_loss did not improve from 0.38514\n",
      "Epoch 1171/3000\n",
      "13/13 - 0s - loss: 0.2104 - accuracy: 0.9014 - val_loss: 0.8145 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01171: val_loss did not improve from 0.38514\n",
      "Epoch 1172/3000\n",
      "13/13 - 0s - loss: 0.2098 - accuracy: 0.8988 - val_loss: 0.8629 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01172: val_loss did not improve from 0.38514\n",
      "Epoch 1173/3000\n",
      "13/13 - 0s - loss: 0.2086 - accuracy: 0.8988 - val_loss: 0.8611 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01173: val_loss did not improve from 0.38514\n",
      "Epoch 1174/3000\n",
      "13/13 - 0s - loss: 0.2067 - accuracy: 0.9014 - val_loss: 0.8615 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01174: val_loss did not improve from 0.38514\n",
      "Epoch 1175/3000\n",
      "13/13 - 0s - loss: 0.2077 - accuracy: 0.8988 - val_loss: 0.8694 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01175: val_loss did not improve from 0.38514\n",
      "Epoch 1176/3000\n",
      "13/13 - 0s - loss: 0.2067 - accuracy: 0.9014 - val_loss: 0.8940 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01176: val_loss did not improve from 0.38514\n",
      "Epoch 1177/3000\n",
      "13/13 - 0s - loss: 0.2176 - accuracy: 0.8885 - val_loss: 0.8923 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01177: val_loss did not improve from 0.38514\n",
      "Epoch 1178/3000\n",
      "13/13 - 0s - loss: 0.2163 - accuracy: 0.8898 - val_loss: 0.9233 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01178: val_loss did not improve from 0.38514\n",
      "Epoch 1179/3000\n",
      "13/13 - 0s - loss: 0.2140 - accuracy: 0.8962 - val_loss: 0.9336 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01179: val_loss did not improve from 0.38514\n",
      "Epoch 1180/3000\n",
      "13/13 - 0s - loss: 0.2117 - accuracy: 0.8936 - val_loss: 0.9438 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01180: val_loss did not improve from 0.38514\n",
      "Epoch 1181/3000\n",
      "13/13 - 0s - loss: 0.2107 - accuracy: 0.8975 - val_loss: 0.9055 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01181: val_loss did not improve from 0.38514\n",
      "Epoch 1182/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.9001 - val_loss: 0.9392 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01182: val_loss did not improve from 0.38514\n",
      "Epoch 1183/3000\n",
      "13/13 - 0s - loss: 0.2070 - accuracy: 0.8988 - val_loss: 0.9673 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01183: val_loss did not improve from 0.38514\n",
      "Epoch 1184/3000\n",
      "13/13 - 0s - loss: 0.2080 - accuracy: 0.9027 - val_loss: 0.9650 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01184: val_loss did not improve from 0.38514\n",
      "Epoch 1185/3000\n",
      "13/13 - 0s - loss: 0.2096 - accuracy: 0.9001 - val_loss: 0.9806 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01185: val_loss did not improve from 0.38514\n",
      "Epoch 1186/3000\n",
      "13/13 - 0s - loss: 0.2056 - accuracy: 0.9027 - val_loss: 0.9845 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01186: val_loss did not improve from 0.38514\n",
      "Epoch 1187/3000\n",
      "13/13 - 0s - loss: 0.2073 - accuracy: 0.8962 - val_loss: 0.9722 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01187: val_loss did not improve from 0.38514\n",
      "Epoch 1188/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.9001 - val_loss: 0.9683 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01188: val_loss did not improve from 0.38514\n",
      "Epoch 1189/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.8975 - val_loss: 0.9693 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01189: val_loss did not improve from 0.38514\n",
      "Epoch 1190/3000\n",
      "13/13 - 0s - loss: 0.2051 - accuracy: 0.8949 - val_loss: 0.9893 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01190: val_loss did not improve from 0.38514\n",
      "Epoch 1191/3000\n",
      "13/13 - 0s - loss: 0.2153 - accuracy: 0.8962 - val_loss: 1.0028 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01191: val_loss did not improve from 0.38514\n",
      "Epoch 1192/3000\n",
      "13/13 - 0s - loss: 0.2213 - accuracy: 0.8923 - val_loss: 0.9439 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01192: val_loss did not improve from 0.38514\n",
      "Epoch 1193/3000\n",
      "13/13 - 0s - loss: 0.2157 - accuracy: 0.9027 - val_loss: 0.9360 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01193: val_loss did not improve from 0.38514\n",
      "Epoch 1194/3000\n",
      "13/13 - 0s - loss: 0.2123 - accuracy: 0.8988 - val_loss: 0.8924 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01194: val_loss did not improve from 0.38514\n",
      "Epoch 1195/3000\n",
      "13/13 - 0s - loss: 0.2116 - accuracy: 0.9014 - val_loss: 0.8435 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01195: val_loss did not improve from 0.38514\n",
      "Epoch 1196/3000\n",
      "13/13 - 0s - loss: 0.2101 - accuracy: 0.9027 - val_loss: 0.8174 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01196: val_loss did not improve from 0.38514\n",
      "Epoch 1197/3000\n",
      "13/13 - 0s - loss: 0.2130 - accuracy: 0.9014 - val_loss: 0.8969 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01197: val_loss did not improve from 0.38514\n",
      "Epoch 1198/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.9001 - val_loss: 1.0870 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01198: val_loss did not improve from 0.38514\n",
      "Epoch 1199/3000\n",
      "13/13 - 0s - loss: 0.2070 - accuracy: 0.9027 - val_loss: 1.1230 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01199: val_loss did not improve from 0.38514\n",
      "Epoch 1200/3000\n",
      "13/13 - 0s - loss: 0.2076 - accuracy: 0.9027 - val_loss: 1.1703 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01200: val_loss did not improve from 0.38514\n",
      "Epoch 1201/3000\n",
      "13/13 - 0s - loss: 0.2068 - accuracy: 0.9014 - val_loss: 1.1350 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01201: val_loss did not improve from 0.38514\n",
      "Epoch 1202/3000\n",
      "13/13 - 0s - loss: 0.2044 - accuracy: 0.9027 - val_loss: 1.1170 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01202: val_loss did not improve from 0.38514\n",
      "Epoch 1203/3000\n",
      "13/13 - 0s - loss: 0.2041 - accuracy: 0.9027 - val_loss: 1.1225 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01203: val_loss did not improve from 0.38514\n",
      "Epoch 1204/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.9027 - val_loss: 1.1422 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01204: val_loss did not improve from 0.38514\n",
      "Epoch 1205/3000\n",
      "13/13 - 0s - loss: 0.2051 - accuracy: 0.9027 - val_loss: 1.1139 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01205: val_loss did not improve from 0.38514\n",
      "Epoch 1206/3000\n",
      "13/13 - 0s - loss: 0.2086 - accuracy: 0.9014 - val_loss: 1.0032 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01206: val_loss did not improve from 0.38514\n",
      "Epoch 1207/3000\n",
      "13/13 - 0s - loss: 0.2135 - accuracy: 0.8962 - val_loss: 0.9083 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01207: val_loss did not improve from 0.38514\n",
      "Epoch 1208/3000\n",
      "13/13 - 0s - loss: 0.2118 - accuracy: 0.9001 - val_loss: 0.8935 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01208: val_loss did not improve from 0.38514\n",
      "Epoch 1209/3000\n",
      "13/13 - 0s - loss: 0.2089 - accuracy: 0.9001 - val_loss: 0.9380 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01209: val_loss did not improve from 0.38514\n",
      "Epoch 1210/3000\n",
      "13/13 - 0s - loss: 0.2078 - accuracy: 0.9027 - val_loss: 0.9510 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01210: val_loss did not improve from 0.38514\n",
      "Epoch 1211/3000\n",
      "13/13 - 0s - loss: 0.2106 - accuracy: 0.9027 - val_loss: 0.9170 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01211: val_loss did not improve from 0.38514\n",
      "Epoch 1212/3000\n",
      "13/13 - 0s - loss: 0.2111 - accuracy: 0.8975 - val_loss: 0.9791 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01212: val_loss did not improve from 0.38514\n",
      "Epoch 1213/3000\n",
      "13/13 - 0s - loss: 0.2154 - accuracy: 0.8936 - val_loss: 1.1503 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01213: val_loss did not improve from 0.38514\n",
      "Epoch 1214/3000\n",
      "13/13 - 0s - loss: 0.2106 - accuracy: 0.9001 - val_loss: 1.2829 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01214: val_loss did not improve from 0.38514\n",
      "Epoch 1215/3000\n",
      "13/13 - 0s - loss: 0.2080 - accuracy: 0.9027 - val_loss: 1.3349 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01215: val_loss did not improve from 0.38514\n",
      "Epoch 1216/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.9027 - val_loss: 1.2896 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01216: val_loss did not improve from 0.38514\n",
      "Epoch 1217/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.9027 - val_loss: 1.3637 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01217: val_loss did not improve from 0.38514\n",
      "Epoch 1218/3000\n",
      "13/13 - 0s - loss: 0.2045 - accuracy: 0.9027 - val_loss: 1.3706 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01218: val_loss did not improve from 0.38514\n",
      "Epoch 1219/3000\n",
      "13/13 - 0s - loss: 0.2036 - accuracy: 0.9027 - val_loss: 1.3595 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01219: val_loss did not improve from 0.38514\n",
      "Epoch 1220/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9014 - val_loss: 1.3224 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01220: val_loss did not improve from 0.38514\n",
      "Epoch 1221/3000\n",
      "13/13 - 0s - loss: 0.2068 - accuracy: 0.9027 - val_loss: 1.3416 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01221: val_loss did not improve from 0.38514\n",
      "Epoch 1222/3000\n",
      "13/13 - 0s - loss: 0.2049 - accuracy: 0.9040 - val_loss: 1.3357 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01222: val_loss did not improve from 0.38514\n",
      "Epoch 1223/3000\n",
      "13/13 - 0s - loss: 0.2045 - accuracy: 0.9001 - val_loss: 1.2783 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01223: val_loss did not improve from 0.38514\n",
      "Epoch 1224/3000\n",
      "13/13 - 0s - loss: 0.2059 - accuracy: 0.9027 - val_loss: 1.2548 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01224: val_loss did not improve from 0.38514\n",
      "Epoch 1225/3000\n",
      "13/13 - 0s - loss: 0.2082 - accuracy: 0.8988 - val_loss: 1.1712 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01225: val_loss did not improve from 0.38514\n",
      "Epoch 1226/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.9001 - val_loss: 1.2063 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01226: val_loss did not improve from 0.38514\n",
      "Epoch 1227/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.9014 - val_loss: 1.2532 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01227: val_loss did not improve from 0.38514\n",
      "Epoch 1228/3000\n",
      "13/13 - 0s - loss: 0.2045 - accuracy: 0.9014 - val_loss: 1.2394 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01228: val_loss did not improve from 0.38514\n",
      "Epoch 1229/3000\n",
      "13/13 - 0s - loss: 0.2031 - accuracy: 0.9027 - val_loss: 1.2493 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01229: val_loss did not improve from 0.38514\n",
      "Epoch 1230/3000\n",
      "13/13 - 0s - loss: 0.2031 - accuracy: 0.9027 - val_loss: 1.2346 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01230: val_loss did not improve from 0.38514\n",
      "Epoch 1231/3000\n",
      "13/13 - 0s - loss: 0.2034 - accuracy: 0.9001 - val_loss: 1.2276 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01231: val_loss did not improve from 0.38514\n",
      "Epoch 1232/3000\n",
      "13/13 - 0s - loss: 0.2048 - accuracy: 0.9001 - val_loss: 1.2461 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01232: val_loss did not improve from 0.38514\n",
      "Epoch 1233/3000\n",
      "13/13 - 0s - loss: 0.2043 - accuracy: 0.9027 - val_loss: 1.3090 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01233: val_loss did not improve from 0.38514\n",
      "Epoch 1234/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9027 - val_loss: 1.3308 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01234: val_loss did not improve from 0.38514\n",
      "Epoch 1235/3000\n",
      "13/13 - 0s - loss: 0.2041 - accuracy: 0.9027 - val_loss: 1.3432 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01235: val_loss did not improve from 0.38514\n",
      "Epoch 1236/3000\n",
      "13/13 - 0s - loss: 0.2041 - accuracy: 0.8975 - val_loss: 1.3321 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01236: val_loss did not improve from 0.38514\n",
      "Epoch 1237/3000\n",
      "13/13 - 0s - loss: 0.2041 - accuracy: 0.9027 - val_loss: 1.3194 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01237: val_loss did not improve from 0.38514\n",
      "Epoch 1238/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.9027 - val_loss: 1.1166 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01238: val_loss did not improve from 0.38514\n",
      "Epoch 1239/3000\n",
      "13/13 - 0s - loss: 0.2060 - accuracy: 0.9027 - val_loss: 1.0624 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01239: val_loss did not improve from 0.38514\n",
      "Epoch 1240/3000\n",
      "13/13 - 0s - loss: 0.2038 - accuracy: 0.9027 - val_loss: 1.0853 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01240: val_loss did not improve from 0.38514\n",
      "Epoch 1241/3000\n",
      "13/13 - 0s - loss: 0.2034 - accuracy: 0.9001 - val_loss: 1.0984 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01241: val_loss did not improve from 0.38514\n",
      "Epoch 1242/3000\n",
      "13/13 - 0s - loss: 0.2024 - accuracy: 0.8988 - val_loss: 1.0738 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01242: val_loss did not improve from 0.38514\n",
      "Epoch 1243/3000\n",
      "13/13 - 0s - loss: 0.2019 - accuracy: 0.9014 - val_loss: 1.0564 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01243: val_loss did not improve from 0.38514\n",
      "Epoch 1244/3000\n",
      "13/13 - 0s - loss: 0.2022 - accuracy: 0.9027 - val_loss: 1.0609 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01244: val_loss did not improve from 0.38514\n",
      "Epoch 1245/3000\n",
      "13/13 - 0s - loss: 0.2020 - accuracy: 0.9027 - val_loss: 1.0689 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01245: val_loss did not improve from 0.38514\n",
      "Epoch 1246/3000\n",
      "13/13 - 0s - loss: 0.2034 - accuracy: 0.9027 - val_loss: 1.0433 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01246: val_loss did not improve from 0.38514\n",
      "Epoch 1247/3000\n",
      "13/13 - 0s - loss: 0.2105 - accuracy: 0.8975 - val_loss: 1.1338 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01247: val_loss did not improve from 0.38514\n",
      "Epoch 1248/3000\n",
      "13/13 - 0s - loss: 0.2114 - accuracy: 0.9027 - val_loss: 1.1609 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01248: val_loss did not improve from 0.38514\n",
      "Epoch 1249/3000\n",
      "13/13 - 0s - loss: 0.2036 - accuracy: 0.9014 - val_loss: 1.1539 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01249: val_loss did not improve from 0.38514\n",
      "Epoch 1250/3000\n",
      "13/13 - 0s - loss: 0.2045 - accuracy: 0.9001 - val_loss: 1.1844 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01250: val_loss did not improve from 0.38514\n",
      "Epoch 1251/3000\n",
      "13/13 - 0s - loss: 0.2039 - accuracy: 0.8988 - val_loss: 1.2146 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01251: val_loss did not improve from 0.38514\n",
      "Epoch 1252/3000\n",
      "13/13 - 0s - loss: 0.2031 - accuracy: 0.9014 - val_loss: 1.2132 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01252: val_loss did not improve from 0.38514\n",
      "Epoch 1253/3000\n",
      "13/13 - 0s - loss: 0.2024 - accuracy: 0.9014 - val_loss: 1.2222 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01253: val_loss did not improve from 0.38514\n",
      "Epoch 1254/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9027 - val_loss: 1.2114 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01254: val_loss did not improve from 0.38514\n",
      "Epoch 1255/3000\n",
      "13/13 - 0s - loss: 0.2045 - accuracy: 0.9014 - val_loss: 1.1760 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01255: val_loss did not improve from 0.38514\n",
      "Epoch 1256/3000\n",
      "13/13 - 0s - loss: 0.2043 - accuracy: 0.9027 - val_loss: 1.1765 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01256: val_loss did not improve from 0.38514\n",
      "Epoch 1257/3000\n",
      "13/13 - 0s - loss: 0.2041 - accuracy: 0.9014 - val_loss: 1.2075 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01257: val_loss did not improve from 0.38514\n",
      "Epoch 1258/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9001 - val_loss: 1.2731 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01258: val_loss did not improve from 0.38514\n",
      "Epoch 1259/3000\n",
      "13/13 - 0s - loss: 0.2036 - accuracy: 0.9014 - val_loss: 1.2702 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01259: val_loss did not improve from 0.38514\n",
      "Epoch 1260/3000\n",
      "13/13 - 0s - loss: 0.2039 - accuracy: 0.9027 - val_loss: 1.2617 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01260: val_loss did not improve from 0.38514\n",
      "Epoch 1261/3000\n",
      "13/13 - 0s - loss: 0.2023 - accuracy: 0.9027 - val_loss: 1.2844 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01261: val_loss did not improve from 0.38514\n",
      "Epoch 1262/3000\n",
      "13/13 - 0s - loss: 0.2023 - accuracy: 0.9014 - val_loss: 1.3031 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01262: val_loss did not improve from 0.38514\n",
      "Epoch 1263/3000\n",
      "13/13 - 0s - loss: 0.2034 - accuracy: 0.9014 - val_loss: 1.3371 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01263: val_loss did not improve from 0.38514\n",
      "Epoch 1264/3000\n",
      "13/13 - 0s - loss: 0.2052 - accuracy: 0.9014 - val_loss: 1.3587 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01264: val_loss did not improve from 0.38514\n",
      "Epoch 1265/3000\n",
      "13/13 - 0s - loss: 0.2038 - accuracy: 0.8988 - val_loss: 1.3450 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01265: val_loss did not improve from 0.38514\n",
      "Epoch 1266/3000\n",
      "13/13 - 0s - loss: 0.2026 - accuracy: 0.8975 - val_loss: 1.3431 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01266: val_loss did not improve from 0.38514\n",
      "Epoch 1267/3000\n",
      "13/13 - 0s - loss: 0.2027 - accuracy: 0.9001 - val_loss: 1.3645 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01267: val_loss did not improve from 0.38514\n",
      "Epoch 1268/3000\n",
      "13/13 - 0s - loss: 0.2013 - accuracy: 0.8988 - val_loss: 1.3801 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01268: val_loss did not improve from 0.38514\n",
      "Epoch 1269/3000\n",
      "13/13 - 0s - loss: 0.2022 - accuracy: 0.8962 - val_loss: 1.3543 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01269: val_loss did not improve from 0.38514\n",
      "Epoch 1270/3000\n",
      "13/13 - 0s - loss: 0.2033 - accuracy: 0.8988 - val_loss: 1.3777 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01270: val_loss did not improve from 0.38514\n",
      "Epoch 1271/3000\n",
      "13/13 - 0s - loss: 0.2025 - accuracy: 0.9027 - val_loss: 1.3718 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01271: val_loss did not improve from 0.38514\n",
      "Epoch 1272/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.8988 - val_loss: 1.5285 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01272: val_loss did not improve from 0.38514\n",
      "Epoch 1273/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.8988 - val_loss: 1.1631 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01273: val_loss did not improve from 0.38514\n",
      "Epoch 1274/3000\n",
      "13/13 - 0s - loss: 0.2040 - accuracy: 0.9014 - val_loss: 1.1597 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01274: val_loss did not improve from 0.38514\n",
      "Epoch 1275/3000\n",
      "13/13 - 0s - loss: 0.2027 - accuracy: 0.8988 - val_loss: 1.2272 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01275: val_loss did not improve from 0.38514\n",
      "Epoch 1276/3000\n",
      "13/13 - 0s - loss: 0.2026 - accuracy: 0.9001 - val_loss: 1.2552 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01276: val_loss did not improve from 0.38514\n",
      "Epoch 1277/3000\n",
      "13/13 - 0s - loss: 0.2044 - accuracy: 0.9027 - val_loss: 1.2429 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01277: val_loss did not improve from 0.38514\n",
      "Epoch 1278/3000\n",
      "13/13 - 0s - loss: 0.2034 - accuracy: 0.8975 - val_loss: 1.2848 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01278: val_loss did not improve from 0.38514\n",
      "Epoch 1279/3000\n",
      "13/13 - 0s - loss: 0.2038 - accuracy: 0.9027 - val_loss: 1.3181 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01279: val_loss did not improve from 0.38514\n",
      "Epoch 1280/3000\n",
      "13/13 - 0s - loss: 0.2033 - accuracy: 0.9014 - val_loss: 1.3450 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01280: val_loss did not improve from 0.38514\n",
      "Epoch 1281/3000\n",
      "13/13 - 0s - loss: 0.2030 - accuracy: 0.9027 - val_loss: 1.3610 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01281: val_loss did not improve from 0.38514\n",
      "Epoch 1282/3000\n",
      "13/13 - 0s - loss: 0.2021 - accuracy: 0.9014 - val_loss: 1.3388 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01282: val_loss did not improve from 0.38514\n",
      "Epoch 1283/3000\n",
      "13/13 - 0s - loss: 0.2020 - accuracy: 0.9014 - val_loss: 1.3234 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01283: val_loss did not improve from 0.38514\n",
      "Epoch 1284/3000\n",
      "13/13 - 0s - loss: 0.2043 - accuracy: 0.9014 - val_loss: 1.2702 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01284: val_loss did not improve from 0.38514\n",
      "Epoch 1285/3000\n",
      "13/13 - 0s - loss: 0.2101 - accuracy: 0.8936 - val_loss: 1.2481 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01285: val_loss did not improve from 0.38514\n",
      "Epoch 1286/3000\n",
      "13/13 - 0s - loss: 0.2092 - accuracy: 0.8962 - val_loss: 1.2245 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01286: val_loss did not improve from 0.38514\n",
      "Epoch 1287/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.8962 - val_loss: 1.2489 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01287: val_loss did not improve from 0.38514\n",
      "Epoch 1288/3000\n",
      "13/13 - 0s - loss: 0.2046 - accuracy: 0.8975 - val_loss: 1.2910 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01288: val_loss did not improve from 0.38514\n",
      "Epoch 1289/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.8962 - val_loss: 1.3010 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01289: val_loss did not improve from 0.38514\n",
      "Epoch 1290/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.9001 - val_loss: 1.3207 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01290: val_loss did not improve from 0.38514\n",
      "Epoch 1291/3000\n",
      "13/13 - 0s - loss: 0.2052 - accuracy: 0.9027 - val_loss: 1.2667 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01291: val_loss did not improve from 0.38514\n",
      "Epoch 1292/3000\n",
      "13/13 - 0s - loss: 0.2060 - accuracy: 0.9001 - val_loss: 1.3520 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01292: val_loss did not improve from 0.38514\n",
      "Epoch 1293/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.8975 - val_loss: 1.2638 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01293: val_loss did not improve from 0.38514\n",
      "Epoch 1294/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.8949 - val_loss: 1.2178 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01294: val_loss did not improve from 0.38514\n",
      "Epoch 1295/3000\n",
      "13/13 - 0s - loss: 0.2047 - accuracy: 0.8975 - val_loss: 1.2306 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01295: val_loss did not improve from 0.38514\n",
      "Epoch 1296/3000\n",
      "13/13 - 0s - loss: 0.2044 - accuracy: 0.9027 - val_loss: 1.2535 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01296: val_loss did not improve from 0.38514\n",
      "Epoch 1297/3000\n",
      "13/13 - 0s - loss: 0.2052 - accuracy: 0.9001 - val_loss: 1.3016 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01297: val_loss did not improve from 0.38514\n",
      "Epoch 1298/3000\n",
      "13/13 - 0s - loss: 0.2082 - accuracy: 0.9014 - val_loss: 1.4513 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01298: val_loss did not improve from 0.38514\n",
      "Epoch 1299/3000\n",
      "13/13 - 0s - loss: 0.2112 - accuracy: 0.8988 - val_loss: 1.3442 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01299: val_loss did not improve from 0.38514\n",
      "Epoch 1300/3000\n",
      "13/13 - 0s - loss: 0.2070 - accuracy: 0.9001 - val_loss: 1.3272 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01300: val_loss did not improve from 0.38514\n",
      "Epoch 1301/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.9027 - val_loss: 1.3600 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01301: val_loss did not improve from 0.38514\n",
      "Epoch 1302/3000\n",
      "13/13 - 0s - loss: 0.2038 - accuracy: 0.9027 - val_loss: 1.3578 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01302: val_loss did not improve from 0.38514\n",
      "Epoch 1303/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9053 - val_loss: 1.4458 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01303: val_loss did not improve from 0.38514\n",
      "Epoch 1304/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9040 - val_loss: 1.4496 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01304: val_loss did not improve from 0.38514\n",
      "Epoch 1305/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.8988 - val_loss: 1.4415 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01305: val_loss did not improve from 0.38514\n",
      "Epoch 1306/3000\n",
      "13/13 - 0s - loss: 0.2028 - accuracy: 0.9027 - val_loss: 1.4266 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01306: val_loss did not improve from 0.38514\n",
      "Epoch 1307/3000\n",
      "13/13 - 0s - loss: 0.2030 - accuracy: 0.9027 - val_loss: 1.4076 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01307: val_loss did not improve from 0.38514\n",
      "Epoch 1308/3000\n",
      "13/13 - 0s - loss: 0.2017 - accuracy: 0.9027 - val_loss: 1.4029 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01308: val_loss did not improve from 0.38514\n",
      "Epoch 1309/3000\n",
      "13/13 - 0s - loss: 0.2020 - accuracy: 0.9027 - val_loss: 1.4219 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01309: val_loss did not improve from 0.38514\n",
      "Epoch 1310/3000\n",
      "13/13 - 0s - loss: 0.2017 - accuracy: 0.9027 - val_loss: 1.4168 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01310: val_loss did not improve from 0.38514\n",
      "Epoch 1311/3000\n",
      "13/13 - 0s - loss: 0.2032 - accuracy: 0.9027 - val_loss: 1.3786 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01311: val_loss did not improve from 0.38514\n",
      "Epoch 1312/3000\n",
      "13/13 - 0s - loss: 0.2026 - accuracy: 0.9014 - val_loss: 1.3424 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01312: val_loss did not improve from 0.38514\n",
      "Epoch 1313/3000\n",
      "13/13 - 0s - loss: 0.2020 - accuracy: 0.9027 - val_loss: 1.3147 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01313: val_loss did not improve from 0.38514\n",
      "Epoch 1314/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.9014 - val_loss: 1.3193 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01314: val_loss did not improve from 0.38514\n",
      "Epoch 1315/3000\n",
      "13/13 - 0s - loss: 0.2065 - accuracy: 0.9014 - val_loss: 1.3668 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01315: val_loss did not improve from 0.38514\n",
      "Epoch 1316/3000\n",
      "13/13 - 0s - loss: 0.2033 - accuracy: 0.9027 - val_loss: 1.4326 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01316: val_loss did not improve from 0.38514\n",
      "Epoch 1317/3000\n",
      "13/13 - 0s - loss: 0.2023 - accuracy: 0.9014 - val_loss: 1.4375 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01317: val_loss did not improve from 0.38514\n",
      "Epoch 1318/3000\n",
      "13/13 - 0s - loss: 0.2034 - accuracy: 0.9027 - val_loss: 1.4496 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01318: val_loss did not improve from 0.38514\n",
      "Epoch 1319/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9001 - val_loss: 1.4054 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01319: val_loss did not improve from 0.38514\n",
      "Epoch 1320/3000\n",
      "13/13 - 0s - loss: 0.2252 - accuracy: 0.9014 - val_loss: 1.2839 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01320: val_loss did not improve from 0.38514\n",
      "Epoch 1321/3000\n",
      "13/13 - 0s - loss: 0.2180 - accuracy: 0.8975 - val_loss: 1.5313 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01321: val_loss did not improve from 0.38514\n",
      "Epoch 1322/3000\n",
      "13/13 - 0s - loss: 0.2215 - accuracy: 0.8975 - val_loss: 1.3851 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01322: val_loss did not improve from 0.38514\n",
      "Epoch 1323/3000\n",
      "13/13 - 0s - loss: 0.2267 - accuracy: 0.8988 - val_loss: 0.9341 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01323: val_loss did not improve from 0.38514\n",
      "Epoch 1324/3000\n",
      "13/13 - 0s - loss: 0.2274 - accuracy: 0.8923 - val_loss: 1.5344 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01324: val_loss did not improve from 0.38514\n",
      "Epoch 1325/3000\n",
      "13/13 - 0s - loss: 0.2599 - accuracy: 0.8755 - val_loss: 1.0986 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01325: val_loss did not improve from 0.38514\n",
      "Epoch 1326/3000\n",
      "13/13 - 0s - loss: 0.2676 - accuracy: 0.8846 - val_loss: 1.1830 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01326: val_loss did not improve from 0.38514\n",
      "Epoch 1327/3000\n",
      "13/13 - 0s - loss: 0.2182 - accuracy: 0.8962 - val_loss: 1.0972 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01327: val_loss did not improve from 0.38514\n",
      "Epoch 1328/3000\n",
      "13/13 - 0s - loss: 0.2097 - accuracy: 0.9001 - val_loss: 1.2482 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01328: val_loss did not improve from 0.38514\n",
      "Epoch 1329/3000\n",
      "13/13 - 0s - loss: 0.2089 - accuracy: 0.9001 - val_loss: 1.1490 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01329: val_loss did not improve from 0.38514\n",
      "Epoch 1330/3000\n",
      "13/13 - 0s - loss: 0.2073 - accuracy: 0.9001 - val_loss: 1.1876 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01330: val_loss did not improve from 0.38514\n",
      "Epoch 1331/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.9001 - val_loss: 1.1229 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01331: val_loss did not improve from 0.38514\n",
      "Epoch 1332/3000\n",
      "13/13 - 0s - loss: 0.2069 - accuracy: 0.8975 - val_loss: 1.0971 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01332: val_loss did not improve from 0.38514\n",
      "Epoch 1333/3000\n",
      "13/13 - 0s - loss: 0.2089 - accuracy: 0.9001 - val_loss: 1.1016 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01333: val_loss did not improve from 0.38514\n",
      "Epoch 1334/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.9001 - val_loss: 1.0787 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01334: val_loss did not improve from 0.38514\n",
      "Epoch 1335/3000\n",
      "13/13 - 0s - loss: 0.2052 - accuracy: 0.8988 - val_loss: 0.9777 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01335: val_loss did not improve from 0.38514\n",
      "Epoch 1336/3000\n",
      "13/13 - 0s - loss: 0.2048 - accuracy: 0.9040 - val_loss: 1.0122 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01336: val_loss did not improve from 0.38514\n",
      "Epoch 1337/3000\n",
      "13/13 - 0s - loss: 0.2040 - accuracy: 0.9001 - val_loss: 1.1012 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01337: val_loss did not improve from 0.38514\n",
      "Epoch 1338/3000\n",
      "13/13 - 0s - loss: 0.2094 - accuracy: 0.9014 - val_loss: 1.1327 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01338: val_loss did not improve from 0.38514\n",
      "Epoch 1339/3000\n",
      "13/13 - 0s - loss: 0.2121 - accuracy: 0.9014 - val_loss: 1.1999 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01339: val_loss did not improve from 0.38514\n",
      "Epoch 1340/3000\n",
      "13/13 - 0s - loss: 0.2123 - accuracy: 0.9014 - val_loss: 1.0701 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01340: val_loss did not improve from 0.38514\n",
      "Epoch 1341/3000\n",
      "13/13 - 0s - loss: 0.2101 - accuracy: 0.9001 - val_loss: 1.1473 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01341: val_loss did not improve from 0.38514\n",
      "Epoch 1342/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.9014 - val_loss: 1.2205 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01342: val_loss did not improve from 0.38514\n",
      "Epoch 1343/3000\n",
      "13/13 - 0s - loss: 0.2064 - accuracy: 0.9040 - val_loss: 1.2654 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01343: val_loss did not improve from 0.38514\n",
      "Epoch 1344/3000\n",
      "13/13 - 0s - loss: 0.2067 - accuracy: 0.9027 - val_loss: 1.2781 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01344: val_loss did not improve from 0.38514\n",
      "Epoch 1345/3000\n",
      "13/13 - 0s - loss: 0.2078 - accuracy: 0.9014 - val_loss: 1.2810 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01345: val_loss did not improve from 0.38514\n",
      "Epoch 1346/3000\n",
      "13/13 - 0s - loss: 0.2070 - accuracy: 0.9027 - val_loss: 1.3157 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01346: val_loss did not improve from 0.38514\n",
      "Epoch 1347/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.9027 - val_loss: 1.3504 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01347: val_loss did not improve from 0.38514\n",
      "Epoch 1348/3000\n",
      "13/13 - 0s - loss: 0.2060 - accuracy: 0.9014 - val_loss: 1.5156 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01348: val_loss did not improve from 0.38514\n",
      "Epoch 1349/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.9001 - val_loss: 1.5110 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01349: val_loss did not improve from 0.38514\n",
      "Epoch 1350/3000\n",
      "13/13 - 0s - loss: 0.2053 - accuracy: 0.9014 - val_loss: 1.4456 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01350: val_loss did not improve from 0.38514\n",
      "Epoch 1351/3000\n",
      "13/13 - 0s - loss: 0.2091 - accuracy: 0.9014 - val_loss: 1.4576 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01351: val_loss did not improve from 0.38514\n",
      "Epoch 1352/3000\n",
      "13/13 - 1s - loss: 0.2107 - accuracy: 0.9027 - val_loss: 1.5555 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01352: val_loss did not improve from 0.38514\n",
      "Epoch 1353/3000\n",
      "13/13 - 0s - loss: 0.2056 - accuracy: 0.9001 - val_loss: 1.5099 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01353: val_loss did not improve from 0.38514\n",
      "Epoch 1354/3000\n",
      "13/13 - 0s - loss: 0.2052 - accuracy: 0.9027 - val_loss: 1.4301 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01354: val_loss did not improve from 0.38514\n",
      "Epoch 1355/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.9027 - val_loss: 1.3191 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01355: val_loss did not improve from 0.38514\n",
      "Epoch 1356/3000\n",
      "13/13 - 0s - loss: 0.2085 - accuracy: 0.9027 - val_loss: 1.3957 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01356: val_loss did not improve from 0.38514\n",
      "Epoch 1357/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.9001 - val_loss: 1.4543 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01357: val_loss did not improve from 0.38514\n",
      "Epoch 1358/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.9014 - val_loss: 1.5374 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01358: val_loss did not improve from 0.38514\n",
      "Epoch 1359/3000\n",
      "13/13 - 0s - loss: 0.2102 - accuracy: 0.9014 - val_loss: 1.5304 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01359: val_loss did not improve from 0.38514\n",
      "Epoch 1360/3000\n",
      "13/13 - 0s - loss: 0.2195 - accuracy: 0.9027 - val_loss: 0.9679 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01360: val_loss did not improve from 0.38514\n",
      "Epoch 1361/3000\n",
      "13/13 - 0s - loss: 0.2323 - accuracy: 0.8975 - val_loss: 1.0233 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01361: val_loss did not improve from 0.38514\n",
      "Epoch 1362/3000\n",
      "13/13 - 0s - loss: 0.2408 - accuracy: 0.8962 - val_loss: 1.4199 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01362: val_loss did not improve from 0.38514\n",
      "Epoch 1363/3000\n",
      "13/13 - 0s - loss: 0.3632 - accuracy: 0.8859 - val_loss: 0.9372 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01363: val_loss did not improve from 0.38514\n",
      "Epoch 1364/3000\n",
      "13/13 - 0s - loss: 0.2878 - accuracy: 0.8898 - val_loss: 1.1407 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01364: val_loss did not improve from 0.38514\n",
      "Epoch 1365/3000\n",
      "13/13 - 0s - loss: 0.2425 - accuracy: 0.8768 - val_loss: 0.8950 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 01365: val_loss did not improve from 0.38514\n",
      "Epoch 1366/3000\n",
      "13/13 - 0s - loss: 0.2648 - accuracy: 0.8781 - val_loss: 0.7019 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 01366: val_loss did not improve from 0.38514\n",
      "Epoch 1367/3000\n",
      "13/13 - 0s - loss: 0.2668 - accuracy: 0.8729 - val_loss: 0.5691 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01367: val_loss did not improve from 0.38514\n",
      "Epoch 1368/3000\n",
      "13/13 - 0s - loss: 0.2390 - accuracy: 0.8898 - val_loss: 0.5182 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01368: val_loss did not improve from 0.38514\n",
      "Epoch 1369/3000\n",
      "13/13 - 0s - loss: 0.2244 - accuracy: 0.8898 - val_loss: 0.5721 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01369: val_loss did not improve from 0.38514\n",
      "Epoch 1370/3000\n",
      "13/13 - 0s - loss: 0.2279 - accuracy: 0.8911 - val_loss: 0.6357 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01370: val_loss did not improve from 0.38514\n",
      "Epoch 1371/3000\n",
      "13/13 - 0s - loss: 0.2196 - accuracy: 0.8936 - val_loss: 0.7122 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01371: val_loss did not improve from 0.38514\n",
      "Epoch 1372/3000\n",
      "13/13 - 0s - loss: 0.2157 - accuracy: 0.8962 - val_loss: 0.7520 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01372: val_loss did not improve from 0.38514\n",
      "Epoch 1373/3000\n",
      "13/13 - 0s - loss: 0.2158 - accuracy: 0.8911 - val_loss: 0.7221 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01373: val_loss did not improve from 0.38514\n",
      "Epoch 1374/3000\n",
      "13/13 - 0s - loss: 0.2144 - accuracy: 0.8975 - val_loss: 0.7212 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01374: val_loss did not improve from 0.38514\n",
      "Epoch 1375/3000\n",
      "13/13 - 0s - loss: 0.2105 - accuracy: 0.9001 - val_loss: 0.7441 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01375: val_loss did not improve from 0.38514\n",
      "Epoch 1376/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.8962 - val_loss: 0.7569 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01376: val_loss did not improve from 0.38514\n",
      "Epoch 1377/3000\n",
      "13/13 - 0s - loss: 0.2073 - accuracy: 0.9014 - val_loss: 0.7650 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01377: val_loss did not improve from 0.38514\n",
      "Epoch 1378/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.9027 - val_loss: 0.7816 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01378: val_loss did not improve from 0.38514\n",
      "Epoch 1379/3000\n",
      "13/13 - 0s - loss: 0.2061 - accuracy: 0.9027 - val_loss: 0.7514 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01379: val_loss did not improve from 0.38514\n",
      "Epoch 1380/3000\n",
      "13/13 - 0s - loss: 0.2093 - accuracy: 0.9001 - val_loss: 0.7582 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01380: val_loss did not improve from 0.38514\n",
      "Epoch 1381/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.8988 - val_loss: 0.7718 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01381: val_loss did not improve from 0.38514\n",
      "Epoch 1382/3000\n",
      "13/13 - 0s - loss: 0.2068 - accuracy: 0.8988 - val_loss: 0.7892 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01382: val_loss did not improve from 0.38514\n",
      "Epoch 1383/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.9001 - val_loss: 0.7821 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01383: val_loss did not improve from 0.38514\n",
      "Epoch 1384/3000\n",
      "13/13 - 0s - loss: 0.2078 - accuracy: 0.9040 - val_loss: 0.7451 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01384: val_loss did not improve from 0.38514\n",
      "Epoch 1385/3000\n",
      "13/13 - 0s - loss: 0.2061 - accuracy: 0.9027 - val_loss: 0.7510 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01385: val_loss did not improve from 0.38514\n",
      "Epoch 1386/3000\n",
      "13/13 - 0s - loss: 0.2044 - accuracy: 0.9001 - val_loss: 0.7404 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01386: val_loss did not improve from 0.38514\n",
      "Epoch 1387/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.8949 - val_loss: 0.7427 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01387: val_loss did not improve from 0.38514\n",
      "Epoch 1388/3000\n",
      "13/13 - 0s - loss: 0.2047 - accuracy: 0.8975 - val_loss: 0.7433 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01388: val_loss did not improve from 0.38514\n",
      "Epoch 1389/3000\n",
      "13/13 - 0s - loss: 0.2225 - accuracy: 0.8794 - val_loss: 0.9421 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01389: val_loss did not improve from 0.38514\n",
      "Epoch 1390/3000\n",
      "13/13 - 0s - loss: 0.2284 - accuracy: 0.8911 - val_loss: 0.7046 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01390: val_loss did not improve from 0.38514\n",
      "Epoch 1391/3000\n",
      "13/13 - 0s - loss: 0.2146 - accuracy: 0.8962 - val_loss: 0.6902 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01391: val_loss did not improve from 0.38514\n",
      "Epoch 1392/3000\n",
      "13/13 - 0s - loss: 0.2118 - accuracy: 0.9027 - val_loss: 0.7335 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01392: val_loss did not improve from 0.38514\n",
      "Epoch 1393/3000\n",
      "13/13 - 0s - loss: 0.2083 - accuracy: 0.9027 - val_loss: 0.7328 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01393: val_loss did not improve from 0.38514\n",
      "Epoch 1394/3000\n",
      "13/13 - 0s - loss: 0.2080 - accuracy: 0.8988 - val_loss: 0.7608 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01394: val_loss did not improve from 0.38514\n",
      "Epoch 1395/3000\n",
      "13/13 - 0s - loss: 0.2087 - accuracy: 0.9027 - val_loss: 0.7670 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01395: val_loss did not improve from 0.38514\n",
      "Epoch 1396/3000\n",
      "13/13 - 0s - loss: 0.2076 - accuracy: 0.9014 - val_loss: 0.7682 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01396: val_loss did not improve from 0.38514\n",
      "Epoch 1397/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.9027 - val_loss: 0.7796 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01397: val_loss did not improve from 0.38514\n",
      "Epoch 1398/3000\n",
      "13/13 - 0s - loss: 0.2051 - accuracy: 0.9014 - val_loss: 0.7765 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01398: val_loss did not improve from 0.38514\n",
      "Epoch 1399/3000\n",
      "13/13 - 0s - loss: 0.2044 - accuracy: 0.9027 - val_loss: 0.7974 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01399: val_loss did not improve from 0.38514\n",
      "Epoch 1400/3000\n",
      "13/13 - 0s - loss: 0.2041 - accuracy: 0.8988 - val_loss: 0.8223 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01400: val_loss did not improve from 0.38514\n",
      "Epoch 1401/3000\n",
      "13/13 - 0s - loss: 0.2046 - accuracy: 0.9014 - val_loss: 0.8282 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01401: val_loss did not improve from 0.38514\n",
      "Epoch 1402/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.8988 - val_loss: 0.8375 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01402: val_loss did not improve from 0.38514\n",
      "Epoch 1403/3000\n",
      "13/13 - 0s - loss: 0.2052 - accuracy: 0.9014 - val_loss: 0.8431 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01403: val_loss did not improve from 0.38514\n",
      "Epoch 1404/3000\n",
      "13/13 - 0s - loss: 0.2059 - accuracy: 0.9014 - val_loss: 0.8154 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01404: val_loss did not improve from 0.38514\n",
      "Epoch 1405/3000\n",
      "13/13 - 0s - loss: 0.2046 - accuracy: 0.9040 - val_loss: 0.8273 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01405: val_loss did not improve from 0.38514\n",
      "Epoch 1406/3000\n",
      "13/13 - 0s - loss: 0.2060 - accuracy: 0.9001 - val_loss: 0.8242 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01406: val_loss did not improve from 0.38514\n",
      "Epoch 1407/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.9001 - val_loss: 0.8374 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01407: val_loss did not improve from 0.38514\n",
      "Epoch 1408/3000\n",
      "13/13 - 0s - loss: 0.2036 - accuracy: 0.9014 - val_loss: 0.8499 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01408: val_loss did not improve from 0.38514\n",
      "Epoch 1409/3000\n",
      "13/13 - 0s - loss: 0.2038 - accuracy: 0.9027 - val_loss: 0.8301 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01409: val_loss did not improve from 0.38514\n",
      "Epoch 1410/3000\n",
      "13/13 - 0s - loss: 0.2064 - accuracy: 0.9027 - val_loss: 0.8409 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01410: val_loss did not improve from 0.38514\n",
      "Epoch 1411/3000\n",
      "13/13 - 0s - loss: 0.2048 - accuracy: 0.9027 - val_loss: 0.8246 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01411: val_loss did not improve from 0.38514\n",
      "Epoch 1412/3000\n",
      "13/13 - 0s - loss: 0.2034 - accuracy: 0.9040 - val_loss: 0.8235 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01412: val_loss did not improve from 0.38514\n",
      "Epoch 1413/3000\n",
      "13/13 - 0s - loss: 0.2036 - accuracy: 0.9027 - val_loss: 0.8196 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01413: val_loss did not improve from 0.38514\n",
      "Epoch 1414/3000\n",
      "13/13 - 0s - loss: 0.2024 - accuracy: 0.9014 - val_loss: 0.8358 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01414: val_loss did not improve from 0.38514\n",
      "Epoch 1415/3000\n",
      "13/13 - 0s - loss: 0.2038 - accuracy: 0.9001 - val_loss: 0.8563 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01415: val_loss did not improve from 0.38514\n",
      "Epoch 1416/3000\n",
      "13/13 - 0s - loss: 0.2029 - accuracy: 0.9014 - val_loss: 0.8369 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01416: val_loss did not improve from 0.38514\n",
      "Epoch 1417/3000\n",
      "13/13 - 0s - loss: 0.2019 - accuracy: 0.9014 - val_loss: 0.8340 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01417: val_loss did not improve from 0.38514\n",
      "Epoch 1418/3000\n",
      "13/13 - 0s - loss: 0.2034 - accuracy: 0.9014 - val_loss: 0.8243 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01418: val_loss did not improve from 0.38514\n",
      "Epoch 1419/3000\n",
      "13/13 - 0s - loss: 0.2058 - accuracy: 0.9027 - val_loss: 0.8444 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01419: val_loss did not improve from 0.38514\n",
      "Epoch 1420/3000\n",
      "13/13 - 0s - loss: 0.2031 - accuracy: 0.9027 - val_loss: 0.8698 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01420: val_loss did not improve from 0.38514\n",
      "Epoch 1421/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9040 - val_loss: 0.8341 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01421: val_loss did not improve from 0.38514\n",
      "Epoch 1422/3000\n",
      "13/13 - 0s - loss: 0.2051 - accuracy: 0.9027 - val_loss: 0.8252 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01422: val_loss did not improve from 0.38514\n",
      "Epoch 1423/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.9027 - val_loss: 0.8334 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01423: val_loss did not improve from 0.38514\n",
      "Epoch 1424/3000\n",
      "13/13 - 0s - loss: 0.2091 - accuracy: 0.8988 - val_loss: 0.9058 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01424: val_loss did not improve from 0.38514\n",
      "Epoch 1425/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.9001 - val_loss: 0.9263 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01425: val_loss did not improve from 0.38514\n",
      "Epoch 1426/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.9001 - val_loss: 0.9064 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01426: val_loss did not improve from 0.38514\n",
      "Epoch 1427/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.9027 - val_loss: 0.8877 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01427: val_loss did not improve from 0.38514\n",
      "Epoch 1428/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.8988 - val_loss: 0.8809 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01428: val_loss did not improve from 0.38514\n",
      "Epoch 1429/3000\n",
      "13/13 - 0s - loss: 0.2049 - accuracy: 0.8988 - val_loss: 0.8789 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01429: val_loss did not improve from 0.38514\n",
      "Epoch 1430/3000\n",
      "13/13 - 0s - loss: 0.2051 - accuracy: 0.9027 - val_loss: 0.7876 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01430: val_loss did not improve from 0.38514\n",
      "Epoch 1431/3000\n",
      "13/13 - 0s - loss: 0.2061 - accuracy: 0.9014 - val_loss: 0.7512 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01431: val_loss did not improve from 0.38514\n",
      "Epoch 1432/3000\n",
      "13/13 - 0s - loss: 0.2123 - accuracy: 0.9014 - val_loss: 0.7514 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01432: val_loss did not improve from 0.38514\n",
      "Epoch 1433/3000\n",
      "13/13 - 0s - loss: 0.2100 - accuracy: 0.9040 - val_loss: 0.7233 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01433: val_loss did not improve from 0.38514\n",
      "Epoch 1434/3000\n",
      "13/13 - 0s - loss: 0.2094 - accuracy: 0.9001 - val_loss: 0.7228 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01434: val_loss did not improve from 0.38514\n",
      "Epoch 1435/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.8988 - val_loss: 0.7262 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01435: val_loss did not improve from 0.38514\n",
      "Epoch 1436/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.9001 - val_loss: 0.7310 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01436: val_loss did not improve from 0.38514\n",
      "Epoch 1437/3000\n",
      "13/13 - 0s - loss: 0.2069 - accuracy: 0.8975 - val_loss: 0.7179 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01437: val_loss did not improve from 0.38514\n",
      "Epoch 1438/3000\n",
      "13/13 - 0s - loss: 0.2068 - accuracy: 0.8988 - val_loss: 0.7189 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01438: val_loss did not improve from 0.38514\n",
      "Epoch 1439/3000\n",
      "13/13 - 0s - loss: 0.2082 - accuracy: 0.8949 - val_loss: 0.6946 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01439: val_loss did not improve from 0.38514\n",
      "Epoch 1440/3000\n",
      "13/13 - 0s - loss: 0.2069 - accuracy: 0.8975 - val_loss: 0.7094 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01440: val_loss did not improve from 0.38514\n",
      "Epoch 1441/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.9014 - val_loss: 0.7395 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01441: val_loss did not improve from 0.38514\n",
      "Epoch 1442/3000\n",
      "13/13 - 0s - loss: 0.2066 - accuracy: 0.9040 - val_loss: 0.7490 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01442: val_loss did not improve from 0.38514\n",
      "Epoch 1443/3000\n",
      "13/13 - 0s - loss: 0.2061 - accuracy: 0.9027 - val_loss: 0.7731 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01443: val_loss did not improve from 0.38514\n",
      "Epoch 1444/3000\n",
      "13/13 - 0s - loss: 0.2076 - accuracy: 0.9014 - val_loss: 0.7673 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01444: val_loss did not improve from 0.38514\n",
      "Epoch 1445/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.8962 - val_loss: 0.7566 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01445: val_loss did not improve from 0.38514\n",
      "Epoch 1446/3000\n",
      "13/13 - 0s - loss: 0.2056 - accuracy: 0.8962 - val_loss: 0.7284 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01446: val_loss did not improve from 0.38514\n",
      "Epoch 1447/3000\n",
      "13/13 - 0s - loss: 0.2082 - accuracy: 0.9001 - val_loss: 0.6851 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01447: val_loss did not improve from 0.38514\n",
      "Epoch 1448/3000\n",
      "13/13 - 0s - loss: 0.2155 - accuracy: 0.8923 - val_loss: 0.6949 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01448: val_loss did not improve from 0.38514\n",
      "Epoch 1449/3000\n",
      "13/13 - 0s - loss: 0.2109 - accuracy: 0.8962 - val_loss: 0.7099 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01449: val_loss did not improve from 0.38514\n",
      "Epoch 1450/3000\n",
      "13/13 - 0s - loss: 0.2058 - accuracy: 0.9001 - val_loss: 0.7290 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01450: val_loss did not improve from 0.38514\n",
      "Epoch 1451/3000\n",
      "13/13 - 0s - loss: 0.2056 - accuracy: 0.8988 - val_loss: 0.7501 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01451: val_loss did not improve from 0.38514\n",
      "Epoch 1452/3000\n",
      "13/13 - 0s - loss: 0.2098 - accuracy: 0.8949 - val_loss: 0.7440 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01452: val_loss did not improve from 0.38514\n",
      "Epoch 1453/3000\n",
      "13/13 - 0s - loss: 0.2078 - accuracy: 0.8936 - val_loss: 0.6958 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01453: val_loss did not improve from 0.38514\n",
      "Epoch 1454/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.8975 - val_loss: 0.6517 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01454: val_loss did not improve from 0.38514\n",
      "Epoch 1455/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.8962 - val_loss: 0.6424 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01455: val_loss did not improve from 0.38514\n",
      "Epoch 1456/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.8975 - val_loss: 0.6723 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01456: val_loss did not improve from 0.38514\n",
      "Epoch 1457/3000\n",
      "13/13 - 0s - loss: 0.2080 - accuracy: 0.8936 - val_loss: 0.6807 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01457: val_loss did not improve from 0.38514\n",
      "Epoch 1458/3000\n",
      "13/13 - 0s - loss: 0.2077 - accuracy: 0.8962 - val_loss: 0.6895 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01458: val_loss did not improve from 0.38514\n",
      "Epoch 1459/3000\n",
      "13/13 - 0s - loss: 0.2059 - accuracy: 0.8988 - val_loss: 0.6946 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01459: val_loss did not improve from 0.38514\n",
      "Epoch 1460/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.8975 - val_loss: 0.7081 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01460: val_loss did not improve from 0.38514\n",
      "Epoch 1461/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.8975 - val_loss: 0.7089 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01461: val_loss did not improve from 0.38514\n",
      "Epoch 1462/3000\n",
      "13/13 - 0s - loss: 0.2091 - accuracy: 0.8975 - val_loss: 0.7492 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01462: val_loss did not improve from 0.38514\n",
      "Epoch 1463/3000\n",
      "13/13 - 0s - loss: 0.2096 - accuracy: 0.8923 - val_loss: 0.7916 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01463: val_loss did not improve from 0.38514\n",
      "Epoch 1464/3000\n",
      "13/13 - 0s - loss: 0.2106 - accuracy: 0.8936 - val_loss: 0.8316 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01464: val_loss did not improve from 0.38514\n",
      "Epoch 1465/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.8962 - val_loss: 0.8471 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01465: val_loss did not improve from 0.38514\n",
      "Epoch 1466/3000\n",
      "13/13 - 0s - loss: 0.2056 - accuracy: 0.8962 - val_loss: 0.8778 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01466: val_loss did not improve from 0.38514\n",
      "Epoch 1467/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.8962 - val_loss: 0.8665 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01467: val_loss did not improve from 0.38514\n",
      "Epoch 1468/3000\n",
      "13/13 - 0s - loss: 0.2240 - accuracy: 0.8936 - val_loss: 0.8609 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01468: val_loss did not improve from 0.38514\n",
      "Epoch 1469/3000\n",
      "13/13 - 0s - loss: 0.2143 - accuracy: 0.8975 - val_loss: 0.9883 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01469: val_loss did not improve from 0.38514\n",
      "Epoch 1470/3000\n",
      "13/13 - 0s - loss: 0.2095 - accuracy: 0.9014 - val_loss: 0.9860 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01470: val_loss did not improve from 0.38514\n",
      "Epoch 1471/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.8988 - val_loss: 1.0136 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01471: val_loss did not improve from 0.38514\n",
      "Epoch 1472/3000\n",
      "13/13 - 0s - loss: 0.2106 - accuracy: 0.9001 - val_loss: 1.0248 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01472: val_loss did not improve from 0.38514\n",
      "Epoch 1473/3000\n",
      "13/13 - 0s - loss: 0.2126 - accuracy: 0.9014 - val_loss: 1.0299 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01473: val_loss did not improve from 0.38514\n",
      "Epoch 1474/3000\n",
      "13/13 - 0s - loss: 0.2154 - accuracy: 0.8936 - val_loss: 0.9872 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01474: val_loss did not improve from 0.38514\n",
      "Epoch 1475/3000\n",
      "13/13 - 1s - loss: 0.2132 - accuracy: 0.8923 - val_loss: 1.0234 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01475: val_loss did not improve from 0.38514\n",
      "Epoch 1476/3000\n",
      "13/13 - 1s - loss: 0.2093 - accuracy: 0.9001 - val_loss: 1.0578 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01476: val_loss did not improve from 0.38514\n",
      "Epoch 1477/3000\n",
      "13/13 - 1s - loss: 0.2102 - accuracy: 0.8988 - val_loss: 1.0745 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01477: val_loss did not improve from 0.38514\n",
      "Epoch 1478/3000\n",
      "13/13 - 0s - loss: 0.2098 - accuracy: 0.8975 - val_loss: 1.1088 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01478: val_loss did not improve from 0.38514\n",
      "Epoch 1479/3000\n",
      "13/13 - 0s - loss: 0.2092 - accuracy: 0.8975 - val_loss: 1.1124 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01479: val_loss did not improve from 0.38514\n",
      "Epoch 1480/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.9014 - val_loss: 1.1270 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01480: val_loss did not improve from 0.38514\n",
      "Epoch 1481/3000\n",
      "13/13 - 0s - loss: 0.2066 - accuracy: 0.9014 - val_loss: 1.2355 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01481: val_loss did not improve from 0.38514\n",
      "Epoch 1482/3000\n",
      "13/13 - 0s - loss: 0.2067 - accuracy: 0.8975 - val_loss: 1.2223 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01482: val_loss did not improve from 0.38514\n",
      "Epoch 1483/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.8975 - val_loss: 1.1546 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01483: val_loss did not improve from 0.38514\n",
      "Epoch 1484/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.8949 - val_loss: 1.2353 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01484: val_loss did not improve from 0.38514\n",
      "Epoch 1485/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.9014 - val_loss: 1.2636 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01485: val_loss did not improve from 0.38514\n",
      "Epoch 1486/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.8988 - val_loss: 1.2828 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01486: val_loss did not improve from 0.38514\n",
      "Epoch 1487/3000\n",
      "13/13 - 0s - loss: 0.2061 - accuracy: 0.8988 - val_loss: 1.2171 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01487: val_loss did not improve from 0.38514\n",
      "Epoch 1488/3000\n",
      "13/13 - 0s - loss: 0.2048 - accuracy: 0.9027 - val_loss: 1.1684 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01488: val_loss did not improve from 0.38514\n",
      "Epoch 1489/3000\n",
      "13/13 - 0s - loss: 0.2044 - accuracy: 0.9027 - val_loss: 1.1517 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01489: val_loss did not improve from 0.38514\n",
      "Epoch 1490/3000\n",
      "13/13 - 0s - loss: 0.2108 - accuracy: 0.9001 - val_loss: 1.1721 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01490: val_loss did not improve from 0.38514\n",
      "Epoch 1491/3000\n",
      "13/13 - 0s - loss: 0.2077 - accuracy: 0.9014 - val_loss: 1.2747 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01491: val_loss did not improve from 0.38514\n",
      "Epoch 1492/3000\n",
      "13/13 - 0s - loss: 0.2061 - accuracy: 0.9027 - val_loss: 1.3876 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01492: val_loss did not improve from 0.38514\n",
      "Epoch 1493/3000\n",
      "13/13 - 0s - loss: 0.2059 - accuracy: 0.8988 - val_loss: 1.4560 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01493: val_loss did not improve from 0.38514\n",
      "Epoch 1494/3000\n",
      "13/13 - 0s - loss: 0.2046 - accuracy: 0.9014 - val_loss: 1.4571 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01494: val_loss did not improve from 0.38514\n",
      "Epoch 1495/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.9001 - val_loss: 1.4506 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01495: val_loss did not improve from 0.38514\n",
      "Epoch 1496/3000\n",
      "13/13 - 0s - loss: 0.2048 - accuracy: 0.9027 - val_loss: 1.5352 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01496: val_loss did not improve from 0.38514\n",
      "Epoch 1497/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.9027 - val_loss: 1.5351 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01497: val_loss did not improve from 0.38514\n",
      "Epoch 1498/3000\n",
      "13/13 - 0s - loss: 0.2060 - accuracy: 0.9014 - val_loss: 1.5814 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01498: val_loss did not improve from 0.38514\n",
      "Epoch 1499/3000\n",
      "13/13 - 0s - loss: 0.2051 - accuracy: 0.9027 - val_loss: 1.5469 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01499: val_loss did not improve from 0.38514\n",
      "Epoch 1500/3000\n",
      "13/13 - 0s - loss: 0.2044 - accuracy: 0.9027 - val_loss: 1.5157 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01500: val_loss did not improve from 0.38514\n",
      "Epoch 1501/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.9027 - val_loss: 1.5346 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01501: val_loss did not improve from 0.38514\n",
      "Epoch 1502/3000\n",
      "13/13 - 0s - loss: 0.2043 - accuracy: 0.9027 - val_loss: 1.5086 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01502: val_loss did not improve from 0.38514\n",
      "Epoch 1503/3000\n",
      "13/13 - 0s - loss: 0.2043 - accuracy: 0.9027 - val_loss: 1.4512 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01503: val_loss did not improve from 0.38514\n",
      "Epoch 1504/3000\n",
      "13/13 - 0s - loss: 0.2038 - accuracy: 0.9027 - val_loss: 1.4294 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01504: val_loss did not improve from 0.38514\n",
      "Epoch 1505/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9027 - val_loss: 1.3711 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01505: val_loss did not improve from 0.38514\n",
      "Epoch 1506/3000\n",
      "13/13 - 0s - loss: 0.2029 - accuracy: 0.9027 - val_loss: 1.3373 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01506: val_loss did not improve from 0.38514\n",
      "Epoch 1507/3000\n",
      "13/13 - 0s - loss: 0.2047 - accuracy: 0.9027 - val_loss: 1.2815 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01507: val_loss did not improve from 0.38514\n",
      "Epoch 1508/3000\n",
      "13/13 - 0s - loss: 0.2046 - accuracy: 0.9027 - val_loss: 1.2707 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01508: val_loss did not improve from 0.38514\n",
      "Epoch 1509/3000\n",
      "13/13 - 0s - loss: 0.2017 - accuracy: 0.9027 - val_loss: 1.3258 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01509: val_loss did not improve from 0.38514\n",
      "Epoch 1510/3000\n",
      "13/13 - 0s - loss: 0.2183 - accuracy: 0.9014 - val_loss: 1.3304 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01510: val_loss did not improve from 0.38514\n",
      "Epoch 1511/3000\n",
      "13/13 - 0s - loss: 0.2048 - accuracy: 0.9027 - val_loss: 1.3916 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01511: val_loss did not improve from 0.38514\n",
      "Epoch 1512/3000\n",
      "13/13 - 0s - loss: 0.2065 - accuracy: 0.9027 - val_loss: 1.4016 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01512: val_loss did not improve from 0.38514\n",
      "Epoch 1513/3000\n",
      "13/13 - 0s - loss: 0.2047 - accuracy: 0.9014 - val_loss: 1.3707 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01513: val_loss did not improve from 0.38514\n",
      "Epoch 1514/3000\n",
      "13/13 - 0s - loss: 0.2036 - accuracy: 0.9027 - val_loss: 1.3228 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01514: val_loss did not improve from 0.38514\n",
      "Epoch 1515/3000\n",
      "13/13 - 0s - loss: 0.2040 - accuracy: 0.9027 - val_loss: 1.3103 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01515: val_loss did not improve from 0.38514\n",
      "Epoch 1516/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9027 - val_loss: 1.2865 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01516: val_loss did not improve from 0.38514\n",
      "Epoch 1517/3000\n",
      "13/13 - 0s - loss: 0.2025 - accuracy: 0.9027 - val_loss: 1.2763 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01517: val_loss did not improve from 0.38514\n",
      "Epoch 1518/3000\n",
      "13/13 - 0s - loss: 0.2028 - accuracy: 0.9027 - val_loss: 1.2729 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01518: val_loss did not improve from 0.38514\n",
      "Epoch 1519/3000\n",
      "13/13 - 0s - loss: 0.2030 - accuracy: 0.9014 - val_loss: 1.2786 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01519: val_loss did not improve from 0.38514\n",
      "Epoch 1520/3000\n",
      "13/13 - 0s - loss: 0.2032 - accuracy: 0.9027 - val_loss: 1.2701 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01520: val_loss did not improve from 0.38514\n",
      "Epoch 1521/3000\n",
      "13/13 - 0s - loss: 0.2017 - accuracy: 0.9027 - val_loss: 1.2791 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01521: val_loss did not improve from 0.38514\n",
      "Epoch 1522/3000\n",
      "13/13 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 1.2927 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01522: val_loss did not improve from 0.38514\n",
      "Epoch 1523/3000\n",
      "13/13 - 0s - loss: 0.2026 - accuracy: 0.9027 - val_loss: 1.2940 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01523: val_loss did not improve from 0.38514\n",
      "Epoch 1524/3000\n",
      "13/13 - 0s - loss: 0.2038 - accuracy: 0.9040 - val_loss: 1.2465 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01524: val_loss did not improve from 0.38514\n",
      "Epoch 1525/3000\n",
      "13/13 - 0s - loss: 0.2036 - accuracy: 0.9040 - val_loss: 1.1420 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01525: val_loss did not improve from 0.38514\n",
      "Epoch 1526/3000\n",
      "13/13 - 0s - loss: 0.2028 - accuracy: 0.9040 - val_loss: 1.1958 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01526: val_loss did not improve from 0.38514\n",
      "Epoch 1527/3000\n",
      "13/13 - 0s - loss: 0.2032 - accuracy: 0.9027 - val_loss: 1.2224 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01527: val_loss did not improve from 0.38514\n",
      "Epoch 1528/3000\n",
      "13/13 - 0s - loss: 0.2028 - accuracy: 0.9027 - val_loss: 1.1927 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01528: val_loss did not improve from 0.38514\n",
      "Epoch 1529/3000\n",
      "13/13 - 0s - loss: 0.2027 - accuracy: 0.9027 - val_loss: 1.1813 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01529: val_loss did not improve from 0.38514\n",
      "Epoch 1530/3000\n",
      "13/13 - 0s - loss: 0.2020 - accuracy: 0.8988 - val_loss: 1.1794 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01530: val_loss did not improve from 0.38514\n",
      "Epoch 1531/3000\n",
      "13/13 - 0s - loss: 0.2017 - accuracy: 0.9001 - val_loss: 1.1985 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01531: val_loss did not improve from 0.38514\n",
      "Epoch 1532/3000\n",
      "13/13 - 0s - loss: 0.2030 - accuracy: 0.9001 - val_loss: 1.2405 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01532: val_loss did not improve from 0.38514\n",
      "Epoch 1533/3000\n",
      "13/13 - 0s - loss: 0.2018 - accuracy: 0.9014 - val_loss: 1.2368 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01533: val_loss did not improve from 0.38514\n",
      "Epoch 1534/3000\n",
      "13/13 - 0s - loss: 0.2034 - accuracy: 0.8988 - val_loss: 1.2479 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01534: val_loss did not improve from 0.38514\n",
      "Epoch 1535/3000\n",
      "13/13 - 0s - loss: 0.2026 - accuracy: 0.8962 - val_loss: 1.2143 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01535: val_loss did not improve from 0.38514\n",
      "Epoch 1536/3000\n",
      "13/13 - 0s - loss: 0.2020 - accuracy: 0.9027 - val_loss: 1.2043 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01536: val_loss did not improve from 0.38514\n",
      "Epoch 1537/3000\n",
      "13/13 - 0s - loss: 0.2024 - accuracy: 0.9001 - val_loss: 1.1874 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01537: val_loss did not improve from 0.38514\n",
      "Epoch 1538/3000\n",
      "13/13 - 0s - loss: 0.2017 - accuracy: 0.9001 - val_loss: 1.1780 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01538: val_loss did not improve from 0.38514\n",
      "Epoch 1539/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9027 - val_loss: 1.2556 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01539: val_loss did not improve from 0.38514\n",
      "Epoch 1540/3000\n",
      "13/13 - 0s - loss: 0.2040 - accuracy: 0.9014 - val_loss: 1.2758 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01540: val_loss did not improve from 0.38514\n",
      "Epoch 1541/3000\n",
      "13/13 - 0s - loss: 0.2031 - accuracy: 0.9027 - val_loss: 1.3180 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01541: val_loss did not improve from 0.38514\n",
      "Epoch 1542/3000\n",
      "13/13 - 0s - loss: 0.2027 - accuracy: 0.9027 - val_loss: 1.3749 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01542: val_loss did not improve from 0.38514\n",
      "Epoch 1543/3000\n",
      "13/13 - 0s - loss: 0.2039 - accuracy: 0.9027 - val_loss: 1.3222 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01543: val_loss did not improve from 0.38514\n",
      "Epoch 1544/3000\n",
      "13/13 - 0s - loss: 0.2091 - accuracy: 0.9001 - val_loss: 1.2731 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01544: val_loss did not improve from 0.38514\n",
      "Epoch 1545/3000\n",
      "13/13 - 0s - loss: 0.2082 - accuracy: 0.9027 - val_loss: 1.1618 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01545: val_loss did not improve from 0.38514\n",
      "Epoch 1546/3000\n",
      "13/13 - 0s - loss: 0.2216 - accuracy: 0.8923 - val_loss: 1.1484 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01546: val_loss did not improve from 0.38514\n",
      "Epoch 1547/3000\n",
      "13/13 - 0s - loss: 0.2267 - accuracy: 0.8962 - val_loss: 1.2652 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01547: val_loss did not improve from 0.38514\n",
      "Epoch 1548/3000\n",
      "13/13 - 0s - loss: 0.2619 - accuracy: 0.8923 - val_loss: 0.8280 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01548: val_loss did not improve from 0.38514\n",
      "Epoch 1549/3000\n",
      "13/13 - 0s - loss: 0.2324 - accuracy: 0.8923 - val_loss: 0.6120 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01549: val_loss did not improve from 0.38514\n",
      "Epoch 1550/3000\n",
      "13/13 - 0s - loss: 0.2174 - accuracy: 0.8936 - val_loss: 0.6783 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01550: val_loss did not improve from 0.38514\n",
      "Epoch 1551/3000\n",
      "13/13 - 0s - loss: 0.2124 - accuracy: 0.8859 - val_loss: 0.6871 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01551: val_loss did not improve from 0.38514\n",
      "Epoch 1552/3000\n",
      "13/13 - 0s - loss: 0.2089 - accuracy: 0.8923 - val_loss: 0.7289 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01552: val_loss did not improve from 0.38514\n",
      "Epoch 1553/3000\n",
      "13/13 - 0s - loss: 0.2051 - accuracy: 0.8923 - val_loss: 0.7645 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01553: val_loss did not improve from 0.38514\n",
      "Epoch 1554/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.8962 - val_loss: 0.7970 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01554: val_loss did not improve from 0.38514\n",
      "Epoch 1555/3000\n",
      "13/13 - 0s - loss: 0.2039 - accuracy: 0.9001 - val_loss: 0.7915 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01555: val_loss did not improve from 0.38514\n",
      "Epoch 1556/3000\n",
      "13/13 - 0s - loss: 0.2065 - accuracy: 0.9001 - val_loss: 0.7700 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01556: val_loss did not improve from 0.38514\n",
      "Epoch 1557/3000\n",
      "13/13 - 0s - loss: 0.2039 - accuracy: 0.9027 - val_loss: 0.7478 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01557: val_loss did not improve from 0.38514\n",
      "Epoch 1558/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9027 - val_loss: 0.7520 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01558: val_loss did not improve from 0.38514\n",
      "Epoch 1559/3000\n",
      "13/13 - 0s - loss: 0.2028 - accuracy: 0.9027 - val_loss: 0.7259 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01559: val_loss did not improve from 0.38514\n",
      "Epoch 1560/3000\n",
      "13/13 - 0s - loss: 0.2064 - accuracy: 0.9001 - val_loss: 0.7079 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01560: val_loss did not improve from 0.38514\n",
      "Epoch 1561/3000\n",
      "13/13 - 0s - loss: 0.2029 - accuracy: 0.9001 - val_loss: 0.7203 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01561: val_loss did not improve from 0.38514\n",
      "Epoch 1562/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9027 - val_loss: 0.7442 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01562: val_loss did not improve from 0.38514\n",
      "Epoch 1563/3000\n",
      "13/13 - 0s - loss: 0.2046 - accuracy: 0.9027 - val_loss: 0.7417 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01563: val_loss did not improve from 0.38514\n",
      "Epoch 1564/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.9014 - val_loss: 0.7409 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01564: val_loss did not improve from 0.38514\n",
      "Epoch 1565/3000\n",
      "13/13 - 0s - loss: 0.2036 - accuracy: 0.9014 - val_loss: 0.7113 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01565: val_loss did not improve from 0.38514\n",
      "Epoch 1566/3000\n",
      "13/13 - 0s - loss: 0.2085 - accuracy: 0.9027 - val_loss: 0.7165 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01566: val_loss did not improve from 0.38514\n",
      "Epoch 1567/3000\n",
      "13/13 - 0s - loss: 0.2105 - accuracy: 0.9027 - val_loss: 0.6544 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01567: val_loss did not improve from 0.38514\n",
      "Epoch 1568/3000\n",
      "13/13 - 0s - loss: 0.2110 - accuracy: 0.9014 - val_loss: 0.6370 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01568: val_loss did not improve from 0.38514\n",
      "Epoch 1569/3000\n",
      "13/13 - 0s - loss: 0.2070 - accuracy: 0.9027 - val_loss: 0.7789 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01569: val_loss did not improve from 0.38514\n",
      "Epoch 1570/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.9027 - val_loss: 0.6326 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01570: val_loss did not improve from 0.38514\n",
      "Epoch 1571/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9001 - val_loss: 0.6249 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01571: val_loss did not improve from 0.38514\n",
      "Epoch 1572/3000\n",
      "13/13 - 0s - loss: 0.2038 - accuracy: 0.9027 - val_loss: 0.6424 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01572: val_loss did not improve from 0.38514\n",
      "Epoch 1573/3000\n",
      "13/13 - 0s - loss: 0.2043 - accuracy: 0.9027 - val_loss: 0.6711 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01573: val_loss did not improve from 0.38514\n",
      "Epoch 1574/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.9027 - val_loss: 0.7251 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01574: val_loss did not improve from 0.38514\n",
      "Epoch 1575/3000\n",
      "13/13 - 0s - loss: 0.2031 - accuracy: 0.9027 - val_loss: 0.7096 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01575: val_loss did not improve from 0.38514\n",
      "Epoch 1576/3000\n",
      "13/13 - 0s - loss: 0.2034 - accuracy: 0.9027 - val_loss: 0.6981 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01576: val_loss did not improve from 0.38514\n",
      "Epoch 1577/3000\n",
      "13/13 - 0s - loss: 0.2022 - accuracy: 0.9027 - val_loss: 0.7077 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01577: val_loss did not improve from 0.38514\n",
      "Epoch 1578/3000\n",
      "13/13 - 0s - loss: 0.2021 - accuracy: 0.9027 - val_loss: 0.7284 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01578: val_loss did not improve from 0.38514\n",
      "Epoch 1579/3000\n",
      "13/13 - 0s - loss: 0.2020 - accuracy: 0.9027 - val_loss: 0.7440 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01579: val_loss did not improve from 0.38514\n",
      "Epoch 1580/3000\n",
      "13/13 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 0.7456 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01580: val_loss did not improve from 0.38514\n",
      "Epoch 1581/3000\n",
      "13/13 - 0s - loss: 0.2023 - accuracy: 0.9027 - val_loss: 0.7630 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01581: val_loss did not improve from 0.38514\n",
      "Epoch 1582/3000\n",
      "13/13 - 0s - loss: 0.2022 - accuracy: 0.9027 - val_loss: 0.7575 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01582: val_loss did not improve from 0.38514\n",
      "Epoch 1583/3000\n",
      "13/13 - 0s - loss: 0.2010 - accuracy: 0.9027 - val_loss: 0.7528 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01583: val_loss did not improve from 0.38514\n",
      "Epoch 1584/3000\n",
      "13/13 - 0s - loss: 0.2027 - accuracy: 0.9014 - val_loss: 0.7519 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01584: val_loss did not improve from 0.38514\n",
      "Epoch 1585/3000\n",
      "13/13 - 0s - loss: 0.2052 - accuracy: 0.9001 - val_loss: 0.7599 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01585: val_loss did not improve from 0.38514\n",
      "Epoch 1586/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.9040 - val_loss: 0.7212 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01586: val_loss did not improve from 0.38514\n",
      "Epoch 1587/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.9027 - val_loss: 0.7189 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01587: val_loss did not improve from 0.38514\n",
      "Epoch 1588/3000\n",
      "13/13 - 0s - loss: 0.2040 - accuracy: 0.9014 - val_loss: 0.7354 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01588: val_loss did not improve from 0.38514\n",
      "Epoch 1589/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9027 - val_loss: 0.7704 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01589: val_loss did not improve from 0.38514\n",
      "Epoch 1590/3000\n",
      "13/13 - 0s - loss: 0.2048 - accuracy: 0.9027 - val_loss: 0.7800 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01590: val_loss did not improve from 0.38514\n",
      "Epoch 1591/3000\n",
      "13/13 - 0s - loss: 0.2028 - accuracy: 0.9027 - val_loss: 0.7734 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01591: val_loss did not improve from 0.38514\n",
      "Epoch 1592/3000\n",
      "13/13 - 0s - loss: 0.2026 - accuracy: 0.9001 - val_loss: 0.7626 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01592: val_loss did not improve from 0.38514\n",
      "Epoch 1593/3000\n",
      "13/13 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 0.7555 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01593: val_loss did not improve from 0.38514\n",
      "Epoch 1594/3000\n",
      "13/13 - 0s - loss: 0.2022 - accuracy: 0.9027 - val_loss: 0.8087 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01594: val_loss did not improve from 0.38514\n",
      "Epoch 1595/3000\n",
      "13/13 - 0s - loss: 0.2029 - accuracy: 0.9027 - val_loss: 0.7976 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01595: val_loss did not improve from 0.38514\n",
      "Epoch 1596/3000\n",
      "13/13 - 0s - loss: 0.2024 - accuracy: 0.9014 - val_loss: 0.7982 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01596: val_loss did not improve from 0.38514\n",
      "Epoch 1597/3000\n",
      "13/13 - 0s - loss: 0.2014 - accuracy: 0.9027 - val_loss: 0.7948 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01597: val_loss did not improve from 0.38514\n",
      "Epoch 1598/3000\n",
      "13/13 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 0.7982 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01598: val_loss did not improve from 0.38514\n",
      "Epoch 1599/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.9001 - val_loss: 0.8109 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01599: val_loss did not improve from 0.38514\n",
      "Epoch 1600/3000\n",
      "13/13 - 0s - loss: 0.2052 - accuracy: 0.9001 - val_loss: 0.8349 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01600: val_loss did not improve from 0.38514\n",
      "Epoch 1601/3000\n",
      "13/13 - 0s - loss: 0.2033 - accuracy: 0.8949 - val_loss: 0.8431 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01601: val_loss did not improve from 0.38514\n",
      "Epoch 1602/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.9027 - val_loss: 0.8320 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01602: val_loss did not improve from 0.38514\n",
      "Epoch 1603/3000\n",
      "13/13 - 0s - loss: 0.2039 - accuracy: 0.9027 - val_loss: 0.8124 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01603: val_loss did not improve from 0.38514\n",
      "Epoch 1604/3000\n",
      "13/13 - 0s - loss: 0.2022 - accuracy: 0.9027 - val_loss: 0.8277 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01604: val_loss did not improve from 0.38514\n",
      "Epoch 1605/3000\n",
      "13/13 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 0.8412 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01605: val_loss did not improve from 0.38514\n",
      "Epoch 1606/3000\n",
      "13/13 - 0s - loss: 0.2030 - accuracy: 0.9014 - val_loss: 0.8533 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01606: val_loss did not improve from 0.38514\n",
      "Epoch 1607/3000\n",
      "13/13 - 0s - loss: 0.2023 - accuracy: 0.9001 - val_loss: 0.8296 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01607: val_loss did not improve from 0.38514\n",
      "Epoch 1608/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.9014 - val_loss: 0.8253 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01608: val_loss did not improve from 0.38514\n",
      "Epoch 1609/3000\n",
      "13/13 - 0s - loss: 0.2076 - accuracy: 0.9014 - val_loss: 0.8016 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01609: val_loss did not improve from 0.38514\n",
      "Epoch 1610/3000\n",
      "13/13 - 0s - loss: 0.2048 - accuracy: 0.9027 - val_loss: 0.7957 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01610: val_loss did not improve from 0.38514\n",
      "Epoch 1611/3000\n",
      "13/13 - 0s - loss: 0.2027 - accuracy: 0.9001 - val_loss: 0.8048 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01611: val_loss did not improve from 0.38514\n",
      "Epoch 1612/3000\n",
      "13/13 - 0s - loss: 0.2029 - accuracy: 0.9027 - val_loss: 0.8266 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01612: val_loss did not improve from 0.38514\n",
      "Epoch 1613/3000\n",
      "13/13 - 0s - loss: 0.2088 - accuracy: 0.9001 - val_loss: 0.8180 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01613: val_loss did not improve from 0.38514\n",
      "Epoch 1614/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.9027 - val_loss: 0.8407 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01614: val_loss did not improve from 0.38514\n",
      "Epoch 1615/3000\n",
      "13/13 - 0s - loss: 0.2044 - accuracy: 0.9027 - val_loss: 0.8733 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01615: val_loss did not improve from 0.38514\n",
      "Epoch 1616/3000\n",
      "13/13 - 0s - loss: 0.2038 - accuracy: 0.9014 - val_loss: 0.9014 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01616: val_loss did not improve from 0.38514\n",
      "Epoch 1617/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9014 - val_loss: 0.8793 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01617: val_loss did not improve from 0.38514\n",
      "Epoch 1618/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.9040 - val_loss: 0.9457 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01618: val_loss did not improve from 0.38514\n",
      "Epoch 1619/3000\n",
      "13/13 - 0s - loss: 0.2056 - accuracy: 0.9027 - val_loss: 0.9231 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01619: val_loss did not improve from 0.38514\n",
      "Epoch 1620/3000\n",
      "13/13 - 0s - loss: 0.2039 - accuracy: 0.9014 - val_loss: 0.8828 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01620: val_loss did not improve from 0.38514\n",
      "Epoch 1621/3000\n",
      "13/13 - 0s - loss: 0.2041 - accuracy: 0.9001 - val_loss: 0.9494 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01621: val_loss did not improve from 0.38514\n",
      "Epoch 1622/3000\n",
      "13/13 - 0s - loss: 0.2028 - accuracy: 0.9014 - val_loss: 0.9878 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01622: val_loss did not improve from 0.38514\n",
      "Epoch 1623/3000\n",
      "13/13 - 0s - loss: 0.2029 - accuracy: 0.9027 - val_loss: 0.9775 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01623: val_loss did not improve from 0.38514\n",
      "Epoch 1624/3000\n",
      "13/13 - 0s - loss: 0.2025 - accuracy: 0.9027 - val_loss: 0.9762 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01624: val_loss did not improve from 0.38514\n",
      "Epoch 1625/3000\n",
      "13/13 - 0s - loss: 0.2029 - accuracy: 0.9001 - val_loss: 0.9960 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01625: val_loss did not improve from 0.38514\n",
      "Epoch 1626/3000\n",
      "13/13 - 0s - loss: 0.2021 - accuracy: 0.9001 - val_loss: 0.9988 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01626: val_loss did not improve from 0.38514\n",
      "Epoch 1627/3000\n",
      "13/13 - 0s - loss: 0.2022 - accuracy: 0.9027 - val_loss: 0.9986 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01627: val_loss did not improve from 0.38514\n",
      "Epoch 1628/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9014 - val_loss: 1.0285 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01628: val_loss did not improve from 0.38514\n",
      "Epoch 1629/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.9027 - val_loss: 1.0704 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01629: val_loss did not improve from 0.38514\n",
      "Epoch 1630/3000\n",
      "13/13 - 0s - loss: 0.2043 - accuracy: 0.9001 - val_loss: 1.1070 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01630: val_loss did not improve from 0.38514\n",
      "Epoch 1631/3000\n",
      "13/13 - 0s - loss: 0.2030 - accuracy: 0.9014 - val_loss: 1.0975 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01631: val_loss did not improve from 0.38514\n",
      "Epoch 1632/3000\n",
      "13/13 - 0s - loss: 0.2017 - accuracy: 0.8962 - val_loss: 1.1577 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01632: val_loss did not improve from 0.38514\n",
      "Epoch 1633/3000\n",
      "13/13 - 0s - loss: 0.2187 - accuracy: 0.9014 - val_loss: 1.1803 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01633: val_loss did not improve from 0.38514\n",
      "Epoch 1634/3000\n",
      "13/13 - 0s - loss: 0.2092 - accuracy: 0.9001 - val_loss: 1.4588 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01634: val_loss did not improve from 0.38514\n",
      "Epoch 1635/3000\n",
      "13/13 - 0s - loss: 0.2094 - accuracy: 0.9027 - val_loss: 1.4252 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01635: val_loss did not improve from 0.38514\n",
      "Epoch 1636/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.9001 - val_loss: 1.4677 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01636: val_loss did not improve from 0.38514\n",
      "Epoch 1637/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.8975 - val_loss: 1.4577 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01637: val_loss did not improve from 0.38514\n",
      "Epoch 1638/3000\n",
      "13/13 - 0s - loss: 0.2032 - accuracy: 0.8988 - val_loss: 1.4438 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01638: val_loss did not improve from 0.38514\n",
      "Epoch 1639/3000\n",
      "13/13 - 0s - loss: 0.2025 - accuracy: 0.8988 - val_loss: 1.4357 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01639: val_loss did not improve from 0.38514\n",
      "Epoch 1640/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.9027 - val_loss: 1.3262 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01640: val_loss did not improve from 0.38514\n",
      "Epoch 1641/3000\n",
      "13/13 - 0s - loss: 0.2085 - accuracy: 0.8962 - val_loss: 1.4224 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01641: val_loss did not improve from 0.38514\n",
      "Epoch 1642/3000\n",
      "13/13 - 0s - loss: 0.2066 - accuracy: 0.9014 - val_loss: 1.3369 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01642: val_loss did not improve from 0.38514\n",
      "Epoch 1643/3000\n",
      "13/13 - 0s - loss: 0.2029 - accuracy: 0.9027 - val_loss: 1.2133 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01643: val_loss did not improve from 0.38514\n",
      "Epoch 1644/3000\n",
      "13/13 - 0s - loss: 0.2031 - accuracy: 0.9014 - val_loss: 0.8811 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01644: val_loss did not improve from 0.38514\n",
      "Epoch 1645/3000\n",
      "13/13 - 0s - loss: 0.2029 - accuracy: 0.8988 - val_loss: 0.8357 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01645: val_loss did not improve from 0.38514\n",
      "Epoch 1646/3000\n",
      "13/13 - 0s - loss: 0.2031 - accuracy: 0.9014 - val_loss: 0.8611 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01646: val_loss did not improve from 0.38514\n",
      "Epoch 1647/3000\n",
      "13/13 - 0s - loss: 0.2015 - accuracy: 0.9001 - val_loss: 0.8872 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01647: val_loss did not improve from 0.38514\n",
      "Epoch 1648/3000\n",
      "13/13 - 0s - loss: 0.2030 - accuracy: 0.9014 - val_loss: 0.8923 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01648: val_loss did not improve from 0.38514\n",
      "Epoch 1649/3000\n",
      "13/13 - 0s - loss: 0.2030 - accuracy: 0.9001 - val_loss: 0.8649 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01649: val_loss did not improve from 0.38514\n",
      "Epoch 1650/3000\n",
      "13/13 - 0s - loss: 0.2022 - accuracy: 0.9027 - val_loss: 0.8710 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01650: val_loss did not improve from 0.38514\n",
      "Epoch 1651/3000\n",
      "13/13 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 0.8747 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01651: val_loss did not improve from 0.38514\n",
      "Epoch 1652/3000\n",
      "13/13 - 0s - loss: 0.2015 - accuracy: 0.9001 - val_loss: 0.8756 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01652: val_loss did not improve from 0.38514\n",
      "Epoch 1653/3000\n",
      "13/13 - 0s - loss: 0.2011 - accuracy: 0.9027 - val_loss: 0.8760 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01653: val_loss did not improve from 0.38514\n",
      "Epoch 1654/3000\n",
      "13/13 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 0.8671 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01654: val_loss did not improve from 0.38514\n",
      "Epoch 1655/3000\n",
      "13/13 - 0s - loss: 0.2038 - accuracy: 0.9001 - val_loss: 0.8773 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01655: val_loss did not improve from 0.38514\n",
      "Epoch 1656/3000\n",
      "13/13 - 0s - loss: 0.2039 - accuracy: 0.9027 - val_loss: 0.9053 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01656: val_loss did not improve from 0.38514\n",
      "Epoch 1657/3000\n",
      "13/13 - 0s - loss: 0.2064 - accuracy: 0.8975 - val_loss: 1.0727 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01657: val_loss did not improve from 0.38514\n",
      "Epoch 1658/3000\n",
      "13/13 - 0s - loss: 0.2097 - accuracy: 0.9001 - val_loss: 1.0396 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01658: val_loss did not improve from 0.38514\n",
      "Epoch 1659/3000\n",
      "13/13 - 0s - loss: 0.2082 - accuracy: 0.8988 - val_loss: 1.0396 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01659: val_loss did not improve from 0.38514\n",
      "Epoch 1660/3000\n",
      "13/13 - 0s - loss: 0.2060 - accuracy: 0.9027 - val_loss: 1.0286 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01660: val_loss did not improve from 0.38514\n",
      "Epoch 1661/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.9001 - val_loss: 0.9742 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01661: val_loss did not improve from 0.38514\n",
      "Epoch 1662/3000\n",
      "13/13 - 0s - loss: 0.2049 - accuracy: 0.9027 - val_loss: 0.9589 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01662: val_loss did not improve from 0.38514\n",
      "Epoch 1663/3000\n",
      "13/13 - 0s - loss: 0.2039 - accuracy: 0.9027 - val_loss: 0.9509 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01663: val_loss did not improve from 0.38514\n",
      "Epoch 1664/3000\n",
      "13/13 - 0s - loss: 0.2046 - accuracy: 0.9027 - val_loss: 0.9188 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01664: val_loss did not improve from 0.38514\n",
      "Epoch 1665/3000\n",
      "13/13 - 0s - loss: 0.2049 - accuracy: 0.9027 - val_loss: 0.8838 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01665: val_loss did not improve from 0.38514\n",
      "Epoch 1666/3000\n",
      "13/13 - 0s - loss: 0.2043 - accuracy: 0.9040 - val_loss: 0.7801 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 01666: val_loss did not improve from 0.38514\n",
      "Epoch 1667/3000\n",
      "13/13 - 0s - loss: 0.2088 - accuracy: 0.8923 - val_loss: 0.8092 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01667: val_loss did not improve from 0.38514\n",
      "Epoch 1668/3000\n",
      "13/13 - 0s - loss: 0.2076 - accuracy: 0.8975 - val_loss: 0.8181 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01668: val_loss did not improve from 0.38514\n",
      "Epoch 1669/3000\n",
      "13/13 - 0s - loss: 0.2082 - accuracy: 0.8975 - val_loss: 0.8252 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01669: val_loss did not improve from 0.38514\n",
      "Epoch 1670/3000\n",
      "13/13 - 0s - loss: 0.2045 - accuracy: 0.9001 - val_loss: 1.1330 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01670: val_loss did not improve from 0.38514\n",
      "Epoch 1671/3000\n",
      "13/13 - 0s - loss: 0.2045 - accuracy: 0.9027 - val_loss: 0.9259 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01671: val_loss did not improve from 0.38514\n",
      "Epoch 1672/3000\n",
      "13/13 - 0s - loss: 0.2044 - accuracy: 0.9027 - val_loss: 0.7495 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01672: val_loss did not improve from 0.38514\n",
      "Epoch 1673/3000\n",
      "13/13 - 1s - loss: 0.2047 - accuracy: 0.9014 - val_loss: 0.7508 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01673: val_loss did not improve from 0.38514\n",
      "Epoch 1674/3000\n",
      "13/13 - 0s - loss: 0.2049 - accuracy: 0.9027 - val_loss: 0.7488 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01674: val_loss did not improve from 0.38514\n",
      "Epoch 1675/3000\n",
      "13/13 - 0s - loss: 0.2039 - accuracy: 0.9040 - val_loss: 0.8565 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01675: val_loss did not improve from 0.38514\n",
      "Epoch 1676/3000\n",
      "13/13 - 0s - loss: 0.2061 - accuracy: 0.9027 - val_loss: 0.9674 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01676: val_loss did not improve from 0.38514\n",
      "Epoch 1677/3000\n",
      "13/13 - 0s - loss: 0.2039 - accuracy: 0.9027 - val_loss: 1.0024 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01677: val_loss did not improve from 0.38514\n",
      "Epoch 1678/3000\n",
      "13/13 - 0s - loss: 0.2027 - accuracy: 0.9027 - val_loss: 1.0272 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01678: val_loss did not improve from 0.38514\n",
      "Epoch 1679/3000\n",
      "13/13 - 0s - loss: 0.2026 - accuracy: 0.9027 - val_loss: 1.1213 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01679: val_loss did not improve from 0.38514\n",
      "Epoch 1680/3000\n",
      "13/13 - 0s - loss: 0.2020 - accuracy: 0.9027 - val_loss: 1.1460 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01680: val_loss did not improve from 0.38514\n",
      "Epoch 1681/3000\n",
      "13/13 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 1.1364 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01681: val_loss did not improve from 0.38514\n",
      "Epoch 1682/3000\n",
      "13/13 - 0s - loss: 0.2013 - accuracy: 0.9027 - val_loss: 1.1350 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01682: val_loss did not improve from 0.38514\n",
      "Epoch 1683/3000\n",
      "13/13 - 0s - loss: 0.2028 - accuracy: 0.9027 - val_loss: 1.1183 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01683: val_loss did not improve from 0.38514\n",
      "Epoch 1684/3000\n",
      "13/13 - 0s - loss: 0.2021 - accuracy: 0.9027 - val_loss: 1.1679 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01684: val_loss did not improve from 0.38514\n",
      "Epoch 1685/3000\n",
      "13/13 - 0s - loss: 0.2021 - accuracy: 0.9027 - val_loss: 1.0394 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01685: val_loss did not improve from 0.38514\n",
      "Epoch 1686/3000\n",
      "13/13 - 0s - loss: 0.2020 - accuracy: 0.9027 - val_loss: 0.9696 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01686: val_loss did not improve from 0.38514\n",
      "Epoch 1687/3000\n",
      "13/13 - 0s - loss: 0.2022 - accuracy: 0.8988 - val_loss: 0.9664 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01687: val_loss did not improve from 0.38514\n",
      "Epoch 1688/3000\n",
      "13/13 - 0s - loss: 0.2023 - accuracy: 0.9040 - val_loss: 0.9645 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01688: val_loss did not improve from 0.38514\n",
      "Epoch 1689/3000\n",
      "13/13 - 0s - loss: 0.2024 - accuracy: 0.9014 - val_loss: 0.9356 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01689: val_loss did not improve from 0.38514\n",
      "Epoch 1690/3000\n",
      "13/13 - 0s - loss: 0.2022 - accuracy: 0.9027 - val_loss: 0.8584 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01690: val_loss did not improve from 0.38514\n",
      "Epoch 1691/3000\n",
      "13/13 - 0s - loss: 0.2020 - accuracy: 0.9027 - val_loss: 0.8448 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01691: val_loss did not improve from 0.38514\n",
      "Epoch 1692/3000\n",
      "13/13 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 0.8630 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01692: val_loss did not improve from 0.38514\n",
      "Epoch 1693/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.8988 - val_loss: 0.9093 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01693: val_loss did not improve from 0.38514\n",
      "Epoch 1694/3000\n",
      "13/13 - 0s - loss: 0.2033 - accuracy: 0.9001 - val_loss: 0.9717 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01694: val_loss did not improve from 0.38514\n",
      "Epoch 1695/3000\n",
      "13/13 - 0s - loss: 0.2045 - accuracy: 0.9027 - val_loss: 1.0056 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01695: val_loss did not improve from 0.38514\n",
      "Epoch 1696/3000\n",
      "13/13 - 0s - loss: 0.2044 - accuracy: 0.9014 - val_loss: 1.0626 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01696: val_loss did not improve from 0.38514\n",
      "Epoch 1697/3000\n",
      "13/13 - 0s - loss: 0.2040 - accuracy: 0.8975 - val_loss: 1.0473 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01697: val_loss did not improve from 0.38514\n",
      "Epoch 1698/3000\n",
      "13/13 - 0s - loss: 0.2033 - accuracy: 0.9014 - val_loss: 1.0530 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01698: val_loss did not improve from 0.38514\n",
      "Epoch 1699/3000\n",
      "13/13 - 0s - loss: 0.2030 - accuracy: 0.9001 - val_loss: 1.0703 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01699: val_loss did not improve from 0.38514\n",
      "Epoch 1700/3000\n",
      "13/13 - 0s - loss: 0.2030 - accuracy: 0.9027 - val_loss: 1.0958 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01700: val_loss did not improve from 0.38514\n",
      "Epoch 1701/3000\n",
      "13/13 - 0s - loss: 0.2032 - accuracy: 0.9001 - val_loss: 1.2936 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01701: val_loss did not improve from 0.38514\n",
      "Epoch 1702/3000\n",
      "13/13 - 0s - loss: 0.2577 - accuracy: 0.9014 - val_loss: 0.8275 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01702: val_loss did not improve from 0.38514\n",
      "Epoch 1703/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.9014 - val_loss: 0.8700 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01703: val_loss did not improve from 0.38514\n",
      "Epoch 1704/3000\n",
      "13/13 - 0s - loss: 0.2504 - accuracy: 0.8936 - val_loss: 1.0756 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01704: val_loss did not improve from 0.38514\n",
      "Epoch 1705/3000\n",
      "13/13 - 0s - loss: 0.2896 - accuracy: 0.8794 - val_loss: 1.4447 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 01705: val_loss did not improve from 0.38514\n",
      "Epoch 1706/3000\n",
      "13/13 - 0s - loss: 0.3236 - accuracy: 0.8716 - val_loss: 1.3582 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 01706: val_loss did not improve from 0.38514\n",
      "Epoch 1707/3000\n",
      "13/13 - 0s - loss: 0.2762 - accuracy: 0.8768 - val_loss: 2.0054 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 01707: val_loss did not improve from 0.38514\n",
      "Epoch 1708/3000\n",
      "13/13 - 0s - loss: 0.2773 - accuracy: 0.8820 - val_loss: 2.1234 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 01708: val_loss did not improve from 0.38514\n",
      "Epoch 1709/3000\n",
      "13/13 - 0s - loss: 0.3758 - accuracy: 0.8729 - val_loss: 2.0342 - val_accuracy: 0.7668\n",
      "\n",
      "Epoch 01709: val_loss did not improve from 0.38514\n",
      "Epoch 1710/3000\n",
      "13/13 - 0s - loss: 0.3067 - accuracy: 0.8781 - val_loss: 1.1101 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 01710: val_loss did not improve from 0.38514\n",
      "Epoch 1711/3000\n",
      "13/13 - 0s - loss: 0.2839 - accuracy: 0.8794 - val_loss: 1.1453 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 01711: val_loss did not improve from 0.38514\n",
      "Epoch 1712/3000\n",
      "13/13 - 0s - loss: 0.2682 - accuracy: 0.8742 - val_loss: 0.7240 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 01712: val_loss did not improve from 0.38514\n",
      "Epoch 1713/3000\n",
      "13/13 - 0s - loss: 0.2421 - accuracy: 0.8794 - val_loss: 0.8399 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01713: val_loss did not improve from 0.38514\n",
      "Epoch 1714/3000\n",
      "13/13 - 0s - loss: 0.2495 - accuracy: 0.8820 - val_loss: 0.7553 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01714: val_loss did not improve from 0.38514\n",
      "Epoch 1715/3000\n",
      "13/13 - 0s - loss: 0.2234 - accuracy: 0.8885 - val_loss: 0.8249 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 01715: val_loss did not improve from 0.38514\n",
      "Epoch 1716/3000\n",
      "13/13 - 0s - loss: 0.2196 - accuracy: 0.8872 - val_loss: 0.8934 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 01716: val_loss did not improve from 0.38514\n",
      "Epoch 1717/3000\n",
      "13/13 - 0s - loss: 0.2182 - accuracy: 0.8885 - val_loss: 0.9350 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 01717: val_loss did not improve from 0.38514\n",
      "Epoch 1718/3000\n",
      "13/13 - 0s - loss: 0.2158 - accuracy: 0.8885 - val_loss: 0.9399 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01718: val_loss did not improve from 0.38514\n",
      "Epoch 1719/3000\n",
      "13/13 - 0s - loss: 0.2159 - accuracy: 0.8898 - val_loss: 0.9349 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01719: val_loss did not improve from 0.38514\n",
      "Epoch 1720/3000\n",
      "13/13 - 0s - loss: 0.2205 - accuracy: 0.8911 - val_loss: 0.9720 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01720: val_loss did not improve from 0.38514\n",
      "Epoch 1721/3000\n",
      "13/13 - 0s - loss: 0.2196 - accuracy: 0.8911 - val_loss: 1.0275 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 01721: val_loss did not improve from 0.38514\n",
      "Epoch 1722/3000\n",
      "13/13 - 0s - loss: 0.2165 - accuracy: 0.8911 - val_loss: 1.0461 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 01722: val_loss did not improve from 0.38514\n",
      "Epoch 1723/3000\n",
      "13/13 - 0s - loss: 0.2151 - accuracy: 0.8898 - val_loss: 1.0597 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01723: val_loss did not improve from 0.38514\n",
      "Epoch 1724/3000\n",
      "13/13 - 0s - loss: 0.2148 - accuracy: 0.8911 - val_loss: 1.0737 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01724: val_loss did not improve from 0.38514\n",
      "Epoch 1725/3000\n",
      "13/13 - 0s - loss: 0.2129 - accuracy: 0.8936 - val_loss: 1.0598 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01725: val_loss did not improve from 0.38514\n",
      "Epoch 1726/3000\n",
      "13/13 - 0s - loss: 0.2126 - accuracy: 0.8936 - val_loss: 1.0762 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01726: val_loss did not improve from 0.38514\n",
      "Epoch 1727/3000\n",
      "13/13 - 0s - loss: 0.2129 - accuracy: 0.8949 - val_loss: 1.1013 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01727: val_loss did not improve from 0.38514\n",
      "Epoch 1728/3000\n",
      "13/13 - 0s - loss: 0.2135 - accuracy: 0.8936 - val_loss: 1.1025 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01728: val_loss did not improve from 0.38514\n",
      "Epoch 1729/3000\n",
      "13/13 - 0s - loss: 0.2116 - accuracy: 0.8936 - val_loss: 1.1059 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01729: val_loss did not improve from 0.38514\n",
      "Epoch 1730/3000\n",
      "13/13 - 0s - loss: 0.2113 - accuracy: 0.8936 - val_loss: 1.1297 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01730: val_loss did not improve from 0.38514\n",
      "Epoch 1731/3000\n",
      "13/13 - 0s - loss: 0.2099 - accuracy: 0.8911 - val_loss: 1.1262 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01731: val_loss did not improve from 0.38514\n",
      "Epoch 1732/3000\n",
      "13/13 - 0s - loss: 0.2135 - accuracy: 0.8923 - val_loss: 1.1578 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01732: val_loss did not improve from 0.38514\n",
      "Epoch 1733/3000\n",
      "13/13 - 0s - loss: 0.2100 - accuracy: 0.8923 - val_loss: 1.1590 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01733: val_loss did not improve from 0.38514\n",
      "Epoch 1734/3000\n",
      "13/13 - 0s - loss: 0.2105 - accuracy: 0.8859 - val_loss: 1.1591 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01734: val_loss did not improve from 0.38514\n",
      "Epoch 1735/3000\n",
      "13/13 - 0s - loss: 0.2088 - accuracy: 0.8911 - val_loss: 1.1874 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01735: val_loss did not improve from 0.38514\n",
      "Epoch 1736/3000\n",
      "13/13 - 0s - loss: 0.2096 - accuracy: 0.8923 - val_loss: 1.1905 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01736: val_loss did not improve from 0.38514\n",
      "Epoch 1737/3000\n",
      "13/13 - 0s - loss: 0.2095 - accuracy: 0.8898 - val_loss: 1.1855 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01737: val_loss did not improve from 0.38514\n",
      "Epoch 1738/3000\n",
      "13/13 - 0s - loss: 0.2088 - accuracy: 0.8885 - val_loss: 1.2362 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 01738: val_loss did not improve from 0.38514\n",
      "Epoch 1739/3000\n",
      "13/13 - 0s - loss: 0.2098 - accuracy: 0.8923 - val_loss: 1.2485 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01739: val_loss did not improve from 0.38514\n",
      "Epoch 1740/3000\n",
      "13/13 - 0s - loss: 0.2099 - accuracy: 0.8911 - val_loss: 1.2434 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01740: val_loss did not improve from 0.38514\n",
      "Epoch 1741/3000\n",
      "13/13 - 0s - loss: 0.2098 - accuracy: 0.8936 - val_loss: 1.2462 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01741: val_loss did not improve from 0.38514\n",
      "Epoch 1742/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.8911 - val_loss: 1.2310 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01742: val_loss did not improve from 0.38514\n",
      "Epoch 1743/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.8923 - val_loss: 1.2213 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01743: val_loss did not improve from 0.38514\n",
      "Epoch 1744/3000\n",
      "13/13 - 0s - loss: 0.2093 - accuracy: 0.8923 - val_loss: 1.2409 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01744: val_loss did not improve from 0.38514\n",
      "Epoch 1745/3000\n",
      "13/13 - 0s - loss: 0.2093 - accuracy: 0.8911 - val_loss: 1.2404 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01745: val_loss did not improve from 0.38514\n",
      "Epoch 1746/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.8923 - val_loss: 1.2373 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01746: val_loss did not improve from 0.38514\n",
      "Epoch 1747/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.8923 - val_loss: 1.2362 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01747: val_loss did not improve from 0.38514\n",
      "Epoch 1748/3000\n",
      "13/13 - 0s - loss: 0.2092 - accuracy: 0.8975 - val_loss: 1.2848 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01748: val_loss did not improve from 0.38514\n",
      "Epoch 1749/3000\n",
      "13/13 - 0s - loss: 0.2107 - accuracy: 0.9014 - val_loss: 1.3110 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01749: val_loss did not improve from 0.38514\n",
      "Epoch 1750/3000\n",
      "13/13 - 0s - loss: 0.2121 - accuracy: 0.9014 - val_loss: 1.3167 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01750: val_loss did not improve from 0.38514\n",
      "Epoch 1751/3000\n",
      "13/13 - 0s - loss: 0.2113 - accuracy: 0.9001 - val_loss: 1.3016 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01751: val_loss did not improve from 0.38514\n",
      "Epoch 1752/3000\n",
      "13/13 - 0s - loss: 0.2089 - accuracy: 0.9014 - val_loss: 1.3076 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01752: val_loss did not improve from 0.38514\n",
      "Epoch 1753/3000\n",
      "13/13 - 0s - loss: 0.2089 - accuracy: 0.9001 - val_loss: 1.3138 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01753: val_loss did not improve from 0.38514\n",
      "Epoch 1754/3000\n",
      "13/13 - 0s - loss: 0.2087 - accuracy: 0.8975 - val_loss: 1.3330 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01754: val_loss did not improve from 0.38514\n",
      "Epoch 1755/3000\n",
      "13/13 - 0s - loss: 0.2089 - accuracy: 0.8962 - val_loss: 1.3631 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01755: val_loss did not improve from 0.38514\n",
      "Epoch 1756/3000\n",
      "13/13 - 0s - loss: 0.2100 - accuracy: 0.8975 - val_loss: 1.3664 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01756: val_loss did not improve from 0.38514\n",
      "Epoch 1757/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.8988 - val_loss: 1.3560 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01757: val_loss did not improve from 0.38514\n",
      "Epoch 1758/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.8988 - val_loss: 1.3822 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01758: val_loss did not improve from 0.38514\n",
      "Epoch 1759/3000\n",
      "13/13 - 0s - loss: 0.2128 - accuracy: 0.8949 - val_loss: 1.3661 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01759: val_loss did not improve from 0.38514\n",
      "Epoch 1760/3000\n",
      "13/13 - 0s - loss: 0.2181 - accuracy: 0.8911 - val_loss: 1.3724 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01760: val_loss did not improve from 0.38514\n",
      "Epoch 1761/3000\n",
      "13/13 - 0s - loss: 0.2185 - accuracy: 0.9001 - val_loss: 1.4063 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01761: val_loss did not improve from 0.38514\n",
      "Epoch 1762/3000\n",
      "13/13 - 0s - loss: 0.2130 - accuracy: 0.9014 - val_loss: 1.3204 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01762: val_loss did not improve from 0.38514\n",
      "Epoch 1763/3000\n",
      "13/13 - 0s - loss: 0.2092 - accuracy: 0.9014 - val_loss: 1.3114 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01763: val_loss did not improve from 0.38514\n",
      "Epoch 1764/3000\n",
      "13/13 - 0s - loss: 0.2102 - accuracy: 0.9001 - val_loss: 1.3164 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01764: val_loss did not improve from 0.38514\n",
      "Epoch 1765/3000\n",
      "13/13 - 0s - loss: 0.2088 - accuracy: 0.8936 - val_loss: 1.3383 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01765: val_loss did not improve from 0.38514\n",
      "Epoch 1766/3000\n",
      "13/13 - 0s - loss: 0.2110 - accuracy: 0.9001 - val_loss: 1.3436 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01766: val_loss did not improve from 0.38514\n",
      "Epoch 1767/3000\n",
      "13/13 - 0s - loss: 0.2136 - accuracy: 0.8975 - val_loss: 1.2635 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01767: val_loss did not improve from 0.38514\n",
      "Epoch 1768/3000\n",
      "13/13 - 0s - loss: 0.2107 - accuracy: 0.9027 - val_loss: 1.2476 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01768: val_loss did not improve from 0.38514\n",
      "Epoch 1769/3000\n",
      "13/13 - 0s - loss: 0.2104 - accuracy: 0.8988 - val_loss: 1.2620 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01769: val_loss did not improve from 0.38514\n",
      "Epoch 1770/3000\n",
      "13/13 - 0s - loss: 0.2110 - accuracy: 0.8975 - val_loss: 1.2860 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01770: val_loss did not improve from 0.38514\n",
      "Epoch 1771/3000\n",
      "13/13 - 0s - loss: 0.2102 - accuracy: 0.8911 - val_loss: 1.2986 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01771: val_loss did not improve from 0.38514\n",
      "Epoch 1772/3000\n",
      "13/13 - 0s - loss: 0.2103 - accuracy: 0.9027 - val_loss: 1.3001 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01772: val_loss did not improve from 0.38514\n",
      "Epoch 1773/3000\n",
      "13/13 - 0s - loss: 0.2124 - accuracy: 0.9001 - val_loss: 1.3158 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01773: val_loss did not improve from 0.38514\n",
      "Epoch 1774/3000\n",
      "13/13 - 0s - loss: 0.2100 - accuracy: 0.8962 - val_loss: 1.3517 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01774: val_loss did not improve from 0.38514\n",
      "Epoch 1775/3000\n",
      "13/13 - 0s - loss: 0.2085 - accuracy: 0.9001 - val_loss: 1.3719 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01775: val_loss did not improve from 0.38514\n",
      "Epoch 1776/3000\n",
      "13/13 - 0s - loss: 0.2077 - accuracy: 0.9014 - val_loss: 1.3781 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01776: val_loss did not improve from 0.38514\n",
      "Epoch 1777/3000\n",
      "13/13 - 0s - loss: 0.2083 - accuracy: 0.9027 - val_loss: 1.3766 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01777: val_loss did not improve from 0.38514\n",
      "Epoch 1778/3000\n",
      "13/13 - 0s - loss: 0.2083 - accuracy: 0.9027 - val_loss: 1.3956 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01778: val_loss did not improve from 0.38514\n",
      "Epoch 1779/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.9001 - val_loss: 1.4206 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01779: val_loss did not improve from 0.38514\n",
      "Epoch 1780/3000\n",
      "13/13 - 0s - loss: 0.2073 - accuracy: 0.9027 - val_loss: 1.3963 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01780: val_loss did not improve from 0.38514\n",
      "Epoch 1781/3000\n",
      "13/13 - 0s - loss: 0.2065 - accuracy: 0.9014 - val_loss: 1.3806 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01781: val_loss did not improve from 0.38514\n",
      "Epoch 1782/3000\n",
      "13/13 - 0s - loss: 0.2095 - accuracy: 0.9027 - val_loss: 1.3777 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01782: val_loss did not improve from 0.38514\n",
      "Epoch 1783/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.8988 - val_loss: 1.4409 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01783: val_loss did not improve from 0.38514\n",
      "Epoch 1784/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.9027 - val_loss: 1.4510 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01784: val_loss did not improve from 0.38514\n",
      "Epoch 1785/3000\n",
      "13/13 - 0s - loss: 0.2073 - accuracy: 0.9014 - val_loss: 1.4613 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01785: val_loss did not improve from 0.38514\n",
      "Epoch 1786/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.8988 - val_loss: 1.4532 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01786: val_loss did not improve from 0.38514\n",
      "Epoch 1787/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.9001 - val_loss: 1.4254 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01787: val_loss did not improve from 0.38514\n",
      "Epoch 1788/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.9001 - val_loss: 1.4377 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01788: val_loss did not improve from 0.38514\n",
      "Epoch 1789/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.9001 - val_loss: 1.4589 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01789: val_loss did not improve from 0.38514\n",
      "Epoch 1790/3000\n",
      "13/13 - 0s - loss: 0.2073 - accuracy: 0.9014 - val_loss: 1.4732 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01790: val_loss did not improve from 0.38514\n",
      "Epoch 1791/3000\n",
      "13/13 - 0s - loss: 0.2073 - accuracy: 0.9014 - val_loss: 1.4888 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01791: val_loss did not improve from 0.38514\n",
      "Epoch 1792/3000\n",
      "13/13 - 0s - loss: 0.2073 - accuracy: 0.8988 - val_loss: 1.4918 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01792: val_loss did not improve from 0.38514\n",
      "Epoch 1793/3000\n",
      "13/13 - 0s - loss: 0.2138 - accuracy: 0.9014 - val_loss: 1.5618 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01793: val_loss did not improve from 0.38514\n",
      "Epoch 1794/3000\n",
      "13/13 - 0s - loss: 0.2171 - accuracy: 0.8936 - val_loss: 1.6011 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01794: val_loss did not improve from 0.38514\n",
      "Epoch 1795/3000\n",
      "13/13 - 0s - loss: 0.2110 - accuracy: 0.9014 - val_loss: 1.5648 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01795: val_loss did not improve from 0.38514\n",
      "Epoch 1796/3000\n",
      "13/13 - 0s - loss: 0.2098 - accuracy: 0.9014 - val_loss: 1.5683 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01796: val_loss did not improve from 0.38514\n",
      "Epoch 1797/3000\n",
      "13/13 - 0s - loss: 0.2210 - accuracy: 0.9001 - val_loss: 1.6551 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01797: val_loss did not improve from 0.38514\n",
      "Epoch 1798/3000\n",
      "13/13 - 0s - loss: 0.2125 - accuracy: 0.8975 - val_loss: 1.6901 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01798: val_loss did not improve from 0.38514\n",
      "Epoch 1799/3000\n",
      "13/13 - 0s - loss: 0.2102 - accuracy: 0.8975 - val_loss: 1.6982 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01799: val_loss did not improve from 0.38514\n",
      "Epoch 1800/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.8962 - val_loss: 1.7123 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01800: val_loss did not improve from 0.38514\n",
      "Epoch 1801/3000\n",
      "13/13 - 0s - loss: 0.2077 - accuracy: 0.9001 - val_loss: 1.7368 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01801: val_loss did not improve from 0.38514\n",
      "Epoch 1802/3000\n",
      "13/13 - 0s - loss: 0.2183 - accuracy: 0.8988 - val_loss: 1.7692 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01802: val_loss did not improve from 0.38514\n",
      "Epoch 1803/3000\n",
      "13/13 - 0s - loss: 0.2095 - accuracy: 0.9001 - val_loss: 1.7970 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01803: val_loss did not improve from 0.38514\n",
      "Epoch 1804/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.9014 - val_loss: 1.7819 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01804: val_loss did not improve from 0.38514\n",
      "Epoch 1805/3000\n",
      "13/13 - 0s - loss: 0.2114 - accuracy: 0.8898 - val_loss: 1.6972 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01805: val_loss did not improve from 0.38514\n",
      "Epoch 1806/3000\n",
      "13/13 - 0s - loss: 0.2145 - accuracy: 0.8923 - val_loss: 1.5399 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01806: val_loss did not improve from 0.38514\n",
      "Epoch 1807/3000\n",
      "13/13 - 0s - loss: 0.2156 - accuracy: 0.8962 - val_loss: 1.5864 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01807: val_loss did not improve from 0.38514\n",
      "Epoch 1808/3000\n",
      "13/13 - 0s - loss: 0.2205 - accuracy: 0.9014 - val_loss: 1.5239 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01808: val_loss did not improve from 0.38514\n",
      "Epoch 1809/3000\n",
      "13/13 - 0s - loss: 0.2163 - accuracy: 0.8988 - val_loss: 1.6515 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01809: val_loss did not improve from 0.38514\n",
      "Epoch 1810/3000\n",
      "13/13 - 0s - loss: 0.2207 - accuracy: 0.9014 - val_loss: 1.6386 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01810: val_loss did not improve from 0.38514\n",
      "Epoch 1811/3000\n",
      "13/13 - 0s - loss: 0.2160 - accuracy: 0.9014 - val_loss: 1.8432 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01811: val_loss did not improve from 0.38514\n",
      "Epoch 1812/3000\n",
      "13/13 - 0s - loss: 0.2108 - accuracy: 0.9001 - val_loss: 1.8357 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01812: val_loss did not improve from 0.38514\n",
      "Epoch 1813/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.8975 - val_loss: 1.8513 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01813: val_loss did not improve from 0.38514\n",
      "Epoch 1814/3000\n",
      "13/13 - 0s - loss: 0.2091 - accuracy: 0.8988 - val_loss: 1.9492 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01814: val_loss did not improve from 0.38514\n",
      "Epoch 1815/3000\n",
      "13/13 - 0s - loss: 0.2107 - accuracy: 0.8975 - val_loss: 1.8711 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01815: val_loss did not improve from 0.38514\n",
      "Epoch 1816/3000\n",
      "13/13 - 0s - loss: 0.2082 - accuracy: 0.8962 - val_loss: 1.8252 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01816: val_loss did not improve from 0.38514\n",
      "Epoch 1817/3000\n",
      "13/13 - 0s - loss: 0.2078 - accuracy: 0.9027 - val_loss: 1.8352 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01817: val_loss did not improve from 0.38514\n",
      "Epoch 1818/3000\n",
      "13/13 - 0s - loss: 0.2088 - accuracy: 0.9014 - val_loss: 1.8306 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01818: val_loss did not improve from 0.38514\n",
      "Epoch 1819/3000\n",
      "13/13 - 0s - loss: 0.2097 - accuracy: 0.8975 - val_loss: 1.8111 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01819: val_loss did not improve from 0.38514\n",
      "Epoch 1820/3000\n",
      "13/13 - 0s - loss: 0.2073 - accuracy: 0.9014 - val_loss: 1.8101 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01820: val_loss did not improve from 0.38514\n",
      "Epoch 1821/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.9027 - val_loss: 1.7949 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01821: val_loss did not improve from 0.38514\n",
      "Epoch 1822/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.9027 - val_loss: 1.8059 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01822: val_loss did not improve from 0.38514\n",
      "Epoch 1823/3000\n",
      "13/13 - 0s - loss: 0.2064 - accuracy: 0.9027 - val_loss: 1.8290 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01823: val_loss did not improve from 0.38514\n",
      "Epoch 1824/3000\n",
      "13/13 - 0s - loss: 0.2059 - accuracy: 0.9001 - val_loss: 1.7942 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01824: val_loss did not improve from 0.38514\n",
      "Epoch 1825/3000\n",
      "13/13 - 0s - loss: 0.2067 - accuracy: 0.9027 - val_loss: 1.8087 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01825: val_loss did not improve from 0.38514\n",
      "Epoch 1826/3000\n",
      "13/13 - 0s - loss: 0.2080 - accuracy: 0.9014 - val_loss: 1.8025 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01826: val_loss did not improve from 0.38514\n",
      "Epoch 1827/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.9027 - val_loss: 1.8385 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01827: val_loss did not improve from 0.38514\n",
      "Epoch 1828/3000\n",
      "13/13 - 0s - loss: 0.2126 - accuracy: 0.8988 - val_loss: 1.8341 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01828: val_loss did not improve from 0.38514\n",
      "Epoch 1829/3000\n",
      "13/13 - 0s - loss: 0.2166 - accuracy: 0.8794 - val_loss: 1.7958 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01829: val_loss did not improve from 0.38514\n",
      "Epoch 1830/3000\n",
      "13/13 - 0s - loss: 0.2131 - accuracy: 0.8962 - val_loss: 1.7615 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01830: val_loss did not improve from 0.38514\n",
      "Epoch 1831/3000\n",
      "13/13 - 0s - loss: 0.2091 - accuracy: 0.9027 - val_loss: 1.7569 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01831: val_loss did not improve from 0.38514\n",
      "Epoch 1832/3000\n",
      "13/13 - 0s - loss: 0.2089 - accuracy: 0.9014 - val_loss: 1.7537 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01832: val_loss did not improve from 0.38514\n",
      "Epoch 1833/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.9014 - val_loss: 1.7535 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01833: val_loss did not improve from 0.38514\n",
      "Epoch 1834/3000\n",
      "13/13 - 0s - loss: 0.2237 - accuracy: 0.8975 - val_loss: 1.7299 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01834: val_loss did not improve from 0.38514\n",
      "Epoch 1835/3000\n",
      "13/13 - 0s - loss: 0.2118 - accuracy: 0.8936 - val_loss: 1.8035 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01835: val_loss did not improve from 0.38514\n",
      "Epoch 1836/3000\n",
      "13/13 - 0s - loss: 0.2083 - accuracy: 0.9027 - val_loss: 1.8014 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01836: val_loss did not improve from 0.38514\n",
      "Epoch 1837/3000\n",
      "13/13 - 0s - loss: 0.2089 - accuracy: 0.9014 - val_loss: 1.8787 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01837: val_loss did not improve from 0.38514\n",
      "Epoch 1838/3000\n",
      "13/13 - 0s - loss: 0.2089 - accuracy: 0.9027 - val_loss: 1.9007 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01838: val_loss did not improve from 0.38514\n",
      "Epoch 1839/3000\n",
      "13/13 - 0s - loss: 0.2082 - accuracy: 0.9027 - val_loss: 1.9176 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01839: val_loss did not improve from 0.38514\n",
      "Epoch 1840/3000\n",
      "13/13 - 0s - loss: 0.2076 - accuracy: 0.9001 - val_loss: 1.9122 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01840: val_loss did not improve from 0.38514\n",
      "Epoch 1841/3000\n",
      "13/13 - 0s - loss: 0.2088 - accuracy: 0.9001 - val_loss: 1.9092 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01841: val_loss did not improve from 0.38514\n",
      "Epoch 1842/3000\n",
      "13/13 - 0s - loss: 0.2088 - accuracy: 0.9001 - val_loss: 1.9017 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01842: val_loss did not improve from 0.38514\n",
      "Epoch 1843/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.9001 - val_loss: 1.9006 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01843: val_loss did not improve from 0.38514\n",
      "Epoch 1844/3000\n",
      "13/13 - 0s - loss: 0.2078 - accuracy: 0.9001 - val_loss: 1.9073 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01844: val_loss did not improve from 0.38514\n",
      "Epoch 1845/3000\n",
      "13/13 - 0s - loss: 0.2083 - accuracy: 0.9027 - val_loss: 1.9507 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01845: val_loss did not improve from 0.38514\n",
      "Epoch 1846/3000\n",
      "13/13 - 0s - loss: 0.2092 - accuracy: 0.9027 - val_loss: 1.9427 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01846: val_loss did not improve from 0.38514\n",
      "Epoch 1847/3000\n",
      "13/13 - 0s - loss: 0.2082 - accuracy: 0.9027 - val_loss: 1.9392 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01847: val_loss did not improve from 0.38514\n",
      "Epoch 1848/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.9001 - val_loss: 1.8900 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01848: val_loss did not improve from 0.38514\n",
      "Epoch 1849/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.9040 - val_loss: 1.8873 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01849: val_loss did not improve from 0.38514\n",
      "Epoch 1850/3000\n",
      "13/13 - 0s - loss: 0.2077 - accuracy: 0.9027 - val_loss: 1.8829 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01850: val_loss did not improve from 0.38514\n",
      "Epoch 1851/3000\n",
      "13/13 - 0s - loss: 0.2068 - accuracy: 0.9014 - val_loss: 1.8966 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01851: val_loss did not improve from 0.38514\n",
      "Epoch 1852/3000\n",
      "13/13 - 0s - loss: 0.2064 - accuracy: 0.9027 - val_loss: 1.8846 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01852: val_loss did not improve from 0.38514\n",
      "Epoch 1853/3000\n",
      "13/13 - 0s - loss: 0.2060 - accuracy: 0.9027 - val_loss: 1.8835 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01853: val_loss did not improve from 0.38514\n",
      "Epoch 1854/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.9014 - val_loss: 1.8645 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01854: val_loss did not improve from 0.38514\n",
      "Epoch 1855/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.9027 - val_loss: 1.9402 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01855: val_loss did not improve from 0.38514\n",
      "Epoch 1856/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.9027 - val_loss: 1.9624 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01856: val_loss did not improve from 0.38514\n",
      "Epoch 1857/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.9027 - val_loss: 1.9316 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01857: val_loss did not improve from 0.38514\n",
      "Epoch 1858/3000\n",
      "13/13 - 0s - loss: 0.2082 - accuracy: 0.9027 - val_loss: 1.9388 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01858: val_loss did not improve from 0.38514\n",
      "Epoch 1859/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.9014 - val_loss: 1.9560 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01859: val_loss did not improve from 0.38514\n",
      "Epoch 1860/3000\n",
      "13/13 - 0s - loss: 0.2076 - accuracy: 0.8988 - val_loss: 1.9711 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01860: val_loss did not improve from 0.38514\n",
      "Epoch 1861/3000\n",
      "13/13 - 0s - loss: 0.2064 - accuracy: 0.9027 - val_loss: 1.9517 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01861: val_loss did not improve from 0.38514\n",
      "Epoch 1862/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.9027 - val_loss: 1.9385 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01862: val_loss did not improve from 0.38514\n",
      "Epoch 1863/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.9027 - val_loss: 1.9154 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01863: val_loss did not improve from 0.38514\n",
      "Epoch 1864/3000\n",
      "13/13 - 0s - loss: 0.2068 - accuracy: 0.9027 - val_loss: 1.9188 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01864: val_loss did not improve from 0.38514\n",
      "Epoch 1865/3000\n",
      "13/13 - 0s - loss: 0.2059 - accuracy: 0.9027 - val_loss: 1.9778 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01865: val_loss did not improve from 0.38514\n",
      "Epoch 1866/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.9027 - val_loss: 1.9767 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01866: val_loss did not improve from 0.38514\n",
      "Epoch 1867/3000\n",
      "13/13 - 0s - loss: 0.2064 - accuracy: 0.9001 - val_loss: 2.0036 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01867: val_loss did not improve from 0.38514\n",
      "Epoch 1868/3000\n",
      "13/13 - 0s - loss: 0.2049 - accuracy: 0.8988 - val_loss: 2.0484 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01868: val_loss did not improve from 0.38514\n",
      "Epoch 1869/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.9001 - val_loss: 2.0529 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01869: val_loss did not improve from 0.38514\n",
      "Epoch 1870/3000\n",
      "13/13 - 0s - loss: 0.2073 - accuracy: 0.9001 - val_loss: 2.0740 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01870: val_loss did not improve from 0.38514\n",
      "Epoch 1871/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.9001 - val_loss: 2.0788 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01871: val_loss did not improve from 0.38514\n",
      "Epoch 1872/3000\n",
      "13/13 - 0s - loss: 0.2080 - accuracy: 0.8988 - val_loss: 2.0696 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01872: val_loss did not improve from 0.38514\n",
      "Epoch 1873/3000\n",
      "13/13 - 0s - loss: 0.2069 - accuracy: 0.9027 - val_loss: 2.0991 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01873: val_loss did not improve from 0.38514\n",
      "Epoch 1874/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.9027 - val_loss: 2.1279 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01874: val_loss did not improve from 0.38514\n",
      "Epoch 1875/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.8988 - val_loss: 2.1239 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01875: val_loss did not improve from 0.38514\n",
      "Epoch 1876/3000\n",
      "13/13 - 0s - loss: 0.2076 - accuracy: 0.9027 - val_loss: 2.0747 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01876: val_loss did not improve from 0.38514\n",
      "Epoch 1877/3000\n",
      "13/13 - 0s - loss: 0.2067 - accuracy: 0.9053 - val_loss: 2.0716 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01877: val_loss did not improve from 0.38514\n",
      "Epoch 1878/3000\n",
      "13/13 - 0s - loss: 0.2098 - accuracy: 0.8949 - val_loss: 2.0260 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01878: val_loss did not improve from 0.38514\n",
      "Epoch 1879/3000\n",
      "13/13 - 0s - loss: 0.2080 - accuracy: 0.8988 - val_loss: 2.0167 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01879: val_loss did not improve from 0.38514\n",
      "Epoch 1880/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.9053 - val_loss: 1.9502 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01880: val_loss did not improve from 0.38514\n",
      "Epoch 1881/3000\n",
      "13/13 - 0s - loss: 0.2094 - accuracy: 0.9027 - val_loss: 1.9504 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01881: val_loss did not improve from 0.38514\n",
      "Epoch 1882/3000\n",
      "13/13 - 0s - loss: 0.2096 - accuracy: 0.9001 - val_loss: 1.9772 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01882: val_loss did not improve from 0.38514\n",
      "Epoch 1883/3000\n",
      "13/13 - 0s - loss: 0.2087 - accuracy: 0.9027 - val_loss: 1.9937 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01883: val_loss did not improve from 0.38514\n",
      "Epoch 1884/3000\n",
      "13/13 - 0s - loss: 0.2092 - accuracy: 0.9027 - val_loss: 2.0390 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01884: val_loss did not improve from 0.38514\n",
      "Epoch 1885/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.9001 - val_loss: 2.1115 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01885: val_loss did not improve from 0.38514\n",
      "Epoch 1886/3000\n",
      "13/13 - 0s - loss: 0.2077 - accuracy: 0.8975 - val_loss: 2.1012 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01886: val_loss did not improve from 0.38514\n",
      "Epoch 1887/3000\n",
      "13/13 - 0s - loss: 0.2118 - accuracy: 0.8975 - val_loss: 1.8710 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01887: val_loss did not improve from 0.38514\n",
      "Epoch 1888/3000\n",
      "13/13 - 0s - loss: 0.2080 - accuracy: 0.9014 - val_loss: 1.7908 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01888: val_loss did not improve from 0.38514\n",
      "Epoch 1889/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.9014 - val_loss: 1.8210 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01889: val_loss did not improve from 0.38514\n",
      "Epoch 1890/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.9014 - val_loss: 1.8202 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01890: val_loss did not improve from 0.38514\n",
      "Epoch 1891/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.8949 - val_loss: 1.8241 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01891: val_loss did not improve from 0.38514\n",
      "Epoch 1892/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.8988 - val_loss: 1.8512 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01892: val_loss did not improve from 0.38514\n",
      "Epoch 1893/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.8988 - val_loss: 1.8596 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01893: val_loss did not improve from 0.38514\n",
      "Epoch 1894/3000\n",
      "13/13 - 0s - loss: 0.2099 - accuracy: 0.8975 - val_loss: 1.8473 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01894: val_loss did not improve from 0.38514\n",
      "Epoch 1895/3000\n",
      "13/13 - 0s - loss: 0.2073 - accuracy: 0.8988 - val_loss: 1.8298 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01895: val_loss did not improve from 0.38514\n",
      "Epoch 1896/3000\n",
      "13/13 - 0s - loss: 0.2070 - accuracy: 0.9014 - val_loss: 1.8202 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01896: val_loss did not improve from 0.38514\n",
      "Epoch 1897/3000\n",
      "13/13 - 0s - loss: 0.2069 - accuracy: 0.9001 - val_loss: 1.8204 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01897: val_loss did not improve from 0.38514\n",
      "Epoch 1898/3000\n",
      "13/13 - 0s - loss: 0.2070 - accuracy: 0.9014 - val_loss: 1.8300 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01898: val_loss did not improve from 0.38514\n",
      "Epoch 1899/3000\n",
      "13/13 - 0s - loss: 0.2100 - accuracy: 0.9001 - val_loss: 1.8184 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01899: val_loss did not improve from 0.38514\n",
      "Epoch 1900/3000\n",
      "13/13 - 0s - loss: 0.2097 - accuracy: 0.8988 - val_loss: 1.7939 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01900: val_loss did not improve from 0.38514\n",
      "Epoch 1901/3000\n",
      "13/13 - 0s - loss: 0.2067 - accuracy: 0.9014 - val_loss: 1.7278 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01901: val_loss did not improve from 0.38514\n",
      "Epoch 1902/3000\n",
      "13/13 - 0s - loss: 0.2064 - accuracy: 0.9027 - val_loss: 1.7730 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01902: val_loss did not improve from 0.38514\n",
      "Epoch 1903/3000\n",
      "13/13 - 0s - loss: 0.2061 - accuracy: 0.9001 - val_loss: 1.8151 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01903: val_loss did not improve from 0.38514\n",
      "Epoch 1904/3000\n",
      "13/13 - 0s - loss: 0.2056 - accuracy: 0.9027 - val_loss: 1.8386 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01904: val_loss did not improve from 0.38514\n",
      "Epoch 1905/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.9040 - val_loss: 1.8463 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01905: val_loss did not improve from 0.38514\n",
      "Epoch 1906/3000\n",
      "13/13 - 0s - loss: 0.2049 - accuracy: 0.9027 - val_loss: 1.8450 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01906: val_loss did not improve from 0.38514\n",
      "Epoch 1907/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.9027 - val_loss: 1.8635 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01907: val_loss did not improve from 0.38514\n",
      "Epoch 1908/3000\n",
      "13/13 - 0s - loss: 0.2051 - accuracy: 0.9027 - val_loss: 1.8332 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01908: val_loss did not improve from 0.38514\n",
      "Epoch 1909/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.8949 - val_loss: 1.8609 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01909: val_loss did not improve from 0.38514\n",
      "Epoch 1910/3000\n",
      "13/13 - 0s - loss: 0.2108 - accuracy: 0.8859 - val_loss: 1.8579 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01910: val_loss did not improve from 0.38514\n",
      "Epoch 1911/3000\n",
      "13/13 - 0s - loss: 0.2077 - accuracy: 0.9001 - val_loss: 1.8729 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01911: val_loss did not improve from 0.38514\n",
      "Epoch 1912/3000\n",
      "13/13 - 0s - loss: 0.2064 - accuracy: 0.8988 - val_loss: 1.8126 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01912: val_loss did not improve from 0.38514\n",
      "Epoch 1913/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.8988 - val_loss: 1.7892 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 01913: val_loss did not improve from 0.38514\n",
      "Epoch 1914/3000\n",
      "13/13 - 0s - loss: 0.2115 - accuracy: 0.8859 - val_loss: 1.7573 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01914: val_loss did not improve from 0.38514\n",
      "Epoch 1915/3000\n",
      "13/13 - 0s - loss: 0.2148 - accuracy: 0.8846 - val_loss: 1.7622 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01915: val_loss did not improve from 0.38514\n",
      "Epoch 1916/3000\n",
      "13/13 - 0s - loss: 0.2108 - accuracy: 0.8846 - val_loss: 1.7996 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01916: val_loss did not improve from 0.38514\n",
      "Epoch 1917/3000\n",
      "13/13 - 0s - loss: 0.2151 - accuracy: 0.8936 - val_loss: 1.7343 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01917: val_loss did not improve from 0.38514\n",
      "Epoch 1918/3000\n",
      "13/13 - 0s - loss: 0.2108 - accuracy: 0.8923 - val_loss: 1.8692 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01918: val_loss did not improve from 0.38514\n",
      "Epoch 1919/3000\n",
      "13/13 - 0s - loss: 0.2092 - accuracy: 0.8923 - val_loss: 1.9576 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01919: val_loss did not improve from 0.38514\n",
      "Epoch 1920/3000\n",
      "13/13 - 0s - loss: 0.2083 - accuracy: 0.9027 - val_loss: 1.9278 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01920: val_loss did not improve from 0.38514\n",
      "Epoch 1921/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.9014 - val_loss: 1.8223 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01921: val_loss did not improve from 0.38514\n",
      "Epoch 1922/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.8936 - val_loss: 1.8505 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01922: val_loss did not improve from 0.38514\n",
      "Epoch 1923/3000\n",
      "13/13 - 0s - loss: 0.2069 - accuracy: 0.9001 - val_loss: 1.8364 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01923: val_loss did not improve from 0.38514\n",
      "Epoch 1924/3000\n",
      "13/13 - 0s - loss: 0.2069 - accuracy: 0.8988 - val_loss: 1.6871 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01924: val_loss did not improve from 0.38514\n",
      "Epoch 1925/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.9027 - val_loss: 1.7304 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01925: val_loss did not improve from 0.38514\n",
      "Epoch 1926/3000\n",
      "13/13 - 0s - loss: 0.2066 - accuracy: 0.9001 - val_loss: 1.7587 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01926: val_loss did not improve from 0.38514\n",
      "Epoch 1927/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.9014 - val_loss: 1.7176 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01927: val_loss did not improve from 0.38514\n",
      "Epoch 1928/3000\n",
      "13/13 - 0s - loss: 0.2141 - accuracy: 0.8962 - val_loss: 1.7584 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 01928: val_loss did not improve from 0.38514\n",
      "Epoch 1929/3000\n",
      "13/13 - 0s - loss: 0.2083 - accuracy: 0.8923 - val_loss: 1.6522 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01929: val_loss did not improve from 0.38514\n",
      "Epoch 1930/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.8988 - val_loss: 1.5113 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01930: val_loss did not improve from 0.38514\n",
      "Epoch 1931/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.8962 - val_loss: 1.4939 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01931: val_loss did not improve from 0.38514\n",
      "Epoch 1932/3000\n",
      "13/13 - 0s - loss: 0.2061 - accuracy: 0.8962 - val_loss: 1.5074 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01932: val_loss did not improve from 0.38514\n",
      "Epoch 1933/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.8975 - val_loss: 1.5757 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01933: val_loss did not improve from 0.38514\n",
      "Epoch 1934/3000\n",
      "13/13 - 0s - loss: 0.2066 - accuracy: 0.9027 - val_loss: 1.6085 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01934: val_loss did not improve from 0.38514\n",
      "Epoch 1935/3000\n",
      "13/13 - 0s - loss: 0.2082 - accuracy: 0.9027 - val_loss: 1.7868 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01935: val_loss did not improve from 0.38514\n",
      "Epoch 1936/3000\n",
      "13/13 - 0s - loss: 0.2101 - accuracy: 0.9027 - val_loss: 1.8345 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01936: val_loss did not improve from 0.38514\n",
      "Epoch 1937/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.9040 - val_loss: 1.8167 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01937: val_loss did not improve from 0.38514\n",
      "Epoch 1938/3000\n",
      "13/13 - 0s - loss: 0.2058 - accuracy: 0.9027 - val_loss: 1.8329 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01938: val_loss did not improve from 0.38514\n",
      "Epoch 1939/3000\n",
      "13/13 - 0s - loss: 0.2076 - accuracy: 0.8975 - val_loss: 1.7752 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01939: val_loss did not improve from 0.38514\n",
      "Epoch 1940/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.8949 - val_loss: 1.8602 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01940: val_loss did not improve from 0.38514\n",
      "Epoch 1941/3000\n",
      "13/13 - 0s - loss: 0.2085 - accuracy: 0.8949 - val_loss: 1.8988 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01941: val_loss did not improve from 0.38514\n",
      "Epoch 1942/3000\n",
      "13/13 - 0s - loss: 0.2125 - accuracy: 0.8949 - val_loss: 1.8182 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01942: val_loss did not improve from 0.38514\n",
      "Epoch 1943/3000\n",
      "13/13 - 0s - loss: 0.2130 - accuracy: 0.8949 - val_loss: 1.8253 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01943: val_loss did not improve from 0.38514\n",
      "Epoch 1944/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.9014 - val_loss: 1.8666 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01944: val_loss did not improve from 0.38514\n",
      "Epoch 1945/3000\n",
      "13/13 - 0s - loss: 0.2064 - accuracy: 0.9014 - val_loss: 1.8597 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01945: val_loss did not improve from 0.38514\n",
      "Epoch 1946/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.9027 - val_loss: 1.8972 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01946: val_loss did not improve from 0.38514\n",
      "Epoch 1947/3000\n",
      "13/13 - 0s - loss: 0.2076 - accuracy: 0.9027 - val_loss: 1.9029 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01947: val_loss did not improve from 0.38514\n",
      "Epoch 1948/3000\n",
      "13/13 - 0s - loss: 0.2056 - accuracy: 0.9027 - val_loss: 1.8328 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01948: val_loss did not improve from 0.38514\n",
      "Epoch 1949/3000\n",
      "13/13 - 0s - loss: 0.2059 - accuracy: 0.9001 - val_loss: 1.7966 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01949: val_loss did not improve from 0.38514\n",
      "Epoch 1950/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.9001 - val_loss: 1.7931 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01950: val_loss did not improve from 0.38514\n",
      "Epoch 1951/3000\n",
      "13/13 - 0s - loss: 0.2098 - accuracy: 0.9001 - val_loss: 1.8069 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01951: val_loss did not improve from 0.38514\n",
      "Epoch 1952/3000\n",
      "13/13 - 0s - loss: 0.2167 - accuracy: 0.8911 - val_loss: 1.8238 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01952: val_loss did not improve from 0.38514\n",
      "Epoch 1953/3000\n",
      "13/13 - 0s - loss: 0.2106 - accuracy: 0.8949 - val_loss: 1.8421 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01953: val_loss did not improve from 0.38514\n",
      "Epoch 1954/3000\n",
      "13/13 - 0s - loss: 0.2078 - accuracy: 0.9053 - val_loss: 1.8817 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01954: val_loss did not improve from 0.38514\n",
      "Epoch 1955/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.9027 - val_loss: 1.9046 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01955: val_loss did not improve from 0.38514\n",
      "Epoch 1956/3000\n",
      "13/13 - 0s - loss: 0.2076 - accuracy: 0.9014 - val_loss: 1.9529 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01956: val_loss did not improve from 0.38514\n",
      "Epoch 1957/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.9027 - val_loss: 1.9667 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01957: val_loss did not improve from 0.38514\n",
      "Epoch 1958/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.9001 - val_loss: 1.9947 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01958: val_loss did not improve from 0.38514\n",
      "Epoch 1959/3000\n",
      "13/13 - 0s - loss: 0.2066 - accuracy: 0.9001 - val_loss: 1.9793 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01959: val_loss did not improve from 0.38514\n",
      "Epoch 1960/3000\n",
      "13/13 - 0s - loss: 0.2064 - accuracy: 0.9014 - val_loss: 1.9830 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01960: val_loss did not improve from 0.38514\n",
      "Epoch 1961/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.9027 - val_loss: 1.9423 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01961: val_loss did not improve from 0.38514\n",
      "Epoch 1962/3000\n",
      "13/13 - 0s - loss: 0.2046 - accuracy: 0.9027 - val_loss: 1.9682 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01962: val_loss did not improve from 0.38514\n",
      "Epoch 1963/3000\n",
      "13/13 - 0s - loss: 0.2077 - accuracy: 0.9014 - val_loss: 1.9751 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01963: val_loss did not improve from 0.38514\n",
      "Epoch 1964/3000\n",
      "13/13 - 0s - loss: 0.2047 - accuracy: 0.9027 - val_loss: 1.9025 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01964: val_loss did not improve from 0.38514\n",
      "Epoch 1965/3000\n",
      "13/13 - 0s - loss: 0.2068 - accuracy: 0.9001 - val_loss: 1.9298 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01965: val_loss did not improve from 0.38514\n",
      "Epoch 1966/3000\n",
      "13/13 - 0s - loss: 0.2082 - accuracy: 0.9014 - val_loss: 1.8377 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01966: val_loss did not improve from 0.38514\n",
      "Epoch 1967/3000\n",
      "13/13 - 0s - loss: 0.2093 - accuracy: 0.9001 - val_loss: 1.9201 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01967: val_loss did not improve from 0.38514\n",
      "Epoch 1968/3000\n",
      "13/13 - 0s - loss: 0.2073 - accuracy: 0.9027 - val_loss: 1.9868 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01968: val_loss did not improve from 0.38514\n",
      "Epoch 1969/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.9014 - val_loss: 2.0294 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01969: val_loss did not improve from 0.38514\n",
      "Epoch 1970/3000\n",
      "13/13 - 0s - loss: 0.2056 - accuracy: 0.9027 - val_loss: 2.0311 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01970: val_loss did not improve from 0.38514\n",
      "Epoch 1971/3000\n",
      "13/13 - 0s - loss: 0.2068 - accuracy: 0.9014 - val_loss: 2.0541 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01971: val_loss did not improve from 0.38514\n",
      "Epoch 1972/3000\n",
      "13/13 - 0s - loss: 0.2053 - accuracy: 0.9027 - val_loss: 2.0748 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01972: val_loss did not improve from 0.38514\n",
      "Epoch 1973/3000\n",
      "13/13 - 0s - loss: 0.2051 - accuracy: 0.9001 - val_loss: 2.1071 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01973: val_loss did not improve from 0.38514\n",
      "Epoch 1974/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.9027 - val_loss: 2.1223 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01974: val_loss did not improve from 0.38514\n",
      "Epoch 1975/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.9027 - val_loss: 2.2872 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01975: val_loss did not improve from 0.38514\n",
      "Epoch 1976/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.9027 - val_loss: 2.3129 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01976: val_loss did not improve from 0.38514\n",
      "Epoch 1977/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.9027 - val_loss: 2.3102 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01977: val_loss did not improve from 0.38514\n",
      "Epoch 1978/3000\n",
      "13/13 - 0s - loss: 0.2051 - accuracy: 0.9027 - val_loss: 2.3969 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01978: val_loss did not improve from 0.38514\n",
      "Epoch 1979/3000\n",
      "13/13 - 0s - loss: 0.2086 - accuracy: 0.8988 - val_loss: 2.5075 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01979: val_loss did not improve from 0.38514\n",
      "Epoch 1980/3000\n",
      "13/13 - 0s - loss: 0.2073 - accuracy: 0.9014 - val_loss: 2.5010 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01980: val_loss did not improve from 0.38514\n",
      "Epoch 1981/3000\n",
      "13/13 - 0s - loss: 0.2086 - accuracy: 0.8975 - val_loss: 2.4597 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01981: val_loss did not improve from 0.38514\n",
      "Epoch 1982/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.9014 - val_loss: 2.4488 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01982: val_loss did not improve from 0.38514\n",
      "Epoch 1983/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.8975 - val_loss: 2.5080 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01983: val_loss did not improve from 0.38514\n",
      "Epoch 1984/3000\n",
      "13/13 - 0s - loss: 0.2077 - accuracy: 0.8988 - val_loss: 2.4823 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01984: val_loss did not improve from 0.38514\n",
      "Epoch 1985/3000\n",
      "13/13 - 0s - loss: 0.2161 - accuracy: 0.9014 - val_loss: 2.3497 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01985: val_loss did not improve from 0.38514\n",
      "Epoch 1986/3000\n",
      "13/13 - 0s - loss: 0.2091 - accuracy: 0.9027 - val_loss: 2.3741 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01986: val_loss did not improve from 0.38514\n",
      "Epoch 1987/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.9027 - val_loss: 2.3762 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01987: val_loss did not improve from 0.38514\n",
      "Epoch 1988/3000\n",
      "13/13 - 0s - loss: 0.2096 - accuracy: 0.9027 - val_loss: 2.3621 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01988: val_loss did not improve from 0.38514\n",
      "Epoch 1989/3000\n",
      "13/13 - 0s - loss: 0.2060 - accuracy: 0.9027 - val_loss: 2.3196 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01989: val_loss did not improve from 0.38514\n",
      "Epoch 1990/3000\n",
      "13/13 - 0s - loss: 0.2060 - accuracy: 0.9027 - val_loss: 2.3283 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01990: val_loss did not improve from 0.38514\n",
      "Epoch 1991/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.9027 - val_loss: 2.3249 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01991: val_loss did not improve from 0.38514\n",
      "Epoch 1992/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.9014 - val_loss: 2.3147 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01992: val_loss did not improve from 0.38514\n",
      "Epoch 1993/3000\n",
      "13/13 - 0s - loss: 0.2056 - accuracy: 0.9014 - val_loss: 2.2466 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01993: val_loss did not improve from 0.38514\n",
      "Epoch 1994/3000\n",
      "13/13 - 0s - loss: 0.2060 - accuracy: 0.9014 - val_loss: 2.3508 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01994: val_loss did not improve from 0.38514\n",
      "Epoch 1995/3000\n",
      "13/13 - 0s - loss: 0.2047 - accuracy: 0.9027 - val_loss: 2.3824 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 01995: val_loss did not improve from 0.38514\n",
      "Epoch 1996/3000\n",
      "13/13 - 0s - loss: 0.2046 - accuracy: 0.9027 - val_loss: 2.4017 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01996: val_loss did not improve from 0.38514\n",
      "Epoch 1997/3000\n",
      "13/13 - 0s - loss: 0.2049 - accuracy: 0.9027 - val_loss: 2.4915 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01997: val_loss did not improve from 0.38514\n",
      "Epoch 1998/3000\n",
      "13/13 - 0s - loss: 0.2067 - accuracy: 0.8962 - val_loss: 2.4372 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 01998: val_loss did not improve from 0.38514\n",
      "Epoch 1999/3000\n",
      "13/13 - 0s - loss: 0.2065 - accuracy: 0.8962 - val_loss: 2.4276 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 01999: val_loss did not improve from 0.38514\n",
      "Epoch 2000/3000\n",
      "13/13 - 0s - loss: 0.2061 - accuracy: 0.8949 - val_loss: 2.3793 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02000: val_loss did not improve from 0.38514\n",
      "Epoch 2001/3000\n",
      "13/13 - 0s - loss: 0.2053 - accuracy: 0.8911 - val_loss: 2.3492 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02001: val_loss did not improve from 0.38514\n",
      "Epoch 2002/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.8962 - val_loss: 2.3451 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02002: val_loss did not improve from 0.38514\n",
      "Epoch 2003/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.9001 - val_loss: 2.2775 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02003: val_loss did not improve from 0.38514\n",
      "Epoch 2004/3000\n",
      "13/13 - 0s - loss: 0.2078 - accuracy: 0.9014 - val_loss: 2.1523 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02004: val_loss did not improve from 0.38514\n",
      "Epoch 2005/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.8988 - val_loss: 2.2094 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02005: val_loss did not improve from 0.38514\n",
      "Epoch 2006/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.9027 - val_loss: 2.1721 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02006: val_loss did not improve from 0.38514\n",
      "Epoch 2007/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.9014 - val_loss: 2.3480 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02007: val_loss did not improve from 0.38514\n",
      "Epoch 2008/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.8975 - val_loss: 2.5129 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02008: val_loss did not improve from 0.38514\n",
      "Epoch 2009/3000\n",
      "13/13 - 0s - loss: 0.2105 - accuracy: 0.8923 - val_loss: 2.4720 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02009: val_loss did not improve from 0.38514\n",
      "Epoch 2010/3000\n",
      "13/13 - 0s - loss: 0.2083 - accuracy: 0.9053 - val_loss: 2.1615 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02010: val_loss did not improve from 0.38514\n",
      "Epoch 2011/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.8975 - val_loss: 2.1413 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02011: val_loss did not improve from 0.38514\n",
      "Epoch 2012/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.9027 - val_loss: 2.1428 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02012: val_loss did not improve from 0.38514\n",
      "Epoch 2013/3000\n",
      "13/13 - 0s - loss: 0.2048 - accuracy: 0.9027 - val_loss: 2.1273 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02013: val_loss did not improve from 0.38514\n",
      "Epoch 2014/3000\n",
      "13/13 - 0s - loss: 0.2046 - accuracy: 0.9027 - val_loss: 2.1704 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02014: val_loss did not improve from 0.38514\n",
      "Epoch 2015/3000\n",
      "13/13 - 0s - loss: 0.2080 - accuracy: 0.8975 - val_loss: 2.3386 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02015: val_loss did not improve from 0.38514\n",
      "Epoch 2016/3000\n",
      "13/13 - 0s - loss: 0.2077 - accuracy: 0.8949 - val_loss: 2.4893 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02016: val_loss did not improve from 0.38514\n",
      "Epoch 2017/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.8949 - val_loss: 2.4938 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02017: val_loss did not improve from 0.38514\n",
      "Epoch 2018/3000\n",
      "13/13 - 0s - loss: 0.2070 - accuracy: 0.9027 - val_loss: 2.4383 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02018: val_loss did not improve from 0.38514\n",
      "Epoch 2019/3000\n",
      "13/13 - 0s - loss: 0.2058 - accuracy: 0.9027 - val_loss: 2.3914 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02019: val_loss did not improve from 0.38514\n",
      "Epoch 2020/3000\n",
      "13/13 - 0s - loss: 0.2047 - accuracy: 0.9027 - val_loss: 2.3449 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02020: val_loss did not improve from 0.38514\n",
      "Epoch 2021/3000\n",
      "13/13 - 0s - loss: 0.2047 - accuracy: 0.9027 - val_loss: 2.2202 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02021: val_loss did not improve from 0.38514\n",
      "Epoch 2022/3000\n",
      "13/13 - 0s - loss: 0.2068 - accuracy: 0.9014 - val_loss: 2.1688 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02022: val_loss did not improve from 0.38514\n",
      "Epoch 2023/3000\n",
      "13/13 - 0s - loss: 0.2052 - accuracy: 0.9027 - val_loss: 2.1842 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02023: val_loss did not improve from 0.38514\n",
      "Epoch 2024/3000\n",
      "13/13 - 0s - loss: 0.2046 - accuracy: 0.9027 - val_loss: 2.2199 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02024: val_loss did not improve from 0.38514\n",
      "Epoch 2025/3000\n",
      "13/13 - 0s - loss: 0.2064 - accuracy: 0.9027 - val_loss: 2.2532 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02025: val_loss did not improve from 0.38514\n",
      "Epoch 2026/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.9040 - val_loss: 2.2495 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02026: val_loss did not improve from 0.38514\n",
      "Epoch 2027/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.9014 - val_loss: 2.2122 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02027: val_loss did not improve from 0.38514\n",
      "Epoch 2028/3000\n",
      "13/13 - 0s - loss: 0.2051 - accuracy: 0.9027 - val_loss: 2.1698 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02028: val_loss did not improve from 0.38514\n",
      "Epoch 2029/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.9027 - val_loss: 2.3626 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02029: val_loss did not improve from 0.38514\n",
      "Epoch 2030/3000\n",
      "13/13 - 0s - loss: 0.2066 - accuracy: 0.8988 - val_loss: 2.6404 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02030: val_loss did not improve from 0.38514\n",
      "Epoch 2031/3000\n",
      "13/13 - 0s - loss: 0.2107 - accuracy: 0.8962 - val_loss: 2.6369 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02031: val_loss did not improve from 0.38514\n",
      "Epoch 2032/3000\n",
      "13/13 - 0s - loss: 0.2190 - accuracy: 0.8872 - val_loss: 2.5643 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02032: val_loss did not improve from 0.38514\n",
      "Epoch 2033/3000\n",
      "13/13 - 0s - loss: 0.2258 - accuracy: 0.8872 - val_loss: 2.6130 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02033: val_loss did not improve from 0.38514\n",
      "Epoch 2034/3000\n",
      "13/13 - 0s - loss: 0.2125 - accuracy: 0.8988 - val_loss: 2.3104 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02034: val_loss did not improve from 0.38514\n",
      "Epoch 2035/3000\n",
      "13/13 - 0s - loss: 0.2144 - accuracy: 0.9027 - val_loss: 2.2299 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02035: val_loss did not improve from 0.38514\n",
      "Epoch 2036/3000\n",
      "13/13 - 0s - loss: 0.2108 - accuracy: 0.9027 - val_loss: 2.2838 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02036: val_loss did not improve from 0.38514\n",
      "Epoch 2037/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.9014 - val_loss: 2.3451 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02037: val_loss did not improve from 0.38514\n",
      "Epoch 2038/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.9027 - val_loss: 2.4222 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02038: val_loss did not improve from 0.38514\n",
      "Epoch 2039/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.8962 - val_loss: 2.4316 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02039: val_loss did not improve from 0.38514\n",
      "Epoch 2040/3000\n",
      "13/13 - 0s - loss: 0.2061 - accuracy: 0.9001 - val_loss: 2.5741 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02040: val_loss did not improve from 0.38514\n",
      "Epoch 2041/3000\n",
      "13/13 - 0s - loss: 0.2080 - accuracy: 0.9027 - val_loss: 2.4885 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02041: val_loss did not improve from 0.38514\n",
      "Epoch 2042/3000\n",
      "13/13 - 0s - loss: 0.2167 - accuracy: 0.8988 - val_loss: 2.4028 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02042: val_loss did not improve from 0.38514\n",
      "Epoch 2043/3000\n",
      "13/13 - 0s - loss: 0.2297 - accuracy: 0.8988 - val_loss: 2.1701 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02043: val_loss did not improve from 0.38514\n",
      "Epoch 2044/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.9027 - val_loss: 2.2487 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02044: val_loss did not improve from 0.38514\n",
      "Epoch 2045/3000\n",
      "13/13 - 0s - loss: 0.2097 - accuracy: 0.8988 - val_loss: 2.3225 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02045: val_loss did not improve from 0.38514\n",
      "Epoch 2046/3000\n",
      "13/13 - 0s - loss: 0.2067 - accuracy: 0.8988 - val_loss: 2.3052 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02046: val_loss did not improve from 0.38514\n",
      "Epoch 2047/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.8988 - val_loss: 2.4206 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02047: val_loss did not improve from 0.38514\n",
      "Epoch 2048/3000\n",
      "13/13 - 0s - loss: 0.2051 - accuracy: 0.9027 - val_loss: 2.4225 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02048: val_loss did not improve from 0.38514\n",
      "Epoch 2049/3000\n",
      "13/13 - 0s - loss: 0.2147 - accuracy: 0.8898 - val_loss: 2.7567 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02049: val_loss did not improve from 0.38514\n",
      "Epoch 2050/3000\n",
      "13/13 - 0s - loss: 0.2176 - accuracy: 0.8820 - val_loss: 2.8207 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02050: val_loss did not improve from 0.38514\n",
      "Epoch 2051/3000\n",
      "13/13 - 0s - loss: 0.2175 - accuracy: 0.8846 - val_loss: 2.8271 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02051: val_loss did not improve from 0.38514\n",
      "Epoch 2052/3000\n",
      "13/13 - 0s - loss: 0.2224 - accuracy: 0.8846 - val_loss: 2.2692 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02052: val_loss did not improve from 0.38514\n",
      "Epoch 2053/3000\n",
      "13/13 - 0s - loss: 0.2217 - accuracy: 0.8988 - val_loss: 1.9877 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02053: val_loss did not improve from 0.38514\n",
      "Epoch 2054/3000\n",
      "13/13 - 0s - loss: 0.2215 - accuracy: 0.9001 - val_loss: 2.1475 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02054: val_loss did not improve from 0.38514\n",
      "Epoch 2055/3000\n",
      "13/13 - 0s - loss: 0.2393 - accuracy: 0.9014 - val_loss: 1.5984 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02055: val_loss did not improve from 0.38514\n",
      "Epoch 2056/3000\n",
      "13/13 - 0s - loss: 0.2103 - accuracy: 0.8962 - val_loss: 1.3485 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02056: val_loss did not improve from 0.38514\n",
      "Epoch 2057/3000\n",
      "13/13 - 0s - loss: 0.2095 - accuracy: 0.8975 - val_loss: 1.5041 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02057: val_loss did not improve from 0.38514\n",
      "Epoch 2058/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.9001 - val_loss: 1.5080 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02058: val_loss did not improve from 0.38514\n",
      "Epoch 2059/3000\n",
      "13/13 - 0s - loss: 0.2056 - accuracy: 0.9001 - val_loss: 1.5208 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02059: val_loss did not improve from 0.38514\n",
      "Epoch 2060/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.8988 - val_loss: 1.5481 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02060: val_loss did not improve from 0.38514\n",
      "Epoch 2061/3000\n",
      "13/13 - 0s - loss: 0.2056 - accuracy: 0.9027 - val_loss: 1.5847 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02061: val_loss did not improve from 0.38514\n",
      "Epoch 2062/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.9001 - val_loss: 1.6234 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02062: val_loss did not improve from 0.38514\n",
      "Epoch 2063/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.9001 - val_loss: 1.6339 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02063: val_loss did not improve from 0.38514\n",
      "Epoch 2064/3000\n",
      "13/13 - 0s - loss: 0.2070 - accuracy: 0.9014 - val_loss: 1.6024 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02064: val_loss did not improve from 0.38514\n",
      "Epoch 2065/3000\n",
      "13/13 - 0s - loss: 0.2060 - accuracy: 0.9001 - val_loss: 1.7071 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02065: val_loss did not improve from 0.38514\n",
      "Epoch 2066/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.9014 - val_loss: 1.5660 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02066: val_loss did not improve from 0.38514\n",
      "Epoch 2067/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.9014 - val_loss: 1.4916 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02067: val_loss did not improve from 0.38514\n",
      "Epoch 2068/3000\n",
      "13/13 - 0s - loss: 0.2080 - accuracy: 0.9001 - val_loss: 1.3711 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02068: val_loss did not improve from 0.38514\n",
      "Epoch 2069/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.9001 - val_loss: 1.2060 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02069: val_loss did not improve from 0.38514\n",
      "Epoch 2070/3000\n",
      "13/13 - 0s - loss: 0.2058 - accuracy: 0.9014 - val_loss: 1.1905 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02070: val_loss did not improve from 0.38514\n",
      "Epoch 2071/3000\n",
      "13/13 - 0s - loss: 0.2097 - accuracy: 0.8975 - val_loss: 1.2329 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02071: val_loss did not improve from 0.38514\n",
      "Epoch 2072/3000\n",
      "13/13 - 0s - loss: 0.2085 - accuracy: 0.8962 - val_loss: 1.2510 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02072: val_loss did not improve from 0.38514\n",
      "Epoch 2073/3000\n",
      "13/13 - 0s - loss: 0.2077 - accuracy: 0.8923 - val_loss: 1.3198 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02073: val_loss did not improve from 0.38514\n",
      "Epoch 2074/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.9001 - val_loss: 1.3243 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02074: val_loss did not improve from 0.38514\n",
      "Epoch 2075/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.9014 - val_loss: 1.4119 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02075: val_loss did not improve from 0.38514\n",
      "Epoch 2076/3000\n",
      "13/13 - 0s - loss: 0.2058 - accuracy: 0.9014 - val_loss: 1.4443 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02076: val_loss did not improve from 0.38514\n",
      "Epoch 2077/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.9027 - val_loss: 1.4775 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02077: val_loss did not improve from 0.38514\n",
      "Epoch 2078/3000\n",
      "13/13 - 0s - loss: 0.2045 - accuracy: 0.9001 - val_loss: 1.4911 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02078: val_loss did not improve from 0.38514\n",
      "Epoch 2079/3000\n",
      "13/13 - 0s - loss: 0.2047 - accuracy: 0.9014 - val_loss: 1.5074 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02079: val_loss did not improve from 0.38514\n",
      "Epoch 2080/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.9001 - val_loss: 1.4872 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02080: val_loss did not improve from 0.38514\n",
      "Epoch 2081/3000\n",
      "13/13 - 0s - loss: 0.2135 - accuracy: 0.8911 - val_loss: 1.5065 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02081: val_loss did not improve from 0.38514\n",
      "Epoch 2082/3000\n",
      "13/13 - 0s - loss: 0.2166 - accuracy: 0.8911 - val_loss: 1.4099 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02082: val_loss did not improve from 0.38514\n",
      "Epoch 2083/3000\n",
      "13/13 - 0s - loss: 0.2111 - accuracy: 0.9014 - val_loss: 1.3533 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02083: val_loss did not improve from 0.38514\n",
      "Epoch 2084/3000\n",
      "13/13 - 0s - loss: 0.2088 - accuracy: 0.9027 - val_loss: 1.5504 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02084: val_loss did not improve from 0.38514\n",
      "Epoch 2085/3000\n",
      "13/13 - 0s - loss: 0.2112 - accuracy: 0.9027 - val_loss: 1.3882 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02085: val_loss did not improve from 0.38514\n",
      "Epoch 2086/3000\n",
      "13/13 - 0s - loss: 0.2147 - accuracy: 0.9014 - val_loss: 1.1405 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02086: val_loss did not improve from 0.38514\n",
      "Epoch 2087/3000\n",
      "13/13 - 0s - loss: 0.2236 - accuracy: 0.8962 - val_loss: 1.1807 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02087: val_loss did not improve from 0.38514\n",
      "Epoch 2088/3000\n",
      "13/13 - 0s - loss: 0.2551 - accuracy: 0.8923 - val_loss: 1.8677 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02088: val_loss did not improve from 0.38514\n",
      "Epoch 2089/3000\n",
      "13/13 - 0s - loss: 0.4301 - accuracy: 0.8936 - val_loss: 1.0066 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02089: val_loss did not improve from 0.38514\n",
      "Epoch 2090/3000\n",
      "13/13 - 0s - loss: 0.2171 - accuracy: 0.8988 - val_loss: 1.2073 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02090: val_loss did not improve from 0.38514\n",
      "Epoch 2091/3000\n",
      "13/13 - 0s - loss: 0.2114 - accuracy: 0.9014 - val_loss: 1.4069 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02091: val_loss did not improve from 0.38514\n",
      "Epoch 2092/3000\n",
      "13/13 - 0s - loss: 0.2126 - accuracy: 0.9027 - val_loss: 1.5329 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02092: val_loss did not improve from 0.38514\n",
      "Epoch 2093/3000\n",
      "13/13 - 0s - loss: 0.2088 - accuracy: 0.9027 - val_loss: 1.8610 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02093: val_loss did not improve from 0.38514\n",
      "Epoch 2094/3000\n",
      "13/13 - 0s - loss: 0.2122 - accuracy: 0.9027 - val_loss: 1.9499 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02094: val_loss did not improve from 0.38514\n",
      "Epoch 2095/3000\n",
      "13/13 - 0s - loss: 0.2109 - accuracy: 0.9001 - val_loss: 1.7732 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02095: val_loss did not improve from 0.38514\n",
      "Epoch 2096/3000\n",
      "13/13 - 0s - loss: 0.2085 - accuracy: 0.9014 - val_loss: 1.7424 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02096: val_loss did not improve from 0.38514\n",
      "Epoch 2097/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.9027 - val_loss: 1.6904 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02097: val_loss did not improve from 0.38514\n",
      "Epoch 2098/3000\n",
      "13/13 - 0s - loss: 0.2196 - accuracy: 0.9027 - val_loss: 1.6513 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02098: val_loss did not improve from 0.38514\n",
      "Epoch 2099/3000\n",
      "13/13 - 0s - loss: 0.2094 - accuracy: 0.9014 - val_loss: 1.6178 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02099: val_loss did not improve from 0.38514\n",
      "Epoch 2100/3000\n",
      "13/13 - 0s - loss: 0.2088 - accuracy: 0.9040 - val_loss: 1.7923 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02100: val_loss did not improve from 0.38514\n",
      "Epoch 2101/3000\n",
      "13/13 - 0s - loss: 0.2120 - accuracy: 0.9001 - val_loss: 1.8439 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02101: val_loss did not improve from 0.38514\n",
      "Epoch 2102/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9001 - val_loss: 1.8040 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02102: val_loss did not improve from 0.38514\n",
      "Epoch 2103/3000\n",
      "13/13 - 0s - loss: 0.2093 - accuracy: 0.9001 - val_loss: 1.7291 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02103: val_loss did not improve from 0.38514\n",
      "Epoch 2104/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.9027 - val_loss: 1.6765 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02104: val_loss did not improve from 0.38514\n",
      "Epoch 2105/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.9027 - val_loss: 1.6794 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02105: val_loss did not improve from 0.38514\n",
      "Epoch 2106/3000\n",
      "13/13 - 0s - loss: 0.2066 - accuracy: 0.9040 - val_loss: 1.7558 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02106: val_loss did not improve from 0.38514\n",
      "Epoch 2107/3000\n",
      "13/13 - 0s - loss: 0.2060 - accuracy: 0.9027 - val_loss: 1.8786 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02107: val_loss did not improve from 0.38514\n",
      "Epoch 2108/3000\n",
      "13/13 - 0s - loss: 0.2104 - accuracy: 0.8898 - val_loss: 1.7492 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02108: val_loss did not improve from 0.38514\n",
      "Epoch 2109/3000\n",
      "13/13 - 0s - loss: 0.2120 - accuracy: 0.8807 - val_loss: 1.6327 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02109: val_loss did not improve from 0.38514\n",
      "Epoch 2110/3000\n",
      "13/13 - 0s - loss: 0.2092 - accuracy: 0.9014 - val_loss: 1.7315 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02110: val_loss did not improve from 0.38514\n",
      "Epoch 2111/3000\n",
      "13/13 - 0s - loss: 0.2059 - accuracy: 0.8988 - val_loss: 1.6944 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02111: val_loss did not improve from 0.38514\n",
      "Epoch 2112/3000\n",
      "13/13 - 0s - loss: 0.2261 - accuracy: 0.9027 - val_loss: 1.6259 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02112: val_loss did not improve from 0.38514\n",
      "Epoch 2113/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.8923 - val_loss: 1.1323 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02113: val_loss did not improve from 0.38514\n",
      "Epoch 2114/3000\n",
      "13/13 - 0s - loss: 0.2171 - accuracy: 0.8898 - val_loss: 1.1603 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02114: val_loss did not improve from 0.38514\n",
      "Epoch 2115/3000\n",
      "13/13 - 0s - loss: 0.2165 - accuracy: 0.9001 - val_loss: 1.2271 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02115: val_loss did not improve from 0.38514\n",
      "Epoch 2116/3000\n",
      "13/13 - 0s - loss: 0.2162 - accuracy: 0.8923 - val_loss: 1.6609 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02116: val_loss did not improve from 0.38514\n",
      "Epoch 2117/3000\n",
      "13/13 - 0s - loss: 0.2864 - accuracy: 0.8885 - val_loss: 1.3712 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 02117: val_loss did not improve from 0.38514\n",
      "Epoch 2118/3000\n",
      "13/13 - 0s - loss: 0.3427 - accuracy: 0.8781 - val_loss: 1.4225 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02118: val_loss did not improve from 0.38514\n",
      "Epoch 2119/3000\n",
      "13/13 - 0s - loss: 0.2763 - accuracy: 0.8820 - val_loss: 1.1953 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 02119: val_loss did not improve from 0.38514\n",
      "Epoch 2120/3000\n",
      "13/13 - 0s - loss: 0.2357 - accuracy: 0.8859 - val_loss: 1.4272 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02120: val_loss did not improve from 0.38514\n",
      "Epoch 2121/3000\n",
      "13/13 - 0s - loss: 0.2307 - accuracy: 0.8885 - val_loss: 1.6597 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02121: val_loss did not improve from 0.38514\n",
      "Epoch 2122/3000\n",
      "13/13 - 0s - loss: 0.2210 - accuracy: 0.8911 - val_loss: 1.7811 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02122: val_loss did not improve from 0.38514\n",
      "Epoch 2123/3000\n",
      "13/13 - 0s - loss: 0.2208 - accuracy: 0.8923 - val_loss: 1.7273 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02123: val_loss did not improve from 0.38514\n",
      "Epoch 2124/3000\n",
      "13/13 - 0s - loss: 0.2277 - accuracy: 0.8923 - val_loss: 1.7178 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02124: val_loss did not improve from 0.38514\n",
      "Epoch 2125/3000\n",
      "13/13 - 0s - loss: 0.2179 - accuracy: 0.8988 - val_loss: 1.5107 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02125: val_loss did not improve from 0.38514\n",
      "Epoch 2126/3000\n",
      "13/13 - 0s - loss: 0.2078 - accuracy: 0.8975 - val_loss: 1.6047 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02126: val_loss did not improve from 0.38514\n",
      "Epoch 2127/3000\n",
      "13/13 - 0s - loss: 0.2098 - accuracy: 0.8949 - val_loss: 1.6425 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02127: val_loss did not improve from 0.38514\n",
      "Epoch 2128/3000\n",
      "13/13 - 0s - loss: 0.2095 - accuracy: 0.8962 - val_loss: 1.7063 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02128: val_loss did not improve from 0.38514\n",
      "Epoch 2129/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.9014 - val_loss: 1.7386 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02129: val_loss did not improve from 0.38514\n",
      "Epoch 2130/3000\n",
      "13/13 - 0s - loss: 0.2073 - accuracy: 0.9001 - val_loss: 1.7886 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02130: val_loss did not improve from 0.38514\n",
      "Epoch 2131/3000\n",
      "13/13 - 0s - loss: 0.2086 - accuracy: 0.8975 - val_loss: 1.8051 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02131: val_loss did not improve from 0.38514\n",
      "Epoch 2132/3000\n",
      "13/13 - 0s - loss: 0.2060 - accuracy: 0.8975 - val_loss: 1.8299 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02132: val_loss did not improve from 0.38514\n",
      "Epoch 2133/3000\n",
      "13/13 - 0s - loss: 0.2059 - accuracy: 0.9001 - val_loss: 1.8348 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02133: val_loss did not improve from 0.38514\n",
      "Epoch 2134/3000\n",
      "13/13 - 0s - loss: 0.2049 - accuracy: 0.8988 - val_loss: 1.8912 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02134: val_loss did not improve from 0.38514\n",
      "Epoch 2135/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.9001 - val_loss: 1.9077 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02135: val_loss did not improve from 0.38514\n",
      "Epoch 2136/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.9001 - val_loss: 1.9568 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02136: val_loss did not improve from 0.38514\n",
      "Epoch 2137/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.8988 - val_loss: 1.9482 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02137: val_loss did not improve from 0.38514\n",
      "Epoch 2138/3000\n",
      "13/13 - 0s - loss: 0.2060 - accuracy: 0.8988 - val_loss: 1.9816 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02138: val_loss did not improve from 0.38514\n",
      "Epoch 2139/3000\n",
      "13/13 - 0s - loss: 0.2047 - accuracy: 0.9001 - val_loss: 1.9956 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02139: val_loss did not improve from 0.38514\n",
      "Epoch 2140/3000\n",
      "13/13 - 0s - loss: 0.2093 - accuracy: 0.8988 - val_loss: 2.0363 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02140: val_loss did not improve from 0.38514\n",
      "Epoch 2141/3000\n",
      "13/13 - 0s - loss: 0.2067 - accuracy: 0.9001 - val_loss: 1.9752 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02141: val_loss did not improve from 0.38514\n",
      "Epoch 2142/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.8962 - val_loss: 1.9258 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02142: val_loss did not improve from 0.38514\n",
      "Epoch 2143/3000\n",
      "13/13 - 0s - loss: 0.2048 - accuracy: 0.9001 - val_loss: 1.8681 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02143: val_loss did not improve from 0.38514\n",
      "Epoch 2144/3000\n",
      "13/13 - 0s - loss: 0.2041 - accuracy: 0.9001 - val_loss: 1.8732 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02144: val_loss did not improve from 0.38514\n",
      "Epoch 2145/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9001 - val_loss: 1.8263 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02145: val_loss did not improve from 0.38514\n",
      "Epoch 2146/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.9014 - val_loss: 1.6024 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02146: val_loss did not improve from 0.38514\n",
      "Epoch 2147/3000\n",
      "13/13 - 0s - loss: 0.2049 - accuracy: 0.8988 - val_loss: 1.5578 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02147: val_loss did not improve from 0.38514\n",
      "Epoch 2148/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.8988 - val_loss: 1.3697 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02148: val_loss did not improve from 0.38514\n",
      "Epoch 2149/3000\n",
      "13/13 - 0s - loss: 0.2114 - accuracy: 0.8962 - val_loss: 1.5753 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02149: val_loss did not improve from 0.38514\n",
      "Epoch 2150/3000\n",
      "13/13 - 0s - loss: 0.2099 - accuracy: 0.8962 - val_loss: 1.7561 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02150: val_loss did not improve from 0.38514\n",
      "Epoch 2151/3000\n",
      "13/13 - 0s - loss: 0.2068 - accuracy: 0.8962 - val_loss: 1.8038 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02151: val_loss did not improve from 0.38514\n",
      "Epoch 2152/3000\n",
      "13/13 - 0s - loss: 0.2095 - accuracy: 0.8962 - val_loss: 1.7945 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02152: val_loss did not improve from 0.38514\n",
      "Epoch 2153/3000\n",
      "13/13 - 0s - loss: 0.2101 - accuracy: 0.8975 - val_loss: 1.8173 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02153: val_loss did not improve from 0.38514\n",
      "Epoch 2154/3000\n",
      "13/13 - 0s - loss: 0.2092 - accuracy: 0.9001 - val_loss: 1.8081 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02154: val_loss did not improve from 0.38514\n",
      "Epoch 2155/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.8988 - val_loss: 1.7598 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02155: val_loss did not improve from 0.38514\n",
      "Epoch 2156/3000\n",
      "13/13 - 0s - loss: 0.2051 - accuracy: 0.9027 - val_loss: 1.7592 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02156: val_loss did not improve from 0.38514\n",
      "Epoch 2157/3000\n",
      "13/13 - 0s - loss: 0.2052 - accuracy: 0.9001 - val_loss: 1.7580 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02157: val_loss did not improve from 0.38514\n",
      "Epoch 2158/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9001 - val_loss: 1.7769 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02158: val_loss did not improve from 0.38514\n",
      "Epoch 2159/3000\n",
      "13/13 - 0s - loss: 0.2052 - accuracy: 0.9001 - val_loss: 1.7805 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02159: val_loss did not improve from 0.38514\n",
      "Epoch 2160/3000\n",
      "13/13 - 0s - loss: 0.2066 - accuracy: 0.8975 - val_loss: 1.8014 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02160: val_loss did not improve from 0.38514\n",
      "Epoch 2161/3000\n",
      "13/13 - 0s - loss: 0.2139 - accuracy: 0.9027 - val_loss: 1.8656 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02161: val_loss did not improve from 0.38514\n",
      "Epoch 2162/3000\n",
      "13/13 - 0s - loss: 0.2114 - accuracy: 0.9001 - val_loss: 1.8226 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02162: val_loss did not improve from 0.38514\n",
      "Epoch 2163/3000\n",
      "13/13 - 0s - loss: 0.2043 - accuracy: 0.8988 - val_loss: 1.8638 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02163: val_loss did not improve from 0.38514\n",
      "Epoch 2164/3000\n",
      "13/13 - 0s - loss: 0.2039 - accuracy: 0.9014 - val_loss: 1.8923 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02164: val_loss did not improve from 0.38514\n",
      "Epoch 2165/3000\n",
      "13/13 - 0s - loss: 0.2060 - accuracy: 0.9027 - val_loss: 1.9265 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02165: val_loss did not improve from 0.38514\n",
      "Epoch 2166/3000\n",
      "13/13 - 0s - loss: 0.2077 - accuracy: 0.8975 - val_loss: 1.8861 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02166: val_loss did not improve from 0.38514\n",
      "Epoch 2167/3000\n",
      "13/13 - 0s - loss: 0.2073 - accuracy: 0.8988 - val_loss: 1.9438 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02167: val_loss did not improve from 0.38514\n",
      "Epoch 2168/3000\n",
      "13/13 - 0s - loss: 0.2092 - accuracy: 0.9001 - val_loss: 1.9736 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02168: val_loss did not improve from 0.38514\n",
      "Epoch 2169/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.9014 - val_loss: 1.9949 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02169: val_loss did not improve from 0.38514\n",
      "Epoch 2170/3000\n",
      "13/13 - 0s - loss: 0.2051 - accuracy: 0.9027 - val_loss: 2.0280 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02170: val_loss did not improve from 0.38514\n",
      "Epoch 2171/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.8936 - val_loss: 1.9959 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02171: val_loss did not improve from 0.38514\n",
      "Epoch 2172/3000\n",
      "13/13 - 0s - loss: 0.2049 - accuracy: 0.8975 - val_loss: 2.0135 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02172: val_loss did not improve from 0.38514\n",
      "Epoch 2173/3000\n",
      "13/13 - 0s - loss: 0.2043 - accuracy: 0.9040 - val_loss: 2.0506 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02173: val_loss did not improve from 0.38514\n",
      "Epoch 2174/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.9027 - val_loss: 2.0225 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02174: val_loss did not improve from 0.38514\n",
      "Epoch 2175/3000\n",
      "13/13 - 0s - loss: 0.2039 - accuracy: 0.9014 - val_loss: 2.0215 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02175: val_loss did not improve from 0.38514\n",
      "Epoch 2176/3000\n",
      "13/13 - 0s - loss: 0.2033 - accuracy: 0.9027 - val_loss: 2.0529 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02176: val_loss did not improve from 0.38514\n",
      "Epoch 2177/3000\n",
      "13/13 - 0s - loss: 0.2040 - accuracy: 0.9027 - val_loss: 2.0731 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02177: val_loss did not improve from 0.38514\n",
      "Epoch 2178/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9040 - val_loss: 2.0650 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02178: val_loss did not improve from 0.38514\n",
      "Epoch 2179/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.9027 - val_loss: 2.0797 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02179: val_loss did not improve from 0.38514\n",
      "Epoch 2180/3000\n",
      "13/13 - 0s - loss: 0.2036 - accuracy: 0.9001 - val_loss: 2.1532 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02180: val_loss did not improve from 0.38514\n",
      "Epoch 2181/3000\n",
      "13/13 - 0s - loss: 0.2051 - accuracy: 0.9027 - val_loss: 2.0960 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02181: val_loss did not improve from 0.38514\n",
      "Epoch 2182/3000\n",
      "13/13 - 0s - loss: 0.2032 - accuracy: 0.9027 - val_loss: 2.0653 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02182: val_loss did not improve from 0.38514\n",
      "Epoch 2183/3000\n",
      "13/13 - 0s - loss: 0.2049 - accuracy: 0.8988 - val_loss: 2.0325 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02183: val_loss did not improve from 0.38514\n",
      "Epoch 2184/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.8975 - val_loss: 1.9957 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02184: val_loss did not improve from 0.38514\n",
      "Epoch 2185/3000\n",
      "13/13 - 0s - loss: 0.2059 - accuracy: 0.9014 - val_loss: 2.0352 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02185: val_loss did not improve from 0.38514\n",
      "Epoch 2186/3000\n",
      "13/13 - 0s - loss: 0.2045 - accuracy: 0.8988 - val_loss: 2.0443 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02186: val_loss did not improve from 0.38514\n",
      "Epoch 2187/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.9001 - val_loss: 2.0060 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02187: val_loss did not improve from 0.38514\n",
      "Epoch 2188/3000\n",
      "13/13 - 0s - loss: 0.2053 - accuracy: 0.9014 - val_loss: 2.0075 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02188: val_loss did not improve from 0.38514\n",
      "Epoch 2189/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.8975 - val_loss: 1.9979 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02189: val_loss did not improve from 0.38514\n",
      "Epoch 2190/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9014 - val_loss: 1.9500 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02190: val_loss did not improve from 0.38514\n",
      "Epoch 2191/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9027 - val_loss: 1.9617 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02191: val_loss did not improve from 0.38514\n",
      "Epoch 2192/3000\n",
      "13/13 - 0s - loss: 0.2059 - accuracy: 0.9027 - val_loss: 1.9609 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02192: val_loss did not improve from 0.38514\n",
      "Epoch 2193/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.9014 - val_loss: 1.9510 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02193: val_loss did not improve from 0.38514\n",
      "Epoch 2194/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.9027 - val_loss: 1.9363 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02194: val_loss did not improve from 0.38514\n",
      "Epoch 2195/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.9027 - val_loss: 1.9305 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02195: val_loss did not improve from 0.38514\n",
      "Epoch 2196/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.9027 - val_loss: 1.9188 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02196: val_loss did not improve from 0.38514\n",
      "Epoch 2197/3000\n",
      "13/13 - 0s - loss: 0.2039 - accuracy: 0.9014 - val_loss: 1.9083 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02197: val_loss did not improve from 0.38514\n",
      "Epoch 2198/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.8949 - val_loss: 1.9121 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02198: val_loss did not improve from 0.38514\n",
      "Epoch 2199/3000\n",
      "13/13 - 0s - loss: 0.2038 - accuracy: 0.9014 - val_loss: 1.9387 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02199: val_loss did not improve from 0.38514\n",
      "Epoch 2200/3000\n",
      "13/13 - 0s - loss: 0.2049 - accuracy: 0.8975 - val_loss: 1.9496 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02200: val_loss did not improve from 0.38514\n",
      "Epoch 2201/3000\n",
      "13/13 - 0s - loss: 0.2045 - accuracy: 0.8949 - val_loss: 1.9548 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02201: val_loss did not improve from 0.38514\n",
      "Epoch 2202/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.8988 - val_loss: 1.9281 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02202: val_loss did not improve from 0.38514\n",
      "Epoch 2203/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9001 - val_loss: 1.9656 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02203: val_loss did not improve from 0.38514\n",
      "Epoch 2204/3000\n",
      "13/13 - 0s - loss: 0.2068 - accuracy: 0.9014 - val_loss: 1.9711 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02204: val_loss did not improve from 0.38514\n",
      "Epoch 2205/3000\n",
      "13/13 - 0s - loss: 0.2064 - accuracy: 0.8988 - val_loss: 1.9545 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02205: val_loss did not improve from 0.38514\n",
      "Epoch 2206/3000\n",
      "13/13 - 0s - loss: 0.2040 - accuracy: 0.8988 - val_loss: 1.9596 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02206: val_loss did not improve from 0.38514\n",
      "Epoch 2207/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.9001 - val_loss: 1.9589 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02207: val_loss did not improve from 0.38514\n",
      "Epoch 2208/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9001 - val_loss: 2.0196 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02208: val_loss did not improve from 0.38514\n",
      "Epoch 2209/3000\n",
      "13/13 - 0s - loss: 0.2083 - accuracy: 0.9027 - val_loss: 1.9981 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02209: val_loss did not improve from 0.38514\n",
      "Epoch 2210/3000\n",
      "13/13 - 0s - loss: 0.2061 - accuracy: 0.9027 - val_loss: 1.9846 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02210: val_loss did not improve from 0.38514\n",
      "Epoch 2211/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.9027 - val_loss: 1.9711 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02211: val_loss did not improve from 0.38514\n",
      "Epoch 2212/3000\n",
      "13/13 - 0s - loss: 0.2067 - accuracy: 0.9027 - val_loss: 2.0055 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02212: val_loss did not improve from 0.38514\n",
      "Epoch 2213/3000\n",
      "13/13 - 0s - loss: 0.2033 - accuracy: 0.9014 - val_loss: 2.0128 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02213: val_loss did not improve from 0.38514\n",
      "Epoch 2214/3000\n",
      "13/13 - 0s - loss: 0.2040 - accuracy: 0.9014 - val_loss: 2.0414 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02214: val_loss did not improve from 0.38514\n",
      "Epoch 2215/3000\n",
      "13/13 - 0s - loss: 0.2040 - accuracy: 0.9027 - val_loss: 2.0673 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02215: val_loss did not improve from 0.38514\n",
      "Epoch 2216/3000\n",
      "13/13 - 0s - loss: 0.2029 - accuracy: 0.9027 - val_loss: 2.0385 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02216: val_loss did not improve from 0.38514\n",
      "Epoch 2217/3000\n",
      "13/13 - 0s - loss: 0.2049 - accuracy: 0.9014 - val_loss: 2.0018 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02217: val_loss did not improve from 0.38514\n",
      "Epoch 2218/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.9027 - val_loss: 1.9942 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02218: val_loss did not improve from 0.38514\n",
      "Epoch 2219/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.9040 - val_loss: 2.0079 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02219: val_loss did not improve from 0.38514\n",
      "Epoch 2220/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.9014 - val_loss: 1.9946 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02220: val_loss did not improve from 0.38514\n",
      "Epoch 2221/3000\n",
      "13/13 - 0s - loss: 0.2046 - accuracy: 0.9027 - val_loss: 2.0053 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02221: val_loss did not improve from 0.38514\n",
      "Epoch 2222/3000\n",
      "13/13 - 0s - loss: 0.2058 - accuracy: 0.9027 - val_loss: 2.0590 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02222: val_loss did not improve from 0.38514\n",
      "Epoch 2223/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.8949 - val_loss: 2.0743 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02223: val_loss did not improve from 0.38514\n",
      "Epoch 2224/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.9014 - val_loss: 1.9734 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02224: val_loss did not improve from 0.38514\n",
      "Epoch 2225/3000\n",
      "13/13 - 0s - loss: 0.2066 - accuracy: 0.9027 - val_loss: 2.0208 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02225: val_loss did not improve from 0.38514\n",
      "Epoch 2226/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.8988 - val_loss: 2.1392 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02226: val_loss did not improve from 0.38514\n",
      "Epoch 2227/3000\n",
      "13/13 - 0s - loss: 0.2060 - accuracy: 0.9014 - val_loss: 2.1630 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02227: val_loss did not improve from 0.38514\n",
      "Epoch 2228/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.9001 - val_loss: 2.1264 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02228: val_loss did not improve from 0.38514\n",
      "Epoch 2229/3000\n",
      "13/13 - 0s - loss: 0.2058 - accuracy: 0.9014 - val_loss: 1.9626 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02229: val_loss did not improve from 0.38514\n",
      "Epoch 2230/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.9014 - val_loss: 1.9466 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02230: val_loss did not improve from 0.38514\n",
      "Epoch 2231/3000\n",
      "13/13 - 0s - loss: 0.2044 - accuracy: 0.9014 - val_loss: 1.9984 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02231: val_loss did not improve from 0.38514\n",
      "Epoch 2232/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9014 - val_loss: 1.9625 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02232: val_loss did not improve from 0.38514\n",
      "Epoch 2233/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.9027 - val_loss: 1.9592 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02233: val_loss did not improve from 0.38514\n",
      "Epoch 2234/3000\n",
      "13/13 - 0s - loss: 0.2076 - accuracy: 0.8975 - val_loss: 2.0261 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02234: val_loss did not improve from 0.38514\n",
      "Epoch 2235/3000\n",
      "13/13 - 0s - loss: 0.2056 - accuracy: 0.9001 - val_loss: 2.0476 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02235: val_loss did not improve from 0.38514\n",
      "Epoch 2236/3000\n",
      "13/13 - 0s - loss: 0.2048 - accuracy: 0.9027 - val_loss: 2.0730 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02236: val_loss did not improve from 0.38514\n",
      "Epoch 2237/3000\n",
      "13/13 - 0s - loss: 0.2038 - accuracy: 0.8962 - val_loss: 2.0555 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02237: val_loss did not improve from 0.38514\n",
      "Epoch 2238/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.9001 - val_loss: 2.0724 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02238: val_loss did not improve from 0.38514\n",
      "Epoch 2239/3000\n",
      "13/13 - 0s - loss: 0.2056 - accuracy: 0.9014 - val_loss: 2.1075 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02239: val_loss did not improve from 0.38514\n",
      "Epoch 2240/3000\n",
      "13/13 - 0s - loss: 0.2059 - accuracy: 0.9001 - val_loss: 2.0599 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02240: val_loss did not improve from 0.38514\n",
      "Epoch 2241/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.8962 - val_loss: 2.0327 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02241: val_loss did not improve from 0.38514\n",
      "Epoch 2242/3000\n",
      "13/13 - 0s - loss: 0.2151 - accuracy: 0.9027 - val_loss: 1.9939 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02242: val_loss did not improve from 0.38514\n",
      "Epoch 2243/3000\n",
      "13/13 - 0s - loss: 0.2053 - accuracy: 0.9014 - val_loss: 2.0108 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02243: val_loss did not improve from 0.38514\n",
      "Epoch 2244/3000\n",
      "13/13 - 0s - loss: 0.2045 - accuracy: 0.9027 - val_loss: 2.0354 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02244: val_loss did not improve from 0.38514\n",
      "Epoch 2245/3000\n",
      "13/13 - 0s - loss: 0.2039 - accuracy: 0.9027 - val_loss: 2.0459 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02245: val_loss did not improve from 0.38514\n",
      "Epoch 2246/3000\n",
      "13/13 - 0s - loss: 0.2046 - accuracy: 0.9014 - val_loss: 2.0767 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02246: val_loss did not improve from 0.38514\n",
      "Epoch 2247/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.8988 - val_loss: 2.0919 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02247: val_loss did not improve from 0.38514\n",
      "Epoch 2248/3000\n",
      "13/13 - 0s - loss: 0.2038 - accuracy: 0.9027 - val_loss: 2.0513 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02248: val_loss did not improve from 0.38514\n",
      "Epoch 2249/3000\n",
      "13/13 - 0s - loss: 0.2032 - accuracy: 0.9027 - val_loss: 2.0808 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02249: val_loss did not improve from 0.38514\n",
      "Epoch 2250/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9027 - val_loss: 2.0814 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02250: val_loss did not improve from 0.38514\n",
      "Epoch 2251/3000\n",
      "13/13 - 0s - loss: 0.2032 - accuracy: 0.9027 - val_loss: 2.1514 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02251: val_loss did not improve from 0.38514\n",
      "Epoch 2252/3000\n",
      "13/13 - 0s - loss: 0.2039 - accuracy: 0.9027 - val_loss: 2.1294 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02252: val_loss did not improve from 0.38514\n",
      "Epoch 2253/3000\n",
      "13/13 - 0s - loss: 0.2021 - accuracy: 0.9014 - val_loss: 2.2061 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02253: val_loss did not improve from 0.38514\n",
      "Epoch 2254/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9027 - val_loss: 2.1977 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02254: val_loss did not improve from 0.38514\n",
      "Epoch 2255/3000\n",
      "13/13 - 0s - loss: 0.2025 - accuracy: 0.9027 - val_loss: 2.2378 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02255: val_loss did not improve from 0.38514\n",
      "Epoch 2256/3000\n",
      "13/13 - 0s - loss: 0.2045 - accuracy: 0.9014 - val_loss: 2.2228 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02256: val_loss did not improve from 0.38514\n",
      "Epoch 2257/3000\n",
      "13/13 - 0s - loss: 0.2046 - accuracy: 0.9027 - val_loss: 2.2677 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02257: val_loss did not improve from 0.38514\n",
      "Epoch 2258/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9001 - val_loss: 2.2580 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02258: val_loss did not improve from 0.38514\n",
      "Epoch 2259/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9027 - val_loss: 2.3110 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02259: val_loss did not improve from 0.38514\n",
      "Epoch 2260/3000\n",
      "13/13 - 0s - loss: 0.2040 - accuracy: 0.8988 - val_loss: 2.2733 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02260: val_loss did not improve from 0.38514\n",
      "Epoch 2261/3000\n",
      "13/13 - 0s - loss: 0.2043 - accuracy: 0.8988 - val_loss: 2.2593 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02261: val_loss did not improve from 0.38514\n",
      "Epoch 2262/3000\n",
      "13/13 - 0s - loss: 0.2034 - accuracy: 0.9014 - val_loss: 2.2905 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02262: val_loss did not improve from 0.38514\n",
      "Epoch 2263/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.9027 - val_loss: 2.2583 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02263: val_loss did not improve from 0.38514\n",
      "Epoch 2264/3000\n",
      "13/13 - 1s - loss: 0.2049 - accuracy: 0.9027 - val_loss: 2.5083 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02264: val_loss did not improve from 0.38514\n",
      "Epoch 2265/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.9014 - val_loss: 2.6339 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02265: val_loss did not improve from 0.38514\n",
      "Epoch 2266/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.9014 - val_loss: 2.6629 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02266: val_loss did not improve from 0.38514\n",
      "Epoch 2267/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.9027 - val_loss: 2.7038 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02267: val_loss did not improve from 0.38514\n",
      "Epoch 2268/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.9027 - val_loss: 2.7216 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02268: val_loss did not improve from 0.38514\n",
      "Epoch 2269/3000\n",
      "13/13 - 0s - loss: 0.2155 - accuracy: 0.9027 - val_loss: 2.7861 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02269: val_loss did not improve from 0.38514\n",
      "Epoch 2270/3000\n",
      "13/13 - 0s - loss: 0.2067 - accuracy: 0.9027 - val_loss: 2.6591 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02270: val_loss did not improve from 0.38514\n",
      "Epoch 2271/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.9027 - val_loss: 2.7479 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02271: val_loss did not improve from 0.38514\n",
      "Epoch 2272/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.9027 - val_loss: 2.7940 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02272: val_loss did not improve from 0.38514\n",
      "Epoch 2273/3000\n",
      "13/13 - 0s - loss: 0.2367 - accuracy: 0.9027 - val_loss: 2.4647 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02273: val_loss did not improve from 0.38514\n",
      "Epoch 2274/3000\n",
      "13/13 - 0s - loss: 0.2149 - accuracy: 0.9001 - val_loss: 2.2524 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02274: val_loss did not improve from 0.38514\n",
      "Epoch 2275/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.9027 - val_loss: 2.3891 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02275: val_loss did not improve from 0.38514\n",
      "Epoch 2276/3000\n",
      "13/13 - 0s - loss: 0.2068 - accuracy: 0.9027 - val_loss: 2.4223 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02276: val_loss did not improve from 0.38514\n",
      "Epoch 2277/3000\n",
      "13/13 - 0s - loss: 0.2065 - accuracy: 0.9027 - val_loss: 2.4627 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02277: val_loss did not improve from 0.38514\n",
      "Epoch 2278/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.9027 - val_loss: 2.4749 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02278: val_loss did not improve from 0.38514\n",
      "Epoch 2279/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.9027 - val_loss: 2.4905 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02279: val_loss did not improve from 0.38514\n",
      "Epoch 2280/3000\n",
      "13/13 - 0s - loss: 0.2060 - accuracy: 0.9027 - val_loss: 2.5094 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02280: val_loss did not improve from 0.38514\n",
      "Epoch 2281/3000\n",
      "13/13 - 0s - loss: 0.2052 - accuracy: 0.9027 - val_loss: 2.5283 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02281: val_loss did not improve from 0.38514\n",
      "Epoch 2282/3000\n",
      "13/13 - 0s - loss: 0.2051 - accuracy: 0.9027 - val_loss: 2.5321 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02282: val_loss did not improve from 0.38514\n",
      "Epoch 2283/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.9027 - val_loss: 2.5286 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02283: val_loss did not improve from 0.38514\n",
      "Epoch 2284/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.9027 - val_loss: 2.5557 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02284: val_loss did not improve from 0.38514\n",
      "Epoch 2285/3000\n",
      "13/13 - 0s - loss: 0.2034 - accuracy: 0.9027 - val_loss: 2.5290 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02285: val_loss did not improve from 0.38514\n",
      "Epoch 2286/3000\n",
      "13/13 - 0s - loss: 0.2094 - accuracy: 0.9001 - val_loss: 2.4153 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02286: val_loss did not improve from 0.38514\n",
      "Epoch 2287/3000\n",
      "13/13 - 0s - loss: 0.2080 - accuracy: 0.9040 - val_loss: 2.3505 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02287: val_loss did not improve from 0.38514\n",
      "Epoch 2288/3000\n",
      "13/13 - 0s - loss: 0.2082 - accuracy: 0.9027 - val_loss: 2.3914 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02288: val_loss did not improve from 0.38514\n",
      "Epoch 2289/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.9027 - val_loss: 2.4323 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02289: val_loss did not improve from 0.38514\n",
      "Epoch 2290/3000\n",
      "13/13 - 0s - loss: 0.2048 - accuracy: 0.9027 - val_loss: 2.4946 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02290: val_loss did not improve from 0.38514\n",
      "Epoch 2291/3000\n",
      "13/13 - 0s - loss: 0.2048 - accuracy: 0.9027 - val_loss: 2.4389 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02291: val_loss did not improve from 0.38514\n",
      "Epoch 2292/3000\n",
      "13/13 - 0s - loss: 0.2052 - accuracy: 0.9001 - val_loss: 2.4036 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02292: val_loss did not improve from 0.38514\n",
      "Epoch 2293/3000\n",
      "13/13 - 0s - loss: 0.2048 - accuracy: 0.9027 - val_loss: 2.4203 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02293: val_loss did not improve from 0.38514\n",
      "Epoch 2294/3000\n",
      "13/13 - 0s - loss: 0.2047 - accuracy: 0.9027 - val_loss: 2.4727 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02294: val_loss did not improve from 0.38514\n",
      "Epoch 2295/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.9027 - val_loss: 2.5583 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02295: val_loss did not improve from 0.38514\n",
      "Epoch 2296/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.9014 - val_loss: 2.5529 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02296: val_loss did not improve from 0.38514\n",
      "Epoch 2297/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.9014 - val_loss: 2.5040 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02297: val_loss did not improve from 0.38514\n",
      "Epoch 2298/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.9014 - val_loss: 2.4702 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02298: val_loss did not improve from 0.38514\n",
      "Epoch 2299/3000\n",
      "13/13 - 0s - loss: 0.2044 - accuracy: 0.9053 - val_loss: 2.4448 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02299: val_loss did not improve from 0.38514\n",
      "Epoch 2300/3000\n",
      "13/13 - 0s - loss: 0.2058 - accuracy: 0.9027 - val_loss: 2.4112 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02300: val_loss did not improve from 0.38514\n",
      "Epoch 2301/3000\n",
      "13/13 - 0s - loss: 0.2045 - accuracy: 0.9027 - val_loss: 2.3770 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02301: val_loss did not improve from 0.38514\n",
      "Epoch 2302/3000\n",
      "13/13 - 0s - loss: 0.2036 - accuracy: 0.9027 - val_loss: 2.4080 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02302: val_loss did not improve from 0.38514\n",
      "Epoch 2303/3000\n",
      "13/13 - 0s - loss: 0.2041 - accuracy: 0.9027 - val_loss: 2.4307 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02303: val_loss did not improve from 0.38514\n",
      "Epoch 2304/3000\n",
      "13/13 - 0s - loss: 0.2036 - accuracy: 0.9027 - val_loss: 2.4367 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02304: val_loss did not improve from 0.38514\n",
      "Epoch 2305/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9027 - val_loss: 2.4505 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02305: val_loss did not improve from 0.38514\n",
      "Epoch 2306/3000\n",
      "13/13 - 0s - loss: 0.2036 - accuracy: 0.9027 - val_loss: 2.4983 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02306: val_loss did not improve from 0.38514\n",
      "Epoch 2307/3000\n",
      "13/13 - 0s - loss: 0.2040 - accuracy: 0.8988 - val_loss: 2.5327 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02307: val_loss did not improve from 0.38514\n",
      "Epoch 2308/3000\n",
      "13/13 - 0s - loss: 0.2048 - accuracy: 0.9014 - val_loss: 2.5737 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02308: val_loss did not improve from 0.38514\n",
      "Epoch 2309/3000\n",
      "13/13 - 0s - loss: 0.2059 - accuracy: 0.9001 - val_loss: 2.6316 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02309: val_loss did not improve from 0.38514\n",
      "Epoch 2310/3000\n",
      "13/13 - 0s - loss: 0.2049 - accuracy: 0.9027 - val_loss: 2.6562 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02310: val_loss did not improve from 0.38514\n",
      "Epoch 2311/3000\n",
      "13/13 - 0s - loss: 0.2034 - accuracy: 0.9040 - val_loss: 2.6192 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02311: val_loss did not improve from 0.38514\n",
      "Epoch 2312/3000\n",
      "13/13 - 0s - loss: 0.2038 - accuracy: 0.9027 - val_loss: 2.5623 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02312: val_loss did not improve from 0.38514\n",
      "Epoch 2313/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.9027 - val_loss: 2.5279 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02313: val_loss did not improve from 0.38514\n",
      "Epoch 2314/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.8988 - val_loss: 2.5396 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02314: val_loss did not improve from 0.38514\n",
      "Epoch 2315/3000\n",
      "13/13 - 0s - loss: 0.2070 - accuracy: 0.8962 - val_loss: 2.5587 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02315: val_loss did not improve from 0.38514\n",
      "Epoch 2316/3000\n",
      "13/13 - 0s - loss: 0.2049 - accuracy: 0.9014 - val_loss: 2.5628 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02316: val_loss did not improve from 0.38514\n",
      "Epoch 2317/3000\n",
      "13/13 - 0s - loss: 0.2038 - accuracy: 0.9027 - val_loss: 2.5744 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02317: val_loss did not improve from 0.38514\n",
      "Epoch 2318/3000\n",
      "13/13 - 0s - loss: 0.2034 - accuracy: 0.9027 - val_loss: 2.6056 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02318: val_loss did not improve from 0.38514\n",
      "Epoch 2319/3000\n",
      "13/13 - 0s - loss: 0.2030 - accuracy: 0.9001 - val_loss: 2.5969 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02319: val_loss did not improve from 0.38514\n",
      "Epoch 2320/3000\n",
      "13/13 - 0s - loss: 0.2034 - accuracy: 0.9001 - val_loss: 2.5958 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02320: val_loss did not improve from 0.38514\n",
      "Epoch 2321/3000\n",
      "13/13 - 0s - loss: 0.2044 - accuracy: 0.9027 - val_loss: 2.5894 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02321: val_loss did not improve from 0.38514\n",
      "Epoch 2322/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9027 - val_loss: 2.6326 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02322: val_loss did not improve from 0.38514\n",
      "Epoch 2323/3000\n",
      "13/13 - 0s - loss: 0.2123 - accuracy: 0.9066 - val_loss: 2.6055 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02323: val_loss did not improve from 0.38514\n",
      "Epoch 2324/3000\n",
      "13/13 - 0s - loss: 0.2049 - accuracy: 0.9027 - val_loss: 2.6409 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02324: val_loss did not improve from 0.38514\n",
      "Epoch 2325/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.9014 - val_loss: 2.5773 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02325: val_loss did not improve from 0.38514\n",
      "Epoch 2326/3000\n",
      "13/13 - 0s - loss: 0.2045 - accuracy: 0.9001 - val_loss: 2.5385 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02326: val_loss did not improve from 0.38514\n",
      "Epoch 2327/3000\n",
      "13/13 - 0s - loss: 0.2048 - accuracy: 0.9001 - val_loss: 2.3804 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02327: val_loss did not improve from 0.38514\n",
      "Epoch 2328/3000\n",
      "13/13 - 0s - loss: 0.2089 - accuracy: 0.9027 - val_loss: 2.3940 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02328: val_loss did not improve from 0.38514\n",
      "Epoch 2329/3000\n",
      "13/13 - 0s - loss: 0.2078 - accuracy: 0.8975 - val_loss: 2.4695 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02329: val_loss did not improve from 0.38514\n",
      "Epoch 2330/3000\n",
      "13/13 - 0s - loss: 0.2048 - accuracy: 0.9014 - val_loss: 2.4981 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02330: val_loss did not improve from 0.38514\n",
      "Epoch 2331/3000\n",
      "13/13 - 0s - loss: 0.2080 - accuracy: 0.9040 - val_loss: 2.5811 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02331: val_loss did not improve from 0.38514\n",
      "Epoch 2332/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.9001 - val_loss: 2.5647 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02332: val_loss did not improve from 0.38514\n",
      "Epoch 2333/3000\n",
      "13/13 - 0s - loss: 0.2086 - accuracy: 0.9001 - val_loss: 2.5583 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02333: val_loss did not improve from 0.38514\n",
      "Epoch 2334/3000\n",
      "13/13 - 0s - loss: 0.2064 - accuracy: 0.9027 - val_loss: 2.5040 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02334: val_loss did not improve from 0.38514\n",
      "Epoch 2335/3000\n",
      "13/13 - 0s - loss: 0.2048 - accuracy: 0.9027 - val_loss: 2.5115 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02335: val_loss did not improve from 0.38514\n",
      "Epoch 2336/3000\n",
      "13/13 - 0s - loss: 0.2043 - accuracy: 0.9027 - val_loss: 2.5475 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02336: val_loss did not improve from 0.38514\n",
      "Epoch 2337/3000\n",
      "13/13 - 0s - loss: 0.2051 - accuracy: 0.9014 - val_loss: 2.6229 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02337: val_loss did not improve from 0.38514\n",
      "Epoch 2338/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9027 - val_loss: 2.6444 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02338: val_loss did not improve from 0.38514\n",
      "Epoch 2339/3000\n",
      "13/13 - 0s - loss: 0.2027 - accuracy: 0.9001 - val_loss: 2.6631 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02339: val_loss did not improve from 0.38514\n",
      "Epoch 2340/3000\n",
      "13/13 - 0s - loss: 0.2043 - accuracy: 0.8962 - val_loss: 2.5410 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02340: val_loss did not improve from 0.38514\n",
      "Epoch 2341/3000\n",
      "13/13 - 0s - loss: 0.2066 - accuracy: 0.8975 - val_loss: 2.5468 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02341: val_loss did not improve from 0.38514\n",
      "Epoch 2342/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.9001 - val_loss: 2.4819 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02342: val_loss did not improve from 0.38514\n",
      "Epoch 2343/3000\n",
      "13/13 - 0s - loss: 0.2047 - accuracy: 0.9027 - val_loss: 2.5101 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02343: val_loss did not improve from 0.38514\n",
      "Epoch 2344/3000\n",
      "13/13 - 0s - loss: 0.2048 - accuracy: 0.9027 - val_loss: 2.5076 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02344: val_loss did not improve from 0.38514\n",
      "Epoch 2345/3000\n",
      "13/13 - 0s - loss: 0.2046 - accuracy: 0.9027 - val_loss: 2.5256 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02345: val_loss did not improve from 0.38514\n",
      "Epoch 2346/3000\n",
      "13/13 - 0s - loss: 0.2047 - accuracy: 0.9027 - val_loss: 2.5358 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02346: val_loss did not improve from 0.38514\n",
      "Epoch 2347/3000\n",
      "13/13 - 0s - loss: 0.2038 - accuracy: 0.9014 - val_loss: 2.4976 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02347: val_loss did not improve from 0.38514\n",
      "Epoch 2348/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.9014 - val_loss: 2.4298 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02348: val_loss did not improve from 0.38514\n",
      "Epoch 2349/3000\n",
      "13/13 - 0s - loss: 0.2033 - accuracy: 0.9001 - val_loss: 2.4575 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02349: val_loss did not improve from 0.38514\n",
      "Epoch 2350/3000\n",
      "13/13 - 0s - loss: 0.2041 - accuracy: 0.9040 - val_loss: 2.4659 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02350: val_loss did not improve from 0.38514\n",
      "Epoch 2351/3000\n",
      "13/13 - 0s - loss: 0.2030 - accuracy: 0.9040 - val_loss: 2.5716 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02351: val_loss did not improve from 0.38514\n",
      "Epoch 2352/3000\n",
      "13/13 - 0s - loss: 0.2023 - accuracy: 0.9014 - val_loss: 2.6334 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02352: val_loss did not improve from 0.38514\n",
      "Epoch 2353/3000\n",
      "13/13 - 0s - loss: 0.2034 - accuracy: 0.9014 - val_loss: 2.6677 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02353: val_loss did not improve from 0.38514\n",
      "Epoch 2354/3000\n",
      "13/13 - 0s - loss: 0.2023 - accuracy: 0.9027 - val_loss: 2.6768 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02354: val_loss did not improve from 0.38514\n",
      "Epoch 2355/3000\n",
      "13/13 - 0s - loss: 0.2029 - accuracy: 0.9027 - val_loss: 2.7236 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02355: val_loss did not improve from 0.38514\n",
      "Epoch 2356/3000\n",
      "13/13 - 0s - loss: 0.2027 - accuracy: 0.9027 - val_loss: 2.7048 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02356: val_loss did not improve from 0.38514\n",
      "Epoch 2357/3000\n",
      "13/13 - 0s - loss: 0.2027 - accuracy: 0.9001 - val_loss: 2.6979 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02357: val_loss did not improve from 0.38514\n",
      "Epoch 2358/3000\n",
      "13/13 - 0s - loss: 0.2021 - accuracy: 0.8975 - val_loss: 2.7368 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02358: val_loss did not improve from 0.38514\n",
      "Epoch 2359/3000\n",
      "13/13 - 0s - loss: 0.2024 - accuracy: 0.8975 - val_loss: 2.7500 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02359: val_loss did not improve from 0.38514\n",
      "Epoch 2360/3000\n",
      "13/13 - 0s - loss: 0.2021 - accuracy: 0.9001 - val_loss: 2.7501 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02360: val_loss did not improve from 0.38514\n",
      "Epoch 2361/3000\n",
      "13/13 - 0s - loss: 0.2024 - accuracy: 0.9027 - val_loss: 2.7523 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02361: val_loss did not improve from 0.38514\n",
      "Epoch 2362/3000\n",
      "13/13 - 0s - loss: 0.2018 - accuracy: 0.9014 - val_loss: 2.7795 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02362: val_loss did not improve from 0.38514\n",
      "Epoch 2363/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9001 - val_loss: 2.7883 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02363: val_loss did not improve from 0.38514\n",
      "Epoch 2364/3000\n",
      "13/13 - 0s - loss: 0.2038 - accuracy: 0.9027 - val_loss: 2.8108 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02364: val_loss did not improve from 0.38514\n",
      "Epoch 2365/3000\n",
      "13/13 - 0s - loss: 0.2023 - accuracy: 0.9014 - val_loss: 2.7699 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02365: val_loss did not improve from 0.38514\n",
      "Epoch 2366/3000\n",
      "13/13 - 0s - loss: 0.2026 - accuracy: 0.9027 - val_loss: 2.7313 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02366: val_loss did not improve from 0.38514\n",
      "Epoch 2367/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9027 - val_loss: 2.6878 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02367: val_loss did not improve from 0.38514\n",
      "Epoch 2368/3000\n",
      "13/13 - 0s - loss: 0.2027 - accuracy: 0.9027 - val_loss: 2.7292 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02368: val_loss did not improve from 0.38514\n",
      "Epoch 2369/3000\n",
      "13/13 - 0s - loss: 0.2020 - accuracy: 0.9014 - val_loss: 2.7784 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02369: val_loss did not improve from 0.38514\n",
      "Epoch 2370/3000\n",
      "13/13 - 0s - loss: 0.2027 - accuracy: 0.8975 - val_loss: 2.7988 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02370: val_loss did not improve from 0.38514\n",
      "Epoch 2371/3000\n",
      "13/13 - 0s - loss: 0.2026 - accuracy: 0.8962 - val_loss: 2.7452 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02371: val_loss did not improve from 0.38514\n",
      "Epoch 2372/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.9001 - val_loss: 2.6750 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02372: val_loss did not improve from 0.38514\n",
      "Epoch 2373/3000\n",
      "13/13 - 0s - loss: 0.2053 - accuracy: 0.9001 - val_loss: 2.6664 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02373: val_loss did not improve from 0.38514\n",
      "Epoch 2374/3000\n",
      "13/13 - 0s - loss: 0.2056 - accuracy: 0.8975 - val_loss: 2.9440 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02374: val_loss did not improve from 0.38514\n",
      "Epoch 2375/3000\n",
      "13/13 - 0s - loss: 0.2034 - accuracy: 0.9001 - val_loss: 3.0726 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02375: val_loss did not improve from 0.38514\n",
      "Epoch 2376/3000\n",
      "13/13 - 0s - loss: 0.2029 - accuracy: 0.9014 - val_loss: 3.1624 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02376: val_loss did not improve from 0.38514\n",
      "Epoch 2377/3000\n",
      "13/13 - 0s - loss: 0.2033 - accuracy: 0.9014 - val_loss: 3.2220 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02377: val_loss did not improve from 0.38514\n",
      "Epoch 2378/3000\n",
      "13/13 - 0s - loss: 0.2030 - accuracy: 0.9001 - val_loss: 3.2598 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02378: val_loss did not improve from 0.38514\n",
      "Epoch 2379/3000\n",
      "13/13 - 0s - loss: 0.2030 - accuracy: 0.8962 - val_loss: 3.2562 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02379: val_loss did not improve from 0.38514\n",
      "Epoch 2380/3000\n",
      "13/13 - 0s - loss: 0.2038 - accuracy: 0.9027 - val_loss: 3.3434 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02380: val_loss did not improve from 0.38514\n",
      "Epoch 2381/3000\n",
      "13/13 - 0s - loss: 0.2044 - accuracy: 0.9027 - val_loss: 4.0031 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02381: val_loss did not improve from 0.38514\n",
      "Epoch 2382/3000\n",
      "13/13 - 0s - loss: 0.4129 - accuracy: 0.8923 - val_loss: 2.7538 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02382: val_loss did not improve from 0.38514\n",
      "Epoch 2383/3000\n",
      "13/13 - 0s - loss: 0.3045 - accuracy: 0.9001 - val_loss: 1.8712 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02383: val_loss did not improve from 0.38514\n",
      "Epoch 2384/3000\n",
      "13/13 - 0s - loss: 0.2736 - accuracy: 0.8794 - val_loss: 1.2167 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02384: val_loss did not improve from 0.38514\n",
      "Epoch 2385/3000\n",
      "13/13 - 0s - loss: 0.2506 - accuracy: 0.8885 - val_loss: 2.6742 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02385: val_loss did not improve from 0.38514\n",
      "Epoch 2386/3000\n",
      "13/13 - 0s - loss: 0.2369 - accuracy: 0.8923 - val_loss: 2.2623 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02386: val_loss did not improve from 0.38514\n",
      "Epoch 2387/3000\n",
      "13/13 - 0s - loss: 0.2234 - accuracy: 0.8936 - val_loss: 2.0015 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02387: val_loss did not improve from 0.38514\n",
      "Epoch 2388/3000\n",
      "13/13 - 0s - loss: 0.2203 - accuracy: 0.8936 - val_loss: 1.9209 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02388: val_loss did not improve from 0.38514\n",
      "Epoch 2389/3000\n",
      "13/13 - 0s - loss: 0.2113 - accuracy: 0.9001 - val_loss: 2.0006 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02389: val_loss did not improve from 0.38514\n",
      "Epoch 2390/3000\n",
      "13/13 - 0s - loss: 0.2121 - accuracy: 0.9001 - val_loss: 1.9319 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02390: val_loss did not improve from 0.38514\n",
      "Epoch 2391/3000\n",
      "13/13 - 0s - loss: 0.2107 - accuracy: 0.9014 - val_loss: 1.7949 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02391: val_loss did not improve from 0.38514\n",
      "Epoch 2392/3000\n",
      "13/13 - 0s - loss: 0.2100 - accuracy: 0.8949 - val_loss: 1.8325 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02392: val_loss did not improve from 0.38514\n",
      "Epoch 2393/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.9001 - val_loss: 1.8496 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02393: val_loss did not improve from 0.38514\n",
      "Epoch 2394/3000\n",
      "13/13 - 0s - loss: 0.2110 - accuracy: 0.9027 - val_loss: 1.8305 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02394: val_loss did not improve from 0.38514\n",
      "Epoch 2395/3000\n",
      "13/13 - 0s - loss: 0.2108 - accuracy: 0.9027 - val_loss: 1.8912 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02395: val_loss did not improve from 0.38514\n",
      "Epoch 2396/3000\n",
      "13/13 - 0s - loss: 0.2070 - accuracy: 0.9027 - val_loss: 2.0080 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02396: val_loss did not improve from 0.38514\n",
      "Epoch 2397/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.9014 - val_loss: 2.0612 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02397: val_loss did not improve from 0.38514\n",
      "Epoch 2398/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.9027 - val_loss: 2.0703 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02398: val_loss did not improve from 0.38514\n",
      "Epoch 2399/3000\n",
      "13/13 - 0s - loss: 0.2047 - accuracy: 0.9027 - val_loss: 2.0342 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02399: val_loss did not improve from 0.38514\n",
      "Epoch 2400/3000\n",
      "13/13 - 0s - loss: 0.2047 - accuracy: 0.9027 - val_loss: 1.9707 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02400: val_loss did not improve from 0.38514\n",
      "Epoch 2401/3000\n",
      "13/13 - 0s - loss: 0.2073 - accuracy: 0.9040 - val_loss: 1.9440 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02401: val_loss did not improve from 0.38514\n",
      "Epoch 2402/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.8988 - val_loss: 1.9358 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02402: val_loss did not improve from 0.38514\n",
      "Epoch 2403/3000\n",
      "13/13 - 0s - loss: 0.2053 - accuracy: 0.9014 - val_loss: 1.9551 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02403: val_loss did not improve from 0.38514\n",
      "Epoch 2404/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.9027 - val_loss: 1.9815 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02404: val_loss did not improve from 0.38514\n",
      "Epoch 2405/3000\n",
      "13/13 - 0s - loss: 0.2046 - accuracy: 0.9001 - val_loss: 1.9419 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02405: val_loss did not improve from 0.38514\n",
      "Epoch 2406/3000\n",
      "13/13 - 0s - loss: 0.2058 - accuracy: 0.9014 - val_loss: 1.9433 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02406: val_loss did not improve from 0.38514\n",
      "Epoch 2407/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.9014 - val_loss: 1.9044 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02407: val_loss did not improve from 0.38514\n",
      "Epoch 2408/3000\n",
      "13/13 - 0s - loss: 0.2061 - accuracy: 0.9027 - val_loss: 1.9010 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02408: val_loss did not improve from 0.38514\n",
      "Epoch 2409/3000\n",
      "13/13 - 0s - loss: 0.2043 - accuracy: 0.9027 - val_loss: 1.8837 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02409: val_loss did not improve from 0.38514\n",
      "Epoch 2410/3000\n",
      "13/13 - 0s - loss: 0.2040 - accuracy: 0.9014 - val_loss: 2.0600 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02410: val_loss did not improve from 0.38514\n",
      "Epoch 2411/3000\n",
      "13/13 - 0s - loss: 0.2068 - accuracy: 0.8988 - val_loss: 2.1577 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02411: val_loss did not improve from 0.38514\n",
      "Epoch 2412/3000\n",
      "13/13 - 0s - loss: 0.2051 - accuracy: 0.8949 - val_loss: 2.1913 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02412: val_loss did not improve from 0.38514\n",
      "Epoch 2413/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.9001 - val_loss: 2.2138 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02413: val_loss did not improve from 0.38514\n",
      "Epoch 2414/3000\n",
      "13/13 - 0s - loss: 0.2061 - accuracy: 0.9001 - val_loss: 2.2535 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02414: val_loss did not improve from 0.38514\n",
      "Epoch 2415/3000\n",
      "13/13 - 0s - loss: 0.2049 - accuracy: 0.9001 - val_loss: 2.2307 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02415: val_loss did not improve from 0.38514\n",
      "Epoch 2416/3000\n",
      "13/13 - 0s - loss: 0.2034 - accuracy: 0.9001 - val_loss: 2.2268 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02416: val_loss did not improve from 0.38514\n",
      "Epoch 2417/3000\n",
      "13/13 - 0s - loss: 0.2029 - accuracy: 0.9027 - val_loss: 2.2343 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02417: val_loss did not improve from 0.38514\n",
      "Epoch 2418/3000\n",
      "13/13 - 0s - loss: 0.2029 - accuracy: 0.9027 - val_loss: 2.2289 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02418: val_loss did not improve from 0.38514\n",
      "Epoch 2419/3000\n",
      "13/13 - 0s - loss: 0.2036 - accuracy: 0.9027 - val_loss: 2.2200 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02419: val_loss did not improve from 0.38514\n",
      "Epoch 2420/3000\n",
      "13/13 - 0s - loss: 0.2043 - accuracy: 0.9027 - val_loss: 2.2424 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02420: val_loss did not improve from 0.38514\n",
      "Epoch 2421/3000\n",
      "13/13 - 0s - loss: 0.2114 - accuracy: 0.9027 - val_loss: 2.3496 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02421: val_loss did not improve from 0.38514\n",
      "Epoch 2422/3000\n",
      "13/13 - 0s - loss: 0.2156 - accuracy: 0.8923 - val_loss: 2.3865 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02422: val_loss did not improve from 0.38514\n",
      "Epoch 2423/3000\n",
      "13/13 - 0s - loss: 0.2066 - accuracy: 0.9040 - val_loss: 2.3818 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02423: val_loss did not improve from 0.38514\n",
      "Epoch 2424/3000\n",
      "13/13 - 0s - loss: 0.2060 - accuracy: 0.9001 - val_loss: 2.4213 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02424: val_loss did not improve from 0.38514\n",
      "Epoch 2425/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.9027 - val_loss: 2.4160 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02425: val_loss did not improve from 0.38514\n",
      "Epoch 2426/3000\n",
      "13/13 - 0s - loss: 0.2044 - accuracy: 0.9001 - val_loss: 2.3588 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02426: val_loss did not improve from 0.38514\n",
      "Epoch 2427/3000\n",
      "13/13 - 0s - loss: 0.2036 - accuracy: 0.9014 - val_loss: 2.3512 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02427: val_loss did not improve from 0.38514\n",
      "Epoch 2428/3000\n",
      "13/13 - 0s - loss: 0.2032 - accuracy: 0.9014 - val_loss: 2.3146 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02428: val_loss did not improve from 0.38514\n",
      "Epoch 2429/3000\n",
      "13/13 - 0s - loss: 0.2047 - accuracy: 0.9014 - val_loss: 2.2909 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02429: val_loss did not improve from 0.38514\n",
      "Epoch 2430/3000\n",
      "13/13 - 0s - loss: 0.2043 - accuracy: 0.9027 - val_loss: 2.3088 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02430: val_loss did not improve from 0.38514\n",
      "Epoch 2431/3000\n",
      "13/13 - 0s - loss: 0.2040 - accuracy: 0.9014 - val_loss: 2.2871 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02431: val_loss did not improve from 0.38514\n",
      "Epoch 2432/3000\n",
      "13/13 - 0s - loss: 0.2048 - accuracy: 0.9027 - val_loss: 2.3369 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02432: val_loss did not improve from 0.38514\n",
      "Epoch 2433/3000\n",
      "13/13 - 0s - loss: 0.2038 - accuracy: 0.9014 - val_loss: 2.3248 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02433: val_loss did not improve from 0.38514\n",
      "Epoch 2434/3000\n",
      "13/13 - 0s - loss: 0.2040 - accuracy: 0.8988 - val_loss: 2.3884 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02434: val_loss did not improve from 0.38514\n",
      "Epoch 2435/3000\n",
      "13/13 - 0s - loss: 0.2044 - accuracy: 0.9027 - val_loss: 2.4505 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02435: val_loss did not improve from 0.38514\n",
      "Epoch 2436/3000\n",
      "13/13 - 0s - loss: 0.2040 - accuracy: 0.9053 - val_loss: 2.5135 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02436: val_loss did not improve from 0.38514\n",
      "Epoch 2437/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.8936 - val_loss: 2.5063 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02437: val_loss did not improve from 0.38514\n",
      "Epoch 2438/3000\n",
      "13/13 - 0s - loss: 0.2053 - accuracy: 0.9001 - val_loss: 2.4959 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02438: val_loss did not improve from 0.38514\n",
      "Epoch 2439/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.9001 - val_loss: 2.4664 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02439: val_loss did not improve from 0.38514\n",
      "Epoch 2440/3000\n",
      "13/13 - 0s - loss: 0.2114 - accuracy: 0.8923 - val_loss: 2.4835 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02440: val_loss did not improve from 0.38514\n",
      "Epoch 2441/3000\n",
      "13/13 - 0s - loss: 0.2059 - accuracy: 0.8988 - val_loss: 2.4767 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02441: val_loss did not improve from 0.38514\n",
      "Epoch 2442/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.9027 - val_loss: 2.4511 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02442: val_loss did not improve from 0.38514\n",
      "Epoch 2443/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9027 - val_loss: 2.4732 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02443: val_loss did not improve from 0.38514\n",
      "Epoch 2444/3000\n",
      "13/13 - 0s - loss: 0.2028 - accuracy: 0.9040 - val_loss: 2.4748 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02444: val_loss did not improve from 0.38514\n",
      "Epoch 2445/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.9027 - val_loss: 2.4277 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02445: val_loss did not improve from 0.38514\n",
      "Epoch 2446/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9027 - val_loss: 2.4527 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02446: val_loss did not improve from 0.38514\n",
      "Epoch 2447/3000\n",
      "13/13 - 0s - loss: 0.2025 - accuracy: 0.9014 - val_loss: 2.4937 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02447: val_loss did not improve from 0.38514\n",
      "Epoch 2448/3000\n",
      "13/13 - 0s - loss: 0.2032 - accuracy: 0.8975 - val_loss: 2.5248 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02448: val_loss did not improve from 0.38514\n",
      "Epoch 2449/3000\n",
      "13/13 - 0s - loss: 0.2029 - accuracy: 0.9027 - val_loss: 2.5214 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02449: val_loss did not improve from 0.38514\n",
      "Epoch 2450/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9027 - val_loss: 2.5078 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02450: val_loss did not improve from 0.38514\n",
      "Epoch 2451/3000\n",
      "13/13 - 0s - loss: 0.2082 - accuracy: 0.9014 - val_loss: 2.5025 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02451: val_loss did not improve from 0.38514\n",
      "Epoch 2452/3000\n",
      "13/13 - 0s - loss: 0.2489 - accuracy: 0.9014 - val_loss: 2.1608 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02452: val_loss did not improve from 0.38514\n",
      "Epoch 2453/3000\n",
      "13/13 - 0s - loss: 0.2067 - accuracy: 0.9001 - val_loss: 1.7088 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02453: val_loss did not improve from 0.38514\n",
      "Epoch 2454/3000\n",
      "13/13 - 0s - loss: 0.2056 - accuracy: 0.9014 - val_loss: 1.7230 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02454: val_loss did not improve from 0.38514\n",
      "Epoch 2455/3000\n",
      "13/13 - 0s - loss: 0.2089 - accuracy: 0.9027 - val_loss: 1.7155 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02455: val_loss did not improve from 0.38514\n",
      "Epoch 2456/3000\n",
      "13/13 - 0s - loss: 0.2049 - accuracy: 0.9001 - val_loss: 1.7911 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02456: val_loss did not improve from 0.38514\n",
      "Epoch 2457/3000\n",
      "13/13 - 0s - loss: 0.2082 - accuracy: 0.8962 - val_loss: 1.8674 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02457: val_loss did not improve from 0.38514\n",
      "Epoch 2458/3000\n",
      "13/13 - 0s - loss: 0.2284 - accuracy: 0.9014 - val_loss: 1.9622 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02458: val_loss did not improve from 0.38514\n",
      "Epoch 2459/3000\n",
      "13/13 - 0s - loss: 0.2107 - accuracy: 0.8962 - val_loss: 1.8361 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02459: val_loss did not improve from 0.38514\n",
      "Epoch 2460/3000\n",
      "13/13 - 0s - loss: 0.2133 - accuracy: 0.8975 - val_loss: 2.4066 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02460: val_loss did not improve from 0.38514\n",
      "Epoch 2461/3000\n",
      "13/13 - 0s - loss: 0.2116 - accuracy: 0.8923 - val_loss: 2.8535 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02461: val_loss did not improve from 0.38514\n",
      "Epoch 2462/3000\n",
      "13/13 - 0s - loss: 0.2045 - accuracy: 0.9001 - val_loss: 2.9790 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02462: val_loss did not improve from 0.38514\n",
      "Epoch 2463/3000\n",
      "13/13 - 0s - loss: 0.2046 - accuracy: 0.9027 - val_loss: 3.1621 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02463: val_loss did not improve from 0.38514\n",
      "Epoch 2464/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.9001 - val_loss: 3.1327 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02464: val_loss did not improve from 0.38514\n",
      "Epoch 2465/3000\n",
      "13/13 - 0s - loss: 0.2038 - accuracy: 0.9027 - val_loss: 3.1437 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02465: val_loss did not improve from 0.38514\n",
      "Epoch 2466/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.8988 - val_loss: 3.0504 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02466: val_loss did not improve from 0.38514\n",
      "Epoch 2467/3000\n",
      "13/13 - 0s - loss: 0.2096 - accuracy: 0.8872 - val_loss: 3.1045 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02467: val_loss did not improve from 0.38514\n",
      "Epoch 2468/3000\n",
      "13/13 - 0s - loss: 0.2065 - accuracy: 0.8949 - val_loss: 3.1643 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02468: val_loss did not improve from 0.38514\n",
      "Epoch 2469/3000\n",
      "13/13 - 0s - loss: 0.2069 - accuracy: 0.9027 - val_loss: 3.2432 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02469: val_loss did not improve from 0.38514\n",
      "Epoch 2470/3000\n",
      "13/13 - 0s - loss: 0.2041 - accuracy: 0.9027 - val_loss: 3.2237 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02470: val_loss did not improve from 0.38514\n",
      "Epoch 2471/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.9014 - val_loss: 3.2259 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02471: val_loss did not improve from 0.38514\n",
      "Epoch 2472/3000\n",
      "13/13 - 0s - loss: 0.2104 - accuracy: 0.8962 - val_loss: 3.1809 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02472: val_loss did not improve from 0.38514\n",
      "Epoch 2473/3000\n",
      "13/13 - 0s - loss: 0.2114 - accuracy: 0.8949 - val_loss: 3.2112 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02473: val_loss did not improve from 0.38514\n",
      "Epoch 2474/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.9027 - val_loss: 3.2259 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02474: val_loss did not improve from 0.38514\n",
      "Epoch 2475/3000\n",
      "13/13 - 0s - loss: 0.2052 - accuracy: 0.9014 - val_loss: 3.2661 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02475: val_loss did not improve from 0.38514\n",
      "Epoch 2476/3000\n",
      "13/13 - 0s - loss: 0.2051 - accuracy: 0.9040 - val_loss: 3.3154 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02476: val_loss did not improve from 0.38514\n",
      "Epoch 2477/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9001 - val_loss: 3.3332 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02477: val_loss did not improve from 0.38514\n",
      "Epoch 2478/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9027 - val_loss: 3.3560 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02478: val_loss did not improve from 0.38514\n",
      "Epoch 2479/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9027 - val_loss: 3.3548 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02479: val_loss did not improve from 0.38514\n",
      "Epoch 2480/3000\n",
      "13/13 - 0s - loss: 0.2030 - accuracy: 0.8988 - val_loss: 3.3285 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02480: val_loss did not improve from 0.38514\n",
      "Epoch 2481/3000\n",
      "13/13 - 0s - loss: 0.2046 - accuracy: 0.9027 - val_loss: 3.3255 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02481: val_loss did not improve from 0.38514\n",
      "Epoch 2482/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.9027 - val_loss: 3.3050 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02482: val_loss did not improve from 0.38514\n",
      "Epoch 2483/3000\n",
      "13/13 - 0s - loss: 0.2052 - accuracy: 0.8988 - val_loss: 3.2538 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02483: val_loss did not improve from 0.38514\n",
      "Epoch 2484/3000\n",
      "13/13 - 0s - loss: 0.2039 - accuracy: 0.9014 - val_loss: 3.2635 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02484: val_loss did not improve from 0.38514\n",
      "Epoch 2485/3000\n",
      "13/13 - 0s - loss: 0.2038 - accuracy: 0.9027 - val_loss: 3.2710 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02485: val_loss did not improve from 0.38514\n",
      "Epoch 2486/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.9014 - val_loss: 3.2291 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02486: val_loss did not improve from 0.38514\n",
      "Epoch 2487/3000\n",
      "13/13 - 0s - loss: 0.2044 - accuracy: 0.9027 - val_loss: 3.2926 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02487: val_loss did not improve from 0.38514\n",
      "Epoch 2488/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9027 - val_loss: 3.3925 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02488: val_loss did not improve from 0.38514\n",
      "Epoch 2489/3000\n",
      "13/13 - 0s - loss: 0.2039 - accuracy: 0.9014 - val_loss: 3.4277 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02489: val_loss did not improve from 0.38514\n",
      "Epoch 2490/3000\n",
      "13/13 - 0s - loss: 0.2036 - accuracy: 0.9001 - val_loss: 3.4523 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02490: val_loss did not improve from 0.38514\n",
      "Epoch 2491/3000\n",
      "13/13 - 0s - loss: 0.2048 - accuracy: 0.9027 - val_loss: 3.3800 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02491: val_loss did not improve from 0.38514\n",
      "Epoch 2492/3000\n",
      "13/13 - 0s - loss: 0.2046 - accuracy: 0.8988 - val_loss: 3.3785 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02492: val_loss did not improve from 0.38514\n",
      "Epoch 2493/3000\n",
      "13/13 - 0s - loss: 0.2051 - accuracy: 0.9001 - val_loss: 3.4637 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02493: val_loss did not improve from 0.38514\n",
      "Epoch 2494/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.9027 - val_loss: 3.4452 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02494: val_loss did not improve from 0.38514\n",
      "Epoch 2495/3000\n",
      "13/13 - 0s - loss: 0.2048 - accuracy: 0.9053 - val_loss: 3.4626 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02495: val_loss did not improve from 0.38514\n",
      "Epoch 2496/3000\n",
      "13/13 - 0s - loss: 0.2046 - accuracy: 0.9027 - val_loss: 3.4770 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02496: val_loss did not improve from 0.38514\n",
      "Epoch 2497/3000\n",
      "13/13 - 0s - loss: 0.2043 - accuracy: 0.9014 - val_loss: 3.4474 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02497: val_loss did not improve from 0.38514\n",
      "Epoch 2498/3000\n",
      "13/13 - 0s - loss: 0.2046 - accuracy: 0.8988 - val_loss: 3.4428 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02498: val_loss did not improve from 0.38514\n",
      "Epoch 2499/3000\n",
      "13/13 - 0s - loss: 0.2036 - accuracy: 0.9014 - val_loss: 3.4433 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02499: val_loss did not improve from 0.38514\n",
      "Epoch 2500/3000\n",
      "13/13 - 0s - loss: 0.2041 - accuracy: 0.9001 - val_loss: 3.4374 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02500: val_loss did not improve from 0.38514\n",
      "Epoch 2501/3000\n",
      "13/13 - 0s - loss: 0.2028 - accuracy: 0.9027 - val_loss: 3.4456 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02501: val_loss did not improve from 0.38514\n",
      "Epoch 2502/3000\n",
      "13/13 - 0s - loss: 0.2025 - accuracy: 0.9040 - val_loss: 3.4603 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02502: val_loss did not improve from 0.38514\n",
      "Epoch 2503/3000\n",
      "13/13 - 0s - loss: 0.2028 - accuracy: 0.9027 - val_loss: 3.4361 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02503: val_loss did not improve from 0.38514\n",
      "Epoch 2504/3000\n",
      "13/13 - 0s - loss: 0.2036 - accuracy: 0.9027 - val_loss: 3.4575 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02504: val_loss did not improve from 0.38514\n",
      "Epoch 2505/3000\n",
      "13/13 - 0s - loss: 0.2038 - accuracy: 0.8988 - val_loss: 3.4423 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02505: val_loss did not improve from 0.38514\n",
      "Epoch 2506/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9027 - val_loss: 3.4505 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02506: val_loss did not improve from 0.38514\n",
      "Epoch 2507/3000\n",
      "13/13 - 0s - loss: 0.2024 - accuracy: 0.9040 - val_loss: 3.3510 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02507: val_loss did not improve from 0.38514\n",
      "Epoch 2508/3000\n",
      "13/13 - 0s - loss: 0.2080 - accuracy: 0.8975 - val_loss: 3.3906 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02508: val_loss did not improve from 0.38514\n",
      "Epoch 2509/3000\n",
      "13/13 - 0s - loss: 0.2126 - accuracy: 0.8949 - val_loss: 3.4395 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02509: val_loss did not improve from 0.38514\n",
      "Epoch 2510/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.8962 - val_loss: 3.4790 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02510: val_loss did not improve from 0.38514\n",
      "Epoch 2511/3000\n",
      "13/13 - 0s - loss: 0.2031 - accuracy: 0.9014 - val_loss: 3.4882 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02511: val_loss did not improve from 0.38514\n",
      "Epoch 2512/3000\n",
      "13/13 - 0s - loss: 0.2049 - accuracy: 0.9027 - val_loss: 3.4804 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02512: val_loss did not improve from 0.38514\n",
      "Epoch 2513/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9001 - val_loss: 3.4279 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02513: val_loss did not improve from 0.38514\n",
      "Epoch 2514/3000\n",
      "13/13 - 0s - loss: 0.2026 - accuracy: 0.9014 - val_loss: 3.3943 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02514: val_loss did not improve from 0.38514\n",
      "Epoch 2515/3000\n",
      "13/13 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 3.3679 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02515: val_loss did not improve from 0.38514\n",
      "Epoch 2516/3000\n",
      "13/13 - 0s - loss: 0.2031 - accuracy: 0.9027 - val_loss: 3.3480 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02516: val_loss did not improve from 0.38514\n",
      "Epoch 2517/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9014 - val_loss: 3.3170 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02517: val_loss did not improve from 0.38514\n",
      "Epoch 2518/3000\n",
      "13/13 - 0s - loss: 0.2047 - accuracy: 0.8949 - val_loss: 3.3051 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02518: val_loss did not improve from 0.38514\n",
      "Epoch 2519/3000\n",
      "13/13 - 0s - loss: 0.2092 - accuracy: 0.8962 - val_loss: 3.3138 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02519: val_loss did not improve from 0.38514\n",
      "Epoch 2520/3000\n",
      "13/13 - 0s - loss: 0.2069 - accuracy: 0.9040 - val_loss: 3.3133 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02520: val_loss did not improve from 0.38514\n",
      "Epoch 2521/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.9027 - val_loss: 3.3828 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02521: val_loss did not improve from 0.38514\n",
      "Epoch 2522/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.9001 - val_loss: 3.3281 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02522: val_loss did not improve from 0.38514\n",
      "Epoch 2523/3000\n",
      "13/13 - 0s - loss: 0.2066 - accuracy: 0.9014 - val_loss: 3.2957 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02523: val_loss did not improve from 0.38514\n",
      "Epoch 2524/3000\n",
      "13/13 - 0s - loss: 0.2056 - accuracy: 0.9014 - val_loss: 3.5230 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02524: val_loss did not improve from 0.38514\n",
      "Epoch 2525/3000\n",
      "13/13 - 0s - loss: 0.2053 - accuracy: 0.9014 - val_loss: 3.5241 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02525: val_loss did not improve from 0.38514\n",
      "Epoch 2526/3000\n",
      "13/13 - 0s - loss: 0.2049 - accuracy: 0.9027 - val_loss: 3.5437 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02526: val_loss did not improve from 0.38514\n",
      "Epoch 2527/3000\n",
      "13/13 - 0s - loss: 0.2058 - accuracy: 0.9014 - val_loss: 3.5150 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02527: val_loss did not improve from 0.38514\n",
      "Epoch 2528/3000\n",
      "13/13 - 0s - loss: 0.2045 - accuracy: 0.9014 - val_loss: 3.4612 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02528: val_loss did not improve from 0.38514\n",
      "Epoch 2529/3000\n",
      "13/13 - 0s - loss: 0.2036 - accuracy: 0.9027 - val_loss: 3.4725 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02529: val_loss did not improve from 0.38514\n",
      "Epoch 2530/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9027 - val_loss: 3.4218 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02530: val_loss did not improve from 0.38514\n",
      "Epoch 2531/3000\n",
      "13/13 - 0s - loss: 0.2032 - accuracy: 0.9027 - val_loss: 3.3657 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02531: val_loss did not improve from 0.38514\n",
      "Epoch 2532/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.9014 - val_loss: 3.2382 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02532: val_loss did not improve from 0.38514\n",
      "Epoch 2533/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.8975 - val_loss: 3.2077 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02533: val_loss did not improve from 0.38514\n",
      "Epoch 2534/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.9001 - val_loss: 3.3402 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02534: val_loss did not improve from 0.38514\n",
      "Epoch 2535/3000\n",
      "13/13 - 0s - loss: 0.2043 - accuracy: 0.9014 - val_loss: 3.3952 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02535: val_loss did not improve from 0.38514\n",
      "Epoch 2536/3000\n",
      "13/13 - 0s - loss: 0.2038 - accuracy: 0.9014 - val_loss: 3.3756 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02536: val_loss did not improve from 0.38514\n",
      "Epoch 2537/3000\n",
      "13/13 - 0s - loss: 0.2032 - accuracy: 0.9027 - val_loss: 3.3521 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02537: val_loss did not improve from 0.38514\n",
      "Epoch 2538/3000\n",
      "13/13 - 0s - loss: 0.2045 - accuracy: 0.9014 - val_loss: 3.3379 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02538: val_loss did not improve from 0.38514\n",
      "Epoch 2539/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9001 - val_loss: 3.2763 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02539: val_loss did not improve from 0.38514\n",
      "Epoch 2540/3000\n",
      "13/13 - 0s - loss: 0.2027 - accuracy: 0.9014 - val_loss: 3.3708 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02540: val_loss did not improve from 0.38514\n",
      "Epoch 2541/3000\n",
      "13/13 - 0s - loss: 0.2028 - accuracy: 0.9027 - val_loss: 3.4713 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02541: val_loss did not improve from 0.38514\n",
      "Epoch 2542/3000\n",
      "13/13 - 0s - loss: 0.2029 - accuracy: 0.9001 - val_loss: 3.4443 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02542: val_loss did not improve from 0.38514\n",
      "Epoch 2543/3000\n",
      "13/13 - 0s - loss: 0.2021 - accuracy: 0.9027 - val_loss: 3.5725 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02543: val_loss did not improve from 0.38514\n",
      "Epoch 2544/3000\n",
      "13/13 - 0s - loss: 0.2044 - accuracy: 0.9014 - val_loss: 3.4310 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02544: val_loss did not improve from 0.38514\n",
      "Epoch 2545/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.9027 - val_loss: 2.9814 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02545: val_loss did not improve from 0.38514\n",
      "Epoch 2546/3000\n",
      "13/13 - 0s - loss: 0.2073 - accuracy: 0.8975 - val_loss: 3.0704 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02546: val_loss did not improve from 0.38514\n",
      "Epoch 2547/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.8949 - val_loss: 3.1358 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02547: val_loss did not improve from 0.38514\n",
      "Epoch 2548/3000\n",
      "13/13 - 0s - loss: 0.2051 - accuracy: 0.8975 - val_loss: 3.1671 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02548: val_loss did not improve from 0.38514\n",
      "Epoch 2549/3000\n",
      "13/13 - 0s - loss: 0.2053 - accuracy: 0.8988 - val_loss: 3.1953 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02549: val_loss did not improve from 0.38514\n",
      "Epoch 2550/3000\n",
      "13/13 - 0s - loss: 0.2036 - accuracy: 0.9040 - val_loss: 3.2675 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02550: val_loss did not improve from 0.38514\n",
      "Epoch 2551/3000\n",
      "13/13 - 0s - loss: 0.2030 - accuracy: 0.9014 - val_loss: 3.3032 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02551: val_loss did not improve from 0.38514\n",
      "Epoch 2552/3000\n",
      "13/13 - 0s - loss: 0.2041 - accuracy: 0.9027 - val_loss: 3.2291 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02552: val_loss did not improve from 0.38514\n",
      "Epoch 2553/3000\n",
      "13/13 - 0s - loss: 0.2045 - accuracy: 0.9014 - val_loss: 3.2085 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02553: val_loss did not improve from 0.38514\n",
      "Epoch 2554/3000\n",
      "13/13 - 0s - loss: 0.2030 - accuracy: 0.9027 - val_loss: 3.2787 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02554: val_loss did not improve from 0.38514\n",
      "Epoch 2555/3000\n",
      "13/13 - 0s - loss: 0.2024 - accuracy: 0.9014 - val_loss: 3.3043 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02555: val_loss did not improve from 0.38514\n",
      "Epoch 2556/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9027 - val_loss: 3.3389 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02556: val_loss did not improve from 0.38514\n",
      "Epoch 2557/3000\n",
      "13/13 - 0s - loss: 0.2020 - accuracy: 0.9001 - val_loss: 3.0108 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02557: val_loss did not improve from 0.38514\n",
      "Epoch 2558/3000\n",
      "13/13 - 0s - loss: 0.2104 - accuracy: 0.9001 - val_loss: 2.8595 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02558: val_loss did not improve from 0.38514\n",
      "Epoch 2559/3000\n",
      "13/13 - 0s - loss: 0.2067 - accuracy: 0.9014 - val_loss: 3.0904 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02559: val_loss did not improve from 0.38514\n",
      "Epoch 2560/3000\n",
      "13/13 - 0s - loss: 0.2061 - accuracy: 0.9027 - val_loss: 3.2397 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02560: val_loss did not improve from 0.38514\n",
      "Epoch 2561/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.8988 - val_loss: 3.2781 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02561: val_loss did not improve from 0.38514\n",
      "Epoch 2562/3000\n",
      "13/13 - 0s - loss: 0.2016 - accuracy: 0.9014 - val_loss: 3.2911 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02562: val_loss did not improve from 0.38514\n",
      "Epoch 2563/3000\n",
      "13/13 - 0s - loss: 0.2021 - accuracy: 0.9027 - val_loss: 3.2433 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02563: val_loss did not improve from 0.38514\n",
      "Epoch 2564/3000\n",
      "13/13 - 0s - loss: 0.2031 - accuracy: 0.9001 - val_loss: 3.2133 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02564: val_loss did not improve from 0.38514\n",
      "Epoch 2565/3000\n",
      "13/13 - 0s - loss: 0.2017 - accuracy: 0.9027 - val_loss: 3.2432 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02565: val_loss did not improve from 0.38514\n",
      "Epoch 2566/3000\n",
      "13/13 - 0s - loss: 0.2029 - accuracy: 0.9027 - val_loss: 3.2306 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02566: val_loss did not improve from 0.38514\n",
      "Epoch 2567/3000\n",
      "13/13 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 3.2185 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02567: val_loss did not improve from 0.38514\n",
      "Epoch 2568/3000\n",
      "13/13 - 0s - loss: 0.2014 - accuracy: 0.9014 - val_loss: 3.2484 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02568: val_loss did not improve from 0.38514\n",
      "Epoch 2569/3000\n",
      "13/13 - 0s - loss: 0.2032 - accuracy: 0.9001 - val_loss: 3.2425 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02569: val_loss did not improve from 0.38514\n",
      "Epoch 2570/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9014 - val_loss: 3.2022 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02570: val_loss did not improve from 0.38514\n",
      "Epoch 2571/3000\n",
      "13/13 - 0s - loss: 0.2023 - accuracy: 0.9027 - val_loss: 3.2114 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02571: val_loss did not improve from 0.38514\n",
      "Epoch 2572/3000\n",
      "13/13 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 3.2692 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02572: val_loss did not improve from 0.38514\n",
      "Epoch 2573/3000\n",
      "13/13 - 0s - loss: 0.2019 - accuracy: 0.9001 - val_loss: 3.2707 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02573: val_loss did not improve from 0.38514\n",
      "Epoch 2574/3000\n",
      "13/13 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 3.2406 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02574: val_loss did not improve from 0.38514\n",
      "Epoch 2575/3000\n",
      "13/13 - 0s - loss: 0.2158 - accuracy: 0.9014 - val_loss: 3.2356 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02575: val_loss did not improve from 0.38514\n",
      "Epoch 2576/3000\n",
      "13/13 - 0s - loss: 0.2087 - accuracy: 0.9027 - val_loss: 3.3821 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02576: val_loss did not improve from 0.38514\n",
      "Epoch 2577/3000\n",
      "13/13 - 0s - loss: 0.2032 - accuracy: 0.9001 - val_loss: 3.4398 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02577: val_loss did not improve from 0.38514\n",
      "Epoch 2578/3000\n",
      "13/13 - 0s - loss: 0.2024 - accuracy: 0.9027 - val_loss: 3.4410 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02578: val_loss did not improve from 0.38514\n",
      "Epoch 2579/3000\n",
      "13/13 - 0s - loss: 0.2021 - accuracy: 0.9001 - val_loss: 3.4522 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02579: val_loss did not improve from 0.38514\n",
      "Epoch 2580/3000\n",
      "13/13 - 0s - loss: 0.2025 - accuracy: 0.9027 - val_loss: 3.4446 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02580: val_loss did not improve from 0.38514\n",
      "Epoch 2581/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.9027 - val_loss: 3.4304 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02581: val_loss did not improve from 0.38514\n",
      "Epoch 2582/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9001 - val_loss: 3.3631 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02582: val_loss did not improve from 0.38514\n",
      "Epoch 2583/3000\n",
      "13/13 - 0s - loss: 0.2022 - accuracy: 0.9014 - val_loss: 3.2964 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02583: val_loss did not improve from 0.38514\n",
      "Epoch 2584/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.8988 - val_loss: 3.2938 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02584: val_loss did not improve from 0.38514\n",
      "Epoch 2585/3000\n",
      "13/13 - 0s - loss: 0.2031 - accuracy: 0.9014 - val_loss: 3.3542 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02585: val_loss did not improve from 0.38514\n",
      "Epoch 2586/3000\n",
      "13/13 - 0s - loss: 0.2026 - accuracy: 0.9001 - val_loss: 3.3199 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02586: val_loss did not improve from 0.38514\n",
      "Epoch 2587/3000\n",
      "13/13 - 0s - loss: 0.2026 - accuracy: 0.9040 - val_loss: 3.3219 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02587: val_loss did not improve from 0.38514\n",
      "Epoch 2588/3000\n",
      "13/13 - 0s - loss: 0.2024 - accuracy: 0.9027 - val_loss: 3.3423 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02588: val_loss did not improve from 0.38514\n",
      "Epoch 2589/3000\n",
      "13/13 - 0s - loss: 0.2032 - accuracy: 0.9014 - val_loss: 3.3617 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02589: val_loss did not improve from 0.38514\n",
      "Epoch 2590/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9040 - val_loss: 3.4380 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02590: val_loss did not improve from 0.38514\n",
      "Epoch 2591/3000\n",
      "13/13 - 0s - loss: 0.2034 - accuracy: 0.9027 - val_loss: 3.4488 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02591: val_loss did not improve from 0.38514\n",
      "Epoch 2592/3000\n",
      "13/13 - 0s - loss: 0.2033 - accuracy: 0.9001 - val_loss: 3.4160 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02592: val_loss did not improve from 0.38514\n",
      "Epoch 2593/3000\n",
      "13/13 - 0s - loss: 0.2032 - accuracy: 0.9027 - val_loss: 3.3783 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02593: val_loss did not improve from 0.38514\n",
      "Epoch 2594/3000\n",
      "13/13 - 0s - loss: 0.2023 - accuracy: 0.9040 - val_loss: 3.3892 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02594: val_loss did not improve from 0.38514\n",
      "Epoch 2595/3000\n",
      "13/13 - 0s - loss: 0.2034 - accuracy: 0.9014 - val_loss: 3.3949 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02595: val_loss did not improve from 0.38514\n",
      "Epoch 2596/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.9001 - val_loss: 3.5169 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02596: val_loss did not improve from 0.38514\n",
      "Epoch 2597/3000\n",
      "13/13 - 0s - loss: 0.2142 - accuracy: 0.9027 - val_loss: 3.4850 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02597: val_loss did not improve from 0.38514\n",
      "Epoch 2598/3000\n",
      "13/13 - 0s - loss: 0.2051 - accuracy: 0.8975 - val_loss: 3.1759 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02598: val_loss did not improve from 0.38514\n",
      "Epoch 2599/3000\n",
      "13/13 - 0s - loss: 0.2175 - accuracy: 0.9014 - val_loss: 3.1759 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02599: val_loss did not improve from 0.38514\n",
      "Epoch 2600/3000\n",
      "13/13 - 0s - loss: 0.2039 - accuracy: 0.9014 - val_loss: 3.1216 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02600: val_loss did not improve from 0.38514\n",
      "Epoch 2601/3000\n",
      "13/13 - 0s - loss: 0.2044 - accuracy: 0.9001 - val_loss: 3.1316 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02601: val_loss did not improve from 0.38514\n",
      "Epoch 2602/3000\n",
      "13/13 - 0s - loss: 0.2033 - accuracy: 0.9027 - val_loss: 3.2210 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02602: val_loss did not improve from 0.38514\n",
      "Epoch 2603/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.9001 - val_loss: 2.7451 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02603: val_loss did not improve from 0.38514\n",
      "Epoch 2604/3000\n",
      "13/13 - 0s - loss: 0.2073 - accuracy: 0.8988 - val_loss: 2.6534 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02604: val_loss did not improve from 0.38514\n",
      "Epoch 2605/3000\n",
      "13/13 - 0s - loss: 0.3171 - accuracy: 0.8703 - val_loss: 2.8635 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02605: val_loss did not improve from 0.38514\n",
      "Epoch 2606/3000\n",
      "13/13 - 0s - loss: 0.2439 - accuracy: 0.8859 - val_loss: 3.1246 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02606: val_loss did not improve from 0.38514\n",
      "Epoch 2607/3000\n",
      "13/13 - 0s - loss: 0.2267 - accuracy: 0.8923 - val_loss: 3.3863 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02607: val_loss did not improve from 0.38514\n",
      "Epoch 2608/3000\n",
      "13/13 - 0s - loss: 0.2105 - accuracy: 0.8975 - val_loss: 3.9904 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 02608: val_loss did not improve from 0.38514\n",
      "Epoch 2609/3000\n",
      "13/13 - 0s - loss: 0.2489 - accuracy: 0.8911 - val_loss: 3.3459 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02609: val_loss did not improve from 0.38514\n",
      "Epoch 2610/3000\n",
      "13/13 - 0s - loss: 0.2125 - accuracy: 0.9027 - val_loss: 3.4353 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02610: val_loss did not improve from 0.38514\n",
      "Epoch 2611/3000\n",
      "13/13 - 0s - loss: 0.2073 - accuracy: 0.9001 - val_loss: 3.4959 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02611: val_loss did not improve from 0.38514\n",
      "Epoch 2612/3000\n",
      "13/13 - 0s - loss: 0.2089 - accuracy: 0.8988 - val_loss: 3.5094 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02612: val_loss did not improve from 0.38514\n",
      "Epoch 2613/3000\n",
      "13/13 - 0s - loss: 0.2176 - accuracy: 0.9014 - val_loss: 3.3716 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02613: val_loss did not improve from 0.38514\n",
      "Epoch 2614/3000\n",
      "13/13 - 0s - loss: 0.2091 - accuracy: 0.9014 - val_loss: 3.4680 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02614: val_loss did not improve from 0.38514\n",
      "Epoch 2615/3000\n",
      "13/13 - 0s - loss: 0.2146 - accuracy: 0.8988 - val_loss: 3.4111 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02615: val_loss did not improve from 0.38514\n",
      "Epoch 2616/3000\n",
      "13/13 - 0s - loss: 0.2098 - accuracy: 0.8911 - val_loss: 3.5667 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02616: val_loss did not improve from 0.38514\n",
      "Epoch 2617/3000\n",
      "13/13 - 0s - loss: 0.2139 - accuracy: 0.8872 - val_loss: 3.8893 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02617: val_loss did not improve from 0.38514\n",
      "Epoch 2618/3000\n",
      "13/13 - 0s - loss: 0.2096 - accuracy: 0.8872 - val_loss: 3.7819 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02618: val_loss did not improve from 0.38514\n",
      "Epoch 2619/3000\n",
      "13/13 - 0s - loss: 0.2089 - accuracy: 0.8923 - val_loss: 3.8061 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02619: val_loss did not improve from 0.38514\n",
      "Epoch 2620/3000\n",
      "13/13 - 0s - loss: 0.2142 - accuracy: 0.9014 - val_loss: 3.4394 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02620: val_loss did not improve from 0.38514\n",
      "Epoch 2621/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.9027 - val_loss: 3.1427 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02621: val_loss did not improve from 0.38514\n",
      "Epoch 2622/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.9001 - val_loss: 3.1943 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02622: val_loss did not improve from 0.38514\n",
      "Epoch 2623/3000\n",
      "13/13 - 0s - loss: 0.2058 - accuracy: 0.9066 - val_loss: 3.1778 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02623: val_loss did not improve from 0.38514\n",
      "Epoch 2624/3000\n",
      "13/13 - 0s - loss: 0.2114 - accuracy: 0.8898 - val_loss: 3.1055 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02624: val_loss did not improve from 0.38514\n",
      "Epoch 2625/3000\n",
      "13/13 - 0s - loss: 0.2104 - accuracy: 0.8898 - val_loss: 3.0999 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 02625: val_loss did not improve from 0.38514\n",
      "Epoch 2626/3000\n",
      "13/13 - 0s - loss: 0.2086 - accuracy: 0.8872 - val_loss: 3.1127 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02626: val_loss did not improve from 0.38514\n",
      "Epoch 2627/3000\n",
      "13/13 - 0s - loss: 0.2067 - accuracy: 0.8988 - val_loss: 3.1350 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02627: val_loss did not improve from 0.38514\n",
      "Epoch 2628/3000\n",
      "13/13 - 0s - loss: 0.2160 - accuracy: 0.8949 - val_loss: 3.1449 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02628: val_loss did not improve from 0.38514\n",
      "Epoch 2629/3000\n",
      "13/13 - 0s - loss: 0.2141 - accuracy: 0.8962 - val_loss: 3.1368 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02629: val_loss did not improve from 0.38514\n",
      "Epoch 2630/3000\n",
      "13/13 - 0s - loss: 0.2097 - accuracy: 0.8949 - val_loss: 3.1413 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02630: val_loss did not improve from 0.38514\n",
      "Epoch 2631/3000\n",
      "13/13 - 0s - loss: 0.2121 - accuracy: 0.8859 - val_loss: 3.1528 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02631: val_loss did not improve from 0.38514\n",
      "Epoch 2632/3000\n",
      "13/13 - 0s - loss: 0.2089 - accuracy: 0.9027 - val_loss: 3.1617 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02632: val_loss did not improve from 0.38514\n",
      "Epoch 2633/3000\n",
      "13/13 - 0s - loss: 0.2085 - accuracy: 0.9014 - val_loss: 3.2166 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02633: val_loss did not improve from 0.38514\n",
      "Epoch 2634/3000\n",
      "13/13 - 0s - loss: 0.2124 - accuracy: 0.8949 - val_loss: 3.2027 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02634: val_loss did not improve from 0.38514\n",
      "Epoch 2635/3000\n",
      "13/13 - 0s - loss: 0.2110 - accuracy: 0.8988 - val_loss: 3.3730 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02635: val_loss did not improve from 0.38514\n",
      "Epoch 2636/3000\n",
      "13/13 - 0s - loss: 0.2150 - accuracy: 0.8923 - val_loss: 3.7266 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02636: val_loss did not improve from 0.38514\n",
      "Epoch 2637/3000\n",
      "13/13 - 0s - loss: 0.2134 - accuracy: 0.9027 - val_loss: 4.2481 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02637: val_loss did not improve from 0.38514\n",
      "Epoch 2638/3000\n",
      "13/13 - 0s - loss: 0.2171 - accuracy: 0.8975 - val_loss: 4.1955 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02638: val_loss did not improve from 0.38514\n",
      "Epoch 2639/3000\n",
      "13/13 - 0s - loss: 0.2094 - accuracy: 0.9014 - val_loss: 4.1550 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02639: val_loss did not improve from 0.38514\n",
      "Epoch 2640/3000\n",
      "13/13 - 0s - loss: 0.2099 - accuracy: 0.9040 - val_loss: 4.1734 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02640: val_loss did not improve from 0.38514\n",
      "Epoch 2641/3000\n",
      "13/13 - 0s - loss: 0.2078 - accuracy: 0.9014 - val_loss: 4.1150 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02641: val_loss did not improve from 0.38514\n",
      "Epoch 2642/3000\n",
      "13/13 - 0s - loss: 0.2076 - accuracy: 0.9027 - val_loss: 3.9560 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02642: val_loss did not improve from 0.38514\n",
      "Epoch 2643/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.9001 - val_loss: 3.8699 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02643: val_loss did not improve from 0.38514\n",
      "Epoch 2644/3000\n",
      "13/13 - 0s - loss: 0.2069 - accuracy: 0.9014 - val_loss: 3.6885 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02644: val_loss did not improve from 0.38514\n",
      "Epoch 2645/3000\n",
      "13/13 - 0s - loss: 0.2059 - accuracy: 0.8988 - val_loss: 3.6325 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02645: val_loss did not improve from 0.38514\n",
      "Epoch 2646/3000\n",
      "13/13 - 0s - loss: 0.2058 - accuracy: 0.9001 - val_loss: 3.6254 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02646: val_loss did not improve from 0.38514\n",
      "Epoch 2647/3000\n",
      "13/13 - 0s - loss: 0.2056 - accuracy: 0.9014 - val_loss: 3.6686 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02647: val_loss did not improve from 0.38514\n",
      "Epoch 2648/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.9014 - val_loss: 3.6850 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02648: val_loss did not improve from 0.38514\n",
      "Epoch 2649/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.8975 - val_loss: 3.6759 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02649: val_loss did not improve from 0.38514\n",
      "Epoch 2650/3000\n",
      "13/13 - 0s - loss: 0.2064 - accuracy: 0.9014 - val_loss: 3.7019 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02650: val_loss did not improve from 0.38514\n",
      "Epoch 2651/3000\n",
      "13/13 - 0s - loss: 0.2053 - accuracy: 0.9001 - val_loss: 3.7035 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02651: val_loss did not improve from 0.38514\n",
      "Epoch 2652/3000\n",
      "13/13 - 0s - loss: 0.2043 - accuracy: 0.9001 - val_loss: 3.7009 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02652: val_loss did not improve from 0.38514\n",
      "Epoch 2653/3000\n",
      "13/13 - 0s - loss: 0.2052 - accuracy: 0.9014 - val_loss: 3.6849 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02653: val_loss did not improve from 0.38514\n",
      "Epoch 2654/3000\n",
      "13/13 - 0s - loss: 0.2048 - accuracy: 0.9027 - val_loss: 3.7961 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02654: val_loss did not improve from 0.38514\n",
      "Epoch 2655/3000\n",
      "13/13 - 0s - loss: 0.2179 - accuracy: 0.9040 - val_loss: 3.0292 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02655: val_loss did not improve from 0.38514\n",
      "Epoch 2656/3000\n",
      "13/13 - 0s - loss: 0.2082 - accuracy: 0.9001 - val_loss: 1.7182 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02656: val_loss did not improve from 0.38514\n",
      "Epoch 2657/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.8975 - val_loss: 1.6603 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02657: val_loss did not improve from 0.38514\n",
      "Epoch 2658/3000\n",
      "13/13 - 0s - loss: 0.2102 - accuracy: 0.8988 - val_loss: 1.7533 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02658: val_loss did not improve from 0.38514\n",
      "Epoch 2659/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.9001 - val_loss: 1.6335 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02659: val_loss did not improve from 0.38514\n",
      "Epoch 2660/3000\n",
      "13/13 - 0s - loss: 0.2048 - accuracy: 0.9053 - val_loss: 1.3815 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02660: val_loss did not improve from 0.38514\n",
      "Epoch 2661/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.8988 - val_loss: 1.4082 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02661: val_loss did not improve from 0.38514\n",
      "Epoch 2662/3000\n",
      "13/13 - 0s - loss: 0.2049 - accuracy: 0.9001 - val_loss: 1.5465 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02662: val_loss did not improve from 0.38514\n",
      "Epoch 2663/3000\n",
      "13/13 - 0s - loss: 0.2086 - accuracy: 0.8911 - val_loss: 1.6282 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02663: val_loss did not improve from 0.38514\n",
      "Epoch 2664/3000\n",
      "13/13 - 0s - loss: 0.2113 - accuracy: 0.8936 - val_loss: 1.7326 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02664: val_loss did not improve from 0.38514\n",
      "Epoch 2665/3000\n",
      "13/13 - 0s - loss: 0.2111 - accuracy: 0.9027 - val_loss: 1.8030 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02665: val_loss did not improve from 0.38514\n",
      "Epoch 2666/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.9027 - val_loss: 1.8619 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02666: val_loss did not improve from 0.38514\n",
      "Epoch 2667/3000\n",
      "13/13 - 0s - loss: 0.2045 - accuracy: 0.9014 - val_loss: 1.8913 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02667: val_loss did not improve from 0.38514\n",
      "Epoch 2668/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.8988 - val_loss: 1.9430 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02668: val_loss did not improve from 0.38514\n",
      "Epoch 2669/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.8975 - val_loss: 2.0012 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02669: val_loss did not improve from 0.38514\n",
      "Epoch 2670/3000\n",
      "13/13 - 0s - loss: 0.2053 - accuracy: 0.9014 - val_loss: 1.9952 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02670: val_loss did not improve from 0.38514\n",
      "Epoch 2671/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.9027 - val_loss: 1.9472 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02671: val_loss did not improve from 0.38514\n",
      "Epoch 2672/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.9027 - val_loss: 1.9589 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02672: val_loss did not improve from 0.38514\n",
      "Epoch 2673/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.9027 - val_loss: 1.8779 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02673: val_loss did not improve from 0.38514\n",
      "Epoch 2674/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.9001 - val_loss: 1.8770 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02674: val_loss did not improve from 0.38514\n",
      "Epoch 2675/3000\n",
      "13/13 - 0s - loss: 0.2048 - accuracy: 0.8988 - val_loss: 1.8954 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02675: val_loss did not improve from 0.38514\n",
      "Epoch 2676/3000\n",
      "13/13 - 0s - loss: 0.2051 - accuracy: 0.8988 - val_loss: 1.9165 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02676: val_loss did not improve from 0.38514\n",
      "Epoch 2677/3000\n",
      "13/13 - 0s - loss: 0.2047 - accuracy: 0.8975 - val_loss: 1.9274 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02677: val_loss did not improve from 0.38514\n",
      "Epoch 2678/3000\n",
      "13/13 - 0s - loss: 0.2040 - accuracy: 0.9014 - val_loss: 1.9283 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02678: val_loss did not improve from 0.38514\n",
      "Epoch 2679/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.8923 - val_loss: 2.0137 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02679: val_loss did not improve from 0.38514\n",
      "Epoch 2680/3000\n",
      "13/13 - 0s - loss: 0.2087 - accuracy: 0.8846 - val_loss: 2.0649 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02680: val_loss did not improve from 0.38514\n",
      "Epoch 2681/3000\n",
      "13/13 - 0s - loss: 0.2120 - accuracy: 0.9001 - val_loss: 2.0957 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02681: val_loss did not improve from 0.38514\n",
      "Epoch 2682/3000\n",
      "13/13 - 0s - loss: 0.2107 - accuracy: 0.8962 - val_loss: 2.2656 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02682: val_loss did not improve from 0.38514\n",
      "Epoch 2683/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.9014 - val_loss: 2.2833 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02683: val_loss did not improve from 0.38514\n",
      "Epoch 2684/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.9014 - val_loss: 2.1476 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02684: val_loss did not improve from 0.38514\n",
      "Epoch 2685/3000\n",
      "13/13 - 0s - loss: 0.2060 - accuracy: 0.9001 - val_loss: 2.1365 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02685: val_loss did not improve from 0.38514\n",
      "Epoch 2686/3000\n",
      "13/13 - 0s - loss: 0.2046 - accuracy: 0.9027 - val_loss: 2.2269 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02686: val_loss did not improve from 0.38514\n",
      "Epoch 2687/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.9001 - val_loss: 2.2584 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02687: val_loss did not improve from 0.38514\n",
      "Epoch 2688/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.9014 - val_loss: 2.2512 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02688: val_loss did not improve from 0.38514\n",
      "Epoch 2689/3000\n",
      "13/13 - 0s - loss: 0.2041 - accuracy: 0.9027 - val_loss: 2.2417 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02689: val_loss did not improve from 0.38514\n",
      "Epoch 2690/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.9027 - val_loss: 2.2668 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02690: val_loss did not improve from 0.38514\n",
      "Epoch 2691/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.9040 - val_loss: 2.2348 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02691: val_loss did not improve from 0.38514\n",
      "Epoch 2692/3000\n",
      "13/13 - 0s - loss: 0.2044 - accuracy: 0.9014 - val_loss: 2.2479 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02692: val_loss did not improve from 0.38514\n",
      "Epoch 2693/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.9027 - val_loss: 2.4098 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02693: val_loss did not improve from 0.38514\n",
      "Epoch 2694/3000\n",
      "13/13 - 0s - loss: 0.2083 - accuracy: 0.8962 - val_loss: 2.4458 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02694: val_loss did not improve from 0.38514\n",
      "Epoch 2695/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.9001 - val_loss: 2.5789 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02695: val_loss did not improve from 0.38514\n",
      "Epoch 2696/3000\n",
      "13/13 - 0s - loss: 0.2041 - accuracy: 0.9001 - val_loss: 2.5902 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02696: val_loss did not improve from 0.38514\n",
      "Epoch 2697/3000\n",
      "13/13 - 0s - loss: 0.2034 - accuracy: 0.8975 - val_loss: 2.5542 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02697: val_loss did not improve from 0.38514\n",
      "Epoch 2698/3000\n",
      "13/13 - 0s - loss: 0.2031 - accuracy: 0.9001 - val_loss: 2.5444 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02698: val_loss did not improve from 0.38514\n",
      "Epoch 2699/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9027 - val_loss: 2.6052 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02699: val_loss did not improve from 0.38514\n",
      "Epoch 2700/3000\n",
      "13/13 - 0s - loss: 0.2041 - accuracy: 0.9027 - val_loss: 2.6780 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02700: val_loss did not improve from 0.38514\n",
      "Epoch 2701/3000\n",
      "13/13 - 0s - loss: 0.2036 - accuracy: 0.9001 - val_loss: 2.6126 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02701: val_loss did not improve from 0.38514\n",
      "Epoch 2702/3000\n",
      "13/13 - 0s - loss: 0.2031 - accuracy: 0.8988 - val_loss: 2.6297 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02702: val_loss did not improve from 0.38514\n",
      "Epoch 2703/3000\n",
      "13/13 - 0s - loss: 0.2025 - accuracy: 0.9014 - val_loss: 2.7202 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02703: val_loss did not improve from 0.38514\n",
      "Epoch 2704/3000\n",
      "13/13 - 0s - loss: 0.2049 - accuracy: 0.9014 - val_loss: 3.2096 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02704: val_loss did not improve from 0.38514\n",
      "Epoch 2705/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.8988 - val_loss: 2.9928 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02705: val_loss did not improve from 0.38514\n",
      "Epoch 2706/3000\n",
      "13/13 - 0s - loss: 0.2053 - accuracy: 0.9014 - val_loss: 2.8212 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02706: val_loss did not improve from 0.38514\n",
      "Epoch 2707/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.8975 - val_loss: 2.7940 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02707: val_loss did not improve from 0.38514\n",
      "Epoch 2708/3000\n",
      "13/13 - 0s - loss: 0.2031 - accuracy: 0.9001 - val_loss: 2.7787 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02708: val_loss did not improve from 0.38514\n",
      "Epoch 2709/3000\n",
      "13/13 - 0s - loss: 0.2036 - accuracy: 0.9014 - val_loss: 2.7556 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02709: val_loss did not improve from 0.38514\n",
      "Epoch 2710/3000\n",
      "13/13 - 0s - loss: 0.2036 - accuracy: 0.9027 - val_loss: 3.0065 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02710: val_loss did not improve from 0.38514\n",
      "Epoch 2711/3000\n",
      "13/13 - 0s - loss: 0.2028 - accuracy: 0.9014 - val_loss: 3.0494 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02711: val_loss did not improve from 0.38514\n",
      "Epoch 2712/3000\n",
      "13/13 - 0s - loss: 0.2029 - accuracy: 0.9027 - val_loss: 2.9900 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02712: val_loss did not improve from 0.38514\n",
      "Epoch 2713/3000\n",
      "13/13 - 0s - loss: 0.2022 - accuracy: 0.9014 - val_loss: 2.8595 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02713: val_loss did not improve from 0.38514\n",
      "Epoch 2714/3000\n",
      "13/13 - 0s - loss: 0.2032 - accuracy: 0.9014 - val_loss: 2.8655 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02714: val_loss did not improve from 0.38514\n",
      "Epoch 2715/3000\n",
      "13/13 - 0s - loss: 0.2018 - accuracy: 0.9027 - val_loss: 2.8441 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02715: val_loss did not improve from 0.38514\n",
      "Epoch 2716/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.9001 - val_loss: 2.7047 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02716: val_loss did not improve from 0.38514\n",
      "Epoch 2717/3000\n",
      "13/13 - 0s - loss: 0.2120 - accuracy: 0.8949 - val_loss: 2.7650 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02717: val_loss did not improve from 0.38514\n",
      "Epoch 2718/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.8975 - val_loss: 2.8108 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02718: val_loss did not improve from 0.38514\n",
      "Epoch 2719/3000\n",
      "13/13 - 0s - loss: 0.2030 - accuracy: 0.8988 - val_loss: 2.8336 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02719: val_loss did not improve from 0.38514\n",
      "Epoch 2720/3000\n",
      "13/13 - 0s - loss: 0.2026 - accuracy: 0.8988 - val_loss: 2.8331 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02720: val_loss did not improve from 0.38514\n",
      "Epoch 2721/3000\n",
      "13/13 - 0s - loss: 0.2023 - accuracy: 0.8975 - val_loss: 2.7034 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02721: val_loss did not improve from 0.38514\n",
      "Epoch 2722/3000\n",
      "13/13 - 0s - loss: 0.2025 - accuracy: 0.9014 - val_loss: 2.7357 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02722: val_loss did not improve from 0.38514\n",
      "Epoch 2723/3000\n",
      "13/13 - 0s - loss: 0.2012 - accuracy: 0.8975 - val_loss: 2.7802 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02723: val_loss did not improve from 0.38514\n",
      "Epoch 2724/3000\n",
      "13/13 - 0s - loss: 0.2018 - accuracy: 0.9014 - val_loss: 2.7814 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02724: val_loss did not improve from 0.38514\n",
      "Epoch 2725/3000\n",
      "13/13 - 0s - loss: 0.2031 - accuracy: 0.8975 - val_loss: 2.7833 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02725: val_loss did not improve from 0.38514\n",
      "Epoch 2726/3000\n",
      "13/13 - 0s - loss: 0.2014 - accuracy: 0.9027 - val_loss: 2.8508 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02726: val_loss did not improve from 0.38514\n",
      "Epoch 2727/3000\n",
      "13/13 - 0s - loss: 0.2016 - accuracy: 0.8988 - val_loss: 2.8683 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02727: val_loss did not improve from 0.38514\n",
      "Epoch 2728/3000\n",
      "13/13 - 0s - loss: 0.2025 - accuracy: 0.9027 - val_loss: 2.8015 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02728: val_loss did not improve from 0.38514\n",
      "Epoch 2729/3000\n",
      "13/13 - 0s - loss: 0.2018 - accuracy: 0.9027 - val_loss: 2.7436 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02729: val_loss did not improve from 0.38514\n",
      "Epoch 2730/3000\n",
      "13/13 - 0s - loss: 0.2018 - accuracy: 0.8962 - val_loss: 2.7395 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02730: val_loss did not improve from 0.38514\n",
      "Epoch 2731/3000\n",
      "13/13 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 2.6943 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02731: val_loss did not improve from 0.38514\n",
      "Epoch 2732/3000\n",
      "13/13 - 0s - loss: 0.2016 - accuracy: 0.9001 - val_loss: 2.7373 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02732: val_loss did not improve from 0.38514\n",
      "Epoch 2733/3000\n",
      "13/13 - 0s - loss: 0.2014 - accuracy: 0.9014 - val_loss: 2.8345 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02733: val_loss did not improve from 0.38514\n",
      "Epoch 2734/3000\n",
      "13/13 - 0s - loss: 0.2022 - accuracy: 0.9014 - val_loss: 2.8540 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02734: val_loss did not improve from 0.38514\n",
      "Epoch 2735/3000\n",
      "13/13 - 0s - loss: 0.2009 - accuracy: 0.9014 - val_loss: 2.8761 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02735: val_loss did not improve from 0.38514\n",
      "Epoch 2736/3000\n",
      "13/13 - 0s - loss: 0.2020 - accuracy: 0.9001 - val_loss: 2.8169 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02736: val_loss did not improve from 0.38514\n",
      "Epoch 2737/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.9027 - val_loss: 2.7335 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02737: val_loss did not improve from 0.38514\n",
      "Epoch 2738/3000\n",
      "13/13 - 0s - loss: 0.2052 - accuracy: 0.9027 - val_loss: 2.6953 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02738: val_loss did not improve from 0.38514\n",
      "Epoch 2739/3000\n",
      "13/13 - 0s - loss: 0.2034 - accuracy: 0.9027 - val_loss: 2.6852 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02739: val_loss did not improve from 0.38514\n",
      "Epoch 2740/3000\n",
      "13/13 - 0s - loss: 0.2043 - accuracy: 0.9001 - val_loss: 2.7205 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02740: val_loss did not improve from 0.38514\n",
      "Epoch 2741/3000\n",
      "13/13 - 0s - loss: 0.2069 - accuracy: 0.9014 - val_loss: 2.6434 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02741: val_loss did not improve from 0.38514\n",
      "Epoch 2742/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.9014 - val_loss: 2.7242 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02742: val_loss did not improve from 0.38514\n",
      "Epoch 2743/3000\n",
      "13/13 - 0s - loss: 0.2033 - accuracy: 0.9053 - val_loss: 2.8443 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02743: val_loss did not improve from 0.38514\n",
      "Epoch 2744/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9027 - val_loss: 2.8667 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02744: val_loss did not improve from 0.38514\n",
      "Epoch 2745/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.9001 - val_loss: 2.8607 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02745: val_loss did not improve from 0.38514\n",
      "Epoch 2746/3000\n",
      "13/13 - 0s - loss: 0.2030 - accuracy: 0.8962 - val_loss: 2.7853 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02746: val_loss did not improve from 0.38514\n",
      "Epoch 2747/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9027 - val_loss: 2.5153 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02747: val_loss did not improve from 0.38514\n",
      "Epoch 2748/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.9027 - val_loss: 2.4845 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02748: val_loss did not improve from 0.38514\n",
      "Epoch 2749/3000\n",
      "13/13 - 0s - loss: 0.2087 - accuracy: 0.8962 - val_loss: 2.5097 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02749: val_loss did not improve from 0.38514\n",
      "Epoch 2750/3000\n",
      "13/13 - 0s - loss: 0.2053 - accuracy: 0.8975 - val_loss: 2.5002 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02750: val_loss did not improve from 0.38514\n",
      "Epoch 2751/3000\n",
      "13/13 - 0s - loss: 0.2065 - accuracy: 0.9001 - val_loss: 2.4949 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02751: val_loss did not improve from 0.38514\n",
      "Epoch 2752/3000\n",
      "13/13 - 0s - loss: 0.2040 - accuracy: 0.9001 - val_loss: 2.5958 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02752: val_loss did not improve from 0.38514\n",
      "Epoch 2753/3000\n",
      "13/13 - 0s - loss: 0.2040 - accuracy: 0.9001 - val_loss: 2.6366 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02753: val_loss did not improve from 0.38514\n",
      "Epoch 2754/3000\n",
      "13/13 - 0s - loss: 0.2041 - accuracy: 0.9001 - val_loss: 2.6598 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02754: val_loss did not improve from 0.38514\n",
      "Epoch 2755/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9001 - val_loss: 2.6900 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02755: val_loss did not improve from 0.38514\n",
      "Epoch 2756/3000\n",
      "13/13 - 0s - loss: 0.2036 - accuracy: 0.9001 - val_loss: 2.7187 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02756: val_loss did not improve from 0.38514\n",
      "Epoch 2757/3000\n",
      "13/13 - 0s - loss: 0.2041 - accuracy: 0.8975 - val_loss: 2.6545 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02757: val_loss did not improve from 0.38514\n",
      "Epoch 2758/3000\n",
      "13/13 - 0s - loss: 0.2061 - accuracy: 0.8988 - val_loss: 2.7071 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02758: val_loss did not improve from 0.38514\n",
      "Epoch 2759/3000\n",
      "13/13 - 0s - loss: 0.2047 - accuracy: 0.8936 - val_loss: 2.7144 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02759: val_loss did not improve from 0.38514\n",
      "Epoch 2760/3000\n",
      "13/13 - 0s - loss: 0.2034 - accuracy: 0.8988 - val_loss: 2.6856 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02760: val_loss did not improve from 0.38514\n",
      "Epoch 2761/3000\n",
      "13/13 - 0s - loss: 0.2030 - accuracy: 0.9027 - val_loss: 2.6854 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02761: val_loss did not improve from 0.38514\n",
      "Epoch 2762/3000\n",
      "13/13 - 0s - loss: 0.2027 - accuracy: 0.9001 - val_loss: 2.7215 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02762: val_loss did not improve from 0.38514\n",
      "Epoch 2763/3000\n",
      "13/13 - 0s - loss: 0.2029 - accuracy: 0.9027 - val_loss: 2.6818 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02763: val_loss did not improve from 0.38514\n",
      "Epoch 2764/3000\n",
      "13/13 - 0s - loss: 0.2022 - accuracy: 0.9014 - val_loss: 2.6715 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02764: val_loss did not improve from 0.38514\n",
      "Epoch 2765/3000\n",
      "13/13 - 0s - loss: 0.2020 - accuracy: 0.9027 - val_loss: 2.7160 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02765: val_loss did not improve from 0.38514\n",
      "Epoch 2766/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.9014 - val_loss: 2.6228 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02766: val_loss did not improve from 0.38514\n",
      "Epoch 2767/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9027 - val_loss: 2.6939 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02767: val_loss did not improve from 0.38514\n",
      "Epoch 2768/3000\n",
      "13/13 - 0s - loss: 0.2028 - accuracy: 0.9014 - val_loss: 2.8575 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02768: val_loss did not improve from 0.38514\n",
      "Epoch 2769/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.9014 - val_loss: 2.9224 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02769: val_loss did not improve from 0.38514\n",
      "Epoch 2770/3000\n",
      "13/13 - 0s - loss: 0.2026 - accuracy: 0.9014 - val_loss: 2.8057 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02770: val_loss did not improve from 0.38514\n",
      "Epoch 2771/3000\n",
      "13/13 - 0s - loss: 0.2021 - accuracy: 0.9027 - val_loss: 2.7688 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02771: val_loss did not improve from 0.38514\n",
      "Epoch 2772/3000\n",
      "13/13 - 0s - loss: 0.2027 - accuracy: 0.9014 - val_loss: 2.7619 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02772: val_loss did not improve from 0.38514\n",
      "Epoch 2773/3000\n",
      "13/13 - 0s - loss: 0.2033 - accuracy: 0.9027 - val_loss: 2.7984 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02773: val_loss did not improve from 0.38514\n",
      "Epoch 2774/3000\n",
      "13/13 - 0s - loss: 0.2032 - accuracy: 0.9001 - val_loss: 2.8173 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02774: val_loss did not improve from 0.38514\n",
      "Epoch 2775/3000\n",
      "13/13 - 0s - loss: 0.2027 - accuracy: 0.9027 - val_loss: 2.8346 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02775: val_loss did not improve from 0.38514\n",
      "Epoch 2776/3000\n",
      "13/13 - 0s - loss: 0.2017 - accuracy: 0.9027 - val_loss: 2.8820 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02776: val_loss did not improve from 0.38514\n",
      "Epoch 2777/3000\n",
      "13/13 - 0s - loss: 0.2045 - accuracy: 0.9040 - val_loss: 2.8697 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02777: val_loss did not improve from 0.38514\n",
      "Epoch 2778/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.9027 - val_loss: 2.8027 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02778: val_loss did not improve from 0.38514\n",
      "Epoch 2779/3000\n",
      "13/13 - 0s - loss: 0.2023 - accuracy: 0.9014 - val_loss: 2.8060 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02779: val_loss did not improve from 0.38514\n",
      "Epoch 2780/3000\n",
      "13/13 - 0s - loss: 0.2021 - accuracy: 0.9027 - val_loss: 2.9367 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02780: val_loss did not improve from 0.38514\n",
      "Epoch 2781/3000\n",
      "13/13 - 0s - loss: 0.2093 - accuracy: 0.9001 - val_loss: 2.6684 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02781: val_loss did not improve from 0.38514\n",
      "Epoch 2782/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.9027 - val_loss: 2.4451 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02782: val_loss did not improve from 0.38514\n",
      "Epoch 2783/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9014 - val_loss: 2.5970 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02783: val_loss did not improve from 0.38514\n",
      "Epoch 2784/3000\n",
      "13/13 - 0s - loss: 0.2039 - accuracy: 0.8975 - val_loss: 2.6190 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02784: val_loss did not improve from 0.38514\n",
      "Epoch 2785/3000\n",
      "13/13 - 0s - loss: 0.2022 - accuracy: 0.9027 - val_loss: 2.6091 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02785: val_loss did not improve from 0.38514\n",
      "Epoch 2786/3000\n",
      "13/13 - 0s - loss: 0.2028 - accuracy: 0.9014 - val_loss: 2.6511 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02786: val_loss did not improve from 0.38514\n",
      "Epoch 2787/3000\n",
      "13/13 - 0s - loss: 0.2033 - accuracy: 0.9014 - val_loss: 2.6418 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02787: val_loss did not improve from 0.38514\n",
      "Epoch 2788/3000\n",
      "13/13 - 0s - loss: 0.2033 - accuracy: 0.9027 - val_loss: 2.6754 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02788: val_loss did not improve from 0.38514\n",
      "Epoch 2789/3000\n",
      "13/13 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 2.6685 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02789: val_loss did not improve from 0.38514\n",
      "Epoch 2790/3000\n",
      "13/13 - 0s - loss: 0.2017 - accuracy: 0.9040 - val_loss: 2.6408 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02790: val_loss did not improve from 0.38514\n",
      "Epoch 2791/3000\n",
      "13/13 - 0s - loss: 0.2024 - accuracy: 0.9001 - val_loss: 2.6155 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02791: val_loss did not improve from 0.38514\n",
      "Epoch 2792/3000\n",
      "13/13 - 0s - loss: 0.2020 - accuracy: 0.9001 - val_loss: 2.6575 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02792: val_loss did not improve from 0.38514\n",
      "Epoch 2793/3000\n",
      "13/13 - 0s - loss: 0.2027 - accuracy: 0.9027 - val_loss: 2.6598 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02793: val_loss did not improve from 0.38514\n",
      "Epoch 2794/3000\n",
      "13/13 - 0s - loss: 0.2052 - accuracy: 0.9014 - val_loss: 2.6407 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02794: val_loss did not improve from 0.38514\n",
      "Epoch 2795/3000\n",
      "13/13 - 0s - loss: 0.2041 - accuracy: 0.9027 - val_loss: 2.6879 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02795: val_loss did not improve from 0.38514\n",
      "Epoch 2796/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9014 - val_loss: 2.7110 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02796: val_loss did not improve from 0.38514\n",
      "Epoch 2797/3000\n",
      "13/13 - 0s - loss: 0.2017 - accuracy: 0.9027 - val_loss: 2.7016 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02797: val_loss did not improve from 0.38514\n",
      "Epoch 2798/3000\n",
      "13/13 - 0s - loss: 0.2014 - accuracy: 0.9027 - val_loss: 2.6817 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02798: val_loss did not improve from 0.38514\n",
      "Epoch 2799/3000\n",
      "13/13 - 0s - loss: 0.2008 - accuracy: 0.9027 - val_loss: 2.6918 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02799: val_loss did not improve from 0.38514\n",
      "Epoch 2800/3000\n",
      "13/13 - 0s - loss: 0.2019 - accuracy: 0.9014 - val_loss: 2.7272 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02800: val_loss did not improve from 0.38514\n",
      "Epoch 2801/3000\n",
      "13/13 - 0s - loss: 0.2020 - accuracy: 0.9040 - val_loss: 2.8194 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02801: val_loss did not improve from 0.38514\n",
      "Epoch 2802/3000\n",
      "13/13 - 0s - loss: 0.2243 - accuracy: 0.9027 - val_loss: 2.7693 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02802: val_loss did not improve from 0.38514\n",
      "Epoch 2803/3000\n",
      "13/13 - 0s - loss: 0.2069 - accuracy: 0.9027 - val_loss: 2.6746 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02803: val_loss did not improve from 0.38514\n",
      "Epoch 2804/3000\n",
      "13/13 - 0s - loss: 0.2106 - accuracy: 0.9001 - val_loss: 2.5621 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02804: val_loss did not improve from 0.38514\n",
      "Epoch 2805/3000\n",
      "13/13 - 0s - loss: 0.2059 - accuracy: 0.9014 - val_loss: 2.4560 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02805: val_loss did not improve from 0.38514\n",
      "Epoch 2806/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9027 - val_loss: 2.4494 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02806: val_loss did not improve from 0.38514\n",
      "Epoch 2807/3000\n",
      "13/13 - 0s - loss: 0.2040 - accuracy: 0.8975 - val_loss: 2.5380 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02807: val_loss did not improve from 0.38514\n",
      "Epoch 2808/3000\n",
      "13/13 - 0s - loss: 0.2024 - accuracy: 0.9014 - val_loss: 2.4942 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02808: val_loss did not improve from 0.38514\n",
      "Epoch 2809/3000\n",
      "13/13 - 0s - loss: 0.2029 - accuracy: 0.9014 - val_loss: 2.5606 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02809: val_loss did not improve from 0.38514\n",
      "Epoch 2810/3000\n",
      "13/13 - 0s - loss: 0.2036 - accuracy: 0.9014 - val_loss: 2.6390 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02810: val_loss did not improve from 0.38514\n",
      "Epoch 2811/3000\n",
      "13/13 - 0s - loss: 0.2029 - accuracy: 0.9040 - val_loss: 2.6783 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02811: val_loss did not improve from 0.38514\n",
      "Epoch 2812/3000\n",
      "13/13 - 0s - loss: 0.2019 - accuracy: 0.9014 - val_loss: 2.6764 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02812: val_loss did not improve from 0.38514\n",
      "Epoch 2813/3000\n",
      "13/13 - 0s - loss: 0.2015 - accuracy: 0.9027 - val_loss: 2.6523 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02813: val_loss did not improve from 0.38514\n",
      "Epoch 2814/3000\n",
      "13/13 - 0s - loss: 0.2019 - accuracy: 0.8962 - val_loss: 2.6570 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02814: val_loss did not improve from 0.38514\n",
      "Epoch 2815/3000\n",
      "13/13 - 0s - loss: 0.2016 - accuracy: 0.9027 - val_loss: 2.6525 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02815: val_loss did not improve from 0.38514\n",
      "Epoch 2816/3000\n",
      "13/13 - 0s - loss: 0.2007 - accuracy: 0.9014 - val_loss: 2.6326 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02816: val_loss did not improve from 0.38514\n",
      "Epoch 2817/3000\n",
      "13/13 - 0s - loss: 0.2041 - accuracy: 0.9027 - val_loss: 2.6004 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02817: val_loss did not improve from 0.38514\n",
      "Epoch 2818/3000\n",
      "13/13 - 0s - loss: 0.2020 - accuracy: 0.9040 - val_loss: 2.5819 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02818: val_loss did not improve from 0.38514\n",
      "Epoch 2819/3000\n",
      "13/13 - 0s - loss: 0.2018 - accuracy: 0.8988 - val_loss: 2.4865 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02819: val_loss did not improve from 0.38514\n",
      "Epoch 2820/3000\n",
      "13/13 - 0s - loss: 0.2019 - accuracy: 0.9027 - val_loss: 2.3502 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02820: val_loss did not improve from 0.38514\n",
      "Epoch 2821/3000\n",
      "13/13 - 0s - loss: 0.2021 - accuracy: 0.9001 - val_loss: 2.3020 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02821: val_loss did not improve from 0.38514\n",
      "Epoch 2822/3000\n",
      "13/13 - 0s - loss: 0.2024 - accuracy: 0.8962 - val_loss: 2.3052 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02822: val_loss did not improve from 0.38514\n",
      "Epoch 2823/3000\n",
      "13/13 - 0s - loss: 0.2031 - accuracy: 0.8962 - val_loss: 2.3627 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02823: val_loss did not improve from 0.38514\n",
      "Epoch 2824/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.8975 - val_loss: 2.3235 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02824: val_loss did not improve from 0.38514\n",
      "Epoch 2825/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.9001 - val_loss: 2.2955 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02825: val_loss did not improve from 0.38514\n",
      "Epoch 2826/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.9001 - val_loss: 2.2705 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02826: val_loss did not improve from 0.38514\n",
      "Epoch 2827/3000\n",
      "13/13 - 0s - loss: 0.2047 - accuracy: 0.9001 - val_loss: 2.1351 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02827: val_loss did not improve from 0.38514\n",
      "Epoch 2828/3000\n",
      "13/13 - 0s - loss: 0.2014 - accuracy: 0.9027 - val_loss: 2.1700 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02828: val_loss did not improve from 0.38514\n",
      "Epoch 2829/3000\n",
      "13/13 - 0s - loss: 0.2029 - accuracy: 0.9027 - val_loss: 2.1621 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02829: val_loss did not improve from 0.38514\n",
      "Epoch 2830/3000\n",
      "13/13 - 0s - loss: 0.2038 - accuracy: 0.8988 - val_loss: 2.1485 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02830: val_loss did not improve from 0.38514\n",
      "Epoch 2831/3000\n",
      "13/13 - 0s - loss: 0.2034 - accuracy: 0.9001 - val_loss: 2.2053 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02831: val_loss did not improve from 0.38514\n",
      "Epoch 2832/3000\n",
      "13/13 - 0s - loss: 0.2022 - accuracy: 0.9014 - val_loss: 2.2287 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02832: val_loss did not improve from 0.38514\n",
      "Epoch 2833/3000\n",
      "13/13 - 0s - loss: 0.2032 - accuracy: 0.8962 - val_loss: 2.1783 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02833: val_loss did not improve from 0.38514\n",
      "Epoch 2834/3000\n",
      "13/13 - 0s - loss: 0.2053 - accuracy: 0.8949 - val_loss: 2.1488 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02834: val_loss did not improve from 0.38514\n",
      "Epoch 2835/3000\n",
      "13/13 - 0s - loss: 0.2040 - accuracy: 0.8988 - val_loss: 2.1471 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02835: val_loss did not improve from 0.38514\n",
      "Epoch 2836/3000\n",
      "13/13 - 0s - loss: 0.2047 - accuracy: 0.8975 - val_loss: 2.1527 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02836: val_loss did not improve from 0.38514\n",
      "Epoch 2837/3000\n",
      "13/13 - 0s - loss: 0.2025 - accuracy: 0.8936 - val_loss: 2.2254 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02837: val_loss did not improve from 0.38514\n",
      "Epoch 2838/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.8988 - val_loss: 2.2528 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02838: val_loss did not improve from 0.38514\n",
      "Epoch 2839/3000\n",
      "13/13 - 0s - loss: 0.2029 - accuracy: 0.9027 - val_loss: 2.2940 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02839: val_loss did not improve from 0.38514\n",
      "Epoch 2840/3000\n",
      "13/13 - 0s - loss: 0.2035 - accuracy: 0.9014 - val_loss: 2.3941 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02840: val_loss did not improve from 0.38514\n",
      "Epoch 2841/3000\n",
      "13/13 - 0s - loss: 0.2038 - accuracy: 0.9040 - val_loss: 2.3241 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02841: val_loss did not improve from 0.38514\n",
      "Epoch 2842/3000\n",
      "13/13 - 0s - loss: 0.2027 - accuracy: 0.9027 - val_loss: 2.3208 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02842: val_loss did not improve from 0.38514\n",
      "Epoch 2843/3000\n",
      "13/13 - 0s - loss: 0.2065 - accuracy: 0.9027 - val_loss: 2.2844 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02843: val_loss did not improve from 0.38514\n",
      "Epoch 2844/3000\n",
      "13/13 - 0s - loss: 0.2026 - accuracy: 0.9014 - val_loss: 2.3350 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02844: val_loss did not improve from 0.38514\n",
      "Epoch 2845/3000\n",
      "13/13 - 0s - loss: 0.2024 - accuracy: 0.9014 - val_loss: 2.3978 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02845: val_loss did not improve from 0.38514\n",
      "Epoch 2846/3000\n",
      "13/13 - 0s - loss: 0.2027 - accuracy: 0.9027 - val_loss: 2.4273 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02846: val_loss did not improve from 0.38514\n",
      "Epoch 2847/3000\n",
      "13/13 - 0s - loss: 0.2026 - accuracy: 0.9014 - val_loss: 2.4194 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02847: val_loss did not improve from 0.38514\n",
      "Epoch 2848/3000\n",
      "13/13 - 0s - loss: 0.2018 - accuracy: 0.8988 - val_loss: 2.4862 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02848: val_loss did not improve from 0.38514\n",
      "Epoch 2849/3000\n",
      "13/13 - 0s - loss: 0.2012 - accuracy: 0.9027 - val_loss: 2.5105 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02849: val_loss did not improve from 0.38514\n",
      "Epoch 2850/3000\n",
      "13/13 - 0s - loss: 0.2016 - accuracy: 0.8988 - val_loss: 2.5711 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02850: val_loss did not improve from 0.38514\n",
      "Epoch 2851/3000\n",
      "13/13 - 0s - loss: 0.2027 - accuracy: 0.9027 - val_loss: 2.4826 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02851: val_loss did not improve from 0.38514\n",
      "Epoch 2852/3000\n",
      "13/13 - 0s - loss: 0.2040 - accuracy: 0.9001 - val_loss: 2.5787 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02852: val_loss did not improve from 0.38514\n",
      "Epoch 2853/3000\n",
      "13/13 - 0s - loss: 0.2024 - accuracy: 0.9027 - val_loss: 2.6318 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02853: val_loss did not improve from 0.38514\n",
      "Epoch 2854/3000\n",
      "13/13 - 0s - loss: 0.2014 - accuracy: 0.9027 - val_loss: 2.6562 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02854: val_loss did not improve from 0.38514\n",
      "Epoch 2855/3000\n",
      "13/13 - 0s - loss: 0.2014 - accuracy: 0.9053 - val_loss: 2.6540 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02855: val_loss did not improve from 0.38514\n",
      "Epoch 2856/3000\n",
      "13/13 - 0s - loss: 0.2031 - accuracy: 0.9027 - val_loss: 2.5879 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02856: val_loss did not improve from 0.38514\n",
      "Epoch 2857/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.9014 - val_loss: 3.1778 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02857: val_loss did not improve from 0.38514\n",
      "Epoch 2858/3000\n",
      "13/13 - 0s - loss: 0.3913 - accuracy: 0.8936 - val_loss: 3.1588 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02858: val_loss did not improve from 0.38514\n",
      "Epoch 2859/3000\n",
      "13/13 - 0s - loss: 0.5539 - accuracy: 0.8872 - val_loss: 1.6911 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02859: val_loss did not improve from 0.38514\n",
      "Epoch 2860/3000\n",
      "13/13 - 0s - loss: 0.4227 - accuracy: 0.8547 - val_loss: 1.2970 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02860: val_loss did not improve from 0.38514\n",
      "Epoch 2861/3000\n",
      "13/13 - 0s - loss: 0.3106 - accuracy: 0.8768 - val_loss: 2.6137 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 02861: val_loss did not improve from 0.38514\n",
      "Epoch 2862/3000\n",
      "13/13 - 0s - loss: 0.2438 - accuracy: 0.8898 - val_loss: 2.2943 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 02862: val_loss did not improve from 0.38514\n",
      "Epoch 2863/3000\n",
      "13/13 - 0s - loss: 0.2324 - accuracy: 0.8898 - val_loss: 2.5389 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 02863: val_loss did not improve from 0.38514\n",
      "Epoch 2864/3000\n",
      "13/13 - 0s - loss: 0.2179 - accuracy: 0.8962 - val_loss: 2.7165 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02864: val_loss did not improve from 0.38514\n",
      "Epoch 2865/3000\n",
      "13/13 - 0s - loss: 0.2184 - accuracy: 0.8988 - val_loss: 2.2245 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02865: val_loss did not improve from 0.38514\n",
      "Epoch 2866/3000\n",
      "13/13 - 0s - loss: 0.2155 - accuracy: 0.8988 - val_loss: 2.2654 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 02866: val_loss did not improve from 0.38514\n",
      "Epoch 2867/3000\n",
      "13/13 - 0s - loss: 0.2157 - accuracy: 0.9027 - val_loss: 2.2919 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02867: val_loss did not improve from 0.38514\n",
      "Epoch 2868/3000\n",
      "13/13 - 0s - loss: 0.2092 - accuracy: 0.9001 - val_loss: 2.2810 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02868: val_loss did not improve from 0.38514\n",
      "Epoch 2869/3000\n",
      "13/13 - 0s - loss: 0.2089 - accuracy: 0.9014 - val_loss: 2.2138 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02869: val_loss did not improve from 0.38514\n",
      "Epoch 2870/3000\n",
      "13/13 - 0s - loss: 0.2070 - accuracy: 0.9027 - val_loss: 2.1659 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02870: val_loss did not improve from 0.38514\n",
      "Epoch 2871/3000\n",
      "13/13 - 0s - loss: 0.2069 - accuracy: 0.9001 - val_loss: 2.1870 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02871: val_loss did not improve from 0.38514\n",
      "Epoch 2872/3000\n",
      "13/13 - 0s - loss: 0.2067 - accuracy: 0.9014 - val_loss: 2.1888 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02872: val_loss did not improve from 0.38514\n",
      "Epoch 2873/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.9027 - val_loss: 2.1895 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02873: val_loss did not improve from 0.38514\n",
      "Epoch 2874/3000\n",
      "13/13 - 0s - loss: 0.2065 - accuracy: 0.9014 - val_loss: 2.2121 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02874: val_loss did not improve from 0.38514\n",
      "Epoch 2875/3000\n",
      "13/13 - 0s - loss: 0.2078 - accuracy: 0.9014 - val_loss: 2.2286 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02875: val_loss did not improve from 0.38514\n",
      "Epoch 2876/3000\n",
      "13/13 - 0s - loss: 0.2144 - accuracy: 0.9014 - val_loss: 2.3752 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02876: val_loss did not improve from 0.38514\n",
      "Epoch 2877/3000\n",
      "13/13 - 0s - loss: 0.2100 - accuracy: 0.8962 - val_loss: 2.3191 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02877: val_loss did not improve from 0.38514\n",
      "Epoch 2878/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.8988 - val_loss: 2.3694 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02878: val_loss did not improve from 0.38514\n",
      "Epoch 2879/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.9027 - val_loss: 2.3899 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02879: val_loss did not improve from 0.38514\n",
      "Epoch 2880/3000\n",
      "13/13 - 0s - loss: 0.2056 - accuracy: 0.9040 - val_loss: 2.3781 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02880: val_loss did not improve from 0.38514\n",
      "Epoch 2881/3000\n",
      "13/13 - 0s - loss: 0.2058 - accuracy: 0.9040 - val_loss: 2.3774 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02881: val_loss did not improve from 0.38514\n",
      "Epoch 2882/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.8975 - val_loss: 2.3707 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02882: val_loss did not improve from 0.38514\n",
      "Epoch 2883/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.9001 - val_loss: 2.3859 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02883: val_loss did not improve from 0.38514\n",
      "Epoch 2884/3000\n",
      "13/13 - 0s - loss: 0.2044 - accuracy: 0.9027 - val_loss: 2.3982 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02884: val_loss did not improve from 0.38514\n",
      "Epoch 2885/3000\n",
      "13/13 - 0s - loss: 0.2046 - accuracy: 0.9027 - val_loss: 2.4142 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02885: val_loss did not improve from 0.38514\n",
      "Epoch 2886/3000\n",
      "13/13 - 0s - loss: 0.2036 - accuracy: 0.9027 - val_loss: 2.4085 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02886: val_loss did not improve from 0.38514\n",
      "Epoch 2887/3000\n",
      "13/13 - 0s - loss: 0.2041 - accuracy: 0.9001 - val_loss: 2.4572 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02887: val_loss did not improve from 0.38514\n",
      "Epoch 2888/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.9027 - val_loss: 2.4779 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02888: val_loss did not improve from 0.38514\n",
      "Epoch 2889/3000\n",
      "13/13 - 0s - loss: 0.2085 - accuracy: 0.9027 - val_loss: 2.4394 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02889: val_loss did not improve from 0.38514\n",
      "Epoch 2890/3000\n",
      "13/13 - 0s - loss: 0.2056 - accuracy: 0.9027 - val_loss: 2.4476 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02890: val_loss did not improve from 0.38514\n",
      "Epoch 2891/3000\n",
      "13/13 - 0s - loss: 0.2096 - accuracy: 0.9027 - val_loss: 2.5200 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02891: val_loss did not improve from 0.38514\n",
      "Epoch 2892/3000\n",
      "13/13 - 0s - loss: 0.2068 - accuracy: 0.8975 - val_loss: 2.4616 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02892: val_loss did not improve from 0.38514\n",
      "Epoch 2893/3000\n",
      "13/13 - 0s - loss: 0.2048 - accuracy: 0.8962 - val_loss: 2.4383 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02893: val_loss did not improve from 0.38514\n",
      "Epoch 2894/3000\n",
      "13/13 - 0s - loss: 0.2042 - accuracy: 0.8988 - val_loss: 2.4392 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02894: val_loss did not improve from 0.38514\n",
      "Epoch 2895/3000\n",
      "13/13 - 0s - loss: 0.2033 - accuracy: 0.8923 - val_loss: 2.4397 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02895: val_loss did not improve from 0.38514\n",
      "Epoch 2896/3000\n",
      "13/13 - 0s - loss: 0.2044 - accuracy: 0.9027 - val_loss: 2.4169 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02896: val_loss did not improve from 0.38514\n",
      "Epoch 2897/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.9001 - val_loss: 2.3305 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02897: val_loss did not improve from 0.38514\n",
      "Epoch 2898/3000\n",
      "13/13 - 0s - loss: 0.2086 - accuracy: 0.9001 - val_loss: 2.3249 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02898: val_loss did not improve from 0.38514\n",
      "Epoch 2899/3000\n",
      "13/13 - 0s - loss: 0.2073 - accuracy: 0.9001 - val_loss: 2.3223 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02899: val_loss did not improve from 0.38514\n",
      "Epoch 2900/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.9014 - val_loss: 2.2737 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02900: val_loss did not improve from 0.38514\n",
      "Epoch 2901/3000\n",
      "13/13 - 0s - loss: 0.2056 - accuracy: 0.9027 - val_loss: 2.3586 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02901: val_loss did not improve from 0.38514\n",
      "Epoch 2902/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.9027 - val_loss: 2.4349 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02902: val_loss did not improve from 0.38514\n",
      "Epoch 2903/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.9014 - val_loss: 2.4373 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02903: val_loss did not improve from 0.38514\n",
      "Epoch 2904/3000\n",
      "13/13 - 0s - loss: 0.2101 - accuracy: 0.9014 - val_loss: 2.3779 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02904: val_loss did not improve from 0.38514\n",
      "Epoch 2905/3000\n",
      "13/13 - 0s - loss: 0.2111 - accuracy: 0.9001 - val_loss: 2.3993 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02905: val_loss did not improve from 0.38514\n",
      "Epoch 2906/3000\n",
      "13/13 - 0s - loss: 0.2076 - accuracy: 0.9040 - val_loss: 2.4347 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02906: val_loss did not improve from 0.38514\n",
      "Epoch 2907/3000\n",
      "13/13 - 0s - loss: 0.2067 - accuracy: 0.9027 - val_loss: 2.4374 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02907: val_loss did not improve from 0.38514\n",
      "Epoch 2908/3000\n",
      "13/13 - 0s - loss: 0.2064 - accuracy: 0.8988 - val_loss: 2.4135 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02908: val_loss did not improve from 0.38514\n",
      "Epoch 2909/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.9014 - val_loss: 2.3824 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02909: val_loss did not improve from 0.38514\n",
      "Epoch 2910/3000\n",
      "13/13 - 0s - loss: 0.2085 - accuracy: 0.8988 - val_loss: 2.4245 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02910: val_loss did not improve from 0.38514\n",
      "Epoch 2911/3000\n",
      "13/13 - 0s - loss: 0.2067 - accuracy: 0.9014 - val_loss: 2.4512 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02911: val_loss did not improve from 0.38514\n",
      "Epoch 2912/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.9027 - val_loss: 2.4584 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02912: val_loss did not improve from 0.38514\n",
      "Epoch 2913/3000\n",
      "13/13 - 0s - loss: 0.2053 - accuracy: 0.9014 - val_loss: 2.4614 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02913: val_loss did not improve from 0.38514\n",
      "Epoch 2914/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9027 - val_loss: 2.4497 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02914: val_loss did not improve from 0.38514\n",
      "Epoch 2915/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9027 - val_loss: 2.4351 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02915: val_loss did not improve from 0.38514\n",
      "Epoch 2916/3000\n",
      "13/13 - 0s - loss: 0.2040 - accuracy: 0.9014 - val_loss: 2.4501 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02916: val_loss did not improve from 0.38514\n",
      "Epoch 2917/3000\n",
      "13/13 - 0s - loss: 0.2033 - accuracy: 0.8988 - val_loss: 2.5345 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02917: val_loss did not improve from 0.38514\n",
      "Epoch 2918/3000\n",
      "13/13 - 0s - loss: 0.2038 - accuracy: 0.9001 - val_loss: 2.5673 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02918: val_loss did not improve from 0.38514\n",
      "Epoch 2919/3000\n",
      "13/13 - 0s - loss: 0.2038 - accuracy: 0.9001 - val_loss: 2.5837 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02919: val_loss did not improve from 0.38514\n",
      "Epoch 2920/3000\n",
      "13/13 - 0s - loss: 0.2040 - accuracy: 0.8988 - val_loss: 2.5630 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02920: val_loss did not improve from 0.38514\n",
      "Epoch 2921/3000\n",
      "13/13 - 0s - loss: 0.2040 - accuracy: 0.8988 - val_loss: 2.5692 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02921: val_loss did not improve from 0.38514\n",
      "Epoch 2922/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.9014 - val_loss: 2.5994 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02922: val_loss did not improve from 0.38514\n",
      "Epoch 2923/3000\n",
      "13/13 - 0s - loss: 0.2101 - accuracy: 0.9014 - val_loss: 2.5485 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02923: val_loss did not improve from 0.38514\n",
      "Epoch 2924/3000\n",
      "13/13 - 0s - loss: 0.2100 - accuracy: 0.9014 - val_loss: 2.4134 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02924: val_loss did not improve from 0.38514\n",
      "Epoch 2925/3000\n",
      "13/13 - 0s - loss: 0.2091 - accuracy: 0.8975 - val_loss: 2.3847 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02925: val_loss did not improve from 0.38514\n",
      "Epoch 2926/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.8988 - val_loss: 2.3807 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02926: val_loss did not improve from 0.38514\n",
      "Epoch 2927/3000\n",
      "13/13 - 0s - loss: 0.2053 - accuracy: 0.8962 - val_loss: 2.3654 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02927: val_loss did not improve from 0.38514\n",
      "Epoch 2928/3000\n",
      "13/13 - 0s - loss: 0.2049 - accuracy: 0.9001 - val_loss: 2.3956 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02928: val_loss did not improve from 0.38514\n",
      "Epoch 2929/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9001 - val_loss: 2.4037 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02929: val_loss did not improve from 0.38514\n",
      "Epoch 2930/3000\n",
      "13/13 - 0s - loss: 0.2034 - accuracy: 0.9001 - val_loss: 2.4276 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02930: val_loss did not improve from 0.38514\n",
      "Epoch 2931/3000\n",
      "13/13 - 0s - loss: 0.2026 - accuracy: 0.9001 - val_loss: 2.4208 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02931: val_loss did not improve from 0.38514\n",
      "Epoch 2932/3000\n",
      "13/13 - 0s - loss: 0.2029 - accuracy: 0.9027 - val_loss: 2.4526 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02932: val_loss did not improve from 0.38514\n",
      "Epoch 2933/3000\n",
      "13/13 - 0s - loss: 0.2021 - accuracy: 0.9027 - val_loss: 2.4759 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02933: val_loss did not improve from 0.38514\n",
      "Epoch 2934/3000\n",
      "13/13 - 0s - loss: 0.2036 - accuracy: 0.9027 - val_loss: 2.5109 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02934: val_loss did not improve from 0.38514\n",
      "Epoch 2935/3000\n",
      "13/13 - 0s - loss: 0.2031 - accuracy: 0.9040 - val_loss: 2.6317 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02935: val_loss did not improve from 0.38514\n",
      "Epoch 2936/3000\n",
      "13/13 - 0s - loss: 0.2109 - accuracy: 0.9014 - val_loss: 2.6386 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02936: val_loss did not improve from 0.38514\n",
      "Epoch 2937/3000\n",
      "13/13 - 0s - loss: 0.2080 - accuracy: 0.9014 - val_loss: 2.7142 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02937: val_loss did not improve from 0.38514\n",
      "Epoch 2938/3000\n",
      "13/13 - 0s - loss: 0.2049 - accuracy: 0.9014 - val_loss: 2.7582 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02938: val_loss did not improve from 0.38514\n",
      "Epoch 2939/3000\n",
      "13/13 - 0s - loss: 0.2150 - accuracy: 0.8975 - val_loss: 2.5793 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02939: val_loss did not improve from 0.38514\n",
      "Epoch 2940/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.9053 - val_loss: 2.4540 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02940: val_loss did not improve from 0.38514\n",
      "Epoch 2941/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.9027 - val_loss: 2.4507 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02941: val_loss did not improve from 0.38514\n",
      "Epoch 2942/3000\n",
      "13/13 - 0s - loss: 0.2044 - accuracy: 0.9027 - val_loss: 2.5694 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02942: val_loss did not improve from 0.38514\n",
      "Epoch 2943/3000\n",
      "13/13 - 0s - loss: 0.2049 - accuracy: 0.9001 - val_loss: 2.6112 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02943: val_loss did not improve from 0.38514\n",
      "Epoch 2944/3000\n",
      "13/13 - 0s - loss: 0.2052 - accuracy: 0.9001 - val_loss: 2.5609 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02944: val_loss did not improve from 0.38514\n",
      "Epoch 2945/3000\n",
      "13/13 - 0s - loss: 0.2029 - accuracy: 0.9040 - val_loss: 2.4694 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02945: val_loss did not improve from 0.38514\n",
      "Epoch 2946/3000\n",
      "13/13 - 0s - loss: 0.2033 - accuracy: 0.9027 - val_loss: 2.5101 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02946: val_loss did not improve from 0.38514\n",
      "Epoch 2947/3000\n",
      "13/13 - 0s - loss: 0.2037 - accuracy: 0.9040 - val_loss: 2.4778 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02947: val_loss did not improve from 0.38514\n",
      "Epoch 2948/3000\n",
      "13/13 - 0s - loss: 0.2036 - accuracy: 0.9027 - val_loss: 2.4481 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02948: val_loss did not improve from 0.38514\n",
      "Epoch 2949/3000\n",
      "13/13 - 0s - loss: 0.2030 - accuracy: 0.9027 - val_loss: 2.4501 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02949: val_loss did not improve from 0.38514\n",
      "Epoch 2950/3000\n",
      "13/13 - 0s - loss: 0.2012 - accuracy: 0.9053 - val_loss: 2.3860 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02950: val_loss did not improve from 0.38514\n",
      "Epoch 2951/3000\n",
      "13/13 - 0s - loss: 0.2067 - accuracy: 0.8936 - val_loss: 2.3708 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02951: val_loss did not improve from 0.38514\n",
      "Epoch 2952/3000\n",
      "13/13 - 0s - loss: 0.2043 - accuracy: 0.9027 - val_loss: 2.3815 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02952: val_loss did not improve from 0.38514\n",
      "Epoch 2953/3000\n",
      "13/13 - 0s - loss: 0.2029 - accuracy: 0.9001 - val_loss: 2.3918 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02953: val_loss did not improve from 0.38514\n",
      "Epoch 2954/3000\n",
      "13/13 - 0s - loss: 0.2032 - accuracy: 0.9027 - val_loss: 2.4021 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02954: val_loss did not improve from 0.38514\n",
      "Epoch 2955/3000\n",
      "13/13 - 0s - loss: 0.2027 - accuracy: 0.9001 - val_loss: 2.4647 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02955: val_loss did not improve from 0.38514\n",
      "Epoch 2956/3000\n",
      "13/13 - 0s - loss: 0.2024 - accuracy: 0.9001 - val_loss: 2.4760 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02956: val_loss did not improve from 0.38514\n",
      "Epoch 2957/3000\n",
      "13/13 - 0s - loss: 0.2031 - accuracy: 0.8988 - val_loss: 2.5032 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02957: val_loss did not improve from 0.38514\n",
      "Epoch 2958/3000\n",
      "13/13 - 0s - loss: 0.2031 - accuracy: 0.9040 - val_loss: 2.4983 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02958: val_loss did not improve from 0.38514\n",
      "Epoch 2959/3000\n",
      "13/13 - 0s - loss: 0.2032 - accuracy: 0.8988 - val_loss: 2.4895 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02959: val_loss did not improve from 0.38514\n",
      "Epoch 2960/3000\n",
      "13/13 - 0s - loss: 0.2025 - accuracy: 0.9014 - val_loss: 2.5325 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02960: val_loss did not improve from 0.38514\n",
      "Epoch 2961/3000\n",
      "13/13 - 0s - loss: 0.2030 - accuracy: 0.8988 - val_loss: 2.5876 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02961: val_loss did not improve from 0.38514\n",
      "Epoch 2962/3000\n",
      "13/13 - 0s - loss: 0.2024 - accuracy: 0.8962 - val_loss: 2.6089 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02962: val_loss did not improve from 0.38514\n",
      "Epoch 2963/3000\n",
      "13/13 - 0s - loss: 0.2021 - accuracy: 0.9001 - val_loss: 2.6211 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02963: val_loss did not improve from 0.38514\n",
      "Epoch 2964/3000\n",
      "13/13 - 0s - loss: 0.2011 - accuracy: 0.9001 - val_loss: 2.6884 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02964: val_loss did not improve from 0.38514\n",
      "Epoch 2965/3000\n",
      "13/13 - 0s - loss: 0.2032 - accuracy: 0.8988 - val_loss: 2.6617 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02965: val_loss did not improve from 0.38514\n",
      "Epoch 2966/3000\n",
      "13/13 - 0s - loss: 0.2024 - accuracy: 0.9014 - val_loss: 2.6386 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02966: val_loss did not improve from 0.38514\n",
      "Epoch 2967/3000\n",
      "13/13 - 0s - loss: 0.2048 - accuracy: 0.8936 - val_loss: 2.6325 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02967: val_loss did not improve from 0.38514\n",
      "Epoch 2968/3000\n",
      "13/13 - 0s - loss: 0.2028 - accuracy: 0.8975 - val_loss: 2.6439 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02968: val_loss did not improve from 0.38514\n",
      "Epoch 2969/3000\n",
      "13/13 - 0s - loss: 0.2028 - accuracy: 0.8962 - val_loss: 2.5608 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02969: val_loss did not improve from 0.38514\n",
      "Epoch 2970/3000\n",
      "13/13 - 0s - loss: 0.2029 - accuracy: 0.8988 - val_loss: 2.5821 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02970: val_loss did not improve from 0.38514\n",
      "Epoch 2971/3000\n",
      "13/13 - 0s - loss: 0.2043 - accuracy: 0.9001 - val_loss: 2.5955 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02971: val_loss did not improve from 0.38514\n",
      "Epoch 2972/3000\n",
      "13/13 - 0s - loss: 0.2030 - accuracy: 0.9014 - val_loss: 2.6480 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02972: val_loss did not improve from 0.38514\n",
      "Epoch 2973/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.9001 - val_loss: 2.6820 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02973: val_loss did not improve from 0.38514\n",
      "Epoch 2974/3000\n",
      "13/13 - 0s - loss: 0.2069 - accuracy: 0.8975 - val_loss: 2.6796 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02974: val_loss did not improve from 0.38514\n",
      "Epoch 2975/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.8962 - val_loss: 2.6341 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02975: val_loss did not improve from 0.38514\n",
      "Epoch 2976/3000\n",
      "13/13 - 0s - loss: 0.2029 - accuracy: 0.8949 - val_loss: 2.5868 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02976: val_loss did not improve from 0.38514\n",
      "Epoch 2977/3000\n",
      "13/13 - 0s - loss: 0.2036 - accuracy: 0.9027 - val_loss: 2.5772 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02977: val_loss did not improve from 0.38514\n",
      "Epoch 2978/3000\n",
      "13/13 - 0s - loss: 0.2061 - accuracy: 0.9014 - val_loss: 2.5802 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02978: val_loss did not improve from 0.38514\n",
      "Epoch 2979/3000\n",
      "13/13 - 0s - loss: 0.2076 - accuracy: 0.8962 - val_loss: 2.6025 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02979: val_loss did not improve from 0.38514\n",
      "Epoch 2980/3000\n",
      "13/13 - 0s - loss: 0.2083 - accuracy: 0.9014 - val_loss: 2.6533 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02980: val_loss did not improve from 0.38514\n",
      "Epoch 2981/3000\n",
      "13/13 - 0s - loss: 0.2066 - accuracy: 0.9014 - val_loss: 2.6210 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02981: val_loss did not improve from 0.38514\n",
      "Epoch 2982/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.9027 - val_loss: 2.6211 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02982: val_loss did not improve from 0.38514\n",
      "Epoch 2983/3000\n",
      "13/13 - 0s - loss: 0.2059 - accuracy: 0.9027 - val_loss: 2.6303 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02983: val_loss did not improve from 0.38514\n",
      "Epoch 2984/3000\n",
      "13/13 - 0s - loss: 0.2058 - accuracy: 0.9027 - val_loss: 2.6120 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02984: val_loss did not improve from 0.38514\n",
      "Epoch 2985/3000\n",
      "13/13 - 0s - loss: 0.2056 - accuracy: 0.9001 - val_loss: 2.5522 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02985: val_loss did not improve from 0.38514\n",
      "Epoch 2986/3000\n",
      "13/13 - 0s - loss: 0.2077 - accuracy: 0.9001 - val_loss: 2.4240 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02986: val_loss did not improve from 0.38514\n",
      "Epoch 2987/3000\n",
      "13/13 - 0s - loss: 0.2093 - accuracy: 0.8988 - val_loss: 2.4495 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02987: val_loss did not improve from 0.38514\n",
      "Epoch 2988/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.9027 - val_loss: 2.4951 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02988: val_loss did not improve from 0.38514\n",
      "Epoch 2989/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.9027 - val_loss: 2.5111 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02989: val_loss did not improve from 0.38514\n",
      "Epoch 2990/3000\n",
      "13/13 - 0s - loss: 0.2052 - accuracy: 0.8988 - val_loss: 2.4840 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02990: val_loss did not improve from 0.38514\n",
      "Epoch 2991/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.9027 - val_loss: 2.4920 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02991: val_loss did not improve from 0.38514\n",
      "Epoch 2992/3000\n",
      "13/13 - 0s - loss: 0.2060 - accuracy: 0.9040 - val_loss: 2.5267 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02992: val_loss did not improve from 0.38514\n",
      "Epoch 2993/3000\n",
      "13/13 - 0s - loss: 0.2052 - accuracy: 0.9027 - val_loss: 2.5176 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02993: val_loss did not improve from 0.38514\n",
      "Epoch 2994/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.9014 - val_loss: 2.4995 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02994: val_loss did not improve from 0.38514\n",
      "Epoch 2995/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.9027 - val_loss: 2.5578 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02995: val_loss did not improve from 0.38514\n",
      "Epoch 2996/3000\n",
      "13/13 - 0s - loss: 0.2056 - accuracy: 0.9027 - val_loss: 2.5445 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02996: val_loss did not improve from 0.38514\n",
      "Epoch 2997/3000\n",
      "13/13 - 0s - loss: 0.2065 - accuracy: 0.8988 - val_loss: 2.5318 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02997: val_loss did not improve from 0.38514\n",
      "Epoch 2998/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.9027 - val_loss: 2.5443 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02998: val_loss did not improve from 0.38514\n",
      "Epoch 2999/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.9027 - val_loss: 2.5452 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02999: val_loss did not improve from 0.38514\n",
      "Epoch 3000/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.9027 - val_loss: 2.4857 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 03000: val_loss did not improve from 0.38514\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                2048      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 14,723\n",
      "Trainable params: 14,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([      \n",
    "      tf.keras.layers.Dense(64, activation='relu'),\n",
    "      tf.keras.layers.Dense(64, activation='relu'),\n",
    "       tf.keras.layers.Dense(64, activation='relu'),\n",
    "      tf.keras.layers.Dense(64, activation='relu'),\n",
    "      tf.keras.layers.Dense(3)\n",
    "    ])\n",
    "learning_rate = 0.005\n",
    "batch_size = 64\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "metrics = ['accuracy']\n",
    "model_filename = 'models/model_4L_v3'\n",
    "model_l_v_e_filename = 'loss_vs_epochs_images/model_4L_v3_le.png'\n",
    "model_l_v_e_title = 'model_4L_v3'\n",
    "model_history_filename = 'history/history_model_4L_v3'\n",
    "\n",
    "model.compile(optimizer, loss_fn, metrics)\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(model_filename, monitor='val_loss', verbose=1,save_best_only=True, mode='min')\n",
    "model.fit(X_train, y_train, epochs = 3000,  validation_data=(X_test, y_test),batch_size = batch_size,callbacks=[checkpoint], verbose=2)\n",
    "model.summary()\n",
    "graph_loss_vs_epochs(model.history, model_l_v_e_filename, model_l_v_e_title)\n",
    "save_history(model_history_filename, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:\n",
      "7/7 [==============================] - 1s 3ms/step - loss: 0.3851 - accuracy: 0.8394\n",
      "\n",
      "Test accuracy: 83.9%, test loss: 0.385139\n"
     ]
    }
   ],
   "source": [
    "best_m4L_v3 = load_model(model_filename)\n",
    "evaluate_model(best_m4L_v3, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241\n"
     ]
    }
   ],
   "source": [
    "test_ds_filename = '../test-ds.csv'\n",
    "output_filename_test_ds_labeled = 'test-ds-m4L_v3.csv'\n",
    "fill_test_ds_labels(model, test_ds_filename, output_filename_test_ds_labeled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: V4\n",
    "#### Model 4 consists in 4 hidden Dense layers:\n",
    "    learning_rate = 0.001\n",
    "    batch_size = 64\n",
    "    loss_fn = CategoricalCrossentropy\n",
    "    optimizer = Adam\n",
    "    Hidden layers:\n",
    "        1. units = 16, activation = relu\n",
    "        2. units = 16, activation = relu\n",
    "        3. units = 16, activation = relu\n",
    "        4. units = 16, activation = relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000\n",
      "13/13 - 3s - loss: 1.0865 - accuracy: 0.3243 - val_loss: 1.0654 - val_accuracy: 0.3316\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.06541, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 2/3000\n",
      "13/13 - 0s - loss: 1.0389 - accuracy: 0.4112 - val_loss: 1.0233 - val_accuracy: 0.3472\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.06541 to 1.02329, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 3/3000\n",
      "13/13 - 0s - loss: 0.9976 - accuracy: 0.4099 - val_loss: 0.9874 - val_accuracy: 0.3420\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02329 to 0.98743, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 4/3000\n",
      "13/13 - 1s - loss: 0.9591 - accuracy: 0.4099 - val_loss: 0.9530 - val_accuracy: 0.3523\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.98743 to 0.95303, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 5/3000\n",
      "13/13 - 1s - loss: 0.9277 - accuracy: 0.4397 - val_loss: 0.9212 - val_accuracy: 0.6010\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.95303 to 0.92123, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 6/3000\n",
      "13/13 - 0s - loss: 0.9025 - accuracy: 0.5850 - val_loss: 0.8981 - val_accuracy: 0.6321\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.92123 to 0.89811, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 7/3000\n",
      "13/13 - 0s - loss: 0.8845 - accuracy: 0.5940 - val_loss: 0.8767 - val_accuracy: 0.6373\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.89811 to 0.87666, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 8/3000\n",
      "13/13 - 0s - loss: 0.8689 - accuracy: 0.6057 - val_loss: 0.8631 - val_accuracy: 0.6321\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.87666 to 0.86308, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 9/3000\n",
      "13/13 - 0s - loss: 0.8532 - accuracy: 0.5992 - val_loss: 0.8469 - val_accuracy: 0.6269\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.86308 to 0.84688, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 10/3000\n",
      "13/13 - 0s - loss: 0.8367 - accuracy: 0.6148 - val_loss: 0.8325 - val_accuracy: 0.6373\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.84688 to 0.83246, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 11/3000\n",
      "13/13 - 0s - loss: 0.8234 - accuracy: 0.6161 - val_loss: 0.8174 - val_accuracy: 0.6373\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.83246 to 0.81737, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 12/3000\n",
      "13/13 - 0s - loss: 0.8089 - accuracy: 0.6265 - val_loss: 0.8018 - val_accuracy: 0.6373\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.81737 to 0.80175, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 13/3000\n",
      "13/13 - 0s - loss: 0.7956 - accuracy: 0.6304 - val_loss: 0.7864 - val_accuracy: 0.6373\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.80175 to 0.78640, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 14/3000\n",
      "13/13 - 0s - loss: 0.7863 - accuracy: 0.6381 - val_loss: 0.7784 - val_accuracy: 0.6477\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.78640 to 0.77837, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 15/3000\n",
      "13/13 - 0s - loss: 0.7710 - accuracy: 0.6511 - val_loss: 0.7602 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.77837 to 0.76020, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 16/3000\n",
      "13/13 - 0s - loss: 0.7595 - accuracy: 0.6524 - val_loss: 0.7462 - val_accuracy: 0.6684\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.76020 to 0.74622, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 17/3000\n",
      "13/13 - 0s - loss: 0.7510 - accuracy: 0.6848 - val_loss: 0.7422 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.74622 to 0.74223, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 18/3000\n",
      "13/13 - 0s - loss: 0.7407 - accuracy: 0.6719 - val_loss: 0.7253 - val_accuracy: 0.6891\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.74223 to 0.72525, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 19/3000\n",
      "13/13 - 0s - loss: 0.7298 - accuracy: 0.6796 - val_loss: 0.7189 - val_accuracy: 0.6943\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.72525 to 0.71888, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 20/3000\n",
      "13/13 - 0s - loss: 0.7200 - accuracy: 0.6757 - val_loss: 0.7161 - val_accuracy: 0.6839\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.71888 to 0.71609, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 21/3000\n",
      "13/13 - 0s - loss: 0.7101 - accuracy: 0.6822 - val_loss: 0.7066 - val_accuracy: 0.7098\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.71609 to 0.70664, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 22/3000\n",
      "13/13 - 0s - loss: 0.6987 - accuracy: 0.6926 - val_loss: 0.6941 - val_accuracy: 0.7202\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.70664 to 0.69410, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 23/3000\n",
      "13/13 - 0s - loss: 0.6910 - accuracy: 0.7017 - val_loss: 0.6902 - val_accuracy: 0.7202\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.69410 to 0.69023, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 24/3000\n",
      "13/13 - 0s - loss: 0.6846 - accuracy: 0.7069 - val_loss: 0.6833 - val_accuracy: 0.7254\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.69023 to 0.68329, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 25/3000\n",
      "13/13 - 0s - loss: 0.6783 - accuracy: 0.6978 - val_loss: 0.6778 - val_accuracy: 0.7098\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.68329 to 0.67778, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 26/3000\n",
      "13/13 - 0s - loss: 0.6706 - accuracy: 0.7224 - val_loss: 0.6763 - val_accuracy: 0.7098\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.67778 to 0.67629, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 27/3000\n",
      "13/13 - 0s - loss: 0.6630 - accuracy: 0.7198 - val_loss: 0.6667 - val_accuracy: 0.7202\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.67629 to 0.66671, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 28/3000\n",
      "13/13 - 0s - loss: 0.6551 - accuracy: 0.7250 - val_loss: 0.6615 - val_accuracy: 0.7202\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.66671 to 0.66154, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 29/3000\n",
      "13/13 - 0s - loss: 0.6499 - accuracy: 0.7224 - val_loss: 0.6614 - val_accuracy: 0.7150\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.66154 to 0.66143, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 30/3000\n",
      "13/13 - 0s - loss: 0.6435 - accuracy: 0.7237 - val_loss: 0.6608 - val_accuracy: 0.7254\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.66143 to 0.66075, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 31/3000\n",
      "13/13 - 0s - loss: 0.6360 - accuracy: 0.7315 - val_loss: 0.6611 - val_accuracy: 0.7254\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.66075\n",
      "Epoch 32/3000\n",
      "13/13 - 0s - loss: 0.6318 - accuracy: 0.7432 - val_loss: 0.6591 - val_accuracy: 0.7202\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.66075 to 0.65914, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 33/3000\n",
      "13/13 - 0s - loss: 0.6390 - accuracy: 0.7134 - val_loss: 0.6437 - val_accuracy: 0.7358\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.65914 to 0.64375, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 34/3000\n",
      "13/13 - 0s - loss: 0.6269 - accuracy: 0.7393 - val_loss: 0.6497 - val_accuracy: 0.7409\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.64375\n",
      "Epoch 35/3000\n",
      "13/13 - 0s - loss: 0.6270 - accuracy: 0.7432 - val_loss: 0.6500 - val_accuracy: 0.7202\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.64375\n",
      "Epoch 36/3000\n",
      "13/13 - 0s - loss: 0.6204 - accuracy: 0.7367 - val_loss: 0.6556 - val_accuracy: 0.7254\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.64375\n",
      "Epoch 37/3000\n",
      "13/13 - 0s - loss: 0.6090 - accuracy: 0.7432 - val_loss: 0.6491 - val_accuracy: 0.7409\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.64375\n",
      "Epoch 38/3000\n",
      "13/13 - 0s - loss: 0.5997 - accuracy: 0.7497 - val_loss: 0.6482 - val_accuracy: 0.7358\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.64375\n",
      "Epoch 39/3000\n",
      "13/13 - 0s - loss: 0.5961 - accuracy: 0.7601 - val_loss: 0.6495 - val_accuracy: 0.7306\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.64375\n",
      "Epoch 40/3000\n",
      "13/13 - 0s - loss: 0.5897 - accuracy: 0.7639 - val_loss: 0.6481 - val_accuracy: 0.7306\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.64375\n",
      "Epoch 41/3000\n",
      "13/13 - 0s - loss: 0.5831 - accuracy: 0.7562 - val_loss: 0.6548 - val_accuracy: 0.7409\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.64375\n",
      "Epoch 42/3000\n",
      "13/13 - 0s - loss: 0.5905 - accuracy: 0.7549 - val_loss: 0.6405 - val_accuracy: 0.7306\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.64375 to 0.64053, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 43/3000\n",
      "13/13 - 0s - loss: 0.5802 - accuracy: 0.7588 - val_loss: 0.6469 - val_accuracy: 0.7306\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.64053\n",
      "Epoch 44/3000\n",
      "13/13 - 0s - loss: 0.5674 - accuracy: 0.7704 - val_loss: 0.6407 - val_accuracy: 0.7409\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.64053\n",
      "Epoch 45/3000\n",
      "13/13 - 0s - loss: 0.5709 - accuracy: 0.7626 - val_loss: 0.6383 - val_accuracy: 0.7461\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.64053 to 0.63832, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 46/3000\n",
      "13/13 - 0s - loss: 0.5553 - accuracy: 0.7704 - val_loss: 0.6308 - val_accuracy: 0.7513\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.63832 to 0.63079, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 47/3000\n",
      "13/13 - 0s - loss: 0.5530 - accuracy: 0.7821 - val_loss: 0.6283 - val_accuracy: 0.7513\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.63079 to 0.62831, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 48/3000\n",
      "13/13 - 0s - loss: 0.5491 - accuracy: 0.7834 - val_loss: 0.6327 - val_accuracy: 0.7254\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.62831\n",
      "Epoch 49/3000\n",
      "13/13 - 0s - loss: 0.5512 - accuracy: 0.7821 - val_loss: 0.6336 - val_accuracy: 0.7306\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.62831\n",
      "Epoch 50/3000\n",
      "13/13 - 0s - loss: 0.5413 - accuracy: 0.7912 - val_loss: 0.6368 - val_accuracy: 0.7461\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.62831\n",
      "Epoch 51/3000\n",
      "13/13 - 0s - loss: 0.5505 - accuracy: 0.7652 - val_loss: 0.6522 - val_accuracy: 0.7254\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.62831\n",
      "Epoch 52/3000\n",
      "13/13 - 0s - loss: 0.5334 - accuracy: 0.7899 - val_loss: 0.6224 - val_accuracy: 0.7461\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.62831 to 0.62239, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 53/3000\n",
      "13/13 - 0s - loss: 0.5208 - accuracy: 0.7938 - val_loss: 0.6204 - val_accuracy: 0.7461\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.62239 to 0.62037, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 54/3000\n",
      "13/13 - 0s - loss: 0.5375 - accuracy: 0.7704 - val_loss: 0.6292 - val_accuracy: 0.7409\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.62037\n",
      "Epoch 55/3000\n",
      "13/13 - 0s - loss: 0.5172 - accuracy: 0.7938 - val_loss: 0.6195 - val_accuracy: 0.7358\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.62037 to 0.61947, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 56/3000\n",
      "13/13 - 0s - loss: 0.5158 - accuracy: 0.7912 - val_loss: 0.6279 - val_accuracy: 0.7617\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.61947\n",
      "Epoch 57/3000\n",
      "13/13 - 0s - loss: 0.5069 - accuracy: 0.8042 - val_loss: 0.6181 - val_accuracy: 0.7513\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.61947 to 0.61810, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 58/3000\n",
      "13/13 - 0s - loss: 0.5004 - accuracy: 0.7938 - val_loss: 0.6160 - val_accuracy: 0.7409\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.61810 to 0.61599, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 59/3000\n",
      "13/13 - 0s - loss: 0.5063 - accuracy: 0.7977 - val_loss: 0.6066 - val_accuracy: 0.7617\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.61599 to 0.60660, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 60/3000\n",
      "13/13 - 0s - loss: 0.5406 - accuracy: 0.7665 - val_loss: 0.6168 - val_accuracy: 0.7409\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.60660\n",
      "Epoch 61/3000\n",
      "13/13 - 0s - loss: 0.5108 - accuracy: 0.7834 - val_loss: 0.6096 - val_accuracy: 0.7513\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.60660\n",
      "Epoch 62/3000\n",
      "13/13 - 0s - loss: 0.4882 - accuracy: 0.7899 - val_loss: 0.6018 - val_accuracy: 0.7565\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.60660 to 0.60175, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 63/3000\n",
      "13/13 - 0s - loss: 0.4879 - accuracy: 0.7990 - val_loss: 0.6149 - val_accuracy: 0.7513\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.60175\n",
      "Epoch 64/3000\n",
      "13/13 - 0s - loss: 0.4754 - accuracy: 0.8054 - val_loss: 0.6058 - val_accuracy: 0.7513\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.60175\n",
      "Epoch 65/3000\n",
      "13/13 - 0s - loss: 0.4864 - accuracy: 0.8054 - val_loss: 0.6158 - val_accuracy: 0.7565\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.60175\n",
      "Epoch 66/3000\n",
      "13/13 - 0s - loss: 0.4762 - accuracy: 0.8132 - val_loss: 0.6127 - val_accuracy: 0.7358\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.60175\n",
      "Epoch 67/3000\n",
      "13/13 - 0s - loss: 0.4676 - accuracy: 0.8119 - val_loss: 0.6108 - val_accuracy: 0.7513\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.60175\n",
      "Epoch 68/3000\n",
      "13/13 - 0s - loss: 0.4620 - accuracy: 0.8106 - val_loss: 0.6056 - val_accuracy: 0.7565\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.60175\n",
      "Epoch 69/3000\n",
      "13/13 - 0s - loss: 0.4612 - accuracy: 0.8210 - val_loss: 0.5997 - val_accuracy: 0.7668\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.60175 to 0.59966, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 70/3000\n",
      "13/13 - 0s - loss: 0.4549 - accuracy: 0.8132 - val_loss: 0.5950 - val_accuracy: 0.7668\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.59966 to 0.59496, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 71/3000\n",
      "13/13 - 0s - loss: 0.4716 - accuracy: 0.7977 - val_loss: 0.5931 - val_accuracy: 0.7617\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.59496 to 0.59311, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 72/3000\n",
      "13/13 - 0s - loss: 0.4554 - accuracy: 0.8171 - val_loss: 0.5984 - val_accuracy: 0.7617\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.59311\n",
      "Epoch 73/3000\n",
      "13/13 - 0s - loss: 0.4451 - accuracy: 0.8236 - val_loss: 0.5897 - val_accuracy: 0.7772\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.59311 to 0.58971, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 74/3000\n",
      "13/13 - 0s - loss: 0.4584 - accuracy: 0.8016 - val_loss: 0.5584 - val_accuracy: 0.7772\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.58971 to 0.55835, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 75/3000\n",
      "13/13 - 0s - loss: 0.4484 - accuracy: 0.8236 - val_loss: 0.5735 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.55835\n",
      "Epoch 76/3000\n",
      "13/13 - 0s - loss: 0.4476 - accuracy: 0.8314 - val_loss: 0.5842 - val_accuracy: 0.7565\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.55835\n",
      "Epoch 77/3000\n",
      "13/13 - 0s - loss: 0.4536 - accuracy: 0.8132 - val_loss: 0.5710 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.55835\n",
      "Epoch 78/3000\n",
      "13/13 - 0s - loss: 0.4433 - accuracy: 0.8275 - val_loss: 0.5673 - val_accuracy: 0.7772\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.55835\n",
      "Epoch 79/3000\n",
      "13/13 - 0s - loss: 0.4345 - accuracy: 0.8275 - val_loss: 0.5778 - val_accuracy: 0.7617\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.55835\n",
      "Epoch 80/3000\n",
      "13/13 - 0s - loss: 0.4268 - accuracy: 0.8119 - val_loss: 0.5739 - val_accuracy: 0.7617\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.55835\n",
      "Epoch 81/3000\n",
      "13/13 - 0s - loss: 0.4231 - accuracy: 0.8223 - val_loss: 0.5711 - val_accuracy: 0.7565\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.55835\n",
      "Epoch 82/3000\n",
      "13/13 - 0s - loss: 0.4288 - accuracy: 0.8067 - val_loss: 0.5754 - val_accuracy: 0.7617\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.55835\n",
      "Epoch 83/3000\n",
      "13/13 - 0s - loss: 0.4263 - accuracy: 0.8184 - val_loss: 0.5670 - val_accuracy: 0.7668\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.55835\n",
      "Epoch 84/3000\n",
      "13/13 - 0s - loss: 0.4159 - accuracy: 0.8145 - val_loss: 0.5512 - val_accuracy: 0.7565\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.55835 to 0.55123, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 85/3000\n",
      "13/13 - 0s - loss: 0.4186 - accuracy: 0.8171 - val_loss: 0.5784 - val_accuracy: 0.7565\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.55123\n",
      "Epoch 86/3000\n",
      "13/13 - 0s - loss: 0.4120 - accuracy: 0.8210 - val_loss: 0.5838 - val_accuracy: 0.7668\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.55123\n",
      "Epoch 87/3000\n",
      "13/13 - 0s - loss: 0.4377 - accuracy: 0.8236 - val_loss: 0.5772 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.55123\n",
      "Epoch 88/3000\n",
      "13/13 - 0s - loss: 0.4067 - accuracy: 0.8327 - val_loss: 0.5854 - val_accuracy: 0.7668\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.55123\n",
      "Epoch 89/3000\n",
      "13/13 - 0s - loss: 0.4008 - accuracy: 0.8340 - val_loss: 0.5726 - val_accuracy: 0.7513\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.55123\n",
      "Epoch 90/3000\n",
      "13/13 - 0s - loss: 0.4081 - accuracy: 0.8288 - val_loss: 0.5833 - val_accuracy: 0.7617\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.55123\n",
      "Epoch 91/3000\n",
      "13/13 - 0s - loss: 0.3972 - accuracy: 0.8340 - val_loss: 0.5642 - val_accuracy: 0.7617\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.55123\n",
      "Epoch 92/3000\n",
      "13/13 - 0s - loss: 0.3938 - accuracy: 0.8249 - val_loss: 0.5591 - val_accuracy: 0.7617\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.55123\n",
      "Epoch 93/3000\n",
      "13/13 - 0s - loss: 0.3894 - accuracy: 0.8353 - val_loss: 0.5661 - val_accuracy: 0.7617\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.55123\n",
      "Epoch 94/3000\n",
      "13/13 - 0s - loss: 0.3908 - accuracy: 0.8379 - val_loss: 0.5568 - val_accuracy: 0.7617\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.55123\n",
      "Epoch 95/3000\n",
      "13/13 - 0s - loss: 0.3852 - accuracy: 0.8405 - val_loss: 0.5612 - val_accuracy: 0.7617\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.55123\n",
      "Epoch 96/3000\n",
      "13/13 - 0s - loss: 0.3813 - accuracy: 0.8392 - val_loss: 0.5620 - val_accuracy: 0.7668\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.55123\n",
      "Epoch 97/3000\n",
      "13/13 - 0s - loss: 0.3809 - accuracy: 0.8444 - val_loss: 0.5604 - val_accuracy: 0.7668\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.55123\n",
      "Epoch 98/3000\n",
      "13/13 - 0s - loss: 0.3748 - accuracy: 0.8495 - val_loss: 0.5522 - val_accuracy: 0.7617\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.55123\n",
      "Epoch 99/3000\n",
      "13/13 - 0s - loss: 0.3758 - accuracy: 0.8547 - val_loss: 0.5473 - val_accuracy: 0.7668\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.55123 to 0.54732, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 100/3000\n",
      "13/13 - 0s - loss: 0.3834 - accuracy: 0.8275 - val_loss: 0.5531 - val_accuracy: 0.7772\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.54732\n",
      "Epoch 101/3000\n",
      "13/13 - 0s - loss: 0.3782 - accuracy: 0.8340 - val_loss: 0.5570 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.54732\n",
      "Epoch 102/3000\n",
      "13/13 - 0s - loss: 0.3829 - accuracy: 0.8392 - val_loss: 0.5501 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.54732\n",
      "Epoch 103/3000\n",
      "13/13 - 0s - loss: 0.3743 - accuracy: 0.8288 - val_loss: 0.5629 - val_accuracy: 0.7772\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.54732\n",
      "Epoch 104/3000\n",
      "13/13 - 0s - loss: 0.3655 - accuracy: 0.8431 - val_loss: 0.5498 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.54732\n",
      "Epoch 105/3000\n",
      "13/13 - 0s - loss: 0.3633 - accuracy: 0.8444 - val_loss: 0.5561 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.54732\n",
      "Epoch 106/3000\n",
      "13/13 - 0s - loss: 0.3599 - accuracy: 0.8444 - val_loss: 0.5435 - val_accuracy: 0.7565\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.54732 to 0.54347, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 107/3000\n",
      "13/13 - 0s - loss: 0.3887 - accuracy: 0.8431 - val_loss: 0.5687 - val_accuracy: 0.7565\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.54347\n",
      "Epoch 108/3000\n",
      "13/13 - 0s - loss: 0.3573 - accuracy: 0.8495 - val_loss: 0.5500 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.54347\n",
      "Epoch 109/3000\n",
      "13/13 - 0s - loss: 0.3782 - accuracy: 0.8431 - val_loss: 0.5405 - val_accuracy: 0.7668\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.54347 to 0.54055, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 110/3000\n",
      "13/13 - 0s - loss: 0.3708 - accuracy: 0.8470 - val_loss: 0.5891 - val_accuracy: 0.7617\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.54055\n",
      "Epoch 111/3000\n",
      "13/13 - 0s - loss: 0.3794 - accuracy: 0.8327 - val_loss: 0.5811 - val_accuracy: 0.7772\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.54055\n",
      "Epoch 112/3000\n",
      "13/13 - 0s - loss: 0.3598 - accuracy: 0.8482 - val_loss: 0.5412 - val_accuracy: 0.7772\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.54055\n",
      "Epoch 113/3000\n",
      "13/13 - 0s - loss: 0.3595 - accuracy: 0.8534 - val_loss: 0.5390 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.54055 to 0.53900, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 114/3000\n",
      "13/13 - 0s - loss: 0.3555 - accuracy: 0.8664 - val_loss: 0.5286 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.53900 to 0.52856, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 115/3000\n",
      "13/13 - 0s - loss: 0.3489 - accuracy: 0.8547 - val_loss: 0.5362 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.52856\n",
      "Epoch 116/3000\n",
      "13/13 - 0s - loss: 0.3469 - accuracy: 0.8534 - val_loss: 0.5178 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.52856 to 0.51779, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 117/3000\n",
      "13/13 - 0s - loss: 0.3440 - accuracy: 0.8547 - val_loss: 0.5085 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.51779 to 0.50847, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 118/3000\n",
      "13/13 - 0s - loss: 0.3537 - accuracy: 0.8508 - val_loss: 0.4943 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.50847 to 0.49427, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 119/3000\n",
      "13/13 - 0s - loss: 0.3479 - accuracy: 0.8651 - val_loss: 0.4913 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.49427 to 0.49133, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 120/3000\n",
      "13/13 - 0s - loss: 0.3348 - accuracy: 0.8586 - val_loss: 0.5033 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.49133\n",
      "Epoch 121/3000\n",
      "13/13 - 0s - loss: 0.3352 - accuracy: 0.8586 - val_loss: 0.5143 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.49133\n",
      "Epoch 122/3000\n",
      "13/13 - 0s - loss: 0.3321 - accuracy: 0.8703 - val_loss: 0.5022 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.49133\n",
      "Epoch 123/3000\n",
      "13/13 - 0s - loss: 0.3310 - accuracy: 0.8638 - val_loss: 0.5062 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.49133\n",
      "Epoch 124/3000\n",
      "13/13 - 0s - loss: 0.3293 - accuracy: 0.8729 - val_loss: 0.5105 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.49133\n",
      "Epoch 125/3000\n",
      "13/13 - 0s - loss: 0.3340 - accuracy: 0.8625 - val_loss: 0.5010 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.49133\n",
      "Epoch 126/3000\n",
      "13/13 - 0s - loss: 0.3706 - accuracy: 0.8379 - val_loss: 0.5231 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.49133\n",
      "Epoch 127/3000\n",
      "13/13 - 0s - loss: 0.3323 - accuracy: 0.8729 - val_loss: 0.5092 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.49133\n",
      "Epoch 128/3000\n",
      "13/13 - 0s - loss: 0.3329 - accuracy: 0.8729 - val_loss: 0.5078 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.49133\n",
      "Epoch 129/3000\n",
      "13/13 - 0s - loss: 0.3206 - accuracy: 0.8768 - val_loss: 0.4940 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.49133\n",
      "Epoch 130/3000\n",
      "13/13 - 0s - loss: 0.3210 - accuracy: 0.8768 - val_loss: 0.4968 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.49133\n",
      "Epoch 131/3000\n",
      "13/13 - 0s - loss: 0.3364 - accuracy: 0.8573 - val_loss: 0.5180 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.49133\n",
      "Epoch 132/3000\n",
      "13/13 - 0s - loss: 0.3173 - accuracy: 0.8664 - val_loss: 0.5030 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.49133\n",
      "Epoch 133/3000\n",
      "13/13 - 0s - loss: 0.3220 - accuracy: 0.8651 - val_loss: 0.5145 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.49133\n",
      "Epoch 134/3000\n",
      "13/13 - 0s - loss: 0.3274 - accuracy: 0.8560 - val_loss: 0.5192 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.49133\n",
      "Epoch 135/3000\n",
      "13/13 - 0s - loss: 0.3560 - accuracy: 0.8612 - val_loss: 0.5237 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.49133\n",
      "Epoch 136/3000\n",
      "13/13 - 0s - loss: 0.3308 - accuracy: 0.8742 - val_loss: 0.5290 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.49133\n",
      "Epoch 137/3000\n",
      "13/13 - 0s - loss: 0.3238 - accuracy: 0.8625 - val_loss: 0.4952 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.49133\n",
      "Epoch 138/3000\n",
      "13/13 - 0s - loss: 0.3410 - accuracy: 0.8677 - val_loss: 0.5043 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.49133\n",
      "Epoch 139/3000\n",
      "13/13 - 0s - loss: 0.3452 - accuracy: 0.8534 - val_loss: 0.5169 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.49133\n",
      "Epoch 140/3000\n",
      "13/13 - 0s - loss: 0.3278 - accuracy: 0.8625 - val_loss: 0.5153 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.49133\n",
      "Epoch 141/3000\n",
      "13/13 - 0s - loss: 0.3273 - accuracy: 0.8651 - val_loss: 0.5052 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.49133\n",
      "Epoch 142/3000\n",
      "13/13 - 0s - loss: 0.3120 - accuracy: 0.8651 - val_loss: 0.4934 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.49133\n",
      "Epoch 143/3000\n",
      "13/13 - 0s - loss: 0.3217 - accuracy: 0.8703 - val_loss: 0.4902 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.49133 to 0.49025, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 144/3000\n",
      "13/13 - 0s - loss: 0.3207 - accuracy: 0.8716 - val_loss: 0.5172 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.49025\n",
      "Epoch 145/3000\n",
      "13/13 - 0s - loss: 0.3188 - accuracy: 0.8703 - val_loss: 0.5010 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.49025\n",
      "Epoch 146/3000\n",
      "13/13 - 0s - loss: 0.3134 - accuracy: 0.8638 - val_loss: 0.5322 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.49025\n",
      "Epoch 147/3000\n",
      "13/13 - 0s - loss: 0.3203 - accuracy: 0.8690 - val_loss: 0.5177 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.49025\n",
      "Epoch 148/3000\n",
      "13/13 - 0s - loss: 0.3197 - accuracy: 0.8690 - val_loss: 0.5128 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.49025\n",
      "Epoch 149/3000\n",
      "13/13 - 0s - loss: 0.3068 - accuracy: 0.8677 - val_loss: 0.4992 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.49025\n",
      "Epoch 150/3000\n",
      "13/13 - 0s - loss: 0.3054 - accuracy: 0.8768 - val_loss: 0.5139 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.49025\n",
      "Epoch 151/3000\n",
      "13/13 - 0s - loss: 0.3033 - accuracy: 0.8781 - val_loss: 0.4965 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.49025\n",
      "Epoch 152/3000\n",
      "13/13 - 0s - loss: 0.2985 - accuracy: 0.8729 - val_loss: 0.4883 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.49025 to 0.48833, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 153/3000\n",
      "13/13 - 0s - loss: 0.2977 - accuracy: 0.8833 - val_loss: 0.5049 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.48833\n",
      "Epoch 154/3000\n",
      "13/13 - 0s - loss: 0.3437 - accuracy: 0.8677 - val_loss: 0.5037 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.48833\n",
      "Epoch 155/3000\n",
      "13/13 - 0s - loss: 0.3182 - accuracy: 0.8794 - val_loss: 0.5212 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.48833\n",
      "Epoch 156/3000\n",
      "13/13 - 0s - loss: 0.3045 - accuracy: 0.8859 - val_loss: 0.4912 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.48833\n",
      "Epoch 157/3000\n",
      "13/13 - 0s - loss: 0.3088 - accuracy: 0.8755 - val_loss: 0.5091 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.48833\n",
      "Epoch 158/3000\n",
      "13/13 - 0s - loss: 0.3053 - accuracy: 0.8781 - val_loss: 0.4904 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.48833\n",
      "Epoch 159/3000\n",
      "13/13 - 0s - loss: 0.2976 - accuracy: 0.8872 - val_loss: 0.5095 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.48833\n",
      "Epoch 160/3000\n",
      "13/13 - 0s - loss: 0.3207 - accuracy: 0.8846 - val_loss: 0.5101 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.48833\n",
      "Epoch 161/3000\n",
      "13/13 - 0s - loss: 0.3075 - accuracy: 0.8807 - val_loss: 0.4850 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.48833 to 0.48498, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 162/3000\n",
      "13/13 - 0s - loss: 0.2938 - accuracy: 0.8872 - val_loss: 0.4794 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.48498 to 0.47944, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 163/3000\n",
      "13/13 - 0s - loss: 0.2913 - accuracy: 0.8846 - val_loss: 0.4926 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.47944\n",
      "Epoch 164/3000\n",
      "13/13 - 0s - loss: 0.2960 - accuracy: 0.8794 - val_loss: 0.4894 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.47944\n",
      "Epoch 165/3000\n",
      "13/13 - 0s - loss: 0.2897 - accuracy: 0.8846 - val_loss: 0.4958 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.47944\n",
      "Epoch 166/3000\n",
      "13/13 - 0s - loss: 0.2900 - accuracy: 0.8859 - val_loss: 0.4897 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.47944\n",
      "Epoch 167/3000\n",
      "13/13 - 0s - loss: 0.2860 - accuracy: 0.8872 - val_loss: 0.4965 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.47944\n",
      "Epoch 168/3000\n",
      "13/13 - 0s - loss: 0.3236 - accuracy: 0.8599 - val_loss: 0.5252 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.47944\n",
      "Epoch 169/3000\n",
      "13/13 - 0s - loss: 0.3055 - accuracy: 0.8794 - val_loss: 0.4960 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.47944\n",
      "Epoch 170/3000\n",
      "13/13 - 0s - loss: 0.2971 - accuracy: 0.8833 - val_loss: 0.4893 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.47944\n",
      "Epoch 171/3000\n",
      "13/13 - 0s - loss: 0.2945 - accuracy: 0.8820 - val_loss: 0.4962 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.47944\n",
      "Epoch 172/3000\n",
      "13/13 - 0s - loss: 0.2884 - accuracy: 0.8833 - val_loss: 0.4971 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.47944\n",
      "Epoch 173/3000\n",
      "13/13 - 0s - loss: 0.2862 - accuracy: 0.8923 - val_loss: 0.4945 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.47944\n",
      "Epoch 174/3000\n",
      "13/13 - 0s - loss: 0.2886 - accuracy: 0.8859 - val_loss: 0.4938 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.47944\n",
      "Epoch 175/3000\n",
      "13/13 - 0s - loss: 0.2817 - accuracy: 0.8949 - val_loss: 0.4882 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.47944\n",
      "Epoch 176/3000\n",
      "13/13 - 0s - loss: 0.2853 - accuracy: 0.8781 - val_loss: 0.4910 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.47944\n",
      "Epoch 177/3000\n",
      "13/13 - 0s - loss: 0.2841 - accuracy: 0.8911 - val_loss: 0.4907 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.47944\n",
      "Epoch 178/3000\n",
      "13/13 - 0s - loss: 0.2805 - accuracy: 0.8962 - val_loss: 0.5040 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.47944\n",
      "Epoch 179/3000\n",
      "13/13 - 0s - loss: 0.2816 - accuracy: 0.8923 - val_loss: 0.4924 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.47944\n",
      "Epoch 180/3000\n",
      "13/13 - 0s - loss: 0.2777 - accuracy: 0.8872 - val_loss: 0.4846 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.47944\n",
      "Epoch 181/3000\n",
      "13/13 - 0s - loss: 0.2830 - accuracy: 0.8820 - val_loss: 0.5005 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.47944\n",
      "Epoch 182/3000\n",
      "13/13 - 0s - loss: 0.2802 - accuracy: 0.8898 - val_loss: 0.4876 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.47944\n",
      "Epoch 183/3000\n",
      "13/13 - 0s - loss: 0.2881 - accuracy: 0.8872 - val_loss: 0.5134 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.47944\n",
      "Epoch 184/3000\n",
      "13/13 - 0s - loss: 0.2976 - accuracy: 0.8768 - val_loss: 0.5544 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.47944\n",
      "Epoch 185/3000\n",
      "13/13 - 0s - loss: 0.2908 - accuracy: 0.8911 - val_loss: 0.4963 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.47944\n",
      "Epoch 186/3000\n",
      "13/13 - 0s - loss: 0.2788 - accuracy: 0.8911 - val_loss: 0.4997 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.47944\n",
      "Epoch 187/3000\n",
      "13/13 - 0s - loss: 0.2768 - accuracy: 0.8923 - val_loss: 0.4853 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.47944\n",
      "Epoch 188/3000\n",
      "13/13 - 0s - loss: 0.2795 - accuracy: 0.8872 - val_loss: 0.4921 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.47944\n",
      "Epoch 189/3000\n",
      "13/13 - 0s - loss: 0.2751 - accuracy: 0.8936 - val_loss: 0.4916 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.47944\n",
      "Epoch 190/3000\n",
      "13/13 - 0s - loss: 0.2782 - accuracy: 0.8923 - val_loss: 0.4843 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.47944\n",
      "Epoch 191/3000\n",
      "13/13 - 0s - loss: 0.2829 - accuracy: 0.8872 - val_loss: 0.4815 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.47944\n",
      "Epoch 192/3000\n",
      "13/13 - 0s - loss: 0.2917 - accuracy: 0.8885 - val_loss: 0.4916 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.47944\n",
      "Epoch 193/3000\n",
      "13/13 - 0s - loss: 0.2806 - accuracy: 0.8911 - val_loss: 0.4811 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.47944\n",
      "Epoch 194/3000\n",
      "13/13 - 0s - loss: 0.2756 - accuracy: 0.8949 - val_loss: 0.4865 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.47944\n",
      "Epoch 195/3000\n",
      "13/13 - 0s - loss: 0.2744 - accuracy: 0.8936 - val_loss: 0.4880 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.47944\n",
      "Epoch 196/3000\n",
      "13/13 - 0s - loss: 0.2719 - accuracy: 0.8885 - val_loss: 0.4966 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.47944\n",
      "Epoch 197/3000\n",
      "13/13 - 0s - loss: 0.2705 - accuracy: 0.8833 - val_loss: 0.4869 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.47944\n",
      "Epoch 198/3000\n",
      "13/13 - 0s - loss: 0.2766 - accuracy: 0.8833 - val_loss: 0.4944 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.47944\n",
      "Epoch 199/3000\n",
      "13/13 - 0s - loss: 0.2650 - accuracy: 0.8885 - val_loss: 0.4764 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.47944 to 0.47640, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 200/3000\n",
      "13/13 - 0s - loss: 0.2706 - accuracy: 0.8872 - val_loss: 0.4739 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00200: val_loss improved from 0.47640 to 0.47392, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 201/3000\n",
      "13/13 - 0s - loss: 0.2718 - accuracy: 0.8898 - val_loss: 0.5149 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.47392\n",
      "Epoch 202/3000\n",
      "13/13 - 0s - loss: 0.2681 - accuracy: 0.8949 - val_loss: 0.4892 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.47392\n",
      "Epoch 203/3000\n",
      "13/13 - 0s - loss: 0.2673 - accuracy: 0.8898 - val_loss: 0.4907 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.47392\n",
      "Epoch 204/3000\n",
      "13/13 - 0s - loss: 0.2678 - accuracy: 0.8885 - val_loss: 0.4889 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.47392\n",
      "Epoch 205/3000\n",
      "13/13 - 0s - loss: 0.2714 - accuracy: 0.8885 - val_loss: 0.5121 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.47392\n",
      "Epoch 206/3000\n",
      "13/13 - 0s - loss: 0.2721 - accuracy: 0.8885 - val_loss: 0.4804 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.47392\n",
      "Epoch 207/3000\n",
      "13/13 - 0s - loss: 0.2751 - accuracy: 0.8807 - val_loss: 0.5428 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.47392\n",
      "Epoch 208/3000\n",
      "13/13 - 0s - loss: 0.3226 - accuracy: 0.8573 - val_loss: 0.4905 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.47392\n",
      "Epoch 209/3000\n",
      "13/13 - 0s - loss: 0.2969 - accuracy: 0.8729 - val_loss: 0.5035 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.47392\n",
      "Epoch 210/3000\n",
      "13/13 - 0s - loss: 0.2663 - accuracy: 0.8988 - val_loss: 0.4771 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.47392\n",
      "Epoch 211/3000\n",
      "13/13 - 0s - loss: 0.2649 - accuracy: 0.8962 - val_loss: 0.4997 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.47392\n",
      "Epoch 212/3000\n",
      "13/13 - 0s - loss: 0.2621 - accuracy: 0.8859 - val_loss: 0.4813 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.47392\n",
      "Epoch 213/3000\n",
      "13/13 - 0s - loss: 0.2757 - accuracy: 0.8859 - val_loss: 0.5194 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.47392\n",
      "Epoch 214/3000\n",
      "13/13 - 0s - loss: 0.2724 - accuracy: 0.8768 - val_loss: 0.4812 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.47392\n",
      "Epoch 215/3000\n",
      "13/13 - 0s - loss: 0.2739 - accuracy: 0.8781 - val_loss: 0.4745 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.47392\n",
      "Epoch 216/3000\n",
      "13/13 - 0s - loss: 0.2637 - accuracy: 0.8911 - val_loss: 0.4958 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.47392\n",
      "Epoch 217/3000\n",
      "13/13 - 0s - loss: 0.2638 - accuracy: 0.8923 - val_loss: 0.4939 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.47392\n",
      "Epoch 218/3000\n",
      "13/13 - 0s - loss: 0.2601 - accuracy: 0.8988 - val_loss: 0.4786 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.47392\n",
      "Epoch 219/3000\n",
      "13/13 - 0s - loss: 0.2566 - accuracy: 0.8911 - val_loss: 0.4733 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00219: val_loss improved from 0.47392 to 0.47326, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 220/3000\n",
      "13/13 - 0s - loss: 0.2612 - accuracy: 0.8859 - val_loss: 0.4856 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.47326\n",
      "Epoch 221/3000\n",
      "13/13 - 0s - loss: 0.2808 - accuracy: 0.8729 - val_loss: 0.4725 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00221: val_loss improved from 0.47326 to 0.47251, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 222/3000\n",
      "13/13 - 0s - loss: 0.2765 - accuracy: 0.8885 - val_loss: 0.4964 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.47251\n",
      "Epoch 223/3000\n",
      "13/13 - 0s - loss: 0.2684 - accuracy: 0.8949 - val_loss: 0.5016 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.47251\n",
      "Epoch 224/3000\n",
      "13/13 - 0s - loss: 0.2719 - accuracy: 0.8923 - val_loss: 0.4715 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00224: val_loss improved from 0.47251 to 0.47148, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 225/3000\n",
      "13/13 - 0s - loss: 0.2592 - accuracy: 0.8898 - val_loss: 0.4803 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.47148\n",
      "Epoch 226/3000\n",
      "13/13 - 0s - loss: 0.2629 - accuracy: 0.8807 - val_loss: 0.4903 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.47148\n",
      "Epoch 227/3000\n",
      "13/13 - 0s - loss: 0.2563 - accuracy: 0.8936 - val_loss: 0.4901 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.47148\n",
      "Epoch 228/3000\n",
      "13/13 - 0s - loss: 0.2765 - accuracy: 0.8949 - val_loss: 0.4781 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.47148\n",
      "Epoch 229/3000\n",
      "13/13 - 0s - loss: 0.2583 - accuracy: 0.8936 - val_loss: 0.5374 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.47148\n",
      "Epoch 230/3000\n",
      "13/13 - 0s - loss: 0.3222 - accuracy: 0.8599 - val_loss: 0.5379 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.47148\n",
      "Epoch 231/3000\n",
      "13/13 - 0s - loss: 0.3052 - accuracy: 0.8664 - val_loss: 0.5037 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.47148\n",
      "Epoch 232/3000\n",
      "13/13 - 0s - loss: 0.2639 - accuracy: 0.8911 - val_loss: 0.4795 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.47148\n",
      "Epoch 233/3000\n",
      "13/13 - 0s - loss: 0.2680 - accuracy: 0.8872 - val_loss: 0.4726 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.47148\n",
      "Epoch 234/3000\n",
      "13/13 - 0s - loss: 0.2680 - accuracy: 0.8936 - val_loss: 0.4842 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.47148\n",
      "Epoch 235/3000\n",
      "13/13 - 0s - loss: 0.2593 - accuracy: 0.8962 - val_loss: 0.5068 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.47148\n",
      "Epoch 236/3000\n",
      "13/13 - 0s - loss: 0.2823 - accuracy: 0.8872 - val_loss: 0.4703 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 00236: val_loss improved from 0.47148 to 0.47025, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 237/3000\n",
      "13/13 - 0s - loss: 0.2609 - accuracy: 0.8936 - val_loss: 0.4834 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.47025\n",
      "Epoch 238/3000\n",
      "13/13 - 0s - loss: 0.2612 - accuracy: 0.8975 - val_loss: 0.4677 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00238: val_loss improved from 0.47025 to 0.46774, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 239/3000\n",
      "13/13 - 0s - loss: 0.2641 - accuracy: 0.8859 - val_loss: 0.4910 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.46774\n",
      "Epoch 240/3000\n",
      "13/13 - 0s - loss: 0.2540 - accuracy: 0.8962 - val_loss: 0.4924 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.46774\n",
      "Epoch 241/3000\n",
      "13/13 - 0s - loss: 0.2687 - accuracy: 0.8936 - val_loss: 0.5229 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.46774\n",
      "Epoch 242/3000\n",
      "13/13 - 0s - loss: 0.2669 - accuracy: 0.8923 - val_loss: 0.5002 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.46774\n",
      "Epoch 243/3000\n",
      "13/13 - 0s - loss: 0.2754 - accuracy: 0.8872 - val_loss: 0.5047 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.46774\n",
      "Epoch 244/3000\n",
      "13/13 - 0s - loss: 0.2842 - accuracy: 0.8573 - val_loss: 0.4718 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.46774\n",
      "Epoch 245/3000\n",
      "13/13 - 0s - loss: 0.2563 - accuracy: 0.8923 - val_loss: 0.4843 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.46774\n",
      "Epoch 246/3000\n",
      "13/13 - 0s - loss: 0.3098 - accuracy: 0.8755 - val_loss: 0.5130 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.46774\n",
      "Epoch 247/3000\n",
      "13/13 - 0s - loss: 0.2842 - accuracy: 0.8859 - val_loss: 0.4827 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.46774\n",
      "Epoch 248/3000\n",
      "13/13 - 0s - loss: 0.2628 - accuracy: 0.8949 - val_loss: 0.4917 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.46774\n",
      "Epoch 249/3000\n",
      "13/13 - 0s - loss: 0.2576 - accuracy: 0.8962 - val_loss: 0.4865 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.46774\n",
      "Epoch 250/3000\n",
      "13/13 - 0s - loss: 0.2683 - accuracy: 0.8898 - val_loss: 0.4739 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.46774\n",
      "Epoch 251/3000\n",
      "13/13 - 0s - loss: 0.2755 - accuracy: 0.8742 - val_loss: 0.4951 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.46774\n",
      "Epoch 252/3000\n",
      "13/13 - 0s - loss: 0.2563 - accuracy: 0.8949 - val_loss: 0.4703 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.46774\n",
      "Epoch 253/3000\n",
      "13/13 - 0s - loss: 0.2584 - accuracy: 0.8949 - val_loss: 0.4770 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.46774\n",
      "Epoch 254/3000\n",
      "13/13 - 0s - loss: 0.2560 - accuracy: 0.8859 - val_loss: 0.4799 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.46774\n",
      "Epoch 255/3000\n",
      "13/13 - 0s - loss: 0.2642 - accuracy: 0.8794 - val_loss: 0.4839 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.46774\n",
      "Epoch 256/3000\n",
      "13/13 - 0s - loss: 0.2572 - accuracy: 0.8859 - val_loss: 0.4765 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.46774\n",
      "Epoch 257/3000\n",
      "13/13 - 0s - loss: 0.2468 - accuracy: 0.8962 - val_loss: 0.4666 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00257: val_loss improved from 0.46774 to 0.46658, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 258/3000\n",
      "13/13 - 0s - loss: 0.2546 - accuracy: 0.8962 - val_loss: 0.4744 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.46658\n",
      "Epoch 259/3000\n",
      "13/13 - 0s - loss: 0.2639 - accuracy: 0.8872 - val_loss: 0.4759 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.46658\n",
      "Epoch 260/3000\n",
      "13/13 - 0s - loss: 0.2549 - accuracy: 0.8833 - val_loss: 0.4623 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00260: val_loss improved from 0.46658 to 0.46231, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 261/3000\n",
      "13/13 - 0s - loss: 0.2481 - accuracy: 0.8936 - val_loss: 0.4685 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.46231\n",
      "Epoch 262/3000\n",
      "13/13 - 0s - loss: 0.2451 - accuracy: 0.8975 - val_loss: 0.4620 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00262: val_loss improved from 0.46231 to 0.46199, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 263/3000\n",
      "13/13 - 0s - loss: 0.2667 - accuracy: 0.8923 - val_loss: 0.4884 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.46199\n",
      "Epoch 264/3000\n",
      "13/13 - 0s - loss: 0.2570 - accuracy: 0.8859 - val_loss: 0.5204 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.46199\n",
      "Epoch 265/3000\n",
      "13/13 - 0s - loss: 0.2522 - accuracy: 0.8949 - val_loss: 0.4849 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.46199\n",
      "Epoch 266/3000\n",
      "13/13 - 0s - loss: 0.2615 - accuracy: 0.8988 - val_loss: 0.4691 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.46199\n",
      "Epoch 267/3000\n",
      "13/13 - 0s - loss: 0.2541 - accuracy: 0.8949 - val_loss: 0.5047 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.46199\n",
      "Epoch 268/3000\n",
      "13/13 - 0s - loss: 0.2575 - accuracy: 0.8975 - val_loss: 0.4913 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.46199\n",
      "Epoch 269/3000\n",
      "13/13 - 0s - loss: 0.2533 - accuracy: 0.8898 - val_loss: 0.5065 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.46199\n",
      "Epoch 270/3000\n",
      "13/13 - 0s - loss: 0.2526 - accuracy: 0.8923 - val_loss: 0.4648 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.46199\n",
      "Epoch 271/3000\n",
      "13/13 - 0s - loss: 0.2433 - accuracy: 0.8988 - val_loss: 0.5005 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.46199\n",
      "Epoch 272/3000\n",
      "13/13 - 0s - loss: 0.2467 - accuracy: 0.8988 - val_loss: 0.4694 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.46199\n",
      "Epoch 273/3000\n",
      "13/13 - 0s - loss: 0.2436 - accuracy: 0.8988 - val_loss: 0.4961 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.46199\n",
      "Epoch 274/3000\n",
      "13/13 - 0s - loss: 0.2422 - accuracy: 0.8962 - val_loss: 0.4743 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.46199\n",
      "Epoch 275/3000\n",
      "13/13 - 0s - loss: 0.2837 - accuracy: 0.8742 - val_loss: 0.5461 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.46199\n",
      "Epoch 276/3000\n",
      "13/13 - 0s - loss: 0.2732 - accuracy: 0.8911 - val_loss: 0.4644 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.46199\n",
      "Epoch 277/3000\n",
      "13/13 - 0s - loss: 0.2935 - accuracy: 0.8742 - val_loss: 0.5695 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.46199\n",
      "Epoch 278/3000\n",
      "13/13 - 0s - loss: 0.2744 - accuracy: 0.8872 - val_loss: 0.4686 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.46199\n",
      "Epoch 279/3000\n",
      "13/13 - 0s - loss: 0.2719 - accuracy: 0.8755 - val_loss: 0.4788 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.46199\n",
      "Epoch 280/3000\n",
      "13/13 - 0s - loss: 0.2568 - accuracy: 0.8885 - val_loss: 0.4769 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.46199\n",
      "Epoch 281/3000\n",
      "13/13 - 0s - loss: 0.2508 - accuracy: 0.8988 - val_loss: 0.4731 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.46199\n",
      "Epoch 282/3000\n",
      "13/13 - 0s - loss: 0.2486 - accuracy: 0.8923 - val_loss: 0.5101 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.46199\n",
      "Epoch 283/3000\n",
      "13/13 - 0s - loss: 0.2547 - accuracy: 0.8962 - val_loss: 0.4804 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.46199\n",
      "Epoch 284/3000\n",
      "13/13 - 0s - loss: 0.2458 - accuracy: 0.8911 - val_loss: 0.4931 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.46199\n",
      "Epoch 285/3000\n",
      "13/13 - 0s - loss: 0.3263 - accuracy: 0.8521 - val_loss: 0.5310 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.46199\n",
      "Epoch 286/3000\n",
      "13/13 - 0s - loss: 0.2917 - accuracy: 0.8755 - val_loss: 0.4515 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 00286: val_loss improved from 0.46199 to 0.45146, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 287/3000\n",
      "13/13 - 0s - loss: 0.2894 - accuracy: 0.8872 - val_loss: 0.4742 - val_accuracy: 0.8653\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.45146\n",
      "Epoch 288/3000\n",
      "13/13 - 0s - loss: 0.2686 - accuracy: 0.8911 - val_loss: 0.4799 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.45146\n",
      "Epoch 289/3000\n",
      "13/13 - 0s - loss: 0.2587 - accuracy: 0.8872 - val_loss: 0.4744 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.45146\n",
      "Epoch 290/3000\n",
      "13/13 - 0s - loss: 0.2524 - accuracy: 0.8936 - val_loss: 0.4938 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.45146\n",
      "Epoch 291/3000\n",
      "13/13 - 0s - loss: 0.2521 - accuracy: 0.8949 - val_loss: 0.4776 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.45146\n",
      "Epoch 292/3000\n",
      "13/13 - 0s - loss: 0.2523 - accuracy: 0.8923 - val_loss: 0.4859 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.45146\n",
      "Epoch 293/3000\n",
      "13/13 - 0s - loss: 0.2462 - accuracy: 0.8975 - val_loss: 0.4903 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.45146\n",
      "Epoch 294/3000\n",
      "13/13 - 0s - loss: 0.2716 - accuracy: 0.8833 - val_loss: 0.4660 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.45146\n",
      "Epoch 295/3000\n",
      "13/13 - 0s - loss: 0.2558 - accuracy: 0.8936 - val_loss: 0.4689 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.45146\n",
      "Epoch 296/3000\n",
      "13/13 - 0s - loss: 0.2435 - accuracy: 0.8936 - val_loss: 0.4761 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.45146\n",
      "Epoch 297/3000\n",
      "13/13 - 0s - loss: 0.2431 - accuracy: 0.8988 - val_loss: 0.4815 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.45146\n",
      "Epoch 298/3000\n",
      "13/13 - 0s - loss: 0.2721 - accuracy: 0.8833 - val_loss: 0.4788 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.45146\n",
      "Epoch 299/3000\n",
      "13/13 - 0s - loss: 0.2566 - accuracy: 0.8885 - val_loss: 0.4717 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.45146\n",
      "Epoch 300/3000\n",
      "13/13 - 0s - loss: 0.2512 - accuracy: 0.8911 - val_loss: 0.4615 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.45146\n",
      "Epoch 301/3000\n",
      "13/13 - 0s - loss: 0.2461 - accuracy: 0.8898 - val_loss: 0.4608 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.45146\n",
      "Epoch 302/3000\n",
      "13/13 - 0s - loss: 0.2409 - accuracy: 0.8936 - val_loss: 0.4794 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.45146\n",
      "Epoch 303/3000\n",
      "13/13 - 0s - loss: 0.2516 - accuracy: 0.8962 - val_loss: 0.4826 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.45146\n",
      "Epoch 304/3000\n",
      "13/13 - 0s - loss: 0.2462 - accuracy: 0.8949 - val_loss: 0.4727 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.45146\n",
      "Epoch 305/3000\n",
      "13/13 - 0s - loss: 0.2561 - accuracy: 0.8911 - val_loss: 0.4755 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.45146\n",
      "Epoch 306/3000\n",
      "13/13 - 0s - loss: 0.2469 - accuracy: 0.8962 - val_loss: 0.4802 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.45146\n",
      "Epoch 307/3000\n",
      "13/13 - 0s - loss: 0.2663 - accuracy: 0.8716 - val_loss: 0.4995 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.45146\n",
      "Epoch 308/3000\n",
      "13/13 - 0s - loss: 0.2460 - accuracy: 0.8962 - val_loss: 0.4933 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.45146\n",
      "Epoch 309/3000\n",
      "13/13 - 0s - loss: 0.2602 - accuracy: 0.8807 - val_loss: 0.4700 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.45146\n",
      "Epoch 310/3000\n",
      "13/13 - 0s - loss: 0.2415 - accuracy: 0.8911 - val_loss: 0.4941 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.45146\n",
      "Epoch 311/3000\n",
      "13/13 - 0s - loss: 0.2453 - accuracy: 0.8975 - val_loss: 0.4939 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.45146\n",
      "Epoch 312/3000\n",
      "13/13 - 0s - loss: 0.2388 - accuracy: 0.8962 - val_loss: 0.4856 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.45146\n",
      "Epoch 313/3000\n",
      "13/13 - 0s - loss: 0.2375 - accuracy: 0.8923 - val_loss: 0.4663 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.45146\n",
      "Epoch 314/3000\n",
      "13/13 - 0s - loss: 0.2652 - accuracy: 0.8703 - val_loss: 0.5020 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.45146\n",
      "Epoch 315/3000\n",
      "13/13 - 0s - loss: 0.2682 - accuracy: 0.8781 - val_loss: 0.4634 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.45146\n",
      "Epoch 316/3000\n",
      "13/13 - 0s - loss: 0.2435 - accuracy: 0.8962 - val_loss: 0.4580 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.45146\n",
      "Epoch 317/3000\n",
      "13/13 - 0s - loss: 0.2539 - accuracy: 0.8885 - val_loss: 0.4495 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00317: val_loss improved from 0.45146 to 0.44954, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 318/3000\n",
      "13/13 - 0s - loss: 0.2439 - accuracy: 0.8911 - val_loss: 0.4607 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.44954\n",
      "Epoch 319/3000\n",
      "13/13 - 0s - loss: 0.2420 - accuracy: 0.8988 - val_loss: 0.4513 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.44954\n",
      "Epoch 320/3000\n",
      "13/13 - 0s - loss: 0.3008 - accuracy: 0.8703 - val_loss: 0.5143 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.44954\n",
      "Epoch 321/3000\n",
      "13/13 - 0s - loss: 0.2753 - accuracy: 0.8833 - val_loss: 0.4941 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.44954\n",
      "Epoch 322/3000\n",
      "13/13 - 0s - loss: 0.2496 - accuracy: 0.8923 - val_loss: 0.5029 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.44954\n",
      "Epoch 323/3000\n",
      "13/13 - 0s - loss: 0.2563 - accuracy: 0.8911 - val_loss: 0.4781 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.44954\n",
      "Epoch 324/3000\n",
      "13/13 - 0s - loss: 0.2387 - accuracy: 0.8962 - val_loss: 0.4709 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.44954\n",
      "Epoch 325/3000\n",
      "13/13 - 0s - loss: 0.2442 - accuracy: 0.8949 - val_loss: 0.4542 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.44954\n",
      "Epoch 326/3000\n",
      "13/13 - 0s - loss: 0.2476 - accuracy: 0.8820 - val_loss: 0.4632 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.44954\n",
      "Epoch 327/3000\n",
      "13/13 - 0s - loss: 0.2382 - accuracy: 0.8962 - val_loss: 0.4792 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.44954\n",
      "Epoch 328/3000\n",
      "13/13 - 0s - loss: 0.2435 - accuracy: 0.8975 - val_loss: 0.4756 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.44954\n",
      "Epoch 329/3000\n",
      "13/13 - 0s - loss: 0.2366 - accuracy: 0.8975 - val_loss: 0.4864 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.44954\n",
      "Epoch 330/3000\n",
      "13/13 - 0s - loss: 0.2336 - accuracy: 0.8975 - val_loss: 0.4590 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.44954\n",
      "Epoch 331/3000\n",
      "13/13 - 0s - loss: 0.2820 - accuracy: 0.8807 - val_loss: 0.4433 - val_accuracy: 0.8653\n",
      "\n",
      "Epoch 00331: val_loss improved from 0.44954 to 0.44329, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 332/3000\n",
      "13/13 - 0s - loss: 0.2666 - accuracy: 0.8949 - val_loss: 0.4811 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.44329\n",
      "Epoch 333/3000\n",
      "13/13 - 0s - loss: 0.2417 - accuracy: 0.8923 - val_loss: 0.4841 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.44329\n",
      "Epoch 334/3000\n",
      "13/13 - 0s - loss: 0.2521 - accuracy: 0.8911 - val_loss: 0.5014 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.44329\n",
      "Epoch 335/3000\n",
      "13/13 - 0s - loss: 0.2465 - accuracy: 0.8846 - val_loss: 0.4812 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.44329\n",
      "Epoch 336/3000\n",
      "13/13 - 0s - loss: 0.2377 - accuracy: 0.8923 - val_loss: 0.4811 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.44329\n",
      "Epoch 337/3000\n",
      "13/13 - 0s - loss: 0.2358 - accuracy: 0.8988 - val_loss: 0.4534 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.44329\n",
      "Epoch 338/3000\n",
      "13/13 - 0s - loss: 0.2669 - accuracy: 0.8846 - val_loss: 0.4594 - val_accuracy: 0.8653\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.44329\n",
      "Epoch 339/3000\n",
      "13/13 - 0s - loss: 0.2486 - accuracy: 0.8898 - val_loss: 0.4595 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.44329\n",
      "Epoch 340/3000\n",
      "13/13 - 0s - loss: 0.2331 - accuracy: 0.8898 - val_loss: 0.4690 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.44329\n",
      "Epoch 341/3000\n",
      "13/13 - 0s - loss: 0.2355 - accuracy: 0.8962 - val_loss: 0.4657 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.44329\n",
      "Epoch 342/3000\n",
      "13/13 - 0s - loss: 0.2318 - accuracy: 0.8962 - val_loss: 0.4693 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.44329\n",
      "Epoch 343/3000\n",
      "13/13 - 0s - loss: 0.2317 - accuracy: 0.8936 - val_loss: 0.4742 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.44329\n",
      "Epoch 344/3000\n",
      "13/13 - 0s - loss: 0.2434 - accuracy: 0.8911 - val_loss: 0.5108 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.44329\n",
      "Epoch 345/3000\n",
      "13/13 - 0s - loss: 0.2351 - accuracy: 0.8988 - val_loss: 0.4816 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.44329\n",
      "Epoch 346/3000\n",
      "13/13 - 0s - loss: 0.2323 - accuracy: 0.8988 - val_loss: 0.4714 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.44329\n",
      "Epoch 347/3000\n",
      "13/13 - 0s - loss: 0.2332 - accuracy: 0.8975 - val_loss: 0.4925 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.44329\n",
      "Epoch 348/3000\n",
      "13/13 - 0s - loss: 0.2392 - accuracy: 0.8988 - val_loss: 0.4713 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.44329\n",
      "Epoch 349/3000\n",
      "13/13 - 0s - loss: 0.2396 - accuracy: 0.8859 - val_loss: 0.4798 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.44329\n",
      "Epoch 350/3000\n",
      "13/13 - 0s - loss: 0.2386 - accuracy: 0.8949 - val_loss: 0.4831 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.44329\n",
      "Epoch 351/3000\n",
      "13/13 - 0s - loss: 0.2289 - accuracy: 0.8988 - val_loss: 0.4757 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.44329\n",
      "Epoch 352/3000\n",
      "13/13 - 0s - loss: 0.2336 - accuracy: 0.8962 - val_loss: 0.4745 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.44329\n",
      "Epoch 353/3000\n",
      "13/13 - 0s - loss: 0.2320 - accuracy: 0.8988 - val_loss: 0.4791 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.44329\n",
      "Epoch 354/3000\n",
      "13/13 - 0s - loss: 0.2314 - accuracy: 0.9001 - val_loss: 0.4698 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.44329\n",
      "Epoch 355/3000\n",
      "13/13 - 0s - loss: 0.2386 - accuracy: 0.8923 - val_loss: 0.4981 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.44329\n",
      "Epoch 356/3000\n",
      "13/13 - 0s - loss: 0.2396 - accuracy: 0.8936 - val_loss: 0.4721 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.44329\n",
      "Epoch 357/3000\n",
      "13/13 - 0s - loss: 0.2378 - accuracy: 0.8988 - val_loss: 0.4934 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.44329\n",
      "Epoch 358/3000\n",
      "13/13 - 0s - loss: 0.2436 - accuracy: 0.8936 - val_loss: 0.4862 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.44329\n",
      "Epoch 359/3000\n",
      "13/13 - 0s - loss: 0.2451 - accuracy: 0.9014 - val_loss: 0.4982 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.44329\n",
      "Epoch 360/3000\n",
      "13/13 - 0s - loss: 0.2333 - accuracy: 0.8975 - val_loss: 0.4749 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.44329\n",
      "Epoch 361/3000\n",
      "13/13 - 0s - loss: 0.2647 - accuracy: 0.8794 - val_loss: 0.5470 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.44329\n",
      "Epoch 362/3000\n",
      "13/13 - 0s - loss: 0.2736 - accuracy: 0.8859 - val_loss: 0.4711 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.44329\n",
      "Epoch 363/3000\n",
      "13/13 - 0s - loss: 0.2530 - accuracy: 0.8833 - val_loss: 0.4906 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 0.44329\n",
      "Epoch 364/3000\n",
      "13/13 - 0s - loss: 0.2407 - accuracy: 0.9027 - val_loss: 0.4505 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.44329\n",
      "Epoch 365/3000\n",
      "13/13 - 0s - loss: 0.2406 - accuracy: 0.8949 - val_loss: 0.4783 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.44329\n",
      "Epoch 366/3000\n",
      "13/13 - 0s - loss: 0.2377 - accuracy: 0.8898 - val_loss: 0.4741 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.44329\n",
      "Epoch 367/3000\n",
      "13/13 - 0s - loss: 0.2594 - accuracy: 0.8949 - val_loss: 0.4938 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.44329\n",
      "Epoch 368/3000\n",
      "13/13 - 0s - loss: 0.2401 - accuracy: 0.8936 - val_loss: 0.4776 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.44329\n",
      "Epoch 369/3000\n",
      "13/13 - 0s - loss: 0.2331 - accuracy: 0.8936 - val_loss: 0.4825 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.44329\n",
      "Epoch 370/3000\n",
      "13/13 - 0s - loss: 0.2450 - accuracy: 0.8936 - val_loss: 0.4769 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.44329\n",
      "Epoch 371/3000\n",
      "13/13 - 0s - loss: 0.2393 - accuracy: 0.8923 - val_loss: 0.4741 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.44329\n",
      "Epoch 372/3000\n",
      "13/13 - 0s - loss: 0.2435 - accuracy: 0.8846 - val_loss: 0.4604 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.44329\n",
      "Epoch 373/3000\n",
      "13/13 - 0s - loss: 0.2436 - accuracy: 0.8962 - val_loss: 0.4680 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.44329\n",
      "Epoch 374/3000\n",
      "13/13 - 0s - loss: 0.2457 - accuracy: 0.8936 - val_loss: 0.5050 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.44329\n",
      "Epoch 375/3000\n",
      "13/13 - 0s - loss: 0.2469 - accuracy: 0.8911 - val_loss: 0.5011 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.44329\n",
      "Epoch 376/3000\n",
      "13/13 - 0s - loss: 0.2476 - accuracy: 0.8859 - val_loss: 0.4839 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.44329\n",
      "Epoch 377/3000\n",
      "13/13 - 0s - loss: 0.2332 - accuracy: 0.8936 - val_loss: 0.4768 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.44329\n",
      "Epoch 378/3000\n",
      "13/13 - 0s - loss: 0.2488 - accuracy: 0.8911 - val_loss: 0.5117 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.44329\n",
      "Epoch 379/3000\n",
      "13/13 - 0s - loss: 0.2332 - accuracy: 0.8936 - val_loss: 0.4669 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.44329\n",
      "Epoch 380/3000\n",
      "13/13 - 0s - loss: 0.2292 - accuracy: 0.8975 - val_loss: 0.4696 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.44329\n",
      "Epoch 381/3000\n",
      "13/13 - 0s - loss: 0.2257 - accuracy: 0.8962 - val_loss: 0.4839 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 0.44329\n",
      "Epoch 382/3000\n",
      "13/13 - 0s - loss: 0.2797 - accuracy: 0.8911 - val_loss: 0.4546 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 0.44329\n",
      "Epoch 383/3000\n",
      "13/13 - 0s - loss: 0.2581 - accuracy: 0.8898 - val_loss: 0.4824 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 0.44329\n",
      "Epoch 384/3000\n",
      "13/13 - 0s - loss: 0.2502 - accuracy: 0.8988 - val_loss: 0.4547 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 0.44329\n",
      "Epoch 385/3000\n",
      "13/13 - 0s - loss: 0.2457 - accuracy: 0.8833 - val_loss: 0.4781 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 0.44329\n",
      "Epoch 386/3000\n",
      "13/13 - 0s - loss: 0.2414 - accuracy: 0.8975 - val_loss: 0.4746 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.44329\n",
      "Epoch 387/3000\n",
      "13/13 - 0s - loss: 0.2325 - accuracy: 0.8936 - val_loss: 0.4777 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 0.44329\n",
      "Epoch 388/3000\n",
      "13/13 - 0s - loss: 0.2572 - accuracy: 0.8911 - val_loss: 0.5152 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.44329\n",
      "Epoch 389/3000\n",
      "13/13 - 0s - loss: 0.2402 - accuracy: 0.8872 - val_loss: 0.4937 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 0.44329\n",
      "Epoch 390/3000\n",
      "13/13 - 0s - loss: 0.2587 - accuracy: 0.8794 - val_loss: 0.4737 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.44329\n",
      "Epoch 391/3000\n",
      "13/13 - 0s - loss: 0.2591 - accuracy: 0.8807 - val_loss: 0.4656 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.44329\n",
      "Epoch 392/3000\n",
      "13/13 - 0s - loss: 0.2450 - accuracy: 0.8872 - val_loss: 0.4835 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.44329\n",
      "Epoch 393/3000\n",
      "13/13 - 0s - loss: 0.2605 - accuracy: 0.8898 - val_loss: 0.4474 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.44329\n",
      "Epoch 394/3000\n",
      "13/13 - 0s - loss: 0.2498 - accuracy: 0.8898 - val_loss: 0.4666 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 0.44329\n",
      "Epoch 395/3000\n",
      "13/13 - 0s - loss: 0.2336 - accuracy: 0.8949 - val_loss: 0.4684 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 0.44329\n",
      "Epoch 396/3000\n",
      "13/13 - 0s - loss: 0.2319 - accuracy: 0.8949 - val_loss: 0.4771 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 0.44329\n",
      "Epoch 397/3000\n",
      "13/13 - 0s - loss: 0.2282 - accuracy: 0.8962 - val_loss: 0.4742 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.44329\n",
      "Epoch 398/3000\n",
      "13/13 - 0s - loss: 0.2305 - accuracy: 0.8885 - val_loss: 0.4896 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 0.44329\n",
      "Epoch 399/3000\n",
      "13/13 - 0s - loss: 0.2263 - accuracy: 0.9027 - val_loss: 0.4629 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 0.44329\n",
      "Epoch 400/3000\n",
      "13/13 - 0s - loss: 0.2246 - accuracy: 0.8949 - val_loss: 0.4751 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.44329\n",
      "Epoch 401/3000\n",
      "13/13 - 0s - loss: 0.2276 - accuracy: 0.8988 - val_loss: 0.4662 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 0.44329\n",
      "Epoch 402/3000\n",
      "13/13 - 0s - loss: 0.2333 - accuracy: 0.8833 - val_loss: 0.4831 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 0.44329\n",
      "Epoch 403/3000\n",
      "13/13 - 0s - loss: 0.2260 - accuracy: 0.9014 - val_loss: 0.4683 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 0.44329\n",
      "Epoch 404/3000\n",
      "13/13 - 0s - loss: 0.2232 - accuracy: 0.9001 - val_loss: 0.4739 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 0.44329\n",
      "Epoch 405/3000\n",
      "13/13 - 0s - loss: 0.2402 - accuracy: 0.8885 - val_loss: 0.4975 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 0.44329\n",
      "Epoch 406/3000\n",
      "13/13 - 0s - loss: 0.2321 - accuracy: 0.8988 - val_loss: 0.5150 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 0.44329\n",
      "Epoch 407/3000\n",
      "13/13 - 0s - loss: 0.2428 - accuracy: 0.8936 - val_loss: 0.4922 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 0.44329\n",
      "Epoch 408/3000\n",
      "13/13 - 0s - loss: 0.2362 - accuracy: 0.8923 - val_loss: 0.4974 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 0.44329\n",
      "Epoch 409/3000\n",
      "13/13 - 0s - loss: 0.2472 - accuracy: 0.8923 - val_loss: 0.4993 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 0.44329\n",
      "Epoch 410/3000\n",
      "13/13 - 0s - loss: 0.2404 - accuracy: 0.8872 - val_loss: 0.5022 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 0.44329\n",
      "Epoch 411/3000\n",
      "13/13 - 0s - loss: 0.2408 - accuracy: 0.8846 - val_loss: 0.4921 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 0.44329\n",
      "Epoch 412/3000\n",
      "13/13 - 0s - loss: 0.2356 - accuracy: 0.8833 - val_loss: 0.4742 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 0.44329\n",
      "Epoch 413/3000\n",
      "13/13 - 0s - loss: 0.2350 - accuracy: 0.8923 - val_loss: 0.4620 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 0.44329\n",
      "Epoch 414/3000\n",
      "13/13 - 0s - loss: 0.2382 - accuracy: 0.9001 - val_loss: 0.4880 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 0.44329\n",
      "Epoch 415/3000\n",
      "13/13 - 0s - loss: 0.2633 - accuracy: 0.8949 - val_loss: 0.5042 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 0.44329\n",
      "Epoch 416/3000\n",
      "13/13 - 0s - loss: 0.2478 - accuracy: 0.8949 - val_loss: 0.4576 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.44329\n",
      "Epoch 417/3000\n",
      "13/13 - 0s - loss: 0.2328 - accuracy: 0.8911 - val_loss: 0.4565 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.44329\n",
      "Epoch 418/3000\n",
      "13/13 - 0s - loss: 0.2325 - accuracy: 0.8911 - val_loss: 0.4479 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 0.44329\n",
      "Epoch 419/3000\n",
      "13/13 - 0s - loss: 0.2349 - accuracy: 0.8962 - val_loss: 0.4713 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 0.44329\n",
      "Epoch 420/3000\n",
      "13/13 - 0s - loss: 0.2284 - accuracy: 0.8975 - val_loss: 0.4788 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 0.44329\n",
      "Epoch 421/3000\n",
      "13/13 - 0s - loss: 0.2941 - accuracy: 0.8729 - val_loss: 0.5234 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 0.44329\n",
      "Epoch 422/3000\n",
      "13/13 - 0s - loss: 0.2465 - accuracy: 0.8898 - val_loss: 0.4934 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 0.44329\n",
      "Epoch 423/3000\n",
      "13/13 - 0s - loss: 0.2318 - accuracy: 0.8911 - val_loss: 0.4910 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 0.44329\n",
      "Epoch 424/3000\n",
      "13/13 - 0s - loss: 0.2291 - accuracy: 0.8923 - val_loss: 0.4905 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 0.44329\n",
      "Epoch 425/3000\n",
      "13/13 - 0s - loss: 0.2352 - accuracy: 0.8923 - val_loss: 0.4865 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 0.44329\n",
      "Epoch 426/3000\n",
      "13/13 - 0s - loss: 0.2354 - accuracy: 0.8923 - val_loss: 0.4822 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 0.44329\n",
      "Epoch 427/3000\n",
      "13/13 - 0s - loss: 0.2507 - accuracy: 0.8846 - val_loss: 0.5108 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 0.44329\n",
      "Epoch 428/3000\n",
      "13/13 - 0s - loss: 0.2423 - accuracy: 0.8975 - val_loss: 0.4725 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 0.44329\n",
      "Epoch 429/3000\n",
      "13/13 - 0s - loss: 0.2539 - accuracy: 0.8807 - val_loss: 0.5159 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 0.44329\n",
      "Epoch 430/3000\n",
      "13/13 - 0s - loss: 0.2532 - accuracy: 0.8923 - val_loss: 0.4650 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.44329\n",
      "Epoch 431/3000\n",
      "13/13 - 0s - loss: 0.2418 - accuracy: 0.8872 - val_loss: 0.4850 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 0.44329\n",
      "Epoch 432/3000\n",
      "13/13 - 0s - loss: 0.2318 - accuracy: 0.8975 - val_loss: 0.4579 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.44329\n",
      "Epoch 433/3000\n",
      "13/13 - 0s - loss: 0.2415 - accuracy: 0.8820 - val_loss: 0.4775 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.44329\n",
      "Epoch 434/3000\n",
      "13/13 - 0s - loss: 0.2342 - accuracy: 0.8962 - val_loss: 0.4546 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 0.44329\n",
      "Epoch 435/3000\n",
      "13/13 - 0s - loss: 0.2334 - accuracy: 0.8949 - val_loss: 0.4523 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 0.44329\n",
      "Epoch 436/3000\n",
      "13/13 - 0s - loss: 0.2675 - accuracy: 0.8898 - val_loss: 0.4478 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 0.44329\n",
      "Epoch 437/3000\n",
      "13/13 - 0s - loss: 0.2482 - accuracy: 0.8949 - val_loss: 0.4740 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 0.44329\n",
      "Epoch 438/3000\n",
      "13/13 - 0s - loss: 0.2303 - accuracy: 0.8949 - val_loss: 0.4944 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 0.44329\n",
      "Epoch 439/3000\n",
      "13/13 - 0s - loss: 0.2550 - accuracy: 0.8885 - val_loss: 0.5253 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 0.44329\n",
      "Epoch 440/3000\n",
      "13/13 - 0s - loss: 0.2457 - accuracy: 0.8833 - val_loss: 0.4909 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.44329\n",
      "Epoch 441/3000\n",
      "13/13 - 0s - loss: 0.2336 - accuracy: 0.8872 - val_loss: 0.4870 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 0.44329\n",
      "Epoch 442/3000\n",
      "13/13 - 0s - loss: 0.2296 - accuracy: 0.8949 - val_loss: 0.4781 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.44329\n",
      "Epoch 443/3000\n",
      "13/13 - 0s - loss: 0.2422 - accuracy: 0.8872 - val_loss: 0.4847 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.44329\n",
      "Epoch 444/3000\n",
      "13/13 - 0s - loss: 0.2289 - accuracy: 0.9001 - val_loss: 0.4889 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.44329\n",
      "Epoch 445/3000\n",
      "13/13 - 0s - loss: 0.2281 - accuracy: 0.8949 - val_loss: 0.4890 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.44329\n",
      "Epoch 446/3000\n",
      "13/13 - 0s - loss: 0.2237 - accuracy: 0.8962 - val_loss: 0.4856 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.44329\n",
      "Epoch 447/3000\n",
      "13/13 - 0s - loss: 0.2220 - accuracy: 0.8975 - val_loss: 0.4718 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 0.44329\n",
      "Epoch 448/3000\n",
      "13/13 - 0s - loss: 0.2433 - accuracy: 0.9027 - val_loss: 0.4878 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 0.44329\n",
      "Epoch 449/3000\n",
      "13/13 - 0s - loss: 0.2419 - accuracy: 0.8949 - val_loss: 0.4742 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 0.44329\n",
      "Epoch 450/3000\n",
      "13/13 - 0s - loss: 0.2593 - accuracy: 0.8794 - val_loss: 0.4583 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 0.44329\n",
      "Epoch 451/3000\n",
      "13/13 - 0s - loss: 0.3308 - accuracy: 0.8833 - val_loss: 0.4760 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 0.44329\n",
      "Epoch 452/3000\n",
      "13/13 - 0s - loss: 0.2715 - accuracy: 0.8833 - val_loss: 0.4366 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00452: val_loss improved from 0.44329 to 0.43662, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 453/3000\n",
      "13/13 - 0s - loss: 0.2443 - accuracy: 0.8949 - val_loss: 0.4498 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 0.43662\n",
      "Epoch 454/3000\n",
      "13/13 - 0s - loss: 0.2331 - accuracy: 0.8936 - val_loss: 0.4586 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 0.43662\n",
      "Epoch 455/3000\n",
      "13/13 - 0s - loss: 0.2292 - accuracy: 0.8962 - val_loss: 0.4688 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 0.43662\n",
      "Epoch 456/3000\n",
      "13/13 - 0s - loss: 0.2289 - accuracy: 0.8988 - val_loss: 0.4832 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.43662\n",
      "Epoch 457/3000\n",
      "13/13 - 0s - loss: 0.2300 - accuracy: 0.8923 - val_loss: 0.4572 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 0.43662\n",
      "Epoch 458/3000\n",
      "13/13 - 0s - loss: 0.2309 - accuracy: 0.8936 - val_loss: 0.4543 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 0.43662\n",
      "Epoch 459/3000\n",
      "13/13 - 0s - loss: 0.2296 - accuracy: 0.8949 - val_loss: 0.4604 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 0.43662\n",
      "Epoch 460/3000\n",
      "13/13 - 0s - loss: 0.2309 - accuracy: 0.8962 - val_loss: 0.4642 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 0.43662\n",
      "Epoch 461/3000\n",
      "13/13 - 0s - loss: 0.2257 - accuracy: 0.8962 - val_loss: 0.4670 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 0.43662\n",
      "Epoch 462/3000\n",
      "13/13 - 0s - loss: 0.2279 - accuracy: 0.8988 - val_loss: 0.4766 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 0.43662\n",
      "Epoch 463/3000\n",
      "13/13 - 0s - loss: 0.2304 - accuracy: 0.8988 - val_loss: 0.4665 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 0.43662\n",
      "Epoch 464/3000\n",
      "13/13 - 0s - loss: 0.2263 - accuracy: 0.8988 - val_loss: 0.4796 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 0.43662\n",
      "Epoch 465/3000\n",
      "13/13 - 0s - loss: 0.2402 - accuracy: 0.8911 - val_loss: 0.4605 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 0.43662\n",
      "Epoch 466/3000\n",
      "13/13 - 0s - loss: 0.2251 - accuracy: 0.9027 - val_loss: 0.4747 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 0.43662\n",
      "Epoch 467/3000\n",
      "13/13 - 0s - loss: 0.2346 - accuracy: 0.8949 - val_loss: 0.4826 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.43662\n",
      "Epoch 468/3000\n",
      "13/13 - 0s - loss: 0.2263 - accuracy: 0.8988 - val_loss: 0.4636 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 0.43662\n",
      "Epoch 469/3000\n",
      "13/13 - 0s - loss: 0.2251 - accuracy: 0.9001 - val_loss: 0.4561 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 0.43662\n",
      "Epoch 470/3000\n",
      "13/13 - 0s - loss: 0.2226 - accuracy: 0.8911 - val_loss: 0.4690 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.43662\n",
      "Epoch 471/3000\n",
      "13/13 - 0s - loss: 0.2207 - accuracy: 0.8975 - val_loss: 0.4656 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 0.43662\n",
      "Epoch 472/3000\n",
      "13/13 - 0s - loss: 0.2328 - accuracy: 0.8911 - val_loss: 0.4610 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.43662\n",
      "Epoch 473/3000\n",
      "13/13 - 0s - loss: 0.2585 - accuracy: 0.8781 - val_loss: 0.5008 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 0.43662\n",
      "Epoch 474/3000\n",
      "13/13 - 0s - loss: 0.2567 - accuracy: 0.8885 - val_loss: 0.4586 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 0.43662\n",
      "Epoch 475/3000\n",
      "13/13 - 0s - loss: 0.2307 - accuracy: 0.8949 - val_loss: 0.4616 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.43662\n",
      "Epoch 476/3000\n",
      "13/13 - 0s - loss: 0.2698 - accuracy: 0.8859 - val_loss: 0.4913 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 0.43662\n",
      "Epoch 477/3000\n",
      "13/13 - 0s - loss: 0.2462 - accuracy: 0.8872 - val_loss: 0.4907 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 0.43662\n",
      "Epoch 478/3000\n",
      "13/13 - 0s - loss: 0.2405 - accuracy: 0.8898 - val_loss: 0.4619 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 0.43662\n",
      "Epoch 479/3000\n",
      "13/13 - 0s - loss: 0.2282 - accuracy: 0.8988 - val_loss: 0.4732 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 0.43662\n",
      "Epoch 480/3000\n",
      "13/13 - 0s - loss: 0.2262 - accuracy: 0.9027 - val_loss: 0.4644 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.43662\n",
      "Epoch 481/3000\n",
      "13/13 - 0s - loss: 0.2307 - accuracy: 0.8949 - val_loss: 0.4699 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 0.43662\n",
      "Epoch 482/3000\n",
      "13/13 - 0s - loss: 0.2295 - accuracy: 0.8911 - val_loss: 0.4733 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 0.43662\n",
      "Epoch 483/3000\n",
      "13/13 - 0s - loss: 0.2246 - accuracy: 0.8936 - val_loss: 0.4729 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 0.43662\n",
      "Epoch 484/3000\n",
      "13/13 - 0s - loss: 0.2209 - accuracy: 0.8988 - val_loss: 0.4684 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.43662\n",
      "Epoch 485/3000\n",
      "13/13 - 0s - loss: 0.2194 - accuracy: 0.9001 - val_loss: 0.4653 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 0.43662\n",
      "Epoch 486/3000\n",
      "13/13 - 0s - loss: 0.2187 - accuracy: 0.8962 - val_loss: 0.4645 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.43662\n",
      "Epoch 487/3000\n",
      "13/13 - 0s - loss: 0.2229 - accuracy: 0.8988 - val_loss: 0.4617 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.43662\n",
      "Epoch 488/3000\n",
      "13/13 - 0s - loss: 0.2349 - accuracy: 0.8885 - val_loss: 0.4895 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 0.43662\n",
      "Epoch 489/3000\n",
      "13/13 - 0s - loss: 0.2671 - accuracy: 0.8794 - val_loss: 0.4722 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 0.43662\n",
      "Epoch 490/3000\n",
      "13/13 - 0s - loss: 0.2454 - accuracy: 0.8949 - val_loss: 0.4966 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.43662\n",
      "Epoch 491/3000\n",
      "13/13 - 0s - loss: 0.2369 - accuracy: 0.8923 - val_loss: 0.4751 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 0.43662\n",
      "Epoch 492/3000\n",
      "13/13 - 0s - loss: 0.2307 - accuracy: 0.8949 - val_loss: 0.4896 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 0.43662\n",
      "Epoch 493/3000\n",
      "13/13 - 0s - loss: 0.2256 - accuracy: 0.8911 - val_loss: 0.5291 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 0.43662\n",
      "Epoch 494/3000\n",
      "13/13 - 0s - loss: 0.2313 - accuracy: 0.8911 - val_loss: 0.4981 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 0.43662\n",
      "Epoch 495/3000\n",
      "13/13 - 0s - loss: 0.2308 - accuracy: 0.8936 - val_loss: 0.4746 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.43662\n",
      "Epoch 496/3000\n",
      "13/13 - 0s - loss: 0.2275 - accuracy: 0.8949 - val_loss: 0.4755 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.43662\n",
      "Epoch 497/3000\n",
      "13/13 - 0s - loss: 0.2252 - accuracy: 0.8975 - val_loss: 0.4730 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 0.43662\n",
      "Epoch 498/3000\n",
      "13/13 - 0s - loss: 0.2233 - accuracy: 0.8962 - val_loss: 0.4751 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 0.43662\n",
      "Epoch 499/3000\n",
      "13/13 - 0s - loss: 0.2182 - accuracy: 0.8988 - val_loss: 0.4558 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 0.43662\n",
      "Epoch 500/3000\n",
      "13/13 - 0s - loss: 0.2717 - accuracy: 0.8872 - val_loss: 0.4391 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.43662\n",
      "Epoch 501/3000\n",
      "13/13 - 0s - loss: 0.2512 - accuracy: 0.8846 - val_loss: 0.4662 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 0.43662\n",
      "Epoch 502/3000\n",
      "13/13 - 0s - loss: 0.2353 - accuracy: 0.8859 - val_loss: 0.4750 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 0.43662\n",
      "Epoch 503/3000\n",
      "13/13 - 0s - loss: 0.2245 - accuracy: 0.8936 - val_loss: 0.4772 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 0.43662\n",
      "Epoch 504/3000\n",
      "13/13 - 0s - loss: 0.2827 - accuracy: 0.8703 - val_loss: 0.4681 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 0.43662\n",
      "Epoch 505/3000\n",
      "13/13 - 0s - loss: 0.2566 - accuracy: 0.8833 - val_loss: 0.4774 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 0.43662\n",
      "Epoch 506/3000\n",
      "13/13 - 0s - loss: 0.2360 - accuracy: 0.9001 - val_loss: 0.4709 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 0.43662\n",
      "Epoch 507/3000\n",
      "13/13 - 0s - loss: 0.2253 - accuracy: 0.8936 - val_loss: 0.4668 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 0.43662\n",
      "Epoch 508/3000\n",
      "13/13 - 0s - loss: 0.2213 - accuracy: 0.8975 - val_loss: 0.4763 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 0.43662\n",
      "Epoch 509/3000\n",
      "13/13 - 0s - loss: 0.2314 - accuracy: 0.8949 - val_loss: 0.4706 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 0.43662\n",
      "Epoch 510/3000\n",
      "13/13 - 0s - loss: 0.2287 - accuracy: 0.8975 - val_loss: 0.4893 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 0.43662\n",
      "Epoch 511/3000\n",
      "13/13 - 0s - loss: 0.2297 - accuracy: 0.8936 - val_loss: 0.4809 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 0.43662\n",
      "Epoch 512/3000\n",
      "13/13 - 0s - loss: 0.2293 - accuracy: 0.8911 - val_loss: 0.4587 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 0.43662\n",
      "Epoch 513/3000\n",
      "13/13 - 0s - loss: 0.2268 - accuracy: 0.8923 - val_loss: 0.4575 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 0.43662\n",
      "Epoch 514/3000\n",
      "13/13 - 0s - loss: 0.2260 - accuracy: 0.8936 - val_loss: 0.4751 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 0.43662\n",
      "Epoch 515/3000\n",
      "13/13 - 0s - loss: 0.2390 - accuracy: 0.8911 - val_loss: 0.4707 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 0.43662\n",
      "Epoch 516/3000\n",
      "13/13 - 0s - loss: 0.2288 - accuracy: 0.8872 - val_loss: 0.4866 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 0.43662\n",
      "Epoch 517/3000\n",
      "13/13 - 0s - loss: 0.2253 - accuracy: 0.8962 - val_loss: 0.4926 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 0.43662\n",
      "Epoch 518/3000\n",
      "13/13 - 0s - loss: 0.2230 - accuracy: 0.8923 - val_loss: 0.4741 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 0.43662\n",
      "Epoch 519/3000\n",
      "13/13 - 0s - loss: 0.2201 - accuracy: 0.8962 - val_loss: 0.4764 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 0.43662\n",
      "Epoch 520/3000\n",
      "13/13 - 0s - loss: 0.2178 - accuracy: 0.9014 - val_loss: 0.4685 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 0.43662\n",
      "Epoch 521/3000\n",
      "13/13 - 0s - loss: 0.2180 - accuracy: 0.8975 - val_loss: 0.4849 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 0.43662\n",
      "Epoch 522/3000\n",
      "13/13 - 0s - loss: 0.2209 - accuracy: 0.8988 - val_loss: 0.4787 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 0.43662\n",
      "Epoch 523/3000\n",
      "13/13 - 0s - loss: 0.2179 - accuracy: 0.9014 - val_loss: 0.4818 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 0.43662\n",
      "Epoch 524/3000\n",
      "13/13 - 0s - loss: 0.2167 - accuracy: 0.9053 - val_loss: 0.4789 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 0.43662\n",
      "Epoch 525/3000\n",
      "13/13 - 0s - loss: 0.2193 - accuracy: 0.8949 - val_loss: 0.4722 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 0.43662\n",
      "Epoch 526/3000\n",
      "13/13 - 0s - loss: 0.2175 - accuracy: 0.8962 - val_loss: 0.4682 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 0.43662\n",
      "Epoch 527/3000\n",
      "13/13 - 0s - loss: 0.2161 - accuracy: 0.8975 - val_loss: 0.4728 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 0.43662\n",
      "Epoch 528/3000\n",
      "13/13 - 0s - loss: 0.2236 - accuracy: 0.8962 - val_loss: 0.4684 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 0.43662\n",
      "Epoch 529/3000\n",
      "13/13 - 0s - loss: 0.2206 - accuracy: 0.9014 - val_loss: 0.4628 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 0.43662\n",
      "Epoch 530/3000\n",
      "13/13 - 0s - loss: 0.2393 - accuracy: 0.8923 - val_loss: 0.4870 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 0.43662\n",
      "Epoch 531/3000\n",
      "13/13 - 0s - loss: 0.2276 - accuracy: 0.8962 - val_loss: 0.4597 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 0.43662\n",
      "Epoch 532/3000\n",
      "13/13 - 0s - loss: 0.2196 - accuracy: 0.8962 - val_loss: 0.4729 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 0.43662\n",
      "Epoch 533/3000\n",
      "13/13 - 0s - loss: 0.2202 - accuracy: 0.8975 - val_loss: 0.4739 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 0.43662\n",
      "Epoch 534/3000\n",
      "13/13 - 0s - loss: 0.2192 - accuracy: 0.8923 - val_loss: 0.4859 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 0.43662\n",
      "Epoch 535/3000\n",
      "13/13 - 0s - loss: 0.2189 - accuracy: 0.9027 - val_loss: 0.4755 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 0.43662\n",
      "Epoch 536/3000\n",
      "13/13 - 0s - loss: 0.2186 - accuracy: 0.9014 - val_loss: 0.4748 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 0.43662\n",
      "Epoch 537/3000\n",
      "13/13 - 0s - loss: 0.2171 - accuracy: 0.8975 - val_loss: 0.4704 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 0.43662\n",
      "Epoch 538/3000\n",
      "13/13 - 0s - loss: 0.2177 - accuracy: 0.8936 - val_loss: 0.4695 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 0.43662\n",
      "Epoch 539/3000\n",
      "13/13 - 0s - loss: 0.2149 - accuracy: 0.9027 - val_loss: 0.4697 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 0.43662\n",
      "Epoch 540/3000\n",
      "13/13 - 0s - loss: 0.2219 - accuracy: 0.8962 - val_loss: 0.4621 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 0.43662\n",
      "Epoch 541/3000\n",
      "13/13 - 0s - loss: 0.2220 - accuracy: 0.8885 - val_loss: 0.4834 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 0.43662\n",
      "Epoch 542/3000\n",
      "13/13 - 0s - loss: 0.2347 - accuracy: 0.9001 - val_loss: 0.4794 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 0.43662\n",
      "Epoch 543/3000\n",
      "13/13 - 0s - loss: 0.2334 - accuracy: 0.8962 - val_loss: 0.4874 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 0.43662\n",
      "Epoch 544/3000\n",
      "13/13 - 0s - loss: 0.2208 - accuracy: 0.8975 - val_loss: 0.4737 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 0.43662\n",
      "Epoch 545/3000\n",
      "13/13 - 0s - loss: 0.2254 - accuracy: 0.8911 - val_loss: 0.4692 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 0.43662\n",
      "Epoch 546/3000\n",
      "13/13 - 0s - loss: 0.2328 - accuracy: 0.8988 - val_loss: 0.4894 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 0.43662\n",
      "Epoch 547/3000\n",
      "13/13 - 0s - loss: 0.2285 - accuracy: 0.8962 - val_loss: 0.4861 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 0.43662\n",
      "Epoch 548/3000\n",
      "13/13 - 0s - loss: 0.2176 - accuracy: 0.8988 - val_loss: 0.4914 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 0.43662\n",
      "Epoch 549/3000\n",
      "13/13 - 0s - loss: 0.2223 - accuracy: 0.9040 - val_loss: 0.4852 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 0.43662\n",
      "Epoch 550/3000\n",
      "13/13 - 0s - loss: 0.2301 - accuracy: 0.8936 - val_loss: 0.4889 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 0.43662\n",
      "Epoch 551/3000\n",
      "13/13 - 0s - loss: 0.2264 - accuracy: 0.8949 - val_loss: 0.4920 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00551: val_loss did not improve from 0.43662\n",
      "Epoch 552/3000\n",
      "13/13 - 0s - loss: 0.2267 - accuracy: 0.9014 - val_loss: 0.4767 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00552: val_loss did not improve from 0.43662\n",
      "Epoch 553/3000\n",
      "13/13 - 0s - loss: 0.2233 - accuracy: 0.9014 - val_loss: 0.4683 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00553: val_loss did not improve from 0.43662\n",
      "Epoch 554/3000\n",
      "13/13 - 0s - loss: 0.2327 - accuracy: 0.8911 - val_loss: 0.4627 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00554: val_loss did not improve from 0.43662\n",
      "Epoch 555/3000\n",
      "13/13 - 0s - loss: 0.2303 - accuracy: 0.8885 - val_loss: 0.4662 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00555: val_loss did not improve from 0.43662\n",
      "Epoch 556/3000\n",
      "13/13 - 0s - loss: 0.2234 - accuracy: 0.8936 - val_loss: 0.4818 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00556: val_loss did not improve from 0.43662\n",
      "Epoch 557/3000\n",
      "13/13 - 0s - loss: 0.2281 - accuracy: 0.8975 - val_loss: 0.4662 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00557: val_loss did not improve from 0.43662\n",
      "Epoch 558/3000\n",
      "13/13 - 0s - loss: 0.2244 - accuracy: 0.9001 - val_loss: 0.4912 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00558: val_loss did not improve from 0.43662\n",
      "Epoch 559/3000\n",
      "13/13 - 0s - loss: 0.2178 - accuracy: 0.8975 - val_loss: 0.4699 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00559: val_loss did not improve from 0.43662\n",
      "Epoch 560/3000\n",
      "13/13 - 0s - loss: 0.2187 - accuracy: 0.8949 - val_loss: 0.4847 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 0.43662\n",
      "Epoch 561/3000\n",
      "13/13 - 0s - loss: 0.2240 - accuracy: 0.9001 - val_loss: 0.4602 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00561: val_loss did not improve from 0.43662\n",
      "Epoch 562/3000\n",
      "13/13 - 0s - loss: 0.2241 - accuracy: 0.8975 - val_loss: 0.4637 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00562: val_loss did not improve from 0.43662\n",
      "Epoch 563/3000\n",
      "13/13 - 0s - loss: 0.2180 - accuracy: 0.8975 - val_loss: 0.4849 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00563: val_loss did not improve from 0.43662\n",
      "Epoch 564/3000\n",
      "13/13 - 0s - loss: 0.2255 - accuracy: 0.8975 - val_loss: 0.4867 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00564: val_loss did not improve from 0.43662\n",
      "Epoch 565/3000\n",
      "13/13 - 0s - loss: 0.2201 - accuracy: 0.8962 - val_loss: 0.4957 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00565: val_loss did not improve from 0.43662\n",
      "Epoch 566/3000\n",
      "13/13 - 0s - loss: 0.2228 - accuracy: 0.8975 - val_loss: 0.4789 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00566: val_loss did not improve from 0.43662\n",
      "Epoch 567/3000\n",
      "13/13 - 0s - loss: 0.2371 - accuracy: 0.8872 - val_loss: 0.5142 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00567: val_loss did not improve from 0.43662\n",
      "Epoch 568/3000\n",
      "13/13 - 0s - loss: 0.2325 - accuracy: 0.8962 - val_loss: 0.4734 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00568: val_loss did not improve from 0.43662\n",
      "Epoch 569/3000\n",
      "13/13 - 0s - loss: 0.2327 - accuracy: 0.8911 - val_loss: 0.5147 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00569: val_loss did not improve from 0.43662\n",
      "Epoch 570/3000\n",
      "13/13 - 0s - loss: 0.2257 - accuracy: 0.9040 - val_loss: 0.4703 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00570: val_loss did not improve from 0.43662\n",
      "Epoch 571/3000\n",
      "13/13 - 0s - loss: 0.2211 - accuracy: 0.8820 - val_loss: 0.4952 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00571: val_loss did not improve from 0.43662\n",
      "Epoch 572/3000\n",
      "13/13 - 0s - loss: 0.2191 - accuracy: 0.9027 - val_loss: 0.4716 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00572: val_loss did not improve from 0.43662\n",
      "Epoch 573/3000\n",
      "13/13 - 0s - loss: 0.2201 - accuracy: 0.8975 - val_loss: 0.4722 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00573: val_loss did not improve from 0.43662\n",
      "Epoch 574/3000\n",
      "13/13 - 0s - loss: 0.2249 - accuracy: 0.9001 - val_loss: 0.4674 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00574: val_loss did not improve from 0.43662\n",
      "Epoch 575/3000\n",
      "13/13 - 0s - loss: 0.2296 - accuracy: 0.8975 - val_loss: 0.4863 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00575: val_loss did not improve from 0.43662\n",
      "Epoch 576/3000\n",
      "13/13 - 0s - loss: 0.2372 - accuracy: 0.8949 - val_loss: 0.4709 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00576: val_loss did not improve from 0.43662\n",
      "Epoch 577/3000\n",
      "13/13 - 0s - loss: 0.2276 - accuracy: 0.8988 - val_loss: 0.4775 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00577: val_loss did not improve from 0.43662\n",
      "Epoch 578/3000\n",
      "13/13 - 0s - loss: 0.2175 - accuracy: 0.9001 - val_loss: 0.4613 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00578: val_loss did not improve from 0.43662\n",
      "Epoch 579/3000\n",
      "13/13 - 0s - loss: 0.2225 - accuracy: 0.8949 - val_loss: 0.4646 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00579: val_loss did not improve from 0.43662\n",
      "Epoch 580/3000\n",
      "13/13 - 0s - loss: 0.2202 - accuracy: 0.9001 - val_loss: 0.4712 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00580: val_loss did not improve from 0.43662\n",
      "Epoch 581/3000\n",
      "13/13 - 0s - loss: 0.2458 - accuracy: 0.8807 - val_loss: 0.4929 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00581: val_loss did not improve from 0.43662\n",
      "Epoch 582/3000\n",
      "13/13 - 0s - loss: 0.2635 - accuracy: 0.8638 - val_loss: 0.4923 - val_accuracy: 0.8653\n",
      "\n",
      "Epoch 00582: val_loss did not improve from 0.43662\n",
      "Epoch 583/3000\n",
      "13/13 - 0s - loss: 0.2276 - accuracy: 0.8936 - val_loss: 0.4618 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00583: val_loss did not improve from 0.43662\n",
      "Epoch 584/3000\n",
      "13/13 - 0s - loss: 0.2147 - accuracy: 0.9027 - val_loss: 0.4683 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00584: val_loss did not improve from 0.43662\n",
      "Epoch 585/3000\n",
      "13/13 - 0s - loss: 0.2152 - accuracy: 0.8962 - val_loss: 0.4791 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00585: val_loss did not improve from 0.43662\n",
      "Epoch 586/3000\n",
      "13/13 - 0s - loss: 0.2238 - accuracy: 0.9014 - val_loss: 0.4627 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00586: val_loss did not improve from 0.43662\n",
      "Epoch 587/3000\n",
      "13/13 - 0s - loss: 0.2226 - accuracy: 0.8923 - val_loss: 0.4664 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00587: val_loss did not improve from 0.43662\n",
      "Epoch 588/3000\n",
      "13/13 - 0s - loss: 0.2381 - accuracy: 0.8859 - val_loss: 0.5087 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00588: val_loss did not improve from 0.43662\n",
      "Epoch 589/3000\n",
      "13/13 - 0s - loss: 0.2268 - accuracy: 0.9014 - val_loss: 0.4926 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00589: val_loss did not improve from 0.43662\n",
      "Epoch 590/3000\n",
      "13/13 - 0s - loss: 0.2313 - accuracy: 0.8949 - val_loss: 0.5117 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00590: val_loss did not improve from 0.43662\n",
      "Epoch 591/3000\n",
      "13/13 - 0s - loss: 0.2282 - accuracy: 0.9014 - val_loss: 0.4859 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00591: val_loss did not improve from 0.43662\n",
      "Epoch 592/3000\n",
      "13/13 - 0s - loss: 0.2323 - accuracy: 0.8859 - val_loss: 0.5224 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00592: val_loss did not improve from 0.43662\n",
      "Epoch 593/3000\n",
      "13/13 - 0s - loss: 0.2413 - accuracy: 0.8885 - val_loss: 0.4840 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00593: val_loss did not improve from 0.43662\n",
      "Epoch 594/3000\n",
      "13/13 - 0s - loss: 0.2229 - accuracy: 0.8949 - val_loss: 0.4895 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00594: val_loss did not improve from 0.43662\n",
      "Epoch 595/3000\n",
      "13/13 - 0s - loss: 0.2212 - accuracy: 0.8936 - val_loss: 0.4719 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00595: val_loss did not improve from 0.43662\n",
      "Epoch 596/3000\n",
      "13/13 - 0s - loss: 0.2168 - accuracy: 0.8962 - val_loss: 0.4801 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00596: val_loss did not improve from 0.43662\n",
      "Epoch 597/3000\n",
      "13/13 - 0s - loss: 0.2244 - accuracy: 0.9027 - val_loss: 0.4833 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00597: val_loss did not improve from 0.43662\n",
      "Epoch 598/3000\n",
      "13/13 - 0s - loss: 0.2241 - accuracy: 0.8911 - val_loss: 0.5126 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00598: val_loss did not improve from 0.43662\n",
      "Epoch 599/3000\n",
      "13/13 - 0s - loss: 0.2628 - accuracy: 0.8781 - val_loss: 0.4979 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00599: val_loss did not improve from 0.43662\n",
      "Epoch 600/3000\n",
      "13/13 - 0s - loss: 0.2439 - accuracy: 0.8872 - val_loss: 0.4867 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00600: val_loss did not improve from 0.43662\n",
      "Epoch 601/3000\n",
      "13/13 - 0s - loss: 0.2352 - accuracy: 0.8988 - val_loss: 0.4656 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00601: val_loss did not improve from 0.43662\n",
      "Epoch 602/3000\n",
      "13/13 - 0s - loss: 0.2250 - accuracy: 0.8962 - val_loss: 0.4883 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00602: val_loss did not improve from 0.43662\n",
      "Epoch 603/3000\n",
      "13/13 - 0s - loss: 0.2228 - accuracy: 0.8975 - val_loss: 0.4606 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00603: val_loss did not improve from 0.43662\n",
      "Epoch 604/3000\n",
      "13/13 - 0s - loss: 0.2279 - accuracy: 0.8923 - val_loss: 0.4608 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00604: val_loss did not improve from 0.43662\n",
      "Epoch 605/3000\n",
      "13/13 - 0s - loss: 0.2216 - accuracy: 0.8975 - val_loss: 0.4624 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00605: val_loss did not improve from 0.43662\n",
      "Epoch 606/3000\n",
      "13/13 - 0s - loss: 0.2365 - accuracy: 0.8898 - val_loss: 0.4944 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00606: val_loss did not improve from 0.43662\n",
      "Epoch 607/3000\n",
      "13/13 - 0s - loss: 0.2216 - accuracy: 0.8962 - val_loss: 0.4691 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00607: val_loss did not improve from 0.43662\n",
      "Epoch 608/3000\n",
      "13/13 - 0s - loss: 0.2184 - accuracy: 0.8988 - val_loss: 0.4760 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00608: val_loss did not improve from 0.43662\n",
      "Epoch 609/3000\n",
      "13/13 - 0s - loss: 0.2239 - accuracy: 0.8975 - val_loss: 0.4740 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00609: val_loss did not improve from 0.43662\n",
      "Epoch 610/3000\n",
      "13/13 - 0s - loss: 0.2283 - accuracy: 0.9001 - val_loss: 0.5029 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00610: val_loss did not improve from 0.43662\n",
      "Epoch 611/3000\n",
      "13/13 - 0s - loss: 0.2455 - accuracy: 0.8885 - val_loss: 0.4697 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00611: val_loss did not improve from 0.43662\n",
      "Epoch 612/3000\n",
      "13/13 - 0s - loss: 0.2284 - accuracy: 0.8923 - val_loss: 0.4917 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00612: val_loss did not improve from 0.43662\n",
      "Epoch 613/3000\n",
      "13/13 - 0s - loss: 0.2247 - accuracy: 0.8975 - val_loss: 0.4825 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00613: val_loss did not improve from 0.43662\n",
      "Epoch 614/3000\n",
      "13/13 - 0s - loss: 0.2414 - accuracy: 0.8898 - val_loss: 0.4737 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00614: val_loss did not improve from 0.43662\n",
      "Epoch 615/3000\n",
      "13/13 - 0s - loss: 0.2326 - accuracy: 0.8975 - val_loss: 0.4727 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00615: val_loss did not improve from 0.43662\n",
      "Epoch 616/3000\n",
      "13/13 - 0s - loss: 0.2291 - accuracy: 0.8988 - val_loss: 0.4774 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00616: val_loss did not improve from 0.43662\n",
      "Epoch 617/3000\n",
      "13/13 - 0s - loss: 0.2196 - accuracy: 0.9001 - val_loss: 0.4753 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00617: val_loss did not improve from 0.43662\n",
      "Epoch 618/3000\n",
      "13/13 - 0s - loss: 0.2257 - accuracy: 0.8975 - val_loss: 0.4569 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00618: val_loss did not improve from 0.43662\n",
      "Epoch 619/3000\n",
      "13/13 - 0s - loss: 0.2210 - accuracy: 0.8949 - val_loss: 0.4675 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00619: val_loss did not improve from 0.43662\n",
      "Epoch 620/3000\n",
      "13/13 - 0s - loss: 0.2162 - accuracy: 0.8936 - val_loss: 0.4641 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00620: val_loss did not improve from 0.43662\n",
      "Epoch 621/3000\n",
      "13/13 - 0s - loss: 0.2147 - accuracy: 0.9001 - val_loss: 0.4653 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00621: val_loss did not improve from 0.43662\n",
      "Epoch 622/3000\n",
      "13/13 - 0s - loss: 0.2146 - accuracy: 0.8975 - val_loss: 0.4638 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00622: val_loss did not improve from 0.43662\n",
      "Epoch 623/3000\n",
      "13/13 - 0s - loss: 0.2133 - accuracy: 0.8988 - val_loss: 0.4565 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00623: val_loss did not improve from 0.43662\n",
      "Epoch 624/3000\n",
      "13/13 - 0s - loss: 0.2149 - accuracy: 0.8988 - val_loss: 0.4537 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00624: val_loss did not improve from 0.43662\n",
      "Epoch 625/3000\n",
      "13/13 - 0s - loss: 0.2198 - accuracy: 0.8962 - val_loss: 0.4876 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00625: val_loss did not improve from 0.43662\n",
      "Epoch 626/3000\n",
      "13/13 - 0s - loss: 0.2277 - accuracy: 0.8962 - val_loss: 0.4572 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00626: val_loss did not improve from 0.43662\n",
      "Epoch 627/3000\n",
      "13/13 - 0s - loss: 0.2146 - accuracy: 0.9027 - val_loss: 0.4706 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00627: val_loss did not improve from 0.43662\n",
      "Epoch 628/3000\n",
      "13/13 - 0s - loss: 0.2168 - accuracy: 0.9001 - val_loss: 0.4564 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00628: val_loss did not improve from 0.43662\n",
      "Epoch 629/3000\n",
      "13/13 - 0s - loss: 0.2179 - accuracy: 0.9014 - val_loss: 0.4914 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00629: val_loss did not improve from 0.43662\n",
      "Epoch 630/3000\n",
      "13/13 - 0s - loss: 0.2297 - accuracy: 0.8949 - val_loss: 0.4689 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00630: val_loss did not improve from 0.43662\n",
      "Epoch 631/3000\n",
      "13/13 - 0s - loss: 0.2246 - accuracy: 0.9001 - val_loss: 0.4680 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00631: val_loss did not improve from 0.43662\n",
      "Epoch 632/3000\n",
      "13/13 - 0s - loss: 0.2341 - accuracy: 0.8962 - val_loss: 0.4596 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00632: val_loss did not improve from 0.43662\n",
      "Epoch 633/3000\n",
      "13/13 - 0s - loss: 0.2557 - accuracy: 0.8781 - val_loss: 0.5606 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00633: val_loss did not improve from 0.43662\n",
      "Epoch 634/3000\n",
      "13/13 - 0s - loss: 0.2348 - accuracy: 0.8923 - val_loss: 0.5277 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00634: val_loss did not improve from 0.43662\n",
      "Epoch 635/3000\n",
      "13/13 - 0s - loss: 0.2313 - accuracy: 0.8949 - val_loss: 0.5176 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00635: val_loss did not improve from 0.43662\n",
      "Epoch 636/3000\n",
      "13/13 - 0s - loss: 0.2327 - accuracy: 0.8872 - val_loss: 0.5192 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00636: val_loss did not improve from 0.43662\n",
      "Epoch 637/3000\n",
      "13/13 - 0s - loss: 0.2264 - accuracy: 0.9001 - val_loss: 0.4845 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00637: val_loss did not improve from 0.43662\n",
      "Epoch 638/3000\n",
      "13/13 - 0s - loss: 0.2261 - accuracy: 0.9001 - val_loss: 0.4883 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00638: val_loss did not improve from 0.43662\n",
      "Epoch 639/3000\n",
      "13/13 - 0s - loss: 0.2188 - accuracy: 0.8962 - val_loss: 0.4664 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00639: val_loss did not improve from 0.43662\n",
      "Epoch 640/3000\n",
      "13/13 - 0s - loss: 0.2183 - accuracy: 0.9014 - val_loss: 0.4742 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00640: val_loss did not improve from 0.43662\n",
      "Epoch 641/3000\n",
      "13/13 - 0s - loss: 0.2438 - accuracy: 0.8923 - val_loss: 0.5018 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00641: val_loss did not improve from 0.43662\n",
      "Epoch 642/3000\n",
      "13/13 - 0s - loss: 0.2311 - accuracy: 0.8898 - val_loss: 0.4399 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00642: val_loss did not improve from 0.43662\n",
      "Epoch 643/3000\n",
      "13/13 - 0s - loss: 0.2775 - accuracy: 0.8872 - val_loss: 0.4370 - val_accuracy: 0.8653\n",
      "\n",
      "Epoch 00643: val_loss did not improve from 0.43662\n",
      "Epoch 644/3000\n",
      "13/13 - 0s - loss: 0.2603 - accuracy: 0.8936 - val_loss: 0.4643 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00644: val_loss did not improve from 0.43662\n",
      "Epoch 645/3000\n",
      "13/13 - 0s - loss: 0.2682 - accuracy: 0.8859 - val_loss: 0.6111 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00645: val_loss did not improve from 0.43662\n",
      "Epoch 646/3000\n",
      "13/13 - 0s - loss: 0.2606 - accuracy: 0.8898 - val_loss: 0.5367 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00646: val_loss did not improve from 0.43662\n",
      "Epoch 647/3000\n",
      "13/13 - 0s - loss: 0.2362 - accuracy: 0.8988 - val_loss: 0.4827 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00647: val_loss did not improve from 0.43662\n",
      "Epoch 648/3000\n",
      "13/13 - 0s - loss: 0.2237 - accuracy: 0.9001 - val_loss: 0.4830 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00648: val_loss did not improve from 0.43662\n",
      "Epoch 649/3000\n",
      "13/13 - 0s - loss: 0.2174 - accuracy: 0.9014 - val_loss: 0.4706 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00649: val_loss did not improve from 0.43662\n",
      "Epoch 650/3000\n",
      "13/13 - 0s - loss: 0.2234 - accuracy: 0.8988 - val_loss: 0.4750 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00650: val_loss did not improve from 0.43662\n",
      "Epoch 651/3000\n",
      "13/13 - 0s - loss: 0.2249 - accuracy: 0.8885 - val_loss: 0.4509 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00651: val_loss did not improve from 0.43662\n",
      "Epoch 652/3000\n",
      "13/13 - 0s - loss: 0.2199 - accuracy: 0.9001 - val_loss: 0.4572 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00652: val_loss did not improve from 0.43662\n",
      "Epoch 653/3000\n",
      "13/13 - 0s - loss: 0.2182 - accuracy: 0.9053 - val_loss: 0.4603 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00653: val_loss did not improve from 0.43662\n",
      "Epoch 654/3000\n",
      "13/13 - 0s - loss: 0.2169 - accuracy: 0.9014 - val_loss: 0.4716 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00654: val_loss did not improve from 0.43662\n",
      "Epoch 655/3000\n",
      "13/13 - 0s - loss: 0.2140 - accuracy: 0.8975 - val_loss: 0.4583 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00655: val_loss did not improve from 0.43662\n",
      "Epoch 656/3000\n",
      "13/13 - 0s - loss: 0.2474 - accuracy: 0.8898 - val_loss: 0.5073 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00656: val_loss did not improve from 0.43662\n",
      "Epoch 657/3000\n",
      "13/13 - 0s - loss: 0.2466 - accuracy: 0.8872 - val_loss: 0.4709 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00657: val_loss did not improve from 0.43662\n",
      "Epoch 658/3000\n",
      "13/13 - 0s - loss: 0.2334 - accuracy: 0.8936 - val_loss: 0.4776 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00658: val_loss did not improve from 0.43662\n",
      "Epoch 659/3000\n",
      "13/13 - 0s - loss: 0.2240 - accuracy: 0.9014 - val_loss: 0.4592 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00659: val_loss did not improve from 0.43662\n",
      "Epoch 660/3000\n",
      "13/13 - 0s - loss: 0.2567 - accuracy: 0.8794 - val_loss: 0.5114 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00660: val_loss did not improve from 0.43662\n",
      "Epoch 661/3000\n",
      "13/13 - 0s - loss: 0.2315 - accuracy: 0.8923 - val_loss: 0.4467 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00661: val_loss did not improve from 0.43662\n",
      "Epoch 662/3000\n",
      "13/13 - 0s - loss: 0.2376 - accuracy: 0.8846 - val_loss: 0.4873 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00662: val_loss did not improve from 0.43662\n",
      "Epoch 663/3000\n",
      "13/13 - 0s - loss: 0.2375 - accuracy: 0.8820 - val_loss: 0.4605 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00663: val_loss did not improve from 0.43662\n",
      "Epoch 664/3000\n",
      "13/13 - 0s - loss: 0.2196 - accuracy: 0.8936 - val_loss: 0.4568 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00664: val_loss did not improve from 0.43662\n",
      "Epoch 665/3000\n",
      "13/13 - 0s - loss: 0.2223 - accuracy: 0.8936 - val_loss: 0.4723 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00665: val_loss did not improve from 0.43662\n",
      "Epoch 666/3000\n",
      "13/13 - 0s - loss: 0.2237 - accuracy: 0.9040 - val_loss: 0.4747 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00666: val_loss did not improve from 0.43662\n",
      "Epoch 667/3000\n",
      "13/13 - 0s - loss: 0.2577 - accuracy: 0.8781 - val_loss: 0.4984 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00667: val_loss did not improve from 0.43662\n",
      "Epoch 668/3000\n",
      "13/13 - 0s - loss: 0.2330 - accuracy: 0.8936 - val_loss: 0.4659 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00668: val_loss did not improve from 0.43662\n",
      "Epoch 669/3000\n",
      "13/13 - 0s - loss: 0.2248 - accuracy: 0.8923 - val_loss: 0.4878 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00669: val_loss did not improve from 0.43662\n",
      "Epoch 670/3000\n",
      "13/13 - 0s - loss: 0.2174 - accuracy: 0.9027 - val_loss: 0.4707 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00670: val_loss did not improve from 0.43662\n",
      "Epoch 671/3000\n",
      "13/13 - 0s - loss: 0.2159 - accuracy: 0.8988 - val_loss: 0.4607 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00671: val_loss did not improve from 0.43662\n",
      "Epoch 672/3000\n",
      "13/13 - 0s - loss: 0.2163 - accuracy: 0.9014 - val_loss: 0.4701 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00672: val_loss did not improve from 0.43662\n",
      "Epoch 673/3000\n",
      "13/13 - 0s - loss: 0.2142 - accuracy: 0.9014 - val_loss: 0.4594 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00673: val_loss did not improve from 0.43662\n",
      "Epoch 674/3000\n",
      "13/13 - 0s - loss: 0.2170 - accuracy: 0.9001 - val_loss: 0.4575 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00674: val_loss did not improve from 0.43662\n",
      "Epoch 675/3000\n",
      "13/13 - 0s - loss: 0.2142 - accuracy: 0.9014 - val_loss: 0.4707 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00675: val_loss did not improve from 0.43662\n",
      "Epoch 676/3000\n",
      "13/13 - 0s - loss: 0.2191 - accuracy: 0.8988 - val_loss: 0.4551 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00676: val_loss did not improve from 0.43662\n",
      "Epoch 677/3000\n",
      "13/13 - 0s - loss: 0.2649 - accuracy: 0.8911 - val_loss: 0.4437 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00677: val_loss did not improve from 0.43662\n",
      "Epoch 678/3000\n",
      "13/13 - 0s - loss: 0.2415 - accuracy: 0.8988 - val_loss: 0.4687 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00678: val_loss did not improve from 0.43662\n",
      "Epoch 679/3000\n",
      "13/13 - 0s - loss: 0.2206 - accuracy: 0.8936 - val_loss: 0.4723 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00679: val_loss did not improve from 0.43662\n",
      "Epoch 680/3000\n",
      "13/13 - 0s - loss: 0.2174 - accuracy: 0.9027 - val_loss: 0.4746 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00680: val_loss did not improve from 0.43662\n",
      "Epoch 681/3000\n",
      "13/13 - 0s - loss: 0.2305 - accuracy: 0.8898 - val_loss: 0.4777 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00681: val_loss did not improve from 0.43662\n",
      "Epoch 682/3000\n",
      "13/13 - 0s - loss: 0.2462 - accuracy: 0.8846 - val_loss: 0.4701 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00682: val_loss did not improve from 0.43662\n",
      "Epoch 683/3000\n",
      "13/13 - 0s - loss: 0.2371 - accuracy: 0.8885 - val_loss: 0.4703 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00683: val_loss did not improve from 0.43662\n",
      "Epoch 684/3000\n",
      "13/13 - 0s - loss: 0.2323 - accuracy: 0.8833 - val_loss: 0.4844 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00684: val_loss did not improve from 0.43662\n",
      "Epoch 685/3000\n",
      "13/13 - 0s - loss: 0.2298 - accuracy: 0.8923 - val_loss: 0.4751 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00685: val_loss did not improve from 0.43662\n",
      "Epoch 686/3000\n",
      "13/13 - 0s - loss: 0.2248 - accuracy: 0.8988 - val_loss: 0.4588 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00686: val_loss did not improve from 0.43662\n",
      "Epoch 687/3000\n",
      "13/13 - 0s - loss: 0.2335 - accuracy: 0.8988 - val_loss: 0.4526 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00687: val_loss did not improve from 0.43662\n",
      "Epoch 688/3000\n",
      "13/13 - 0s - loss: 0.2260 - accuracy: 0.8885 - val_loss: 0.4591 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00688: val_loss did not improve from 0.43662\n",
      "Epoch 689/3000\n",
      "13/13 - 0s - loss: 0.2270 - accuracy: 0.9027 - val_loss: 0.4533 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00689: val_loss did not improve from 0.43662\n",
      "Epoch 690/3000\n",
      "13/13 - 0s - loss: 0.2324 - accuracy: 0.8898 - val_loss: 0.4794 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00690: val_loss did not improve from 0.43662\n",
      "Epoch 691/3000\n",
      "13/13 - 0s - loss: 0.2379 - accuracy: 0.8794 - val_loss: 0.4752 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00691: val_loss did not improve from 0.43662\n",
      "Epoch 692/3000\n",
      "13/13 - 0s - loss: 0.2200 - accuracy: 0.8962 - val_loss: 0.4692 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00692: val_loss did not improve from 0.43662\n",
      "Epoch 693/3000\n",
      "13/13 - 0s - loss: 0.2448 - accuracy: 0.8885 - val_loss: 0.4640 - val_accuracy: 0.8653\n",
      "\n",
      "Epoch 00693: val_loss did not improve from 0.43662\n",
      "Epoch 694/3000\n",
      "13/13 - 0s - loss: 0.2279 - accuracy: 0.8911 - val_loss: 0.4748 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00694: val_loss did not improve from 0.43662\n",
      "Epoch 695/3000\n",
      "13/13 - 0s - loss: 0.2217 - accuracy: 0.8988 - val_loss: 0.4593 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00695: val_loss did not improve from 0.43662\n",
      "Epoch 696/3000\n",
      "13/13 - 0s - loss: 0.2236 - accuracy: 0.9014 - val_loss: 0.4824 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00696: val_loss did not improve from 0.43662\n",
      "Epoch 697/3000\n",
      "13/13 - 0s - loss: 0.2305 - accuracy: 0.9014 - val_loss: 0.4615 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00697: val_loss did not improve from 0.43662\n",
      "Epoch 698/3000\n",
      "13/13 - 0s - loss: 0.2531 - accuracy: 0.8768 - val_loss: 0.4708 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00698: val_loss did not improve from 0.43662\n",
      "Epoch 699/3000\n",
      "13/13 - 0s - loss: 0.2452 - accuracy: 0.8820 - val_loss: 0.5111 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00699: val_loss did not improve from 0.43662\n",
      "Epoch 700/3000\n",
      "13/13 - 0s - loss: 0.2406 - accuracy: 0.8807 - val_loss: 0.4612 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00700: val_loss did not improve from 0.43662\n",
      "Epoch 701/3000\n",
      "13/13 - 0s - loss: 0.2475 - accuracy: 0.8742 - val_loss: 0.4951 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00701: val_loss did not improve from 0.43662\n",
      "Epoch 702/3000\n",
      "13/13 - 0s - loss: 0.2307 - accuracy: 0.8898 - val_loss: 0.4639 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00702: val_loss did not improve from 0.43662\n",
      "Epoch 703/3000\n",
      "13/13 - 0s - loss: 0.2219 - accuracy: 0.9014 - val_loss: 0.4591 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00703: val_loss did not improve from 0.43662\n",
      "Epoch 704/3000\n",
      "13/13 - 0s - loss: 0.2372 - accuracy: 0.8885 - val_loss: 0.4849 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00704: val_loss did not improve from 0.43662\n",
      "Epoch 705/3000\n",
      "13/13 - 0s - loss: 0.2207 - accuracy: 0.8898 - val_loss: 0.4697 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00705: val_loss did not improve from 0.43662\n",
      "Epoch 706/3000\n",
      "13/13 - 0s - loss: 0.2161 - accuracy: 0.8962 - val_loss: 0.4741 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00706: val_loss did not improve from 0.43662\n",
      "Epoch 707/3000\n",
      "13/13 - 0s - loss: 0.2284 - accuracy: 0.8936 - val_loss: 0.4623 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00707: val_loss did not improve from 0.43662\n",
      "Epoch 708/3000\n",
      "13/13 - 0s - loss: 0.2736 - accuracy: 0.8846 - val_loss: 0.4359 - val_accuracy: 0.8653\n",
      "\n",
      "Epoch 00708: val_loss improved from 0.43662 to 0.43590, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 709/3000\n",
      "13/13 - 0s - loss: 0.2625 - accuracy: 0.8923 - val_loss: 0.4444 - val_accuracy: 0.8653\n",
      "\n",
      "Epoch 00709: val_loss did not improve from 0.43590\n",
      "Epoch 710/3000\n",
      "13/13 - 0s - loss: 0.2334 - accuracy: 0.9001 - val_loss: 0.4633 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00710: val_loss did not improve from 0.43590\n",
      "Epoch 711/3000\n",
      "13/13 - 0s - loss: 0.2276 - accuracy: 0.9001 - val_loss: 0.4738 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00711: val_loss did not improve from 0.43590\n",
      "Epoch 712/3000\n",
      "13/13 - 0s - loss: 0.2515 - accuracy: 0.8820 - val_loss: 0.4546 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00712: val_loss did not improve from 0.43590\n",
      "Epoch 713/3000\n",
      "13/13 - 0s - loss: 0.2349 - accuracy: 0.9027 - val_loss: 0.4693 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00713: val_loss did not improve from 0.43590\n",
      "Epoch 714/3000\n",
      "13/13 - 0s - loss: 0.2296 - accuracy: 0.9001 - val_loss: 0.4474 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00714: val_loss did not improve from 0.43590\n",
      "Epoch 715/3000\n",
      "13/13 - 0s - loss: 0.2350 - accuracy: 0.9001 - val_loss: 0.4709 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00715: val_loss did not improve from 0.43590\n",
      "Epoch 716/3000\n",
      "13/13 - 0s - loss: 0.2368 - accuracy: 0.8949 - val_loss: 0.4286 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00716: val_loss improved from 0.43590 to 0.42863, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 717/3000\n",
      "13/13 - 0s - loss: 0.2397 - accuracy: 0.8936 - val_loss: 0.4480 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00717: val_loss did not improve from 0.42863\n",
      "Epoch 718/3000\n",
      "13/13 - 0s - loss: 0.2311 - accuracy: 0.8949 - val_loss: 0.4590 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00718: val_loss did not improve from 0.42863\n",
      "Epoch 719/3000\n",
      "13/13 - 0s - loss: 0.2287 - accuracy: 0.8859 - val_loss: 0.4594 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00719: val_loss did not improve from 0.42863\n",
      "Epoch 720/3000\n",
      "13/13 - 0s - loss: 0.2161 - accuracy: 0.8975 - val_loss: 0.4643 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00720: val_loss did not improve from 0.42863\n",
      "Epoch 721/3000\n",
      "13/13 - 0s - loss: 0.2141 - accuracy: 0.8975 - val_loss: 0.4512 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00721: val_loss did not improve from 0.42863\n",
      "Epoch 722/3000\n",
      "13/13 - 0s - loss: 0.2481 - accuracy: 0.8962 - val_loss: 0.4321 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00722: val_loss did not improve from 0.42863\n",
      "Epoch 723/3000\n",
      "13/13 - 0s - loss: 0.2499 - accuracy: 0.8923 - val_loss: 0.4789 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 00723: val_loss did not improve from 0.42863\n",
      "Epoch 724/3000\n",
      "13/13 - 0s - loss: 0.2498 - accuracy: 0.8885 - val_loss: 0.4643 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00724: val_loss did not improve from 0.42863\n",
      "Epoch 725/3000\n",
      "13/13 - 0s - loss: 0.2576 - accuracy: 0.8820 - val_loss: 0.4507 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00725: val_loss did not improve from 0.42863\n",
      "Epoch 726/3000\n",
      "13/13 - 0s - loss: 0.2389 - accuracy: 0.8846 - val_loss: 0.4331 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00726: val_loss did not improve from 0.42863\n",
      "Epoch 727/3000\n",
      "13/13 - 0s - loss: 0.2148 - accuracy: 0.8988 - val_loss: 0.4539 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00727: val_loss did not improve from 0.42863\n",
      "Epoch 728/3000\n",
      "13/13 - 0s - loss: 0.2150 - accuracy: 0.8962 - val_loss: 0.4562 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00728: val_loss did not improve from 0.42863\n",
      "Epoch 729/3000\n",
      "13/13 - 0s - loss: 0.2131 - accuracy: 0.8975 - val_loss: 0.4566 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00729: val_loss did not improve from 0.42863\n",
      "Epoch 730/3000\n",
      "13/13 - 0s - loss: 0.2131 - accuracy: 0.8949 - val_loss: 0.4587 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00730: val_loss did not improve from 0.42863\n",
      "Epoch 731/3000\n",
      "13/13 - 0s - loss: 0.2175 - accuracy: 0.8988 - val_loss: 0.4542 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00731: val_loss did not improve from 0.42863\n",
      "Epoch 732/3000\n",
      "13/13 - 0s - loss: 0.2202 - accuracy: 0.8949 - val_loss: 0.4530 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00732: val_loss did not improve from 0.42863\n",
      "Epoch 733/3000\n",
      "13/13 - 0s - loss: 0.2279 - accuracy: 0.9014 - val_loss: 0.4507 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00733: val_loss did not improve from 0.42863\n",
      "Epoch 734/3000\n",
      "13/13 - 0s - loss: 0.2201 - accuracy: 0.8988 - val_loss: 0.4518 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00734: val_loss did not improve from 0.42863\n",
      "Epoch 735/3000\n",
      "13/13 - 0s - loss: 0.2157 - accuracy: 0.9014 - val_loss: 0.4465 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00735: val_loss did not improve from 0.42863\n",
      "Epoch 736/3000\n",
      "13/13 - 0s - loss: 0.2143 - accuracy: 0.9001 - val_loss: 0.4585 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00736: val_loss did not improve from 0.42863\n",
      "Epoch 737/3000\n",
      "13/13 - 0s - loss: 0.2148 - accuracy: 0.8988 - val_loss: 0.4546 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00737: val_loss did not improve from 0.42863\n",
      "Epoch 738/3000\n",
      "13/13 - 0s - loss: 0.2179 - accuracy: 0.8975 - val_loss: 0.4495 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00738: val_loss did not improve from 0.42863\n",
      "Epoch 739/3000\n",
      "13/13 - 0s - loss: 0.2121 - accuracy: 0.9014 - val_loss: 0.4554 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00739: val_loss did not improve from 0.42863\n",
      "Epoch 740/3000\n",
      "13/13 - 0s - loss: 0.2133 - accuracy: 0.8988 - val_loss: 0.4552 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00740: val_loss did not improve from 0.42863\n",
      "Epoch 741/3000\n",
      "13/13 - 0s - loss: 0.2119 - accuracy: 0.9001 - val_loss: 0.4584 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00741: val_loss did not improve from 0.42863\n",
      "Epoch 742/3000\n",
      "13/13 - 0s - loss: 0.2131 - accuracy: 0.8949 - val_loss: 0.4591 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00742: val_loss did not improve from 0.42863\n",
      "Epoch 743/3000\n",
      "13/13 - 0s - loss: 0.2142 - accuracy: 0.9014 - val_loss: 0.4815 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00743: val_loss did not improve from 0.42863\n",
      "Epoch 744/3000\n",
      "13/13 - 0s - loss: 0.2133 - accuracy: 0.9001 - val_loss: 0.4729 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00744: val_loss did not improve from 0.42863\n",
      "Epoch 745/3000\n",
      "13/13 - 0s - loss: 0.2325 - accuracy: 0.9001 - val_loss: 0.4592 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00745: val_loss did not improve from 0.42863\n",
      "Epoch 746/3000\n",
      "13/13 - 0s - loss: 0.2329 - accuracy: 0.8885 - val_loss: 0.4463 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00746: val_loss did not improve from 0.42863\n",
      "Epoch 747/3000\n",
      "13/13 - 0s - loss: 0.2185 - accuracy: 0.9014 - val_loss: 0.4681 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00747: val_loss did not improve from 0.42863\n",
      "Epoch 748/3000\n",
      "13/13 - 0s - loss: 0.2169 - accuracy: 0.8911 - val_loss: 0.4505 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00748: val_loss did not improve from 0.42863\n",
      "Epoch 749/3000\n",
      "13/13 - 0s - loss: 0.2172 - accuracy: 0.9001 - val_loss: 0.4624 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00749: val_loss did not improve from 0.42863\n",
      "Epoch 750/3000\n",
      "13/13 - 0s - loss: 0.2132 - accuracy: 0.9014 - val_loss: 0.4467 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00750: val_loss did not improve from 0.42863\n",
      "Epoch 751/3000\n",
      "13/13 - 0s - loss: 0.2131 - accuracy: 0.9014 - val_loss: 0.4567 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00751: val_loss did not improve from 0.42863\n",
      "Epoch 752/3000\n",
      "13/13 - 0s - loss: 0.2121 - accuracy: 0.9001 - val_loss: 0.4574 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00752: val_loss did not improve from 0.42863\n",
      "Epoch 753/3000\n",
      "13/13 - 0s - loss: 0.2107 - accuracy: 0.9027 - val_loss: 0.4504 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00753: val_loss did not improve from 0.42863\n",
      "Epoch 754/3000\n",
      "13/13 - 0s - loss: 0.2118 - accuracy: 0.9001 - val_loss: 0.4597 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00754: val_loss did not improve from 0.42863\n",
      "Epoch 755/3000\n",
      "13/13 - 0s - loss: 0.2117 - accuracy: 0.8988 - val_loss: 0.4532 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00755: val_loss did not improve from 0.42863\n",
      "Epoch 756/3000\n",
      "13/13 - 0s - loss: 0.2203 - accuracy: 0.8975 - val_loss: 0.4549 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00756: val_loss did not improve from 0.42863\n",
      "Epoch 757/3000\n",
      "13/13 - 0s - loss: 0.2186 - accuracy: 0.8962 - val_loss: 0.4444 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00757: val_loss did not improve from 0.42863\n",
      "Epoch 758/3000\n",
      "13/13 - 0s - loss: 0.2202 - accuracy: 0.8988 - val_loss: 0.4648 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00758: val_loss did not improve from 0.42863\n",
      "Epoch 759/3000\n",
      "13/13 - 0s - loss: 0.2182 - accuracy: 0.8962 - val_loss: 0.4507 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00759: val_loss did not improve from 0.42863\n",
      "Epoch 760/3000\n",
      "13/13 - 0s - loss: 0.2177 - accuracy: 0.8975 - val_loss: 0.4520 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00760: val_loss did not improve from 0.42863\n",
      "Epoch 761/3000\n",
      "13/13 - 0s - loss: 0.2150 - accuracy: 0.9001 - val_loss: 0.4565 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00761: val_loss did not improve from 0.42863\n",
      "Epoch 762/3000\n",
      "13/13 - 0s - loss: 0.2110 - accuracy: 0.9001 - val_loss: 0.4584 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00762: val_loss did not improve from 0.42863\n",
      "Epoch 763/3000\n",
      "13/13 - 0s - loss: 0.2149 - accuracy: 0.8936 - val_loss: 0.4626 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00763: val_loss did not improve from 0.42863\n",
      "Epoch 764/3000\n",
      "13/13 - 0s - loss: 0.2169 - accuracy: 0.9014 - val_loss: 0.4678 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00764: val_loss did not improve from 0.42863\n",
      "Epoch 765/3000\n",
      "13/13 - 0s - loss: 0.2147 - accuracy: 0.9001 - val_loss: 0.4583 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00765: val_loss did not improve from 0.42863\n",
      "Epoch 766/3000\n",
      "13/13 - 0s - loss: 0.2205 - accuracy: 0.8988 - val_loss: 0.4474 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00766: val_loss did not improve from 0.42863\n",
      "Epoch 767/3000\n",
      "13/13 - 0s - loss: 0.2367 - accuracy: 0.8885 - val_loss: 0.4296 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00767: val_loss did not improve from 0.42863\n",
      "Epoch 768/3000\n",
      "13/13 - 0s - loss: 0.2245 - accuracy: 0.8911 - val_loss: 0.4537 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00768: val_loss did not improve from 0.42863\n",
      "Epoch 769/3000\n",
      "13/13 - 0s - loss: 0.2155 - accuracy: 0.8949 - val_loss: 0.4508 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00769: val_loss did not improve from 0.42863\n",
      "Epoch 770/3000\n",
      "13/13 - 0s - loss: 0.2138 - accuracy: 0.8988 - val_loss: 0.4489 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00770: val_loss did not improve from 0.42863\n",
      "Epoch 771/3000\n",
      "13/13 - 0s - loss: 0.2184 - accuracy: 0.8923 - val_loss: 0.4518 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00771: val_loss did not improve from 0.42863\n",
      "Epoch 772/3000\n",
      "13/13 - 0s - loss: 0.2195 - accuracy: 0.9001 - val_loss: 0.4551 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00772: val_loss did not improve from 0.42863\n",
      "Epoch 773/3000\n",
      "13/13 - 0s - loss: 0.2160 - accuracy: 0.8988 - val_loss: 0.4653 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00773: val_loss did not improve from 0.42863\n",
      "Epoch 774/3000\n",
      "13/13 - 0s - loss: 0.2282 - accuracy: 0.9014 - val_loss: 0.4656 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00774: val_loss did not improve from 0.42863\n",
      "Epoch 775/3000\n",
      "13/13 - 0s - loss: 0.2624 - accuracy: 0.8807 - val_loss: 0.4578 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00775: val_loss did not improve from 0.42863\n",
      "Epoch 776/3000\n",
      "13/13 - 0s - loss: 0.3256 - accuracy: 0.8729 - val_loss: 0.4425 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00776: val_loss did not improve from 0.42863\n",
      "Epoch 777/3000\n",
      "13/13 - 0s - loss: 0.2554 - accuracy: 0.8923 - val_loss: 0.4735 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00777: val_loss did not improve from 0.42863\n",
      "Epoch 778/3000\n",
      "13/13 - 0s - loss: 0.2332 - accuracy: 0.8911 - val_loss: 0.4474 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00778: val_loss did not improve from 0.42863\n",
      "Epoch 779/3000\n",
      "13/13 - 0s - loss: 0.2228 - accuracy: 0.8962 - val_loss: 0.4543 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00779: val_loss did not improve from 0.42863\n",
      "Epoch 780/3000\n",
      "13/13 - 0s - loss: 0.2136 - accuracy: 0.8988 - val_loss: 0.4455 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00780: val_loss did not improve from 0.42863\n",
      "Epoch 781/3000\n",
      "13/13 - 0s - loss: 0.2162 - accuracy: 0.8936 - val_loss: 0.4610 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00781: val_loss did not improve from 0.42863\n",
      "Epoch 782/3000\n",
      "13/13 - 0s - loss: 0.2184 - accuracy: 0.8988 - val_loss: 0.4598 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00782: val_loss did not improve from 0.42863\n",
      "Epoch 783/3000\n",
      "13/13 - 0s - loss: 0.2214 - accuracy: 0.8936 - val_loss: 0.4520 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00783: val_loss did not improve from 0.42863\n",
      "Epoch 784/3000\n",
      "13/13 - 0s - loss: 0.2175 - accuracy: 0.8988 - val_loss: 0.4628 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00784: val_loss did not improve from 0.42863\n",
      "Epoch 785/3000\n",
      "13/13 - 0s - loss: 0.2125 - accuracy: 0.9001 - val_loss: 0.4624 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00785: val_loss did not improve from 0.42863\n",
      "Epoch 786/3000\n",
      "13/13 - 0s - loss: 0.2148 - accuracy: 0.8975 - val_loss: 0.4548 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00786: val_loss did not improve from 0.42863\n",
      "Epoch 787/3000\n",
      "13/13 - 0s - loss: 0.2118 - accuracy: 0.8988 - val_loss: 0.4517 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00787: val_loss did not improve from 0.42863\n",
      "Epoch 788/3000\n",
      "13/13 - 0s - loss: 0.2126 - accuracy: 0.9040 - val_loss: 0.4594 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00788: val_loss did not improve from 0.42863\n",
      "Epoch 789/3000\n",
      "13/13 - 0s - loss: 0.2151 - accuracy: 0.8975 - val_loss: 0.4519 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00789: val_loss did not improve from 0.42863\n",
      "Epoch 790/3000\n",
      "13/13 - 0s - loss: 0.2130 - accuracy: 0.8962 - val_loss: 0.4556 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00790: val_loss did not improve from 0.42863\n",
      "Epoch 791/3000\n",
      "13/13 - 0s - loss: 0.2178 - accuracy: 0.9001 - val_loss: 0.4682 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00791: val_loss did not improve from 0.42863\n",
      "Epoch 792/3000\n",
      "13/13 - 0s - loss: 0.2409 - accuracy: 0.9001 - val_loss: 0.4884 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00792: val_loss did not improve from 0.42863\n",
      "Epoch 793/3000\n",
      "13/13 - 0s - loss: 0.2550 - accuracy: 0.8820 - val_loss: 0.4701 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00793: val_loss did not improve from 0.42863\n",
      "Epoch 794/3000\n",
      "13/13 - 0s - loss: 0.2228 - accuracy: 0.9014 - val_loss: 0.4738 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00794: val_loss did not improve from 0.42863\n",
      "Epoch 795/3000\n",
      "13/13 - 0s - loss: 0.2187 - accuracy: 0.8949 - val_loss: 0.4729 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00795: val_loss did not improve from 0.42863\n",
      "Epoch 796/3000\n",
      "13/13 - 0s - loss: 0.2275 - accuracy: 0.8898 - val_loss: 0.4587 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00796: val_loss did not improve from 0.42863\n",
      "Epoch 797/3000\n",
      "13/13 - 0s - loss: 0.2245 - accuracy: 0.8923 - val_loss: 0.4608 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00797: val_loss did not improve from 0.42863\n",
      "Epoch 798/3000\n",
      "13/13 - 0s - loss: 0.2258 - accuracy: 0.8949 - val_loss: 0.4721 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00798: val_loss did not improve from 0.42863\n",
      "Epoch 799/3000\n",
      "13/13 - 0s - loss: 0.2438 - accuracy: 0.8820 - val_loss: 0.4771 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00799: val_loss did not improve from 0.42863\n",
      "Epoch 800/3000\n",
      "13/13 - 0s - loss: 0.2308 - accuracy: 0.8885 - val_loss: 0.4582 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00800: val_loss did not improve from 0.42863\n",
      "Epoch 801/3000\n",
      "13/13 - 0s - loss: 0.2196 - accuracy: 0.9014 - val_loss: 0.4673 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00801: val_loss did not improve from 0.42863\n",
      "Epoch 802/3000\n",
      "13/13 - 0s - loss: 0.2262 - accuracy: 0.8923 - val_loss: 0.5170 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00802: val_loss did not improve from 0.42863\n",
      "Epoch 803/3000\n",
      "13/13 - 0s - loss: 0.2314 - accuracy: 0.8936 - val_loss: 0.4747 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00803: val_loss did not improve from 0.42863\n",
      "Epoch 804/3000\n",
      "13/13 - 0s - loss: 0.2261 - accuracy: 0.8923 - val_loss: 0.4550 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00804: val_loss did not improve from 0.42863\n",
      "Epoch 805/3000\n",
      "13/13 - 0s - loss: 0.2325 - accuracy: 0.8949 - val_loss: 0.4607 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00805: val_loss did not improve from 0.42863\n",
      "Epoch 806/3000\n",
      "13/13 - 0s - loss: 0.2305 - accuracy: 0.8859 - val_loss: 0.4614 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00806: val_loss did not improve from 0.42863\n",
      "Epoch 807/3000\n",
      "13/13 - 0s - loss: 0.2447 - accuracy: 0.8962 - val_loss: 0.4797 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00807: val_loss did not improve from 0.42863\n",
      "Epoch 808/3000\n",
      "13/13 - 0s - loss: 0.2212 - accuracy: 0.8988 - val_loss: 0.4602 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00808: val_loss did not improve from 0.42863\n",
      "Epoch 809/3000\n",
      "13/13 - 0s - loss: 0.2189 - accuracy: 0.8911 - val_loss: 0.4627 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00809: val_loss did not improve from 0.42863\n",
      "Epoch 810/3000\n",
      "13/13 - 0s - loss: 0.2163 - accuracy: 0.8988 - val_loss: 0.4546 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00810: val_loss did not improve from 0.42863\n",
      "Epoch 811/3000\n",
      "13/13 - 0s - loss: 0.2139 - accuracy: 0.9040 - val_loss: 0.4547 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00811: val_loss did not improve from 0.42863\n",
      "Epoch 812/3000\n",
      "13/13 - 0s - loss: 0.2105 - accuracy: 0.9014 - val_loss: 0.4607 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00812: val_loss did not improve from 0.42863\n",
      "Epoch 813/3000\n",
      "13/13 - 0s - loss: 0.2124 - accuracy: 0.9014 - val_loss: 0.4558 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00813: val_loss did not improve from 0.42863\n",
      "Epoch 814/3000\n",
      "13/13 - 0s - loss: 0.2137 - accuracy: 0.9001 - val_loss: 0.4671 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00814: val_loss did not improve from 0.42863\n",
      "Epoch 815/3000\n",
      "13/13 - 0s - loss: 0.2129 - accuracy: 0.9014 - val_loss: 0.4538 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00815: val_loss did not improve from 0.42863\n",
      "Epoch 816/3000\n",
      "13/13 - 0s - loss: 0.2348 - accuracy: 0.8872 - val_loss: 0.4650 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00816: val_loss did not improve from 0.42863\n",
      "Epoch 817/3000\n",
      "13/13 - 0s - loss: 0.2226 - accuracy: 0.8833 - val_loss: 0.4768 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00817: val_loss did not improve from 0.42863\n",
      "Epoch 818/3000\n",
      "13/13 - 0s - loss: 0.2372 - accuracy: 0.9001 - val_loss: 0.5077 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00818: val_loss did not improve from 0.42863\n",
      "Epoch 819/3000\n",
      "13/13 - 0s - loss: 0.2185 - accuracy: 0.9014 - val_loss: 0.4785 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00819: val_loss did not improve from 0.42863\n",
      "Epoch 820/3000\n",
      "13/13 - 0s - loss: 0.2169 - accuracy: 0.9027 - val_loss: 0.4707 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00820: val_loss did not improve from 0.42863\n",
      "Epoch 821/3000\n",
      "13/13 - 0s - loss: 0.2162 - accuracy: 0.8962 - val_loss: 0.4722 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00821: val_loss did not improve from 0.42863\n",
      "Epoch 822/3000\n",
      "13/13 - 0s - loss: 0.2207 - accuracy: 0.9001 - val_loss: 0.5097 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00822: val_loss did not improve from 0.42863\n",
      "Epoch 823/3000\n",
      "13/13 - 0s - loss: 0.2246 - accuracy: 0.8911 - val_loss: 0.4788 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00823: val_loss did not improve from 0.42863\n",
      "Epoch 824/3000\n",
      "13/13 - 0s - loss: 0.2221 - accuracy: 0.9027 - val_loss: 0.4671 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00824: val_loss did not improve from 0.42863\n",
      "Epoch 825/3000\n",
      "13/13 - 0s - loss: 0.2185 - accuracy: 0.8988 - val_loss: 0.4559 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00825: val_loss did not improve from 0.42863\n",
      "Epoch 826/3000\n",
      "13/13 - 0s - loss: 0.2182 - accuracy: 0.8949 - val_loss: 0.4741 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00826: val_loss did not improve from 0.42863\n",
      "Epoch 827/3000\n",
      "13/13 - 0s - loss: 0.2332 - accuracy: 0.8820 - val_loss: 0.4709 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00827: val_loss did not improve from 0.42863\n",
      "Epoch 828/3000\n",
      "13/13 - 0s - loss: 0.2214 - accuracy: 0.8975 - val_loss: 0.4573 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00828: val_loss did not improve from 0.42863\n",
      "Epoch 829/3000\n",
      "13/13 - 0s - loss: 0.2126 - accuracy: 0.8975 - val_loss: 0.4450 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00829: val_loss did not improve from 0.42863\n",
      "Epoch 830/3000\n",
      "13/13 - 0s - loss: 0.2243 - accuracy: 0.9001 - val_loss: 0.4637 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00830: val_loss did not improve from 0.42863\n",
      "Epoch 831/3000\n",
      "13/13 - 0s - loss: 0.2472 - accuracy: 0.9027 - val_loss: 0.4779 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00831: val_loss did not improve from 0.42863\n",
      "Epoch 832/3000\n",
      "13/13 - 0s - loss: 0.2256 - accuracy: 0.9001 - val_loss: 0.4431 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00832: val_loss did not improve from 0.42863\n",
      "Epoch 833/3000\n",
      "13/13 - 0s - loss: 0.2158 - accuracy: 0.9027 - val_loss: 0.4430 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00833: val_loss did not improve from 0.42863\n",
      "Epoch 834/3000\n",
      "13/13 - 0s - loss: 0.2156 - accuracy: 0.9040 - val_loss: 0.4447 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00834: val_loss did not improve from 0.42863\n",
      "Epoch 835/3000\n",
      "13/13 - 0s - loss: 0.2163 - accuracy: 0.9027 - val_loss: 0.4533 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00835: val_loss did not improve from 0.42863\n",
      "Epoch 836/3000\n",
      "13/13 - 0s - loss: 0.2130 - accuracy: 0.9014 - val_loss: 0.4626 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00836: val_loss did not improve from 0.42863\n",
      "Epoch 837/3000\n",
      "13/13 - 0s - loss: 0.2300 - accuracy: 0.8794 - val_loss: 0.4428 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00837: val_loss did not improve from 0.42863\n",
      "Epoch 838/3000\n",
      "13/13 - 0s - loss: 0.2259 - accuracy: 0.8923 - val_loss: 0.4633 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00838: val_loss did not improve from 0.42863\n",
      "Epoch 839/3000\n",
      "13/13 - 0s - loss: 0.2234 - accuracy: 0.8975 - val_loss: 0.4479 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00839: val_loss did not improve from 0.42863\n",
      "Epoch 840/3000\n",
      "13/13 - 0s - loss: 0.2273 - accuracy: 0.8911 - val_loss: 0.4803 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00840: val_loss did not improve from 0.42863\n",
      "Epoch 841/3000\n",
      "13/13 - 0s - loss: 0.2146 - accuracy: 0.8975 - val_loss: 0.4681 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00841: val_loss did not improve from 0.42863\n",
      "Epoch 842/3000\n",
      "13/13 - 0s - loss: 0.2169 - accuracy: 0.8988 - val_loss: 0.4866 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00842: val_loss did not improve from 0.42863\n",
      "Epoch 843/3000\n",
      "13/13 - 0s - loss: 0.2125 - accuracy: 0.9027 - val_loss: 0.4683 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00843: val_loss did not improve from 0.42863\n",
      "Epoch 844/3000\n",
      "13/13 - 0s - loss: 0.2296 - accuracy: 0.8898 - val_loss: 0.4788 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00844: val_loss did not improve from 0.42863\n",
      "Epoch 845/3000\n",
      "13/13 - 0s - loss: 0.2183 - accuracy: 0.8923 - val_loss: 0.4643 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00845: val_loss did not improve from 0.42863\n",
      "Epoch 846/3000\n",
      "13/13 - 0s - loss: 0.2191 - accuracy: 0.8936 - val_loss: 0.4413 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00846: val_loss did not improve from 0.42863\n",
      "Epoch 847/3000\n",
      "13/13 - 0s - loss: 0.2179 - accuracy: 0.8962 - val_loss: 0.4494 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00847: val_loss did not improve from 0.42863\n",
      "Epoch 848/3000\n",
      "13/13 - 0s - loss: 0.2136 - accuracy: 0.9001 - val_loss: 0.4575 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00848: val_loss did not improve from 0.42863\n",
      "Epoch 849/3000\n",
      "13/13 - 0s - loss: 0.2323 - accuracy: 0.8911 - val_loss: 0.4475 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00849: val_loss did not improve from 0.42863\n",
      "Epoch 850/3000\n",
      "13/13 - 0s - loss: 0.2247 - accuracy: 0.8923 - val_loss: 0.4570 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00850: val_loss did not improve from 0.42863\n",
      "Epoch 851/3000\n",
      "13/13 - 0s - loss: 0.2264 - accuracy: 0.9053 - val_loss: 0.4541 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00851: val_loss did not improve from 0.42863\n",
      "Epoch 852/3000\n",
      "13/13 - 0s - loss: 0.2252 - accuracy: 0.8949 - val_loss: 0.4466 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00852: val_loss did not improve from 0.42863\n",
      "Epoch 853/3000\n",
      "13/13 - 0s - loss: 0.2199 - accuracy: 0.9001 - val_loss: 0.4439 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00853: val_loss did not improve from 0.42863\n",
      "Epoch 854/3000\n",
      "13/13 - 0s - loss: 0.2331 - accuracy: 0.8923 - val_loss: 0.4785 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00854: val_loss did not improve from 0.42863\n",
      "Epoch 855/3000\n",
      "13/13 - 0s - loss: 0.2627 - accuracy: 0.8923 - val_loss: 0.4618 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00855: val_loss did not improve from 0.42863\n",
      "Epoch 856/3000\n",
      "13/13 - 0s - loss: 0.2275 - accuracy: 0.8949 - val_loss: 0.4736 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00856: val_loss did not improve from 0.42863\n",
      "Epoch 857/3000\n",
      "13/13 - 0s - loss: 0.2304 - accuracy: 0.8962 - val_loss: 0.4783 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00857: val_loss did not improve from 0.42863\n",
      "Epoch 858/3000\n",
      "13/13 - 0s - loss: 0.2246 - accuracy: 0.8988 - val_loss: 0.4629 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00858: val_loss did not improve from 0.42863\n",
      "Epoch 859/3000\n",
      "13/13 - 0s - loss: 0.2224 - accuracy: 0.8923 - val_loss: 0.4736 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00859: val_loss did not improve from 0.42863\n",
      "Epoch 860/3000\n",
      "13/13 - 0s - loss: 0.2276 - accuracy: 0.9014 - val_loss: 0.4710 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00860: val_loss did not improve from 0.42863\n",
      "Epoch 861/3000\n",
      "13/13 - 0s - loss: 0.2300 - accuracy: 0.9027 - val_loss: 0.4695 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00861: val_loss did not improve from 0.42863\n",
      "Epoch 862/3000\n",
      "13/13 - 0s - loss: 0.2527 - accuracy: 0.8936 - val_loss: 0.4987 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00862: val_loss did not improve from 0.42863\n",
      "Epoch 863/3000\n",
      "13/13 - 0s - loss: 0.2427 - accuracy: 0.8923 - val_loss: 0.4845 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00863: val_loss did not improve from 0.42863\n",
      "Epoch 864/3000\n",
      "13/13 - 0s - loss: 0.2339 - accuracy: 0.8988 - val_loss: 0.4821 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00864: val_loss did not improve from 0.42863\n",
      "Epoch 865/3000\n",
      "13/13 - 0s - loss: 0.2172 - accuracy: 0.9014 - val_loss: 0.4641 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00865: val_loss did not improve from 0.42863\n",
      "Epoch 866/3000\n",
      "13/13 - 0s - loss: 0.2180 - accuracy: 0.9014 - val_loss: 0.4530 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00866: val_loss did not improve from 0.42863\n",
      "Epoch 867/3000\n",
      "13/13 - 0s - loss: 0.2368 - accuracy: 0.8885 - val_loss: 0.4584 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00867: val_loss did not improve from 0.42863\n",
      "Epoch 868/3000\n",
      "13/13 - 0s - loss: 0.2228 - accuracy: 0.8962 - val_loss: 0.4525 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00868: val_loss did not improve from 0.42863\n",
      "Epoch 869/3000\n",
      "13/13 - 0s - loss: 0.2185 - accuracy: 0.8988 - val_loss: 0.4441 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00869: val_loss did not improve from 0.42863\n",
      "Epoch 870/3000\n",
      "13/13 - 0s - loss: 0.2162 - accuracy: 0.9001 - val_loss: 0.4573 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00870: val_loss did not improve from 0.42863\n",
      "Epoch 871/3000\n",
      "13/13 - 0s - loss: 0.2180 - accuracy: 0.8949 - val_loss: 0.4548 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00871: val_loss did not improve from 0.42863\n",
      "Epoch 872/3000\n",
      "13/13 - 0s - loss: 0.2237 - accuracy: 0.8975 - val_loss: 0.4806 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00872: val_loss did not improve from 0.42863\n",
      "Epoch 873/3000\n",
      "13/13 - 0s - loss: 0.2287 - accuracy: 0.8846 - val_loss: 0.4409 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00873: val_loss did not improve from 0.42863\n",
      "Epoch 874/3000\n",
      "13/13 - 0s - loss: 0.2168 - accuracy: 0.8975 - val_loss: 0.4494 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00874: val_loss did not improve from 0.42863\n",
      "Epoch 875/3000\n",
      "13/13 - 0s - loss: 0.2143 - accuracy: 0.9001 - val_loss: 0.4368 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00875: val_loss did not improve from 0.42863\n",
      "Epoch 876/3000\n",
      "13/13 - 0s - loss: 0.2156 - accuracy: 0.9001 - val_loss: 0.4548 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00876: val_loss did not improve from 0.42863\n",
      "Epoch 877/3000\n",
      "13/13 - 0s - loss: 0.2218 - accuracy: 0.9001 - val_loss: 0.4426 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00877: val_loss did not improve from 0.42863\n",
      "Epoch 878/3000\n",
      "13/13 - 0s - loss: 0.2203 - accuracy: 0.8923 - val_loss: 0.4415 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00878: val_loss did not improve from 0.42863\n",
      "Epoch 879/3000\n",
      "13/13 - 0s - loss: 0.2158 - accuracy: 0.9027 - val_loss: 0.4480 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00879: val_loss did not improve from 0.42863\n",
      "Epoch 880/3000\n",
      "13/13 - 0s - loss: 0.2160 - accuracy: 0.9001 - val_loss: 0.4436 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00880: val_loss did not improve from 0.42863\n",
      "Epoch 881/3000\n",
      "13/13 - 0s - loss: 0.2100 - accuracy: 0.8975 - val_loss: 0.4510 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00881: val_loss did not improve from 0.42863\n",
      "Epoch 882/3000\n",
      "13/13 - 0s - loss: 0.2208 - accuracy: 0.8936 - val_loss: 0.4651 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00882: val_loss did not improve from 0.42863\n",
      "Epoch 883/3000\n",
      "13/13 - 0s - loss: 0.2183 - accuracy: 0.8923 - val_loss: 0.4542 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00883: val_loss did not improve from 0.42863\n",
      "Epoch 884/3000\n",
      "13/13 - 0s - loss: 0.2102 - accuracy: 0.9040 - val_loss: 0.4432 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00884: val_loss did not improve from 0.42863\n",
      "Epoch 885/3000\n",
      "13/13 - 0s - loss: 0.2123 - accuracy: 0.9014 - val_loss: 0.4476 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00885: val_loss did not improve from 0.42863\n",
      "Epoch 886/3000\n",
      "13/13 - 0s - loss: 0.2238 - accuracy: 0.8911 - val_loss: 0.4359 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00886: val_loss did not improve from 0.42863\n",
      "Epoch 887/3000\n",
      "13/13 - 0s - loss: 0.2199 - accuracy: 0.8807 - val_loss: 0.4453 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00887: val_loss did not improve from 0.42863\n",
      "Epoch 888/3000\n",
      "13/13 - 0s - loss: 0.2127 - accuracy: 0.9001 - val_loss: 0.4538 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00888: val_loss did not improve from 0.42863\n",
      "Epoch 889/3000\n",
      "13/13 - 0s - loss: 0.2318 - accuracy: 0.8872 - val_loss: 0.4515 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00889: val_loss did not improve from 0.42863\n",
      "Epoch 890/3000\n",
      "13/13 - 0s - loss: 0.2205 - accuracy: 0.8923 - val_loss: 0.4534 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00890: val_loss did not improve from 0.42863\n",
      "Epoch 891/3000\n",
      "13/13 - 0s - loss: 0.2163 - accuracy: 0.9040 - val_loss: 0.4525 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00891: val_loss did not improve from 0.42863\n",
      "Epoch 892/3000\n",
      "13/13 - 0s - loss: 0.2246 - accuracy: 0.8975 - val_loss: 0.4467 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00892: val_loss did not improve from 0.42863\n",
      "Epoch 893/3000\n",
      "13/13 - 0s - loss: 0.2195 - accuracy: 0.8988 - val_loss: 0.4474 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00893: val_loss did not improve from 0.42863\n",
      "Epoch 894/3000\n",
      "13/13 - 0s - loss: 0.2277 - accuracy: 0.8936 - val_loss: 0.4658 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00894: val_loss did not improve from 0.42863\n",
      "Epoch 895/3000\n",
      "13/13 - 0s - loss: 0.2146 - accuracy: 0.9001 - val_loss: 0.4591 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00895: val_loss did not improve from 0.42863\n",
      "Epoch 896/3000\n",
      "13/13 - 0s - loss: 0.2132 - accuracy: 0.9001 - val_loss: 0.4497 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00896: val_loss did not improve from 0.42863\n",
      "Epoch 897/3000\n",
      "13/13 - 0s - loss: 0.2290 - accuracy: 0.8911 - val_loss: 0.5175 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00897: val_loss did not improve from 0.42863\n",
      "Epoch 898/3000\n",
      "13/13 - 0s - loss: 0.2247 - accuracy: 0.8988 - val_loss: 0.5105 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00898: val_loss did not improve from 0.42863\n",
      "Epoch 899/3000\n",
      "13/13 - 0s - loss: 0.2233 - accuracy: 0.9001 - val_loss: 0.5008 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00899: val_loss did not improve from 0.42863\n",
      "Epoch 900/3000\n",
      "13/13 - 0s - loss: 0.2284 - accuracy: 0.8949 - val_loss: 0.5149 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00900: val_loss did not improve from 0.42863\n",
      "Epoch 901/3000\n",
      "13/13 - 0s - loss: 0.2359 - accuracy: 0.8898 - val_loss: 0.5217 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00901: val_loss did not improve from 0.42863\n",
      "Epoch 902/3000\n",
      "13/13 - 0s - loss: 0.2254 - accuracy: 0.8936 - val_loss: 0.4762 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00902: val_loss did not improve from 0.42863\n",
      "Epoch 903/3000\n",
      "13/13 - 0s - loss: 0.2554 - accuracy: 0.8911 - val_loss: 0.4487 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00903: val_loss did not improve from 0.42863\n",
      "Epoch 904/3000\n",
      "13/13 - 0s - loss: 0.2392 - accuracy: 0.8911 - val_loss: 0.4662 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00904: val_loss did not improve from 0.42863\n",
      "Epoch 905/3000\n",
      "13/13 - 0s - loss: 0.2256 - accuracy: 0.8962 - val_loss: 0.4572 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00905: val_loss did not improve from 0.42863\n",
      "Epoch 906/3000\n",
      "13/13 - 0s - loss: 0.2250 - accuracy: 0.9001 - val_loss: 0.4495 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00906: val_loss did not improve from 0.42863\n",
      "Epoch 907/3000\n",
      "13/13 - 0s - loss: 0.2184 - accuracy: 0.8923 - val_loss: 0.4432 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00907: val_loss did not improve from 0.42863\n",
      "Epoch 908/3000\n",
      "13/13 - 0s - loss: 0.2137 - accuracy: 0.8962 - val_loss: 0.4521 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00908: val_loss did not improve from 0.42863\n",
      "Epoch 909/3000\n",
      "13/13 - 0s - loss: 0.2100 - accuracy: 0.9014 - val_loss: 0.4432 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00909: val_loss did not improve from 0.42863\n",
      "Epoch 910/3000\n",
      "13/13 - 0s - loss: 0.2121 - accuracy: 0.8962 - val_loss: 0.4553 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00910: val_loss did not improve from 0.42863\n",
      "Epoch 911/3000\n",
      "13/13 - 0s - loss: 0.2182 - accuracy: 0.8962 - val_loss: 0.4441 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00911: val_loss did not improve from 0.42863\n",
      "Epoch 912/3000\n",
      "13/13 - 0s - loss: 0.2124 - accuracy: 0.9001 - val_loss: 0.4457 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00912: val_loss did not improve from 0.42863\n",
      "Epoch 913/3000\n",
      "13/13 - 0s - loss: 0.2170 - accuracy: 0.8975 - val_loss: 0.4557 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00913: val_loss did not improve from 0.42863\n",
      "Epoch 914/3000\n",
      "13/13 - 0s - loss: 0.2158 - accuracy: 0.9014 - val_loss: 0.4473 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00914: val_loss did not improve from 0.42863\n",
      "Epoch 915/3000\n",
      "13/13 - 0s - loss: 0.2205 - accuracy: 0.8975 - val_loss: 0.4425 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00915: val_loss did not improve from 0.42863\n",
      "Epoch 916/3000\n",
      "13/13 - 0s - loss: 0.2165 - accuracy: 0.8936 - val_loss: 0.4508 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00916: val_loss did not improve from 0.42863\n",
      "Epoch 917/3000\n",
      "13/13 - 0s - loss: 0.2126 - accuracy: 0.9014 - val_loss: 0.4663 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00917: val_loss did not improve from 0.42863\n",
      "Epoch 918/3000\n",
      "13/13 - 0s - loss: 0.2132 - accuracy: 0.9027 - val_loss: 0.4663 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00918: val_loss did not improve from 0.42863\n",
      "Epoch 919/3000\n",
      "13/13 - 0s - loss: 0.2341 - accuracy: 0.8975 - val_loss: 0.4627 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00919: val_loss did not improve from 0.42863\n",
      "Epoch 920/3000\n",
      "13/13 - 0s - loss: 0.2286 - accuracy: 0.8988 - val_loss: 0.4573 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00920: val_loss did not improve from 0.42863\n",
      "Epoch 921/3000\n",
      "13/13 - 0s - loss: 0.2194 - accuracy: 0.9001 - val_loss: 0.4746 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00921: val_loss did not improve from 0.42863\n",
      "Epoch 922/3000\n",
      "13/13 - 0s - loss: 0.2324 - accuracy: 0.8949 - val_loss: 0.4972 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00922: val_loss did not improve from 0.42863\n",
      "Epoch 923/3000\n",
      "13/13 - 0s - loss: 0.2244 - accuracy: 0.8988 - val_loss: 0.4631 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00923: val_loss did not improve from 0.42863\n",
      "Epoch 924/3000\n",
      "13/13 - 0s - loss: 0.2360 - accuracy: 0.8872 - val_loss: 0.4536 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00924: val_loss did not improve from 0.42863\n",
      "Epoch 925/3000\n",
      "13/13 - 0s - loss: 0.2253 - accuracy: 0.8885 - val_loss: 0.4441 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00925: val_loss did not improve from 0.42863\n",
      "Epoch 926/3000\n",
      "13/13 - 0s - loss: 0.2266 - accuracy: 0.9066 - val_loss: 0.4622 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00926: val_loss did not improve from 0.42863\n",
      "Epoch 927/3000\n",
      "13/13 - 0s - loss: 0.2263 - accuracy: 0.9040 - val_loss: 0.4537 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00927: val_loss did not improve from 0.42863\n",
      "Epoch 928/3000\n",
      "13/13 - 0s - loss: 0.2210 - accuracy: 0.9001 - val_loss: 0.4454 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00928: val_loss did not improve from 0.42863\n",
      "Epoch 929/3000\n",
      "13/13 - 0s - loss: 0.2195 - accuracy: 0.9001 - val_loss: 0.4613 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00929: val_loss did not improve from 0.42863\n",
      "Epoch 930/3000\n",
      "13/13 - 0s - loss: 0.2152 - accuracy: 0.9014 - val_loss: 0.4648 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00930: val_loss did not improve from 0.42863\n",
      "Epoch 931/3000\n",
      "13/13 - 0s - loss: 0.2373 - accuracy: 0.8911 - val_loss: 0.4647 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00931: val_loss did not improve from 0.42863\n",
      "Epoch 932/3000\n",
      "13/13 - 0s - loss: 0.2275 - accuracy: 0.8833 - val_loss: 0.4572 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00932: val_loss did not improve from 0.42863\n",
      "Epoch 933/3000\n",
      "13/13 - 0s - loss: 0.2207 - accuracy: 0.9001 - val_loss: 0.4612 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00933: val_loss did not improve from 0.42863\n",
      "Epoch 934/3000\n",
      "13/13 - 0s - loss: 0.2163 - accuracy: 0.8962 - val_loss: 0.4548 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00934: val_loss did not improve from 0.42863\n",
      "Epoch 935/3000\n",
      "13/13 - 0s - loss: 0.2123 - accuracy: 0.9014 - val_loss: 0.4504 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00935: val_loss did not improve from 0.42863\n",
      "Epoch 936/3000\n",
      "13/13 - 0s - loss: 0.2152 - accuracy: 0.8911 - val_loss: 0.4501 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00936: val_loss did not improve from 0.42863\n",
      "Epoch 937/3000\n",
      "13/13 - 0s - loss: 0.2154 - accuracy: 0.8936 - val_loss: 0.4443 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00937: val_loss did not improve from 0.42863\n",
      "Epoch 938/3000\n",
      "13/13 - 0s - loss: 0.2231 - accuracy: 0.8936 - val_loss: 0.4430 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00938: val_loss did not improve from 0.42863\n",
      "Epoch 939/3000\n",
      "13/13 - 0s - loss: 0.2241 - accuracy: 0.8975 - val_loss: 0.4443 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00939: val_loss did not improve from 0.42863\n",
      "Epoch 940/3000\n",
      "13/13 - 0s - loss: 0.2215 - accuracy: 0.9001 - val_loss: 0.4623 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00940: val_loss did not improve from 0.42863\n",
      "Epoch 941/3000\n",
      "13/13 - 0s - loss: 0.2158 - accuracy: 0.9027 - val_loss: 0.4797 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00941: val_loss did not improve from 0.42863\n",
      "Epoch 942/3000\n",
      "13/13 - 0s - loss: 0.2139 - accuracy: 0.9027 - val_loss: 0.4636 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00942: val_loss did not improve from 0.42863\n",
      "Epoch 943/3000\n",
      "13/13 - 0s - loss: 0.2334 - accuracy: 0.8820 - val_loss: 0.4721 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00943: val_loss did not improve from 0.42863\n",
      "Epoch 944/3000\n",
      "13/13 - 0s - loss: 0.2429 - accuracy: 0.8729 - val_loss: 0.4436 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00944: val_loss did not improve from 0.42863\n",
      "Epoch 945/3000\n",
      "13/13 - 0s - loss: 0.2225 - accuracy: 0.8936 - val_loss: 0.4421 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00945: val_loss did not improve from 0.42863\n",
      "Epoch 946/3000\n",
      "13/13 - 0s - loss: 0.2164 - accuracy: 0.8975 - val_loss: 0.4374 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00946: val_loss did not improve from 0.42863\n",
      "Epoch 947/3000\n",
      "13/13 - 0s - loss: 0.2138 - accuracy: 0.9014 - val_loss: 0.4582 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00947: val_loss did not improve from 0.42863\n",
      "Epoch 948/3000\n",
      "13/13 - 0s - loss: 0.2132 - accuracy: 0.8988 - val_loss: 0.4774 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00948: val_loss did not improve from 0.42863\n",
      "Epoch 949/3000\n",
      "13/13 - 0s - loss: 0.2124 - accuracy: 0.9040 - val_loss: 0.4568 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00949: val_loss did not improve from 0.42863\n",
      "Epoch 950/3000\n",
      "13/13 - 0s - loss: 0.2115 - accuracy: 0.8975 - val_loss: 0.4534 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00950: val_loss did not improve from 0.42863\n",
      "Epoch 951/3000\n",
      "13/13 - 0s - loss: 0.2236 - accuracy: 0.8911 - val_loss: 0.4700 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00951: val_loss did not improve from 0.42863\n",
      "Epoch 952/3000\n",
      "13/13 - 0s - loss: 0.2329 - accuracy: 0.8949 - val_loss: 0.4935 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00952: val_loss did not improve from 0.42863\n",
      "Epoch 953/3000\n",
      "13/13 - 0s - loss: 0.2213 - accuracy: 0.8949 - val_loss: 0.4513 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00953: val_loss did not improve from 0.42863\n",
      "Epoch 954/3000\n",
      "13/13 - 0s - loss: 0.2124 - accuracy: 0.8988 - val_loss: 0.4390 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00954: val_loss did not improve from 0.42863\n",
      "Epoch 955/3000\n",
      "13/13 - 0s - loss: 0.2119 - accuracy: 0.8936 - val_loss: 0.4394 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00955: val_loss did not improve from 0.42863\n",
      "Epoch 956/3000\n",
      "13/13 - 0s - loss: 0.2109 - accuracy: 0.9027 - val_loss: 0.4559 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00956: val_loss did not improve from 0.42863\n",
      "Epoch 957/3000\n",
      "13/13 - 0s - loss: 0.2175 - accuracy: 0.8975 - val_loss: 0.4502 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00957: val_loss did not improve from 0.42863\n",
      "Epoch 958/3000\n",
      "13/13 - 0s - loss: 0.2208 - accuracy: 0.8923 - val_loss: 0.4450 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00958: val_loss did not improve from 0.42863\n",
      "Epoch 959/3000\n",
      "13/13 - 0s - loss: 0.2158 - accuracy: 0.9001 - val_loss: 0.4525 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00959: val_loss did not improve from 0.42863\n",
      "Epoch 960/3000\n",
      "13/13 - 0s - loss: 0.2160 - accuracy: 0.8975 - val_loss: 0.4554 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00960: val_loss did not improve from 0.42863\n",
      "Epoch 961/3000\n",
      "13/13 - 0s - loss: 0.2143 - accuracy: 0.9014 - val_loss: 0.4486 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00961: val_loss did not improve from 0.42863\n",
      "Epoch 962/3000\n",
      "13/13 - 0s - loss: 0.2085 - accuracy: 0.9014 - val_loss: 0.4620 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00962: val_loss did not improve from 0.42863\n",
      "Epoch 963/3000\n",
      "13/13 - 0s - loss: 0.2167 - accuracy: 0.9014 - val_loss: 0.4574 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00963: val_loss did not improve from 0.42863\n",
      "Epoch 964/3000\n",
      "13/13 - 0s - loss: 0.2153 - accuracy: 0.8949 - val_loss: 0.4523 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00964: val_loss did not improve from 0.42863\n",
      "Epoch 965/3000\n",
      "13/13 - 0s - loss: 0.2470 - accuracy: 0.8755 - val_loss: 0.4724 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00965: val_loss did not improve from 0.42863\n",
      "Epoch 966/3000\n",
      "13/13 - 0s - loss: 0.2309 - accuracy: 0.8820 - val_loss: 0.4438 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00966: val_loss did not improve from 0.42863\n",
      "Epoch 967/3000\n",
      "13/13 - 0s - loss: 0.2160 - accuracy: 0.8949 - val_loss: 0.4618 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00967: val_loss did not improve from 0.42863\n",
      "Epoch 968/3000\n",
      "13/13 - 0s - loss: 0.2151 - accuracy: 0.8975 - val_loss: 0.4461 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00968: val_loss did not improve from 0.42863\n",
      "Epoch 969/3000\n",
      "13/13 - 0s - loss: 0.2107 - accuracy: 0.8962 - val_loss: 0.4522 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00969: val_loss did not improve from 0.42863\n",
      "Epoch 970/3000\n",
      "13/13 - 0s - loss: 0.2107 - accuracy: 0.9027 - val_loss: 0.4509 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00970: val_loss did not improve from 0.42863\n",
      "Epoch 971/3000\n",
      "13/13 - 0s - loss: 0.2120 - accuracy: 0.8936 - val_loss: 0.4526 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00971: val_loss did not improve from 0.42863\n",
      "Epoch 972/3000\n",
      "13/13 - 0s - loss: 0.2114 - accuracy: 0.8949 - val_loss: 0.4484 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00972: val_loss did not improve from 0.42863\n",
      "Epoch 973/3000\n",
      "13/13 - 0s - loss: 0.2166 - accuracy: 0.9027 - val_loss: 0.4438 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00973: val_loss did not improve from 0.42863\n",
      "Epoch 974/3000\n",
      "13/13 - 0s - loss: 0.2183 - accuracy: 0.8936 - val_loss: 0.4700 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00974: val_loss did not improve from 0.42863\n",
      "Epoch 975/3000\n",
      "13/13 - 0s - loss: 0.2495 - accuracy: 0.8846 - val_loss: 0.4566 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00975: val_loss did not improve from 0.42863\n",
      "Epoch 976/3000\n",
      "13/13 - 0s - loss: 0.2185 - accuracy: 0.8962 - val_loss: 0.4602 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00976: val_loss did not improve from 0.42863\n",
      "Epoch 977/3000\n",
      "13/13 - 0s - loss: 0.2236 - accuracy: 0.9001 - val_loss: 0.4641 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00977: val_loss did not improve from 0.42863\n",
      "Epoch 978/3000\n",
      "13/13 - 0s - loss: 0.2230 - accuracy: 0.8975 - val_loss: 0.4662 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00978: val_loss did not improve from 0.42863\n",
      "Epoch 979/3000\n",
      "13/13 - 0s - loss: 0.2387 - accuracy: 0.8911 - val_loss: 0.4772 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00979: val_loss did not improve from 0.42863\n",
      "Epoch 980/3000\n",
      "13/13 - 0s - loss: 0.2195 - accuracy: 0.8949 - val_loss: 0.4464 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00980: val_loss did not improve from 0.42863\n",
      "Epoch 981/3000\n",
      "13/13 - 0s - loss: 0.2213 - accuracy: 0.8975 - val_loss: 0.5023 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00981: val_loss did not improve from 0.42863\n",
      "Epoch 982/3000\n",
      "13/13 - 0s - loss: 0.2170 - accuracy: 0.8975 - val_loss: 0.5054 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00982: val_loss did not improve from 0.42863\n",
      "Epoch 983/3000\n",
      "13/13 - 0s - loss: 0.2170 - accuracy: 0.8962 - val_loss: 0.4902 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00983: val_loss did not improve from 0.42863\n",
      "Epoch 984/3000\n",
      "13/13 - 0s - loss: 0.2364 - accuracy: 0.8781 - val_loss: 0.4712 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00984: val_loss did not improve from 0.42863\n",
      "Epoch 985/3000\n",
      "13/13 - 0s - loss: 0.2210 - accuracy: 0.8898 - val_loss: 0.4672 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00985: val_loss did not improve from 0.42863\n",
      "Epoch 986/3000\n",
      "13/13 - 0s - loss: 0.2144 - accuracy: 0.8949 - val_loss: 0.4669 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00986: val_loss did not improve from 0.42863\n",
      "Epoch 987/3000\n",
      "13/13 - 0s - loss: 0.2118 - accuracy: 0.9040 - val_loss: 0.4658 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00987: val_loss did not improve from 0.42863\n",
      "Epoch 988/3000\n",
      "13/13 - 0s - loss: 0.2125 - accuracy: 0.8988 - val_loss: 0.4530 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00988: val_loss did not improve from 0.42863\n",
      "Epoch 989/3000\n",
      "13/13 - 0s - loss: 0.2104 - accuracy: 0.8962 - val_loss: 0.4487 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00989: val_loss did not improve from 0.42863\n",
      "Epoch 990/3000\n",
      "13/13 - 0s - loss: 0.2115 - accuracy: 0.8988 - val_loss: 0.4394 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00990: val_loss did not improve from 0.42863\n",
      "Epoch 991/3000\n",
      "13/13 - 0s - loss: 0.2182 - accuracy: 0.8949 - val_loss: 0.4589 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00991: val_loss did not improve from 0.42863\n",
      "Epoch 992/3000\n",
      "13/13 - 0s - loss: 0.2129 - accuracy: 0.8949 - val_loss: 0.4473 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00992: val_loss did not improve from 0.42863\n",
      "Epoch 993/3000\n",
      "13/13 - 0s - loss: 0.2096 - accuracy: 0.9027 - val_loss: 0.4467 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00993: val_loss did not improve from 0.42863\n",
      "Epoch 994/3000\n",
      "13/13 - 0s - loss: 0.2194 - accuracy: 0.9040 - val_loss: 0.4635 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00994: val_loss did not improve from 0.42863\n",
      "Epoch 995/3000\n",
      "13/13 - 0s - loss: 0.2148 - accuracy: 0.9014 - val_loss: 0.4374 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00995: val_loss did not improve from 0.42863\n",
      "Epoch 996/3000\n",
      "13/13 - 0s - loss: 0.2241 - accuracy: 0.8936 - val_loss: 0.4454 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00996: val_loss did not improve from 0.42863\n",
      "Epoch 997/3000\n",
      "13/13 - 0s - loss: 0.2245 - accuracy: 0.8911 - val_loss: 0.4377 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00997: val_loss did not improve from 0.42863\n",
      "Epoch 998/3000\n",
      "13/13 - 0s - loss: 0.2833 - accuracy: 0.8807 - val_loss: 0.4339 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00998: val_loss did not improve from 0.42863\n",
      "Epoch 999/3000\n",
      "13/13 - 0s - loss: 0.2324 - accuracy: 0.8872 - val_loss: 0.4731 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00999: val_loss did not improve from 0.42863\n",
      "Epoch 1000/3000\n",
      "13/13 - 0s - loss: 0.2373 - accuracy: 0.8833 - val_loss: 0.4617 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01000: val_loss did not improve from 0.42863\n",
      "Epoch 1001/3000\n",
      "13/13 - 0s - loss: 0.2414 - accuracy: 0.8794 - val_loss: 0.4562 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01001: val_loss did not improve from 0.42863\n",
      "Epoch 1002/3000\n",
      "13/13 - 0s - loss: 0.2320 - accuracy: 0.9001 - val_loss: 0.4696 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01002: val_loss did not improve from 0.42863\n",
      "Epoch 1003/3000\n",
      "13/13 - 0s - loss: 0.2180 - accuracy: 0.8949 - val_loss: 0.4561 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01003: val_loss did not improve from 0.42863\n",
      "Epoch 1004/3000\n",
      "13/13 - 0s - loss: 0.2169 - accuracy: 0.8949 - val_loss: 0.4637 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01004: val_loss did not improve from 0.42863\n",
      "Epoch 1005/3000\n",
      "13/13 - 0s - loss: 0.2241 - accuracy: 0.8962 - val_loss: 0.4636 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01005: val_loss did not improve from 0.42863\n",
      "Epoch 1006/3000\n",
      "13/13 - 0s - loss: 0.2177 - accuracy: 0.8975 - val_loss: 0.4472 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01006: val_loss did not improve from 0.42863\n",
      "Epoch 1007/3000\n",
      "13/13 - 0s - loss: 0.2181 - accuracy: 0.9001 - val_loss: 0.4602 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01007: val_loss did not improve from 0.42863\n",
      "Epoch 1008/3000\n",
      "13/13 - 0s - loss: 0.2168 - accuracy: 0.8975 - val_loss: 0.4486 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01008: val_loss did not improve from 0.42863\n",
      "Epoch 1009/3000\n",
      "13/13 - 0s - loss: 0.2169 - accuracy: 0.9027 - val_loss: 0.4398 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01009: val_loss did not improve from 0.42863\n",
      "Epoch 1010/3000\n",
      "13/13 - 0s - loss: 0.2115 - accuracy: 0.8962 - val_loss: 0.4480 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01010: val_loss did not improve from 0.42863\n",
      "Epoch 1011/3000\n",
      "13/13 - 0s - loss: 0.2153 - accuracy: 0.8949 - val_loss: 0.4425 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01011: val_loss did not improve from 0.42863\n",
      "Epoch 1012/3000\n",
      "13/13 - 0s - loss: 0.2141 - accuracy: 0.8988 - val_loss: 0.4505 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01012: val_loss did not improve from 0.42863\n",
      "Epoch 1013/3000\n",
      "13/13 - 0s - loss: 0.2143 - accuracy: 0.9040 - val_loss: 0.4480 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01013: val_loss did not improve from 0.42863\n",
      "Epoch 1014/3000\n",
      "13/13 - 0s - loss: 0.2125 - accuracy: 0.9001 - val_loss: 0.4421 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01014: val_loss did not improve from 0.42863\n",
      "Epoch 1015/3000\n",
      "13/13 - 0s - loss: 0.2149 - accuracy: 0.9001 - val_loss: 0.4428 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01015: val_loss did not improve from 0.42863\n",
      "Epoch 1016/3000\n",
      "13/13 - 0s - loss: 0.2106 - accuracy: 0.9014 - val_loss: 0.4453 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01016: val_loss did not improve from 0.42863\n",
      "Epoch 1017/3000\n",
      "13/13 - 0s - loss: 0.2127 - accuracy: 0.8923 - val_loss: 0.4431 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01017: val_loss did not improve from 0.42863\n",
      "Epoch 1018/3000\n",
      "13/13 - 0s - loss: 0.2095 - accuracy: 0.8975 - val_loss: 0.4393 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01018: val_loss did not improve from 0.42863\n",
      "Epoch 1019/3000\n",
      "13/13 - 0s - loss: 0.2114 - accuracy: 0.8975 - val_loss: 0.4410 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01019: val_loss did not improve from 0.42863\n",
      "Epoch 1020/3000\n",
      "13/13 - 0s - loss: 0.2299 - accuracy: 0.8923 - val_loss: 0.4437 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01020: val_loss did not improve from 0.42863\n",
      "Epoch 1021/3000\n",
      "13/13 - 0s - loss: 0.2228 - accuracy: 0.8962 - val_loss: 0.4443 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01021: val_loss did not improve from 0.42863\n",
      "Epoch 1022/3000\n",
      "13/13 - 0s - loss: 0.2125 - accuracy: 0.9027 - val_loss: 0.4438 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01022: val_loss did not improve from 0.42863\n",
      "Epoch 1023/3000\n",
      "13/13 - 0s - loss: 0.2113 - accuracy: 0.8988 - val_loss: 0.4477 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01023: val_loss did not improve from 0.42863\n",
      "Epoch 1024/3000\n",
      "13/13 - 0s - loss: 0.2096 - accuracy: 0.9027 - val_loss: 0.4516 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01024: val_loss did not improve from 0.42863\n",
      "Epoch 1025/3000\n",
      "13/13 - 0s - loss: 0.2127 - accuracy: 0.8988 - val_loss: 0.4530 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01025: val_loss did not improve from 0.42863\n",
      "Epoch 1026/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.8988 - val_loss: 0.4482 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01026: val_loss did not improve from 0.42863\n",
      "Epoch 1027/3000\n",
      "13/13 - 0s - loss: 0.2217 - accuracy: 0.8820 - val_loss: 0.4774 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01027: val_loss did not improve from 0.42863\n",
      "Epoch 1028/3000\n",
      "13/13 - 0s - loss: 0.2351 - accuracy: 0.8936 - val_loss: 0.4826 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01028: val_loss did not improve from 0.42863\n",
      "Epoch 1029/3000\n",
      "13/13 - 0s - loss: 0.2241 - accuracy: 0.8988 - val_loss: 0.4704 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01029: val_loss did not improve from 0.42863\n",
      "Epoch 1030/3000\n",
      "13/13 - 0s - loss: 0.2191 - accuracy: 0.9001 - val_loss: 0.4597 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01030: val_loss did not improve from 0.42863\n",
      "Epoch 1031/3000\n",
      "13/13 - 0s - loss: 0.2148 - accuracy: 0.9027 - val_loss: 0.4401 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01031: val_loss did not improve from 0.42863\n",
      "Epoch 1032/3000\n",
      "13/13 - 0s - loss: 0.2110 - accuracy: 0.8949 - val_loss: 0.4472 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01032: val_loss did not improve from 0.42863\n",
      "Epoch 1033/3000\n",
      "13/13 - 0s - loss: 0.2124 - accuracy: 0.9040 - val_loss: 0.4423 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01033: val_loss did not improve from 0.42863\n",
      "Epoch 1034/3000\n",
      "13/13 - 0s - loss: 0.2145 - accuracy: 0.9053 - val_loss: 0.4551 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01034: val_loss did not improve from 0.42863\n",
      "Epoch 1035/3000\n",
      "13/13 - 0s - loss: 0.2315 - accuracy: 0.9014 - val_loss: 0.4467 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01035: val_loss did not improve from 0.42863\n",
      "Epoch 1036/3000\n",
      "13/13 - 0s - loss: 0.2179 - accuracy: 0.8911 - val_loss: 0.4385 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01036: val_loss did not improve from 0.42863\n",
      "Epoch 1037/3000\n",
      "13/13 - 0s - loss: 0.2125 - accuracy: 0.9001 - val_loss: 0.4515 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01037: val_loss did not improve from 0.42863\n",
      "Epoch 1038/3000\n",
      "13/13 - 0s - loss: 0.2132 - accuracy: 0.8936 - val_loss: 0.4396 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01038: val_loss did not improve from 0.42863\n",
      "Epoch 1039/3000\n",
      "13/13 - 0s - loss: 0.2141 - accuracy: 0.9014 - val_loss: 0.4668 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01039: val_loss did not improve from 0.42863\n",
      "Epoch 1040/3000\n",
      "13/13 - 0s - loss: 0.2576 - accuracy: 0.8898 - val_loss: 0.4176 - val_accuracy: 0.8705\n",
      "\n",
      "Epoch 01040: val_loss improved from 0.42863 to 0.41762, saving model to models\\model_4L_v4\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v4\\assets\n",
      "Epoch 1041/3000\n",
      "13/13 - 0s - loss: 0.2624 - accuracy: 0.8833 - val_loss: 0.4366 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 01041: val_loss did not improve from 0.41762\n",
      "Epoch 1042/3000\n",
      "13/13 - 0s - loss: 0.2301 - accuracy: 0.9001 - val_loss: 0.4471 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01042: val_loss did not improve from 0.41762\n",
      "Epoch 1043/3000\n",
      "13/13 - 0s - loss: 0.2280 - accuracy: 0.8988 - val_loss: 0.4649 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01043: val_loss did not improve from 0.41762\n",
      "Epoch 1044/3000\n",
      "13/13 - 0s - loss: 0.2178 - accuracy: 0.9001 - val_loss: 0.4664 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01044: val_loss did not improve from 0.41762\n",
      "Epoch 1045/3000\n",
      "13/13 - 0s - loss: 0.2224 - accuracy: 0.8962 - val_loss: 0.5050 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01045: val_loss did not improve from 0.41762\n",
      "Epoch 1046/3000\n",
      "13/13 - 0s - loss: 0.2281 - accuracy: 0.9040 - val_loss: 0.4986 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01046: val_loss did not improve from 0.41762\n",
      "Epoch 1047/3000\n",
      "13/13 - 0s - loss: 0.2512 - accuracy: 0.8872 - val_loss: 0.4772 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01047: val_loss did not improve from 0.41762\n",
      "Epoch 1048/3000\n",
      "13/13 - 0s - loss: 0.2368 - accuracy: 0.8962 - val_loss: 0.4861 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01048: val_loss did not improve from 0.41762\n",
      "Epoch 1049/3000\n",
      "13/13 - 0s - loss: 0.2183 - accuracy: 0.9014 - val_loss: 0.4603 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01049: val_loss did not improve from 0.41762\n",
      "Epoch 1050/3000\n",
      "13/13 - 0s - loss: 0.2121 - accuracy: 0.9014 - val_loss: 0.4600 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01050: val_loss did not improve from 0.41762\n",
      "Epoch 1051/3000\n",
      "13/13 - 0s - loss: 0.2128 - accuracy: 0.8988 - val_loss: 0.4486 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01051: val_loss did not improve from 0.41762\n",
      "Epoch 1052/3000\n",
      "13/13 - 0s - loss: 0.2140 - accuracy: 0.8949 - val_loss: 0.4498 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01052: val_loss did not improve from 0.41762\n",
      "Epoch 1053/3000\n",
      "13/13 - 0s - loss: 0.2225 - accuracy: 0.8975 - val_loss: 0.4466 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01053: val_loss did not improve from 0.41762\n",
      "Epoch 1054/3000\n",
      "13/13 - 0s - loss: 0.2245 - accuracy: 0.8962 - val_loss: 0.4452 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01054: val_loss did not improve from 0.41762\n",
      "Epoch 1055/3000\n",
      "13/13 - 0s - loss: 0.2238 - accuracy: 0.8949 - val_loss: 0.4478 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01055: val_loss did not improve from 0.41762\n",
      "Epoch 1056/3000\n",
      "13/13 - 0s - loss: 0.2184 - accuracy: 0.9001 - val_loss: 0.4472 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01056: val_loss did not improve from 0.41762\n",
      "Epoch 1057/3000\n",
      "13/13 - 0s - loss: 0.2155 - accuracy: 0.8962 - val_loss: 0.4696 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01057: val_loss did not improve from 0.41762\n",
      "Epoch 1058/3000\n",
      "13/13 - 0s - loss: 0.2111 - accuracy: 0.9014 - val_loss: 0.4669 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01058: val_loss did not improve from 0.41762\n",
      "Epoch 1059/3000\n",
      "13/13 - 0s - loss: 0.2131 - accuracy: 0.9014 - val_loss: 0.4540 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01059: val_loss did not improve from 0.41762\n",
      "Epoch 1060/3000\n",
      "13/13 - 0s - loss: 0.2121 - accuracy: 0.9040 - val_loss: 0.4605 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01060: val_loss did not improve from 0.41762\n",
      "Epoch 1061/3000\n",
      "13/13 - 0s - loss: 0.2184 - accuracy: 0.8988 - val_loss: 0.4589 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01061: val_loss did not improve from 0.41762\n",
      "Epoch 1062/3000\n",
      "13/13 - 0s - loss: 0.2215 - accuracy: 0.9040 - val_loss: 0.4821 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01062: val_loss did not improve from 0.41762\n",
      "Epoch 1063/3000\n",
      "13/13 - 0s - loss: 0.2247 - accuracy: 0.9001 - val_loss: 0.4566 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01063: val_loss did not improve from 0.41762\n",
      "Epoch 1064/3000\n",
      "13/13 - 0s - loss: 0.2119 - accuracy: 0.8988 - val_loss: 0.4486 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01064: val_loss did not improve from 0.41762\n",
      "Epoch 1065/3000\n",
      "13/13 - 0s - loss: 0.2115 - accuracy: 0.8988 - val_loss: 0.4384 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01065: val_loss did not improve from 0.41762\n",
      "Epoch 1066/3000\n",
      "13/13 - 0s - loss: 0.2127 - accuracy: 0.8975 - val_loss: 0.4532 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01066: val_loss did not improve from 0.41762\n",
      "Epoch 1067/3000\n",
      "13/13 - 0s - loss: 0.2169 - accuracy: 0.8988 - val_loss: 0.4705 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01067: val_loss did not improve from 0.41762\n",
      "Epoch 1068/3000\n",
      "13/13 - 0s - loss: 0.2135 - accuracy: 0.9014 - val_loss: 0.4535 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01068: val_loss did not improve from 0.41762\n",
      "Epoch 1069/3000\n",
      "13/13 - 0s - loss: 0.2138 - accuracy: 0.8988 - val_loss: 0.4409 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01069: val_loss did not improve from 0.41762\n",
      "Epoch 1070/3000\n",
      "13/13 - 0s - loss: 0.2185 - accuracy: 0.8949 - val_loss: 0.4659 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01070: val_loss did not improve from 0.41762\n",
      "Epoch 1071/3000\n",
      "13/13 - 0s - loss: 0.2428 - accuracy: 0.8833 - val_loss: 0.4399 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01071: val_loss did not improve from 0.41762\n",
      "Epoch 1072/3000\n",
      "13/13 - 0s - loss: 0.2342 - accuracy: 0.9001 - val_loss: 0.4339 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01072: val_loss did not improve from 0.41762\n",
      "Epoch 1073/3000\n",
      "13/13 - 0s - loss: 0.2246 - accuracy: 0.8975 - val_loss: 0.4502 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01073: val_loss did not improve from 0.41762\n",
      "Epoch 1074/3000\n",
      "13/13 - 0s - loss: 0.2197 - accuracy: 0.8988 - val_loss: 0.4372 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01074: val_loss did not improve from 0.41762\n",
      "Epoch 1075/3000\n",
      "13/13 - 0s - loss: 0.2155 - accuracy: 0.8988 - val_loss: 0.4374 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01075: val_loss did not improve from 0.41762\n",
      "Epoch 1076/3000\n",
      "13/13 - 0s - loss: 0.2142 - accuracy: 0.8923 - val_loss: 0.4398 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01076: val_loss did not improve from 0.41762\n",
      "Epoch 1077/3000\n",
      "13/13 - 0s - loss: 0.2186 - accuracy: 0.8936 - val_loss: 0.4417 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 01077: val_loss did not improve from 0.41762\n",
      "Epoch 1078/3000\n",
      "13/13 - 0s - loss: 0.2176 - accuracy: 0.8949 - val_loss: 0.4420 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01078: val_loss did not improve from 0.41762\n",
      "Epoch 1079/3000\n",
      "13/13 - 0s - loss: 0.2156 - accuracy: 0.8975 - val_loss: 0.4380 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01079: val_loss did not improve from 0.41762\n",
      "Epoch 1080/3000\n",
      "13/13 - 0s - loss: 0.2150 - accuracy: 0.8936 - val_loss: 0.4505 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01080: val_loss did not improve from 0.41762\n",
      "Epoch 1081/3000\n",
      "13/13 - 0s - loss: 0.2148 - accuracy: 0.8923 - val_loss: 0.4330 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01081: val_loss did not improve from 0.41762\n",
      "Epoch 1082/3000\n",
      "13/13 - 0s - loss: 0.2126 - accuracy: 0.9040 - val_loss: 0.4389 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01082: val_loss did not improve from 0.41762\n",
      "Epoch 1083/3000\n",
      "13/13 - 0s - loss: 0.2108 - accuracy: 0.8988 - val_loss: 0.4318 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01083: val_loss did not improve from 0.41762\n",
      "Epoch 1084/3000\n",
      "13/13 - 0s - loss: 0.2249 - accuracy: 0.8885 - val_loss: 0.4496 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01084: val_loss did not improve from 0.41762\n",
      "Epoch 1085/3000\n",
      "13/13 - 0s - loss: 0.2248 - accuracy: 0.8975 - val_loss: 0.4561 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01085: val_loss did not improve from 0.41762\n",
      "Epoch 1086/3000\n",
      "13/13 - 0s - loss: 0.2145 - accuracy: 0.8988 - val_loss: 0.4494 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01086: val_loss did not improve from 0.41762\n",
      "Epoch 1087/3000\n",
      "13/13 - 0s - loss: 0.2157 - accuracy: 0.8962 - val_loss: 0.4480 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01087: val_loss did not improve from 0.41762\n",
      "Epoch 1088/3000\n",
      "13/13 - 0s - loss: 0.2116 - accuracy: 0.8962 - val_loss: 0.4558 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01088: val_loss did not improve from 0.41762\n",
      "Epoch 1089/3000\n",
      "13/13 - 0s - loss: 0.2458 - accuracy: 0.8859 - val_loss: 0.4321 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01089: val_loss did not improve from 0.41762\n",
      "Epoch 1090/3000\n",
      "13/13 - 0s - loss: 0.2413 - accuracy: 0.8846 - val_loss: 0.4298 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01090: val_loss did not improve from 0.41762\n",
      "Epoch 1091/3000\n",
      "13/13 - 0s - loss: 0.2218 - accuracy: 0.8962 - val_loss: 0.4373 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01091: val_loss did not improve from 0.41762\n",
      "Epoch 1092/3000\n",
      "13/13 - 0s - loss: 0.2240 - accuracy: 0.8872 - val_loss: 0.4527 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01092: val_loss did not improve from 0.41762\n",
      "Epoch 1093/3000\n",
      "13/13 - 0s - loss: 0.2140 - accuracy: 0.8988 - val_loss: 0.4589 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01093: val_loss did not improve from 0.41762\n",
      "Epoch 1094/3000\n",
      "13/13 - 0s - loss: 0.2123 - accuracy: 0.9027 - val_loss: 0.4605 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01094: val_loss did not improve from 0.41762\n",
      "Epoch 1095/3000\n",
      "13/13 - 0s - loss: 0.2127 - accuracy: 0.9001 - val_loss: 0.4510 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01095: val_loss did not improve from 0.41762\n",
      "Epoch 1096/3000\n",
      "13/13 - 0s - loss: 0.2118 - accuracy: 0.8975 - val_loss: 0.4788 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01096: val_loss did not improve from 0.41762\n",
      "Epoch 1097/3000\n",
      "13/13 - 0s - loss: 0.2203 - accuracy: 0.9014 - val_loss: 0.4545 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01097: val_loss did not improve from 0.41762\n",
      "Epoch 1098/3000\n",
      "13/13 - 0s - loss: 0.2249 - accuracy: 0.9014 - val_loss: 0.4537 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01098: val_loss did not improve from 0.41762\n",
      "Epoch 1099/3000\n",
      "13/13 - 0s - loss: 0.2360 - accuracy: 0.9001 - val_loss: 0.4521 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01099: val_loss did not improve from 0.41762\n",
      "Epoch 1100/3000\n",
      "13/13 - 0s - loss: 0.2212 - accuracy: 0.9014 - val_loss: 0.4625 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01100: val_loss did not improve from 0.41762\n",
      "Epoch 1101/3000\n",
      "13/13 - 0s - loss: 0.2188 - accuracy: 0.8975 - val_loss: 0.4734 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01101: val_loss did not improve from 0.41762\n",
      "Epoch 1102/3000\n",
      "13/13 - 0s - loss: 0.2247 - accuracy: 0.9001 - val_loss: 0.4784 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01102: val_loss did not improve from 0.41762\n",
      "Epoch 1103/3000\n",
      "13/13 - 0s - loss: 0.2175 - accuracy: 0.8975 - val_loss: 0.4659 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01103: val_loss did not improve from 0.41762\n",
      "Epoch 1104/3000\n",
      "13/13 - 0s - loss: 0.2136 - accuracy: 0.9001 - val_loss: 0.4546 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01104: val_loss did not improve from 0.41762\n",
      "Epoch 1105/3000\n",
      "13/13 - 0s - loss: 0.2117 - accuracy: 0.8975 - val_loss: 0.4511 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01105: val_loss did not improve from 0.41762\n",
      "Epoch 1106/3000\n",
      "13/13 - 0s - loss: 0.2157 - accuracy: 0.9014 - val_loss: 0.4439 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01106: val_loss did not improve from 0.41762\n",
      "Epoch 1107/3000\n",
      "13/13 - 0s - loss: 0.2193 - accuracy: 0.8859 - val_loss: 0.4537 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01107: val_loss did not improve from 0.41762\n",
      "Epoch 1108/3000\n",
      "13/13 - 0s - loss: 0.2212 - accuracy: 0.8962 - val_loss: 0.4531 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01108: val_loss did not improve from 0.41762\n",
      "Epoch 1109/3000\n",
      "13/13 - 0s - loss: 0.2120 - accuracy: 0.8988 - val_loss: 0.4596 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01109: val_loss did not improve from 0.41762\n",
      "Epoch 1110/3000\n",
      "13/13 - 0s - loss: 0.2257 - accuracy: 0.8962 - val_loss: 0.4709 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01110: val_loss did not improve from 0.41762\n",
      "Epoch 1111/3000\n",
      "13/13 - 0s - loss: 0.2190 - accuracy: 0.8936 - val_loss: 0.4908 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01111: val_loss did not improve from 0.41762\n",
      "Epoch 1112/3000\n",
      "13/13 - 0s - loss: 0.2261 - accuracy: 0.8988 - val_loss: 0.5085 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01112: val_loss did not improve from 0.41762\n",
      "Epoch 1113/3000\n",
      "13/13 - 0s - loss: 0.2296 - accuracy: 0.8949 - val_loss: 0.4757 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01113: val_loss did not improve from 0.41762\n",
      "Epoch 1114/3000\n",
      "13/13 - 0s - loss: 0.2206 - accuracy: 0.9014 - val_loss: 0.4497 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01114: val_loss did not improve from 0.41762\n",
      "Epoch 1115/3000\n",
      "13/13 - 0s - loss: 0.2388 - accuracy: 0.9001 - val_loss: 0.4802 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01115: val_loss did not improve from 0.41762\n",
      "Epoch 1116/3000\n",
      "13/13 - 0s - loss: 0.2322 - accuracy: 0.9014 - val_loss: 0.4728 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01116: val_loss did not improve from 0.41762\n",
      "Epoch 1117/3000\n",
      "13/13 - 0s - loss: 0.2172 - accuracy: 0.9040 - val_loss: 0.5164 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01117: val_loss did not improve from 0.41762\n",
      "Epoch 1118/3000\n",
      "13/13 - 0s - loss: 0.2273 - accuracy: 0.8988 - val_loss: 0.4877 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01118: val_loss did not improve from 0.41762\n",
      "Epoch 1119/3000\n",
      "13/13 - 0s - loss: 0.2132 - accuracy: 0.9040 - val_loss: 0.4594 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01119: val_loss did not improve from 0.41762\n",
      "Epoch 1120/3000\n",
      "13/13 - 0s - loss: 0.2114 - accuracy: 0.9053 - val_loss: 0.4573 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01120: val_loss did not improve from 0.41762\n",
      "Epoch 1121/3000\n",
      "13/13 - 0s - loss: 0.2131 - accuracy: 0.9027 - val_loss: 0.4501 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01121: val_loss did not improve from 0.41762\n",
      "Epoch 1122/3000\n",
      "13/13 - 0s - loss: 0.2126 - accuracy: 0.9014 - val_loss: 0.4511 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01122: val_loss did not improve from 0.41762\n",
      "Epoch 1123/3000\n",
      "13/13 - 0s - loss: 0.2111 - accuracy: 0.9014 - val_loss: 0.4443 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01123: val_loss did not improve from 0.41762\n",
      "Epoch 1124/3000\n",
      "13/13 - 0s - loss: 0.2209 - accuracy: 0.8846 - val_loss: 0.4578 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01124: val_loss did not improve from 0.41762\n",
      "Epoch 1125/3000\n",
      "13/13 - 0s - loss: 0.2106 - accuracy: 0.9027 - val_loss: 0.4627 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01125: val_loss did not improve from 0.41762\n",
      "Epoch 1126/3000\n",
      "13/13 - 0s - loss: 0.2132 - accuracy: 0.8988 - val_loss: 0.4548 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01126: val_loss did not improve from 0.41762\n",
      "Epoch 1127/3000\n",
      "13/13 - 0s - loss: 0.2105 - accuracy: 0.8988 - val_loss: 0.4589 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01127: val_loss did not improve from 0.41762\n",
      "Epoch 1128/3000\n",
      "13/13 - 0s - loss: 0.2106 - accuracy: 0.9014 - val_loss: 0.4512 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01128: val_loss did not improve from 0.41762\n",
      "Epoch 1129/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.9014 - val_loss: 0.4583 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01129: val_loss did not improve from 0.41762\n",
      "Epoch 1130/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.8988 - val_loss: 0.4548 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01130: val_loss did not improve from 0.41762\n",
      "Epoch 1131/3000\n",
      "13/13 - 0s - loss: 0.2117 - accuracy: 0.8949 - val_loss: 0.4794 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01131: val_loss did not improve from 0.41762\n",
      "Epoch 1132/3000\n",
      "13/13 - 0s - loss: 0.2155 - accuracy: 0.8949 - val_loss: 0.4508 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01132: val_loss did not improve from 0.41762\n",
      "Epoch 1133/3000\n",
      "13/13 - 0s - loss: 0.2235 - accuracy: 0.8962 - val_loss: 0.4457 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01133: val_loss did not improve from 0.41762\n",
      "Epoch 1134/3000\n",
      "13/13 - 0s - loss: 0.2151 - accuracy: 0.8988 - val_loss: 0.4398 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01134: val_loss did not improve from 0.41762\n",
      "Epoch 1135/3000\n",
      "13/13 - 0s - loss: 0.2126 - accuracy: 0.8898 - val_loss: 0.4597 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01135: val_loss did not improve from 0.41762\n",
      "Epoch 1136/3000\n",
      "13/13 - 0s - loss: 0.2114 - accuracy: 0.8923 - val_loss: 0.4567 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01136: val_loss did not improve from 0.41762\n",
      "Epoch 1137/3000\n",
      "13/13 - 0s - loss: 0.2097 - accuracy: 0.8988 - val_loss: 0.4629 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01137: val_loss did not improve from 0.41762\n",
      "Epoch 1138/3000\n",
      "13/13 - 0s - loss: 0.2287 - accuracy: 0.8923 - val_loss: 0.5178 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01138: val_loss did not improve from 0.41762\n",
      "Epoch 1139/3000\n",
      "13/13 - 0s - loss: 0.2276 - accuracy: 0.8988 - val_loss: 0.4727 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01139: val_loss did not improve from 0.41762\n",
      "Epoch 1140/3000\n",
      "13/13 - 0s - loss: 0.2188 - accuracy: 0.9027 - val_loss: 0.4508 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01140: val_loss did not improve from 0.41762\n",
      "Epoch 1141/3000\n",
      "13/13 - 0s - loss: 0.2219 - accuracy: 0.8923 - val_loss: 0.4599 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01141: val_loss did not improve from 0.41762\n",
      "Epoch 1142/3000\n",
      "13/13 - 0s - loss: 0.2119 - accuracy: 0.9001 - val_loss: 0.4605 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01142: val_loss did not improve from 0.41762\n",
      "Epoch 1143/3000\n",
      "13/13 - 0s - loss: 0.2102 - accuracy: 0.9040 - val_loss: 0.4538 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01143: val_loss did not improve from 0.41762\n",
      "Epoch 1144/3000\n",
      "13/13 - 0s - loss: 0.2106 - accuracy: 0.8988 - val_loss: 0.4543 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01144: val_loss did not improve from 0.41762\n",
      "Epoch 1145/3000\n",
      "13/13 - 0s - loss: 0.2126 - accuracy: 0.9014 - val_loss: 0.4674 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01145: val_loss did not improve from 0.41762\n",
      "Epoch 1146/3000\n",
      "13/13 - 0s - loss: 0.2199 - accuracy: 0.9040 - val_loss: 0.4613 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01146: val_loss did not improve from 0.41762\n",
      "Epoch 1147/3000\n",
      "13/13 - 0s - loss: 0.2151 - accuracy: 0.9027 - val_loss: 0.4490 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01147: val_loss did not improve from 0.41762\n",
      "Epoch 1148/3000\n",
      "13/13 - 0s - loss: 0.2326 - accuracy: 0.8859 - val_loss: 0.4627 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01148: val_loss did not improve from 0.41762\n",
      "Epoch 1149/3000\n",
      "13/13 - 0s - loss: 0.2161 - accuracy: 0.8988 - val_loss: 0.4465 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01149: val_loss did not improve from 0.41762\n",
      "Epoch 1150/3000\n",
      "13/13 - 0s - loss: 0.2111 - accuracy: 0.9040 - val_loss: 0.4477 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01150: val_loss did not improve from 0.41762\n",
      "Epoch 1151/3000\n",
      "13/13 - 0s - loss: 0.2123 - accuracy: 0.8988 - val_loss: 0.4504 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01151: val_loss did not improve from 0.41762\n",
      "Epoch 1152/3000\n",
      "13/13 - 0s - loss: 0.2097 - accuracy: 0.9001 - val_loss: 0.4585 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01152: val_loss did not improve from 0.41762\n",
      "Epoch 1153/3000\n",
      "13/13 - 0s - loss: 0.2106 - accuracy: 0.8988 - val_loss: 0.4509 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01153: val_loss did not improve from 0.41762\n",
      "Epoch 1154/3000\n",
      "13/13 - 0s - loss: 0.2085 - accuracy: 0.8988 - val_loss: 0.4548 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01154: val_loss did not improve from 0.41762\n",
      "Epoch 1155/3000\n",
      "13/13 - 0s - loss: 0.2089 - accuracy: 0.9014 - val_loss: 0.4565 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01155: val_loss did not improve from 0.41762\n",
      "Epoch 1156/3000\n",
      "13/13 - 0s - loss: 0.2085 - accuracy: 0.8988 - val_loss: 0.4554 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01156: val_loss did not improve from 0.41762\n",
      "Epoch 1157/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.9027 - val_loss: 0.4539 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01157: val_loss did not improve from 0.41762\n",
      "Epoch 1158/3000\n",
      "13/13 - 0s - loss: 0.2119 - accuracy: 0.9001 - val_loss: 0.4555 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01158: val_loss did not improve from 0.41762\n",
      "Epoch 1159/3000\n",
      "13/13 - 0s - loss: 0.2136 - accuracy: 0.8975 - val_loss: 0.4599 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01159: val_loss did not improve from 0.41762\n",
      "Epoch 1160/3000\n",
      "13/13 - 0s - loss: 0.2228 - accuracy: 0.8936 - val_loss: 0.4711 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01160: val_loss did not improve from 0.41762\n",
      "Epoch 1161/3000\n",
      "13/13 - 0s - loss: 0.2231 - accuracy: 0.8923 - val_loss: 0.4649 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01161: val_loss did not improve from 0.41762\n",
      "Epoch 1162/3000\n",
      "13/13 - 0s - loss: 0.2328 - accuracy: 0.8807 - val_loss: 0.4878 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01162: val_loss did not improve from 0.41762\n",
      "Epoch 1163/3000\n",
      "13/13 - 0s - loss: 0.2187 - accuracy: 0.8911 - val_loss: 0.4849 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01163: val_loss did not improve from 0.41762\n",
      "Epoch 1164/3000\n",
      "13/13 - 0s - loss: 0.2136 - accuracy: 0.8949 - val_loss: 0.4720 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01164: val_loss did not improve from 0.41762\n",
      "Epoch 1165/3000\n",
      "13/13 - 0s - loss: 0.2142 - accuracy: 0.8898 - val_loss: 0.4662 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01165: val_loss did not improve from 0.41762\n",
      "Epoch 1166/3000\n",
      "13/13 - 0s - loss: 0.2119 - accuracy: 0.8898 - val_loss: 0.4516 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01166: val_loss did not improve from 0.41762\n",
      "Epoch 1167/3000\n",
      "13/13 - 0s - loss: 0.2122 - accuracy: 0.8962 - val_loss: 0.4619 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01167: val_loss did not improve from 0.41762\n",
      "Epoch 1168/3000\n",
      "13/13 - 0s - loss: 0.2099 - accuracy: 0.9001 - val_loss: 0.4552 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01168: val_loss did not improve from 0.41762\n",
      "Epoch 1169/3000\n",
      "13/13 - 0s - loss: 0.2080 - accuracy: 0.9001 - val_loss: 0.4582 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01169: val_loss did not improve from 0.41762\n",
      "Epoch 1170/3000\n",
      "13/13 - 0s - loss: 0.2093 - accuracy: 0.9014 - val_loss: 0.4559 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01170: val_loss did not improve from 0.41762\n",
      "Epoch 1171/3000\n",
      "13/13 - 0s - loss: 0.2065 - accuracy: 0.8975 - val_loss: 0.4580 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01171: val_loss did not improve from 0.41762\n",
      "Epoch 1172/3000\n",
      "13/13 - 0s - loss: 0.2083 - accuracy: 0.9014 - val_loss: 0.4544 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01172: val_loss did not improve from 0.41762\n",
      "Epoch 1173/3000\n",
      "13/13 - 0s - loss: 0.2070 - accuracy: 0.8988 - val_loss: 0.4574 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01173: val_loss did not improve from 0.41762\n",
      "Epoch 1174/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.9001 - val_loss: 0.4616 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01174: val_loss did not improve from 0.41762\n",
      "Epoch 1175/3000\n",
      "13/13 - 0s - loss: 0.2086 - accuracy: 0.8962 - val_loss: 0.4655 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01175: val_loss did not improve from 0.41762\n",
      "Epoch 1176/3000\n",
      "13/13 - 0s - loss: 0.2098 - accuracy: 0.8962 - val_loss: 0.4588 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01176: val_loss did not improve from 0.41762\n",
      "Epoch 1177/3000\n",
      "13/13 - 0s - loss: 0.2128 - accuracy: 0.8949 - val_loss: 0.4669 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01177: val_loss did not improve from 0.41762\n",
      "Epoch 1178/3000\n",
      "13/13 - 0s - loss: 0.2098 - accuracy: 0.9014 - val_loss: 0.4737 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01178: val_loss did not improve from 0.41762\n",
      "Epoch 1179/3000\n",
      "13/13 - 0s - loss: 0.2120 - accuracy: 0.8975 - val_loss: 0.4735 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01179: val_loss did not improve from 0.41762\n",
      "Epoch 1180/3000\n",
      "13/13 - 0s - loss: 0.2120 - accuracy: 0.8962 - val_loss: 0.4615 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01180: val_loss did not improve from 0.41762\n",
      "Epoch 1181/3000\n",
      "13/13 - 0s - loss: 0.2218 - accuracy: 0.9001 - val_loss: 0.4696 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01181: val_loss did not improve from 0.41762\n",
      "Epoch 1182/3000\n",
      "13/13 - 0s - loss: 0.2201 - accuracy: 0.9001 - val_loss: 0.4593 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01182: val_loss did not improve from 0.41762\n",
      "Epoch 1183/3000\n",
      "13/13 - 0s - loss: 0.2184 - accuracy: 0.9001 - val_loss: 0.4694 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01183: val_loss did not improve from 0.41762\n",
      "Epoch 1184/3000\n",
      "13/13 - 0s - loss: 0.2209 - accuracy: 0.8962 - val_loss: 0.4697 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01184: val_loss did not improve from 0.41762\n",
      "Epoch 1185/3000\n",
      "13/13 - 0s - loss: 0.2185 - accuracy: 0.9014 - val_loss: 0.4841 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01185: val_loss did not improve from 0.41762\n",
      "Epoch 1186/3000\n",
      "13/13 - 0s - loss: 0.2356 - accuracy: 0.8872 - val_loss: 0.5130 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01186: val_loss did not improve from 0.41762\n",
      "Epoch 1187/3000\n",
      "13/13 - 0s - loss: 0.2378 - accuracy: 0.8975 - val_loss: 0.4689 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01187: val_loss did not improve from 0.41762\n",
      "Epoch 1188/3000\n",
      "13/13 - 0s - loss: 0.2211 - accuracy: 0.8962 - val_loss: 0.4825 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01188: val_loss did not improve from 0.41762\n",
      "Epoch 1189/3000\n",
      "13/13 - 0s - loss: 0.2340 - accuracy: 0.8949 - val_loss: 0.4737 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01189: val_loss did not improve from 0.41762\n",
      "Epoch 1190/3000\n",
      "13/13 - 0s - loss: 0.2408 - accuracy: 0.8949 - val_loss: 0.4746 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01190: val_loss did not improve from 0.41762\n",
      "Epoch 1191/3000\n",
      "13/13 - 0s - loss: 0.2336 - accuracy: 0.8962 - val_loss: 0.4567 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01191: val_loss did not improve from 0.41762\n",
      "Epoch 1192/3000\n",
      "13/13 - 0s - loss: 0.2164 - accuracy: 0.9001 - val_loss: 0.4623 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01192: val_loss did not improve from 0.41762\n",
      "Epoch 1193/3000\n",
      "13/13 - 0s - loss: 0.2149 - accuracy: 0.9027 - val_loss: 0.4730 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01193: val_loss did not improve from 0.41762\n",
      "Epoch 1194/3000\n",
      "13/13 - 0s - loss: 0.2162 - accuracy: 0.9014 - val_loss: 0.4663 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01194: val_loss did not improve from 0.41762\n",
      "Epoch 1195/3000\n",
      "13/13 - 0s - loss: 0.2136 - accuracy: 0.9027 - val_loss: 0.4487 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01195: val_loss did not improve from 0.41762\n",
      "Epoch 1196/3000\n",
      "13/13 - 0s - loss: 0.2216 - accuracy: 0.8962 - val_loss: 0.4479 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01196: val_loss did not improve from 0.41762\n",
      "Epoch 1197/3000\n",
      "13/13 - 0s - loss: 0.2182 - accuracy: 0.8988 - val_loss: 0.4640 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01197: val_loss did not improve from 0.41762\n",
      "Epoch 1198/3000\n",
      "13/13 - 0s - loss: 0.2186 - accuracy: 0.8962 - val_loss: 0.4750 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01198: val_loss did not improve from 0.41762\n",
      "Epoch 1199/3000\n",
      "13/13 - 0s - loss: 0.2149 - accuracy: 0.8885 - val_loss: 0.4720 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01199: val_loss did not improve from 0.41762\n",
      "Epoch 1200/3000\n",
      "13/13 - 0s - loss: 0.2116 - accuracy: 0.9053 - val_loss: 0.4736 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01200: val_loss did not improve from 0.41762\n",
      "Epoch 1201/3000\n",
      "13/13 - 0s - loss: 0.2080 - accuracy: 0.8923 - val_loss: 0.4693 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01201: val_loss did not improve from 0.41762\n",
      "Epoch 1202/3000\n",
      "13/13 - 0s - loss: 0.2127 - accuracy: 0.8988 - val_loss: 0.4735 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01202: val_loss did not improve from 0.41762\n",
      "Epoch 1203/3000\n",
      "13/13 - 0s - loss: 0.2127 - accuracy: 0.9001 - val_loss: 0.4593 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01203: val_loss did not improve from 0.41762\n",
      "Epoch 1204/3000\n",
      "13/13 - 0s - loss: 0.2110 - accuracy: 0.8923 - val_loss: 0.4612 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01204: val_loss did not improve from 0.41762\n",
      "Epoch 1205/3000\n",
      "13/13 - 0s - loss: 0.2453 - accuracy: 0.9001 - val_loss: 0.4686 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01205: val_loss did not improve from 0.41762\n",
      "Epoch 1206/3000\n",
      "13/13 - 0s - loss: 0.2321 - accuracy: 0.8898 - val_loss: 0.4596 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01206: val_loss did not improve from 0.41762\n",
      "Epoch 1207/3000\n",
      "13/13 - 0s - loss: 0.2434 - accuracy: 0.8936 - val_loss: 0.4617 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01207: val_loss did not improve from 0.41762\n",
      "Epoch 1208/3000\n",
      "13/13 - 0s - loss: 0.2301 - accuracy: 0.8962 - val_loss: 0.4407 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01208: val_loss did not improve from 0.41762\n",
      "Epoch 1209/3000\n",
      "13/13 - 0s - loss: 0.2184 - accuracy: 0.8962 - val_loss: 0.4595 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01209: val_loss did not improve from 0.41762\n",
      "Epoch 1210/3000\n",
      "13/13 - 0s - loss: 0.2142 - accuracy: 0.8988 - val_loss: 0.4526 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01210: val_loss did not improve from 0.41762\n",
      "Epoch 1211/3000\n",
      "13/13 - 0s - loss: 0.2134 - accuracy: 0.8962 - val_loss: 0.4584 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01211: val_loss did not improve from 0.41762\n",
      "Epoch 1212/3000\n",
      "13/13 - 0s - loss: 0.2105 - accuracy: 0.8988 - val_loss: 0.4552 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01212: val_loss did not improve from 0.41762\n",
      "Epoch 1213/3000\n",
      "13/13 - 0s - loss: 0.2098 - accuracy: 0.9001 - val_loss: 0.4337 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01213: val_loss did not improve from 0.41762\n",
      "Epoch 1214/3000\n",
      "13/13 - 0s - loss: 0.2387 - accuracy: 0.8949 - val_loss: 0.4352 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01214: val_loss did not improve from 0.41762\n",
      "Epoch 1215/3000\n",
      "13/13 - 0s - loss: 0.2520 - accuracy: 0.8975 - val_loss: 0.4582 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01215: val_loss did not improve from 0.41762\n",
      "Epoch 1216/3000\n",
      "13/13 - 0s - loss: 0.2266 - accuracy: 0.8962 - val_loss: 0.4685 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01216: val_loss did not improve from 0.41762\n",
      "Epoch 1217/3000\n",
      "13/13 - 0s - loss: 0.2164 - accuracy: 0.9001 - val_loss: 0.4656 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01217: val_loss did not improve from 0.41762\n",
      "Epoch 1218/3000\n",
      "13/13 - 0s - loss: 0.2195 - accuracy: 0.8975 - val_loss: 0.4678 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01218: val_loss did not improve from 0.41762\n",
      "Epoch 1219/3000\n",
      "13/13 - 0s - loss: 0.2119 - accuracy: 0.8988 - val_loss: 0.4490 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01219: val_loss did not improve from 0.41762\n",
      "Epoch 1220/3000\n",
      "13/13 - 0s - loss: 0.2240 - accuracy: 0.8988 - val_loss: 0.4498 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01220: val_loss did not improve from 0.41762\n",
      "Epoch 1221/3000\n",
      "13/13 - 0s - loss: 0.2141 - accuracy: 0.8923 - val_loss: 0.4472 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01221: val_loss did not improve from 0.41762\n",
      "Epoch 1222/3000\n",
      "13/13 - 0s - loss: 0.2113 - accuracy: 0.8975 - val_loss: 0.4604 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01222: val_loss did not improve from 0.41762\n",
      "Epoch 1223/3000\n",
      "13/13 - 0s - loss: 0.2160 - accuracy: 0.9027 - val_loss: 0.4517 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01223: val_loss did not improve from 0.41762\n",
      "Epoch 1224/3000\n",
      "13/13 - 0s - loss: 0.2162 - accuracy: 0.8949 - val_loss: 0.4828 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01224: val_loss did not improve from 0.41762\n",
      "Epoch 1225/3000\n",
      "13/13 - 0s - loss: 0.2573 - accuracy: 0.8885 - val_loss: 0.4471 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01225: val_loss did not improve from 0.41762\n",
      "Epoch 1226/3000\n",
      "13/13 - 0s - loss: 0.2218 - accuracy: 0.8911 - val_loss: 0.4268 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01226: val_loss did not improve from 0.41762\n",
      "Epoch 1227/3000\n",
      "13/13 - 0s - loss: 0.2299 - accuracy: 0.8885 - val_loss: 0.4532 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 01227: val_loss did not improve from 0.41762\n",
      "Epoch 1228/3000\n",
      "13/13 - 0s - loss: 0.2267 - accuracy: 0.8936 - val_loss: 0.4443 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01228: val_loss did not improve from 0.41762\n",
      "Epoch 1229/3000\n",
      "13/13 - 0s - loss: 0.2286 - accuracy: 0.8885 - val_loss: 0.4445 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01229: val_loss did not improve from 0.41762\n",
      "Epoch 1230/3000\n",
      "13/13 - 0s - loss: 0.2262 - accuracy: 0.8898 - val_loss: 0.4530 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01230: val_loss did not improve from 0.41762\n",
      "Epoch 1231/3000\n",
      "13/13 - 0s - loss: 0.2130 - accuracy: 0.9014 - val_loss: 0.4473 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01231: val_loss did not improve from 0.41762\n",
      "Epoch 1232/3000\n",
      "13/13 - 0s - loss: 0.2203 - accuracy: 0.8988 - val_loss: 0.4523 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01232: val_loss did not improve from 0.41762\n",
      "Epoch 1233/3000\n",
      "13/13 - 0s - loss: 0.2207 - accuracy: 0.8962 - val_loss: 0.4410 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01233: val_loss did not improve from 0.41762\n",
      "Epoch 1234/3000\n",
      "13/13 - 0s - loss: 0.2149 - accuracy: 0.9053 - val_loss: 0.4571 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01234: val_loss did not improve from 0.41762\n",
      "Epoch 1235/3000\n",
      "13/13 - 0s - loss: 0.2157 - accuracy: 0.8949 - val_loss: 0.4370 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01235: val_loss did not improve from 0.41762\n",
      "Epoch 1236/3000\n",
      "13/13 - 0s - loss: 0.2109 - accuracy: 0.9001 - val_loss: 0.4609 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01236: val_loss did not improve from 0.41762\n",
      "Epoch 1237/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.9027 - val_loss: 0.4551 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01237: val_loss did not improve from 0.41762\n",
      "Epoch 1238/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.8988 - val_loss: 0.4483 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01238: val_loss did not improve from 0.41762\n",
      "Epoch 1239/3000\n",
      "13/13 - 0s - loss: 0.2105 - accuracy: 0.9014 - val_loss: 0.4591 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01239: val_loss did not improve from 0.41762\n",
      "Epoch 1240/3000\n",
      "13/13 - 0s - loss: 0.2149 - accuracy: 0.9001 - val_loss: 0.4438 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01240: val_loss did not improve from 0.41762\n",
      "Epoch 1241/3000\n",
      "13/13 - 0s - loss: 0.2100 - accuracy: 0.9014 - val_loss: 0.4424 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01241: val_loss did not improve from 0.41762\n",
      "Epoch 1242/3000\n",
      "13/13 - 0s - loss: 0.2262 - accuracy: 0.8898 - val_loss: 0.4603 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01242: val_loss did not improve from 0.41762\n",
      "Epoch 1243/3000\n",
      "13/13 - 0s - loss: 0.2161 - accuracy: 0.8988 - val_loss: 0.4398 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01243: val_loss did not improve from 0.41762\n",
      "Epoch 1244/3000\n",
      "13/13 - 0s - loss: 0.2183 - accuracy: 0.8988 - val_loss: 0.4388 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01244: val_loss did not improve from 0.41762\n",
      "Epoch 1245/3000\n",
      "13/13 - 0s - loss: 0.2149 - accuracy: 0.9027 - val_loss: 0.4519 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01245: val_loss did not improve from 0.41762\n",
      "Epoch 1246/3000\n",
      "13/13 - 0s - loss: 0.2155 - accuracy: 0.9027 - val_loss: 0.4424 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01246: val_loss did not improve from 0.41762\n",
      "Epoch 1247/3000\n",
      "13/13 - 0s - loss: 0.2117 - accuracy: 0.9014 - val_loss: 0.4483 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01247: val_loss did not improve from 0.41762\n",
      "Epoch 1248/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.8988 - val_loss: 0.4407 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01248: val_loss did not improve from 0.41762\n",
      "Epoch 1249/3000\n",
      "13/13 - 0s - loss: 0.2106 - accuracy: 0.8975 - val_loss: 0.4497 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01249: val_loss did not improve from 0.41762\n",
      "Epoch 1250/3000\n",
      "13/13 - 0s - loss: 0.2114 - accuracy: 0.9014 - val_loss: 0.4682 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01250: val_loss did not improve from 0.41762\n",
      "Epoch 1251/3000\n",
      "13/13 - 0s - loss: 0.2117 - accuracy: 0.9001 - val_loss: 0.4585 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01251: val_loss did not improve from 0.41762\n",
      "Epoch 1252/3000\n",
      "13/13 - 0s - loss: 0.2113 - accuracy: 0.9014 - val_loss: 0.4593 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01252: val_loss did not improve from 0.41762\n",
      "Epoch 1253/3000\n",
      "13/13 - 0s - loss: 0.2091 - accuracy: 0.8975 - val_loss: 0.4551 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01253: val_loss did not improve from 0.41762\n",
      "Epoch 1254/3000\n",
      "13/13 - 0s - loss: 0.2086 - accuracy: 0.8988 - val_loss: 0.4589 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01254: val_loss did not improve from 0.41762\n",
      "Epoch 1255/3000\n",
      "13/13 - 0s - loss: 0.2121 - accuracy: 0.8962 - val_loss: 0.4686 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01255: val_loss did not improve from 0.41762\n",
      "Epoch 1256/3000\n",
      "13/13 - 0s - loss: 0.2089 - accuracy: 0.9014 - val_loss: 0.4516 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01256: val_loss did not improve from 0.41762\n",
      "Epoch 1257/3000\n",
      "13/13 - 0s - loss: 0.2233 - accuracy: 0.8911 - val_loss: 0.5080 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01257: val_loss did not improve from 0.41762\n",
      "Epoch 1258/3000\n",
      "13/13 - 0s - loss: 0.2260 - accuracy: 0.9001 - val_loss: 0.5054 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01258: val_loss did not improve from 0.41762\n",
      "Epoch 1259/3000\n",
      "13/13 - 0s - loss: 0.2197 - accuracy: 0.9001 - val_loss: 0.4929 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01259: val_loss did not improve from 0.41762\n",
      "Epoch 1260/3000\n",
      "13/13 - 0s - loss: 0.2166 - accuracy: 0.8975 - val_loss: 0.5000 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01260: val_loss did not improve from 0.41762\n",
      "Epoch 1261/3000\n",
      "13/13 - 0s - loss: 0.2162 - accuracy: 0.9027 - val_loss: 0.5066 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01261: val_loss did not improve from 0.41762\n",
      "Epoch 1262/3000\n",
      "13/13 - 0s - loss: 0.2525 - accuracy: 0.8872 - val_loss: 0.4898 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01262: val_loss did not improve from 0.41762\n",
      "Epoch 1263/3000\n",
      "13/13 - 0s - loss: 0.2289 - accuracy: 0.8949 - val_loss: 0.4608 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01263: val_loss did not improve from 0.41762\n",
      "Epoch 1264/3000\n",
      "13/13 - 0s - loss: 0.2174 - accuracy: 0.9040 - val_loss: 0.4661 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01264: val_loss did not improve from 0.41762\n",
      "Epoch 1265/3000\n",
      "13/13 - 0s - loss: 0.2139 - accuracy: 0.8936 - val_loss: 0.4582 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01265: val_loss did not improve from 0.41762\n",
      "Epoch 1266/3000\n",
      "13/13 - 0s - loss: 0.2107 - accuracy: 0.8975 - val_loss: 0.4449 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01266: val_loss did not improve from 0.41762\n",
      "Epoch 1267/3000\n",
      "13/13 - 0s - loss: 0.2686 - accuracy: 0.8923 - val_loss: 0.4392 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01267: val_loss did not improve from 0.41762\n",
      "Epoch 1268/3000\n",
      "13/13 - 0s - loss: 0.2613 - accuracy: 0.8846 - val_loss: 0.4833 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01268: val_loss did not improve from 0.41762\n",
      "Epoch 1269/3000\n",
      "13/13 - 0s - loss: 0.2364 - accuracy: 0.8949 - val_loss: 0.4575 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01269: val_loss did not improve from 0.41762\n",
      "Epoch 1270/3000\n",
      "13/13 - 0s - loss: 0.2311 - accuracy: 0.8936 - val_loss: 0.4615 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01270: val_loss did not improve from 0.41762\n",
      "Epoch 1271/3000\n",
      "13/13 - 0s - loss: 0.2221 - accuracy: 0.8885 - val_loss: 0.4800 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01271: val_loss did not improve from 0.41762\n",
      "Epoch 1272/3000\n",
      "13/13 - 0s - loss: 0.2358 - accuracy: 0.8988 - val_loss: 0.4800 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01272: val_loss did not improve from 0.41762\n",
      "Epoch 1273/3000\n",
      "13/13 - 0s - loss: 0.2291 - accuracy: 0.9027 - val_loss: 0.4510 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01273: val_loss did not improve from 0.41762\n",
      "Epoch 1274/3000\n",
      "13/13 - 0s - loss: 0.2332 - accuracy: 0.8911 - val_loss: 0.4791 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01274: val_loss did not improve from 0.41762\n",
      "Epoch 1275/3000\n",
      "13/13 - 0s - loss: 0.2246 - accuracy: 0.9014 - val_loss: 0.4500 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01275: val_loss did not improve from 0.41762\n",
      "Epoch 1276/3000\n",
      "13/13 - 0s - loss: 0.2251 - accuracy: 0.8923 - val_loss: 0.4608 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01276: val_loss did not improve from 0.41762\n",
      "Epoch 1277/3000\n",
      "13/13 - 0s - loss: 0.2184 - accuracy: 0.9014 - val_loss: 0.4551 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01277: val_loss did not improve from 0.41762\n",
      "Epoch 1278/3000\n",
      "13/13 - 0s - loss: 0.2125 - accuracy: 0.8949 - val_loss: 0.4528 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01278: val_loss did not improve from 0.41762\n",
      "Epoch 1279/3000\n",
      "13/13 - 0s - loss: 0.2100 - accuracy: 0.8988 - val_loss: 0.4473 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01279: val_loss did not improve from 0.41762\n",
      "Epoch 1280/3000\n",
      "13/13 - 0s - loss: 0.2104 - accuracy: 0.8975 - val_loss: 0.4553 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01280: val_loss did not improve from 0.41762\n",
      "Epoch 1281/3000\n",
      "13/13 - 0s - loss: 0.2159 - accuracy: 0.9040 - val_loss: 0.4614 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01281: val_loss did not improve from 0.41762\n",
      "Epoch 1282/3000\n",
      "13/13 - 0s - loss: 0.2140 - accuracy: 0.8975 - val_loss: 0.4544 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01282: val_loss did not improve from 0.41762\n",
      "Epoch 1283/3000\n",
      "13/13 - 0s - loss: 0.2222 - accuracy: 0.9053 - val_loss: 0.5135 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01283: val_loss did not improve from 0.41762\n",
      "Epoch 1284/3000\n",
      "13/13 - 0s - loss: 0.2237 - accuracy: 0.9014 - val_loss: 0.4831 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01284: val_loss did not improve from 0.41762\n",
      "Epoch 1285/3000\n",
      "13/13 - 0s - loss: 0.2209 - accuracy: 0.8885 - val_loss: 0.4755 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01285: val_loss did not improve from 0.41762\n",
      "Epoch 1286/3000\n",
      "13/13 - 0s - loss: 0.2390 - accuracy: 0.8949 - val_loss: 0.4907 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01286: val_loss did not improve from 0.41762\n",
      "Epoch 1287/3000\n",
      "13/13 - 0s - loss: 0.2266 - accuracy: 0.8872 - val_loss: 0.4773 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01287: val_loss did not improve from 0.41762\n",
      "Epoch 1288/3000\n",
      "13/13 - 0s - loss: 0.2125 - accuracy: 0.9027 - val_loss: 0.4689 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01288: val_loss did not improve from 0.41762\n",
      "Epoch 1289/3000\n",
      "13/13 - 0s - loss: 0.2103 - accuracy: 0.8975 - val_loss: 0.4574 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01289: val_loss did not improve from 0.41762\n",
      "Epoch 1290/3000\n",
      "13/13 - 0s - loss: 0.2178 - accuracy: 0.8911 - val_loss: 0.4619 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01290: val_loss did not improve from 0.41762\n",
      "Epoch 1291/3000\n",
      "13/13 - 0s - loss: 0.2293 - accuracy: 0.8898 - val_loss: 0.4511 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01291: val_loss did not improve from 0.41762\n",
      "Epoch 1292/3000\n",
      "13/13 - 0s - loss: 0.2172 - accuracy: 0.9014 - val_loss: 0.4737 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01292: val_loss did not improve from 0.41762\n",
      "Epoch 1293/3000\n",
      "13/13 - 0s - loss: 0.2137 - accuracy: 0.8962 - val_loss: 0.4604 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01293: val_loss did not improve from 0.41762\n",
      "Epoch 1294/3000\n",
      "13/13 - 0s - loss: 0.2170 - accuracy: 0.8936 - val_loss: 0.4641 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01294: val_loss did not improve from 0.41762\n",
      "Epoch 1295/3000\n",
      "13/13 - 0s - loss: 0.2112 - accuracy: 0.9027 - val_loss: 0.4686 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01295: val_loss did not improve from 0.41762\n",
      "Epoch 1296/3000\n",
      "13/13 - 0s - loss: 0.2158 - accuracy: 0.9014 - val_loss: 0.4469 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01296: val_loss did not improve from 0.41762\n",
      "Epoch 1297/3000\n",
      "13/13 - 0s - loss: 0.2145 - accuracy: 0.9027 - val_loss: 0.4691 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01297: val_loss did not improve from 0.41762\n",
      "Epoch 1298/3000\n",
      "13/13 - 0s - loss: 0.2131 - accuracy: 0.9001 - val_loss: 0.4679 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01298: val_loss did not improve from 0.41762\n",
      "Epoch 1299/3000\n",
      "13/13 - 0s - loss: 0.2177 - accuracy: 0.8911 - val_loss: 0.4707 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01299: val_loss did not improve from 0.41762\n",
      "Epoch 1300/3000\n",
      "13/13 - 0s - loss: 0.2185 - accuracy: 0.8988 - val_loss: 0.4691 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01300: val_loss did not improve from 0.41762\n",
      "Epoch 1301/3000\n",
      "13/13 - 0s - loss: 0.2212 - accuracy: 0.8807 - val_loss: 0.4553 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 01301: val_loss did not improve from 0.41762\n",
      "Epoch 1302/3000\n",
      "13/13 - 0s - loss: 0.2112 - accuracy: 0.8975 - val_loss: 0.4503 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01302: val_loss did not improve from 0.41762\n",
      "Epoch 1303/3000\n",
      "13/13 - 0s - loss: 0.2165 - accuracy: 0.8988 - val_loss: 0.4643 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01303: val_loss did not improve from 0.41762\n",
      "Epoch 1304/3000\n",
      "13/13 - 0s - loss: 0.2362 - accuracy: 0.8807 - val_loss: 0.4587 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01304: val_loss did not improve from 0.41762\n",
      "Epoch 1305/3000\n",
      "13/13 - 0s - loss: 0.2142 - accuracy: 0.9014 - val_loss: 0.4558 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01305: val_loss did not improve from 0.41762\n",
      "Epoch 1306/3000\n",
      "13/13 - 0s - loss: 0.2123 - accuracy: 0.9027 - val_loss: 0.4516 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01306: val_loss did not improve from 0.41762\n",
      "Epoch 1307/3000\n",
      "13/13 - 0s - loss: 0.2112 - accuracy: 0.9014 - val_loss: 0.4696 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01307: val_loss did not improve from 0.41762\n",
      "Epoch 1308/3000\n",
      "13/13 - 0s - loss: 0.2149 - accuracy: 0.9014 - val_loss: 0.4681 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01308: val_loss did not improve from 0.41762\n",
      "Epoch 1309/3000\n",
      "13/13 - 0s - loss: 0.2163 - accuracy: 0.8988 - val_loss: 0.4604 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01309: val_loss did not improve from 0.41762\n",
      "Epoch 1310/3000\n",
      "13/13 - 0s - loss: 0.2130 - accuracy: 0.9001 - val_loss: 0.4437 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01310: val_loss did not improve from 0.41762\n",
      "Epoch 1311/3000\n",
      "13/13 - 0s - loss: 0.2100 - accuracy: 0.9014 - val_loss: 0.4415 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01311: val_loss did not improve from 0.41762\n",
      "Epoch 1312/3000\n",
      "13/13 - 0s - loss: 0.2626 - accuracy: 0.8962 - val_loss: 0.4387 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 01312: val_loss did not improve from 0.41762\n",
      "Epoch 1313/3000\n",
      "13/13 - 0s - loss: 0.2550 - accuracy: 0.8923 - val_loss: 0.4727 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01313: val_loss did not improve from 0.41762\n",
      "Epoch 1314/3000\n",
      "13/13 - 0s - loss: 0.2220 - accuracy: 0.8936 - val_loss: 0.4670 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01314: val_loss did not improve from 0.41762\n",
      "Epoch 1315/3000\n",
      "13/13 - 0s - loss: 0.2221 - accuracy: 0.8923 - val_loss: 0.4783 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01315: val_loss did not improve from 0.41762\n",
      "Epoch 1316/3000\n",
      "13/13 - 0s - loss: 0.2164 - accuracy: 0.8962 - val_loss: 0.4626 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01316: val_loss did not improve from 0.41762\n",
      "Epoch 1317/3000\n",
      "13/13 - 0s - loss: 0.2116 - accuracy: 0.9027 - val_loss: 0.4634 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01317: val_loss did not improve from 0.41762\n",
      "Epoch 1318/3000\n",
      "13/13 - 0s - loss: 0.2163 - accuracy: 0.9014 - val_loss: 0.4543 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01318: val_loss did not improve from 0.41762\n",
      "Epoch 1319/3000\n",
      "13/13 - 0s - loss: 0.2217 - accuracy: 0.8859 - val_loss: 0.4363 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01319: val_loss did not improve from 0.41762\n",
      "Epoch 1320/3000\n",
      "13/13 - 0s - loss: 0.2337 - accuracy: 0.8898 - val_loss: 0.4506 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01320: val_loss did not improve from 0.41762\n",
      "Epoch 1321/3000\n",
      "13/13 - 0s - loss: 0.2213 - accuracy: 0.8923 - val_loss: 0.4553 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01321: val_loss did not improve from 0.41762\n",
      "Epoch 1322/3000\n",
      "13/13 - 0s - loss: 0.2154 - accuracy: 0.9014 - val_loss: 0.4525 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01322: val_loss did not improve from 0.41762\n",
      "Epoch 1323/3000\n",
      "13/13 - 0s - loss: 0.2172 - accuracy: 0.8923 - val_loss: 0.4547 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01323: val_loss did not improve from 0.41762\n",
      "Epoch 1324/3000\n",
      "13/13 - 0s - loss: 0.2235 - accuracy: 0.8936 - val_loss: 0.4653 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01324: val_loss did not improve from 0.41762\n",
      "Epoch 1325/3000\n",
      "13/13 - 0s - loss: 0.2213 - accuracy: 0.8911 - val_loss: 0.4691 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01325: val_loss did not improve from 0.41762\n",
      "Epoch 1326/3000\n",
      "13/13 - 0s - loss: 0.2178 - accuracy: 0.8898 - val_loss: 0.4687 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01326: val_loss did not improve from 0.41762\n",
      "Epoch 1327/3000\n",
      "13/13 - 0s - loss: 0.2169 - accuracy: 0.9027 - val_loss: 0.4663 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01327: val_loss did not improve from 0.41762\n",
      "Epoch 1328/3000\n",
      "13/13 - 0s - loss: 0.2136 - accuracy: 0.8936 - val_loss: 0.4512 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01328: val_loss did not improve from 0.41762\n",
      "Epoch 1329/3000\n",
      "13/13 - 0s - loss: 0.2093 - accuracy: 0.8988 - val_loss: 0.4505 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01329: val_loss did not improve from 0.41762\n",
      "Epoch 1330/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.9014 - val_loss: 0.4590 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01330: val_loss did not improve from 0.41762\n",
      "Epoch 1331/3000\n",
      "13/13 - 0s - loss: 0.2182 - accuracy: 0.8898 - val_loss: 0.4654 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01331: val_loss did not improve from 0.41762\n",
      "Epoch 1332/3000\n",
      "13/13 - 0s - loss: 0.2122 - accuracy: 0.8962 - val_loss: 0.4630 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01332: val_loss did not improve from 0.41762\n",
      "Epoch 1333/3000\n",
      "13/13 - 0s - loss: 0.2118 - accuracy: 0.9014 - val_loss: 0.4590 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01333: val_loss did not improve from 0.41762\n",
      "Epoch 1334/3000\n",
      "13/13 - 0s - loss: 0.2217 - accuracy: 0.8962 - val_loss: 0.4942 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01334: val_loss did not improve from 0.41762\n",
      "Epoch 1335/3000\n",
      "13/13 - 0s - loss: 0.2397 - accuracy: 0.8975 - val_loss: 0.4726 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01335: val_loss did not improve from 0.41762\n",
      "Epoch 1336/3000\n",
      "13/13 - 0s - loss: 0.2226 - accuracy: 0.8975 - val_loss: 0.4616 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01336: val_loss did not improve from 0.41762\n",
      "Epoch 1337/3000\n",
      "13/13 - 0s - loss: 0.2143 - accuracy: 0.9001 - val_loss: 0.4624 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01337: val_loss did not improve from 0.41762\n",
      "Epoch 1338/3000\n",
      "13/13 - 0s - loss: 0.2139 - accuracy: 0.9014 - val_loss: 0.4569 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01338: val_loss did not improve from 0.41762\n",
      "Epoch 1339/3000\n",
      "13/13 - 0s - loss: 0.2097 - accuracy: 0.8988 - val_loss: 0.4583 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01339: val_loss did not improve from 0.41762\n",
      "Epoch 1340/3000\n",
      "13/13 - 0s - loss: 0.2101 - accuracy: 0.8962 - val_loss: 0.4531 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01340: val_loss did not improve from 0.41762\n",
      "Epoch 1341/3000\n",
      "13/13 - 0s - loss: 0.2104 - accuracy: 0.9001 - val_loss: 0.4602 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01341: val_loss did not improve from 0.41762\n",
      "Epoch 1342/3000\n",
      "13/13 - 0s - loss: 0.2098 - accuracy: 0.8949 - val_loss: 0.4655 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01342: val_loss did not improve from 0.41762\n",
      "Epoch 1343/3000\n",
      "13/13 - 0s - loss: 0.2140 - accuracy: 0.9014 - val_loss: 0.4607 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01343: val_loss did not improve from 0.41762\n",
      "Epoch 1344/3000\n",
      "13/13 - 0s - loss: 0.2107 - accuracy: 0.9014 - val_loss: 0.4683 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01344: val_loss did not improve from 0.41762\n",
      "Epoch 1345/3000\n",
      "13/13 - 0s - loss: 0.2088 - accuracy: 0.8975 - val_loss: 0.4539 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01345: val_loss did not improve from 0.41762\n",
      "Epoch 1346/3000\n",
      "13/13 - 0s - loss: 0.2184 - accuracy: 0.9001 - val_loss: 0.4775 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01346: val_loss did not improve from 0.41762\n",
      "Epoch 1347/3000\n",
      "13/13 - 0s - loss: 0.2229 - accuracy: 0.9027 - val_loss: 0.4653 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01347: val_loss did not improve from 0.41762\n",
      "Epoch 1348/3000\n",
      "13/13 - 0s - loss: 0.2266 - accuracy: 0.8988 - val_loss: 0.4749 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01348: val_loss did not improve from 0.41762\n",
      "Epoch 1349/3000\n",
      "13/13 - 0s - loss: 0.2238 - accuracy: 0.8975 - val_loss: 0.4537 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01349: val_loss did not improve from 0.41762\n",
      "Epoch 1350/3000\n",
      "13/13 - 0s - loss: 0.2174 - accuracy: 0.8975 - val_loss: 0.4687 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01350: val_loss did not improve from 0.41762\n",
      "Epoch 1351/3000\n",
      "13/13 - 0s - loss: 0.2194 - accuracy: 0.9027 - val_loss: 0.4586 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01351: val_loss did not improve from 0.41762\n",
      "Epoch 1352/3000\n",
      "13/13 - 0s - loss: 0.2145 - accuracy: 0.8975 - val_loss: 0.4587 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01352: val_loss did not improve from 0.41762\n",
      "Epoch 1353/3000\n",
      "13/13 - 0s - loss: 0.2097 - accuracy: 0.8988 - val_loss: 0.4706 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01353: val_loss did not improve from 0.41762\n",
      "Epoch 1354/3000\n",
      "13/13 - 0s - loss: 0.2205 - accuracy: 0.8975 - val_loss: 0.4624 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01354: val_loss did not improve from 0.41762\n",
      "Epoch 1355/3000\n",
      "13/13 - 0s - loss: 0.2119 - accuracy: 0.9014 - val_loss: 0.4557 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01355: val_loss did not improve from 0.41762\n",
      "Epoch 1356/3000\n",
      "13/13 - 0s - loss: 0.2246 - accuracy: 0.8975 - val_loss: 0.4648 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01356: val_loss did not improve from 0.41762\n",
      "Epoch 1357/3000\n",
      "13/13 - 0s - loss: 0.2205 - accuracy: 0.8949 - val_loss: 0.4618 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01357: val_loss did not improve from 0.41762\n",
      "Epoch 1358/3000\n",
      "13/13 - 0s - loss: 0.2122 - accuracy: 0.8962 - val_loss: 0.4682 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01358: val_loss did not improve from 0.41762\n",
      "Epoch 1359/3000\n",
      "13/13 - 0s - loss: 0.2108 - accuracy: 0.8988 - val_loss: 0.4611 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01359: val_loss did not improve from 0.41762\n",
      "Epoch 1360/3000\n",
      "13/13 - 0s - loss: 0.2143 - accuracy: 0.8911 - val_loss: 0.4743 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01360: val_loss did not improve from 0.41762\n",
      "Epoch 1361/3000\n",
      "13/13 - 0s - loss: 0.2311 - accuracy: 0.8923 - val_loss: 0.5131 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01361: val_loss did not improve from 0.41762\n",
      "Epoch 1362/3000\n",
      "13/13 - 0s - loss: 0.2259 - accuracy: 0.9001 - val_loss: 0.4769 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01362: val_loss did not improve from 0.41762\n",
      "Epoch 1363/3000\n",
      "13/13 - 0s - loss: 0.2262 - accuracy: 0.9014 - val_loss: 0.4513 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01363: val_loss did not improve from 0.41762\n",
      "Epoch 1364/3000\n",
      "13/13 - 0s - loss: 0.2250 - accuracy: 0.9027 - val_loss: 0.4742 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01364: val_loss did not improve from 0.41762\n",
      "Epoch 1365/3000\n",
      "13/13 - 0s - loss: 0.2191 - accuracy: 0.9014 - val_loss: 0.4530 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01365: val_loss did not improve from 0.41762\n",
      "Epoch 1366/3000\n",
      "13/13 - 0s - loss: 0.2346 - accuracy: 0.8820 - val_loss: 0.4533 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01366: val_loss did not improve from 0.41762\n",
      "Epoch 1367/3000\n",
      "13/13 - 0s - loss: 0.2350 - accuracy: 0.8872 - val_loss: 0.4618 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01367: val_loss did not improve from 0.41762\n",
      "Epoch 1368/3000\n",
      "13/13 - 0s - loss: 0.2294 - accuracy: 0.8962 - val_loss: 0.4695 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01368: val_loss did not improve from 0.41762\n",
      "Epoch 1369/3000\n",
      "13/13 - 0s - loss: 0.2251 - accuracy: 0.8962 - val_loss: 0.4516 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01369: val_loss did not improve from 0.41762\n",
      "Epoch 1370/3000\n",
      "13/13 - 0s - loss: 0.2150 - accuracy: 0.8988 - val_loss: 0.4531 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01370: val_loss did not improve from 0.41762\n",
      "Epoch 1371/3000\n",
      "13/13 - 0s - loss: 0.2103 - accuracy: 0.8975 - val_loss: 0.4501 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01371: val_loss did not improve from 0.41762\n",
      "Epoch 1372/3000\n",
      "13/13 - 0s - loss: 0.2100 - accuracy: 0.8988 - val_loss: 0.4578 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01372: val_loss did not improve from 0.41762\n",
      "Epoch 1373/3000\n",
      "13/13 - 0s - loss: 0.2136 - accuracy: 0.8988 - val_loss: 0.4543 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01373: val_loss did not improve from 0.41762\n",
      "Epoch 1374/3000\n",
      "13/13 - 0s - loss: 0.2137 - accuracy: 0.8975 - val_loss: 0.4455 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01374: val_loss did not improve from 0.41762\n",
      "Epoch 1375/3000\n",
      "13/13 - 0s - loss: 0.2093 - accuracy: 0.8962 - val_loss: 0.4505 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01375: val_loss did not improve from 0.41762\n",
      "Epoch 1376/3000\n",
      "13/13 - 0s - loss: 0.2105 - accuracy: 0.8975 - val_loss: 0.4490 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01376: val_loss did not improve from 0.41762\n",
      "Epoch 1377/3000\n",
      "13/13 - 0s - loss: 0.2272 - accuracy: 0.8949 - val_loss: 0.4692 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01377: val_loss did not improve from 0.41762\n",
      "Epoch 1378/3000\n",
      "13/13 - 0s - loss: 0.2301 - accuracy: 0.8949 - val_loss: 0.4966 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01378: val_loss did not improve from 0.41762\n",
      "Epoch 1379/3000\n",
      "13/13 - 0s - loss: 0.2191 - accuracy: 0.8962 - val_loss: 0.4565 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01379: val_loss did not improve from 0.41762\n",
      "Epoch 1380/3000\n",
      "13/13 - 0s - loss: 0.2159 - accuracy: 0.9027 - val_loss: 0.4694 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01380: val_loss did not improve from 0.41762\n",
      "Epoch 1381/3000\n",
      "13/13 - 0s - loss: 0.2208 - accuracy: 0.8936 - val_loss: 0.4634 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01381: val_loss did not improve from 0.41762\n",
      "Epoch 1382/3000\n",
      "13/13 - 0s - loss: 0.2112 - accuracy: 0.9001 - val_loss: 0.4718 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01382: val_loss did not improve from 0.41762\n",
      "Epoch 1383/3000\n",
      "13/13 - 0s - loss: 0.2162 - accuracy: 0.9014 - val_loss: 0.4459 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01383: val_loss did not improve from 0.41762\n",
      "Epoch 1384/3000\n",
      "13/13 - 0s - loss: 0.2115 - accuracy: 0.9001 - val_loss: 0.4591 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01384: val_loss did not improve from 0.41762\n",
      "Epoch 1385/3000\n",
      "13/13 - 0s - loss: 0.2120 - accuracy: 0.9001 - val_loss: 0.4593 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01385: val_loss did not improve from 0.41762\n",
      "Epoch 1386/3000\n",
      "13/13 - 0s - loss: 0.2171 - accuracy: 0.9001 - val_loss: 0.4852 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01386: val_loss did not improve from 0.41762\n",
      "Epoch 1387/3000\n",
      "13/13 - 0s - loss: 0.2250 - accuracy: 0.8872 - val_loss: 0.4734 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01387: val_loss did not improve from 0.41762\n",
      "Epoch 1388/3000\n",
      "13/13 - 0s - loss: 0.2167 - accuracy: 0.9014 - val_loss: 0.4534 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01388: val_loss did not improve from 0.41762\n",
      "Epoch 1389/3000\n",
      "13/13 - 0s - loss: 0.2095 - accuracy: 0.9040 - val_loss: 0.4496 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01389: val_loss did not improve from 0.41762\n",
      "Epoch 1390/3000\n",
      "13/13 - 0s - loss: 0.2085 - accuracy: 0.8975 - val_loss: 0.4719 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01390: val_loss did not improve from 0.41762\n",
      "Epoch 1391/3000\n",
      "13/13 - 0s - loss: 0.2176 - accuracy: 0.8962 - val_loss: 0.4787 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01391: val_loss did not improve from 0.41762\n",
      "Epoch 1392/3000\n",
      "13/13 - 0s - loss: 0.2477 - accuracy: 0.8781 - val_loss: 0.5037 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01392: val_loss did not improve from 0.41762\n",
      "Epoch 1393/3000\n",
      "13/13 - 0s - loss: 0.2439 - accuracy: 0.8820 - val_loss: 0.4736 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01393: val_loss did not improve from 0.41762\n",
      "Epoch 1394/3000\n",
      "13/13 - 0s - loss: 0.2155 - accuracy: 0.8936 - val_loss: 0.4501 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01394: val_loss did not improve from 0.41762\n",
      "Epoch 1395/3000\n",
      "13/13 - 0s - loss: 0.2096 - accuracy: 0.8975 - val_loss: 0.4612 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01395: val_loss did not improve from 0.41762\n",
      "Epoch 1396/3000\n",
      "13/13 - 0s - loss: 0.2109 - accuracy: 0.9014 - val_loss: 0.4633 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01396: val_loss did not improve from 0.41762\n",
      "Epoch 1397/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.8988 - val_loss: 0.4560 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01397: val_loss did not improve from 0.41762\n",
      "Epoch 1398/3000\n",
      "13/13 - 0s - loss: 0.2080 - accuracy: 0.9001 - val_loss: 0.4598 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01398: val_loss did not improve from 0.41762\n",
      "Epoch 1399/3000\n",
      "13/13 - 0s - loss: 0.2077 - accuracy: 0.9027 - val_loss: 0.4582 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01399: val_loss did not improve from 0.41762\n",
      "Epoch 1400/3000\n",
      "13/13 - 0s - loss: 0.2199 - accuracy: 0.8846 - val_loss: 0.4477 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01400: val_loss did not improve from 0.41762\n",
      "Epoch 1401/3000\n",
      "13/13 - 0s - loss: 0.2189 - accuracy: 0.8936 - val_loss: 0.4593 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01401: val_loss did not improve from 0.41762\n",
      "Epoch 1402/3000\n",
      "13/13 - 0s - loss: 0.2170 - accuracy: 0.9014 - val_loss: 0.4698 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01402: val_loss did not improve from 0.41762\n",
      "Epoch 1403/3000\n",
      "13/13 - 0s - loss: 0.2134 - accuracy: 0.8962 - val_loss: 0.4788 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01403: val_loss did not improve from 0.41762\n",
      "Epoch 1404/3000\n",
      "13/13 - 0s - loss: 0.2311 - accuracy: 0.8833 - val_loss: 0.4789 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01404: val_loss did not improve from 0.41762\n",
      "Epoch 1405/3000\n",
      "13/13 - 0s - loss: 0.2229 - accuracy: 0.8911 - val_loss: 0.4862 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01405: val_loss did not improve from 0.41762\n",
      "Epoch 1406/3000\n",
      "13/13 - 0s - loss: 0.2142 - accuracy: 0.9027 - val_loss: 0.4630 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01406: val_loss did not improve from 0.41762\n",
      "Epoch 1407/3000\n",
      "13/13 - 0s - loss: 0.2147 - accuracy: 0.9014 - val_loss: 0.4544 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01407: val_loss did not improve from 0.41762\n",
      "Epoch 1408/3000\n",
      "13/13 - 0s - loss: 0.2105 - accuracy: 0.9040 - val_loss: 0.4667 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01408: val_loss did not improve from 0.41762\n",
      "Epoch 1409/3000\n",
      "13/13 - 0s - loss: 0.2082 - accuracy: 0.9027 - val_loss: 0.4551 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01409: val_loss did not improve from 0.41762\n",
      "Epoch 1410/3000\n",
      "13/13 - 0s - loss: 0.2140 - accuracy: 0.8936 - val_loss: 0.4653 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01410: val_loss did not improve from 0.41762\n",
      "Epoch 1411/3000\n",
      "13/13 - 0s - loss: 0.2216 - accuracy: 0.8975 - val_loss: 0.4554 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 01411: val_loss did not improve from 0.41762\n",
      "Epoch 1412/3000\n",
      "13/13 - 0s - loss: 0.2177 - accuracy: 0.8936 - val_loss: 0.4602 - val_accuracy: 0.8653\n",
      "\n",
      "Epoch 01412: val_loss did not improve from 0.41762\n",
      "Epoch 1413/3000\n",
      "13/13 - 0s - loss: 0.2138 - accuracy: 0.8923 - val_loss: 0.4616 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01413: val_loss did not improve from 0.41762\n",
      "Epoch 1414/3000\n",
      "13/13 - 0s - loss: 0.2257 - accuracy: 0.8923 - val_loss: 0.4705 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01414: val_loss did not improve from 0.41762\n",
      "Epoch 1415/3000\n",
      "13/13 - 0s - loss: 0.2105 - accuracy: 0.8949 - val_loss: 0.4535 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01415: val_loss did not improve from 0.41762\n",
      "Epoch 1416/3000\n",
      "13/13 - 0s - loss: 0.2092 - accuracy: 0.9001 - val_loss: 0.4676 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01416: val_loss did not improve from 0.41762\n",
      "Epoch 1417/3000\n",
      "13/13 - 0s - loss: 0.2064 - accuracy: 0.8962 - val_loss: 0.4574 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01417: val_loss did not improve from 0.41762\n",
      "Epoch 1418/3000\n",
      "13/13 - 0s - loss: 0.2123 - accuracy: 0.9001 - val_loss: 0.4538 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01418: val_loss did not improve from 0.41762\n",
      "Epoch 1419/3000\n",
      "13/13 - 0s - loss: 0.2289 - accuracy: 0.8846 - val_loss: 0.4622 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01419: val_loss did not improve from 0.41762\n",
      "Epoch 1420/3000\n",
      "13/13 - 0s - loss: 0.2310 - accuracy: 0.8820 - val_loss: 0.4375 - val_accuracy: 0.8653\n",
      "\n",
      "Epoch 01420: val_loss did not improve from 0.41762\n",
      "Epoch 1421/3000\n",
      "13/13 - 0s - loss: 0.2332 - accuracy: 0.8898 - val_loss: 0.4274 - val_accuracy: 0.8653\n",
      "\n",
      "Epoch 01421: val_loss did not improve from 0.41762\n",
      "Epoch 1422/3000\n",
      "13/13 - 0s - loss: 0.2193 - accuracy: 0.8923 - val_loss: 0.4387 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01422: val_loss did not improve from 0.41762\n",
      "Epoch 1423/3000\n",
      "13/13 - 0s - loss: 0.2176 - accuracy: 0.8988 - val_loss: 0.4469 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01423: val_loss did not improve from 0.41762\n",
      "Epoch 1424/3000\n",
      "13/13 - 0s - loss: 0.2118 - accuracy: 0.8949 - val_loss: 0.4546 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01424: val_loss did not improve from 0.41762\n",
      "Epoch 1425/3000\n",
      "13/13 - 0s - loss: 0.2108 - accuracy: 0.9001 - val_loss: 0.4636 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01425: val_loss did not improve from 0.41762\n",
      "Epoch 1426/3000\n",
      "13/13 - 0s - loss: 0.2135 - accuracy: 0.9014 - val_loss: 0.4637 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01426: val_loss did not improve from 0.41762\n",
      "Epoch 1427/3000\n",
      "13/13 - 0s - loss: 0.2221 - accuracy: 0.8962 - val_loss: 0.4689 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 01427: val_loss did not improve from 0.41762\n",
      "Epoch 1428/3000\n",
      "13/13 - 0s - loss: 0.2208 - accuracy: 0.8949 - val_loss: 0.4457 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01428: val_loss did not improve from 0.41762\n",
      "Epoch 1429/3000\n",
      "13/13 - 0s - loss: 0.2273 - accuracy: 0.8885 - val_loss: 0.4322 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01429: val_loss did not improve from 0.41762\n",
      "Epoch 1430/3000\n",
      "13/13 - 0s - loss: 0.2166 - accuracy: 0.9001 - val_loss: 0.4496 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01430: val_loss did not improve from 0.41762\n",
      "Epoch 1431/3000\n",
      "13/13 - 0s - loss: 0.2142 - accuracy: 0.8988 - val_loss: 0.4512 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01431: val_loss did not improve from 0.41762\n",
      "Epoch 1432/3000\n",
      "13/13 - 0s - loss: 0.2143 - accuracy: 0.8988 - val_loss: 0.4642 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01432: val_loss did not improve from 0.41762\n",
      "Epoch 1433/3000\n",
      "13/13 - 0s - loss: 0.2381 - accuracy: 0.8988 - val_loss: 0.5247 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01433: val_loss did not improve from 0.41762\n",
      "Epoch 1434/3000\n",
      "13/13 - 0s - loss: 0.2252 - accuracy: 0.8936 - val_loss: 0.4660 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01434: val_loss did not improve from 0.41762\n",
      "Epoch 1435/3000\n",
      "13/13 - 0s - loss: 0.2154 - accuracy: 0.9001 - val_loss: 0.4655 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01435: val_loss did not improve from 0.41762\n",
      "Epoch 1436/3000\n",
      "13/13 - 0s - loss: 0.2111 - accuracy: 0.9001 - val_loss: 0.4616 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01436: val_loss did not improve from 0.41762\n",
      "Epoch 1437/3000\n",
      "13/13 - 0s - loss: 0.2091 - accuracy: 0.8988 - val_loss: 0.4630 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01437: val_loss did not improve from 0.41762\n",
      "Epoch 1438/3000\n",
      "13/13 - 0s - loss: 0.2135 - accuracy: 0.9040 - val_loss: 0.4623 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01438: val_loss did not improve from 0.41762\n",
      "Epoch 1439/3000\n",
      "13/13 - 0s - loss: 0.2244 - accuracy: 0.9027 - val_loss: 0.4701 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01439: val_loss did not improve from 0.41762\n",
      "Epoch 1440/3000\n",
      "13/13 - 0s - loss: 0.2175 - accuracy: 0.9027 - val_loss: 0.4641 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01440: val_loss did not improve from 0.41762\n",
      "Epoch 1441/3000\n",
      "13/13 - 0s - loss: 0.2109 - accuracy: 0.9014 - val_loss: 0.4662 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01441: val_loss did not improve from 0.41762\n",
      "Epoch 1442/3000\n",
      "13/13 - 0s - loss: 0.2102 - accuracy: 0.8975 - val_loss: 0.4729 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01442: val_loss did not improve from 0.41762\n",
      "Epoch 1443/3000\n",
      "13/13 - 0s - loss: 0.2108 - accuracy: 0.8988 - val_loss: 0.4679 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01443: val_loss did not improve from 0.41762\n",
      "Epoch 1444/3000\n",
      "13/13 - 0s - loss: 0.2070 - accuracy: 0.8975 - val_loss: 0.4659 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01444: val_loss did not improve from 0.41762\n",
      "Epoch 1445/3000\n",
      "13/13 - 0s - loss: 0.2261 - accuracy: 0.8911 - val_loss: 0.4815 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01445: val_loss did not improve from 0.41762\n",
      "Epoch 1446/3000\n",
      "13/13 - 0s - loss: 0.2168 - accuracy: 0.8898 - val_loss: 0.4728 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01446: val_loss did not improve from 0.41762\n",
      "Epoch 1447/3000\n",
      "13/13 - 0s - loss: 0.2280 - accuracy: 0.8833 - val_loss: 0.4797 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01447: val_loss did not improve from 0.41762\n",
      "Epoch 1448/3000\n",
      "13/13 - 0s - loss: 0.2184 - accuracy: 0.8949 - val_loss: 0.4890 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01448: val_loss did not improve from 0.41762\n",
      "Epoch 1449/3000\n",
      "13/13 - 0s - loss: 0.2151 - accuracy: 0.9040 - val_loss: 0.4689 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01449: val_loss did not improve from 0.41762\n",
      "Epoch 1450/3000\n",
      "13/13 - 0s - loss: 0.2089 - accuracy: 0.9027 - val_loss: 0.4772 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01450: val_loss did not improve from 0.41762\n",
      "Epoch 1451/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.8962 - val_loss: 0.4724 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01451: val_loss did not improve from 0.41762\n",
      "Epoch 1452/3000\n",
      "13/13 - 0s - loss: 0.2120 - accuracy: 0.8962 - val_loss: 0.4802 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01452: val_loss did not improve from 0.41762\n",
      "Epoch 1453/3000\n",
      "13/13 - 0s - loss: 0.2241 - accuracy: 0.8962 - val_loss: 0.4899 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 01453: val_loss did not improve from 0.41762\n",
      "Epoch 1454/3000\n",
      "13/13 - 0s - loss: 0.2202 - accuracy: 0.8975 - val_loss: 0.4804 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01454: val_loss did not improve from 0.41762\n",
      "Epoch 1455/3000\n",
      "13/13 - 0s - loss: 0.2279 - accuracy: 0.8742 - val_loss: 0.4931 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01455: val_loss did not improve from 0.41762\n",
      "Epoch 1456/3000\n",
      "13/13 - 0s - loss: 0.2202 - accuracy: 0.8962 - val_loss: 0.4771 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01456: val_loss did not improve from 0.41762\n",
      "Epoch 1457/3000\n",
      "13/13 - 0s - loss: 0.2186 - accuracy: 0.8988 - val_loss: 0.4698 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01457: val_loss did not improve from 0.41762\n",
      "Epoch 1458/3000\n",
      "13/13 - 0s - loss: 0.2201 - accuracy: 0.8911 - val_loss: 0.4712 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01458: val_loss did not improve from 0.41762\n",
      "Epoch 1459/3000\n",
      "13/13 - 0s - loss: 0.2087 - accuracy: 0.9027 - val_loss: 0.4801 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01459: val_loss did not improve from 0.41762\n",
      "Epoch 1460/3000\n",
      "13/13 - 0s - loss: 0.2103 - accuracy: 0.9001 - val_loss: 0.4790 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01460: val_loss did not improve from 0.41762\n",
      "Epoch 1461/3000\n",
      "13/13 - 0s - loss: 0.2103 - accuracy: 0.8988 - val_loss: 0.4744 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01461: val_loss did not improve from 0.41762\n",
      "Epoch 1462/3000\n",
      "13/13 - 0s - loss: 0.2124 - accuracy: 0.8988 - val_loss: 0.4651 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01462: val_loss did not improve from 0.41762\n",
      "Epoch 1463/3000\n",
      "13/13 - 0s - loss: 0.2109 - accuracy: 0.8962 - val_loss: 0.4831 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01463: val_loss did not improve from 0.41762\n",
      "Epoch 1464/3000\n",
      "13/13 - 0s - loss: 0.2077 - accuracy: 0.9027 - val_loss: 0.4690 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01464: val_loss did not improve from 0.41762\n",
      "Epoch 1465/3000\n",
      "13/13 - 0s - loss: 0.2069 - accuracy: 0.9027 - val_loss: 0.4723 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01465: val_loss did not improve from 0.41762\n",
      "Epoch 1466/3000\n",
      "13/13 - 0s - loss: 0.2096 - accuracy: 0.8975 - val_loss: 0.4724 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01466: val_loss did not improve from 0.41762\n",
      "Epoch 1467/3000\n",
      "13/13 - 0s - loss: 0.2099 - accuracy: 0.9001 - val_loss: 0.4809 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01467: val_loss did not improve from 0.41762\n",
      "Epoch 1468/3000\n",
      "13/13 - 0s - loss: 0.2086 - accuracy: 0.8962 - val_loss: 0.4776 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01468: val_loss did not improve from 0.41762\n",
      "Epoch 1469/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.9027 - val_loss: 0.4788 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01469: val_loss did not improve from 0.41762\n",
      "Epoch 1470/3000\n",
      "13/13 - 0s - loss: 0.2078 - accuracy: 0.8988 - val_loss: 0.4925 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01470: val_loss did not improve from 0.41762\n",
      "Epoch 1471/3000\n",
      "13/13 - 0s - loss: 0.2175 - accuracy: 0.8936 - val_loss: 0.4895 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01471: val_loss did not improve from 0.41762\n",
      "Epoch 1472/3000\n",
      "13/13 - 0s - loss: 0.2188 - accuracy: 0.8859 - val_loss: 0.4890 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01472: val_loss did not improve from 0.41762\n",
      "Epoch 1473/3000\n",
      "13/13 - 0s - loss: 0.2082 - accuracy: 0.9001 - val_loss: 0.4956 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01473: val_loss did not improve from 0.41762\n",
      "Epoch 1474/3000\n",
      "13/13 - 0s - loss: 0.2094 - accuracy: 0.9001 - val_loss: 0.4843 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01474: val_loss did not improve from 0.41762\n",
      "Epoch 1475/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.8949 - val_loss: 0.4922 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01475: val_loss did not improve from 0.41762\n",
      "Epoch 1476/3000\n",
      "13/13 - 0s - loss: 0.2200 - accuracy: 0.8846 - val_loss: 0.4849 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01476: val_loss did not improve from 0.41762\n",
      "Epoch 1477/3000\n",
      "13/13 - 0s - loss: 0.2097 - accuracy: 0.8975 - val_loss: 0.4777 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01477: val_loss did not improve from 0.41762\n",
      "Epoch 1478/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.9001 - val_loss: 0.4876 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01478: val_loss did not improve from 0.41762\n",
      "Epoch 1479/3000\n",
      "13/13 - 0s - loss: 0.2069 - accuracy: 0.8975 - val_loss: 0.4790 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01479: val_loss did not improve from 0.41762\n",
      "Epoch 1480/3000\n",
      "13/13 - 0s - loss: 0.2244 - accuracy: 0.8923 - val_loss: 0.4868 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01480: val_loss did not improve from 0.41762\n",
      "Epoch 1481/3000\n",
      "13/13 - 0s - loss: 0.2148 - accuracy: 0.8898 - val_loss: 0.4750 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01481: val_loss did not improve from 0.41762\n",
      "Epoch 1482/3000\n",
      "13/13 - 0s - loss: 0.2095 - accuracy: 0.9027 - val_loss: 0.4559 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01482: val_loss did not improve from 0.41762\n",
      "Epoch 1483/3000\n",
      "13/13 - 0s - loss: 0.2198 - accuracy: 0.8962 - val_loss: 0.4880 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01483: val_loss did not improve from 0.41762\n",
      "Epoch 1484/3000\n",
      "13/13 - 0s - loss: 0.2193 - accuracy: 0.8885 - val_loss: 0.4785 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01484: val_loss did not improve from 0.41762\n",
      "Epoch 1485/3000\n",
      "13/13 - 0s - loss: 0.2131 - accuracy: 0.8988 - val_loss: 0.4614 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01485: val_loss did not improve from 0.41762\n",
      "Epoch 1486/3000\n",
      "13/13 - 0s - loss: 0.2178 - accuracy: 0.9001 - val_loss: 0.4574 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01486: val_loss did not improve from 0.41762\n",
      "Epoch 1487/3000\n",
      "13/13 - 0s - loss: 0.2170 - accuracy: 0.8975 - val_loss: 0.4944 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01487: val_loss did not improve from 0.41762\n",
      "Epoch 1488/3000\n",
      "13/13 - 0s - loss: 0.2124 - accuracy: 0.9014 - val_loss: 0.4831 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01488: val_loss did not improve from 0.41762\n",
      "Epoch 1489/3000\n",
      "13/13 - 0s - loss: 0.2203 - accuracy: 0.8936 - val_loss: 0.5017 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01489: val_loss did not improve from 0.41762\n",
      "Epoch 1490/3000\n",
      "13/13 - 0s - loss: 0.2274 - accuracy: 0.9001 - val_loss: 0.5467 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01490: val_loss did not improve from 0.41762\n",
      "Epoch 1491/3000\n",
      "13/13 - 0s - loss: 0.2233 - accuracy: 0.9027 - val_loss: 0.5109 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01491: val_loss did not improve from 0.41762\n",
      "Epoch 1492/3000\n",
      "13/13 - 0s - loss: 0.2220 - accuracy: 0.8975 - val_loss: 0.4944 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01492: val_loss did not improve from 0.41762\n",
      "Epoch 1493/3000\n",
      "13/13 - 0s - loss: 0.2136 - accuracy: 0.9040 - val_loss: 0.4804 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01493: val_loss did not improve from 0.41762\n",
      "Epoch 1494/3000\n",
      "13/13 - 0s - loss: 0.2100 - accuracy: 0.9027 - val_loss: 0.4873 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01494: val_loss did not improve from 0.41762\n",
      "Epoch 1495/3000\n",
      "13/13 - 0s - loss: 0.2167 - accuracy: 0.8911 - val_loss: 0.4747 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01495: val_loss did not improve from 0.41762\n",
      "Epoch 1496/3000\n",
      "13/13 - 0s - loss: 0.2219 - accuracy: 0.8988 - val_loss: 0.4854 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01496: val_loss did not improve from 0.41762\n",
      "Epoch 1497/3000\n",
      "13/13 - 0s - loss: 0.2111 - accuracy: 0.9001 - val_loss: 0.4852 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01497: val_loss did not improve from 0.41762\n",
      "Epoch 1498/3000\n",
      "13/13 - 0s - loss: 0.2097 - accuracy: 0.9040 - val_loss: 0.4933 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01498: val_loss did not improve from 0.41762\n",
      "Epoch 1499/3000\n",
      "13/13 - 0s - loss: 0.2143 - accuracy: 0.8962 - val_loss: 0.4894 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01499: val_loss did not improve from 0.41762\n",
      "Epoch 1500/3000\n",
      "13/13 - 0s - loss: 0.2115 - accuracy: 0.9001 - val_loss: 0.4760 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01500: val_loss did not improve from 0.41762\n",
      "Epoch 1501/3000\n",
      "13/13 - 0s - loss: 0.2100 - accuracy: 0.8988 - val_loss: 0.4774 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01501: val_loss did not improve from 0.41762\n",
      "Epoch 1502/3000\n",
      "13/13 - 0s - loss: 0.2108 - accuracy: 0.8936 - val_loss: 0.4824 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01502: val_loss did not improve from 0.41762\n",
      "Epoch 1503/3000\n",
      "13/13 - 0s - loss: 0.2119 - accuracy: 0.8988 - val_loss: 0.4836 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01503: val_loss did not improve from 0.41762\n",
      "Epoch 1504/3000\n",
      "13/13 - 0s - loss: 0.2125 - accuracy: 0.9001 - val_loss: 0.5072 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01504: val_loss did not improve from 0.41762\n",
      "Epoch 1505/3000\n",
      "13/13 - 0s - loss: 0.2259 - accuracy: 0.9027 - val_loss: 0.4929 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01505: val_loss did not improve from 0.41762\n",
      "Epoch 1506/3000\n",
      "13/13 - 0s - loss: 0.2199 - accuracy: 0.9001 - val_loss: 0.5033 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01506: val_loss did not improve from 0.41762\n",
      "Epoch 1507/3000\n",
      "13/13 - 0s - loss: 0.2374 - accuracy: 0.8898 - val_loss: 0.4877 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01507: val_loss did not improve from 0.41762\n",
      "Epoch 1508/3000\n",
      "13/13 - 0s - loss: 0.2161 - accuracy: 0.8846 - val_loss: 0.4838 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01508: val_loss did not improve from 0.41762\n",
      "Epoch 1509/3000\n",
      "13/13 - 0s - loss: 0.2089 - accuracy: 0.8975 - val_loss: 0.4985 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01509: val_loss did not improve from 0.41762\n",
      "Epoch 1510/3000\n",
      "13/13 - 0s - loss: 0.2105 - accuracy: 0.8949 - val_loss: 0.4962 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01510: val_loss did not improve from 0.41762\n",
      "Epoch 1511/3000\n",
      "13/13 - 0s - loss: 0.2113 - accuracy: 0.8975 - val_loss: 0.4940 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01511: val_loss did not improve from 0.41762\n",
      "Epoch 1512/3000\n",
      "13/13 - 0s - loss: 0.2216 - accuracy: 0.8988 - val_loss: 0.4945 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01512: val_loss did not improve from 0.41762\n",
      "Epoch 1513/3000\n",
      "13/13 - 0s - loss: 0.2237 - accuracy: 0.8975 - val_loss: 0.4883 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01513: val_loss did not improve from 0.41762\n",
      "Epoch 1514/3000\n",
      "13/13 - 0s - loss: 0.2228 - accuracy: 0.8923 - val_loss: 0.4809 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01514: val_loss did not improve from 0.41762\n",
      "Epoch 1515/3000\n",
      "13/13 - 0s - loss: 0.2237 - accuracy: 0.8911 - val_loss: 0.4756 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01515: val_loss did not improve from 0.41762\n",
      "Epoch 1516/3000\n",
      "13/13 - 0s - loss: 0.2856 - accuracy: 0.8716 - val_loss: 0.4981 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01516: val_loss did not improve from 0.41762\n",
      "Epoch 1517/3000\n",
      "13/13 - 0s - loss: 0.2493 - accuracy: 0.8768 - val_loss: 0.5079 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01517: val_loss did not improve from 0.41762\n",
      "Epoch 1518/3000\n",
      "13/13 - 0s - loss: 0.2148 - accuracy: 0.9014 - val_loss: 0.4755 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01518: val_loss did not improve from 0.41762\n",
      "Epoch 1519/3000\n",
      "13/13 - 0s - loss: 0.2137 - accuracy: 0.8988 - val_loss: 0.5072 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01519: val_loss did not improve from 0.41762\n",
      "Epoch 1520/3000\n",
      "13/13 - 0s - loss: 0.2164 - accuracy: 0.8988 - val_loss: 0.4809 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01520: val_loss did not improve from 0.41762\n",
      "Epoch 1521/3000\n",
      "13/13 - 0s - loss: 0.2165 - accuracy: 0.9014 - val_loss: 0.4739 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01521: val_loss did not improve from 0.41762\n",
      "Epoch 1522/3000\n",
      "13/13 - 0s - loss: 0.2130 - accuracy: 0.8949 - val_loss: 0.4782 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01522: val_loss did not improve from 0.41762\n",
      "Epoch 1523/3000\n",
      "13/13 - 0s - loss: 0.2106 - accuracy: 0.8988 - val_loss: 0.4763 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01523: val_loss did not improve from 0.41762\n",
      "Epoch 1524/3000\n",
      "13/13 - 0s - loss: 0.2101 - accuracy: 0.8962 - val_loss: 0.4758 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01524: val_loss did not improve from 0.41762\n",
      "Epoch 1525/3000\n",
      "13/13 - 0s - loss: 0.2087 - accuracy: 0.9014 - val_loss: 0.4791 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01525: val_loss did not improve from 0.41762\n",
      "Epoch 1526/3000\n",
      "13/13 - 0s - loss: 0.2103 - accuracy: 0.9014 - val_loss: 0.4736 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01526: val_loss did not improve from 0.41762\n",
      "Epoch 1527/3000\n",
      "13/13 - 0s - loss: 0.2190 - accuracy: 0.8872 - val_loss: 0.4809 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01527: val_loss did not improve from 0.41762\n",
      "Epoch 1528/3000\n",
      "13/13 - 0s - loss: 0.2215 - accuracy: 0.9001 - val_loss: 0.4983 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01528: val_loss did not improve from 0.41762\n",
      "Epoch 1529/3000\n",
      "13/13 - 0s - loss: 0.2512 - accuracy: 0.8742 - val_loss: 0.4874 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 01529: val_loss did not improve from 0.41762\n",
      "Epoch 1530/3000\n",
      "13/13 - 0s - loss: 0.2227 - accuracy: 0.9001 - val_loss: 0.4987 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01530: val_loss did not improve from 0.41762\n",
      "Epoch 1531/3000\n",
      "13/13 - 0s - loss: 0.2152 - accuracy: 0.8975 - val_loss: 0.4846 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01531: val_loss did not improve from 0.41762\n",
      "Epoch 1532/3000\n",
      "13/13 - 0s - loss: 0.2261 - accuracy: 0.9001 - val_loss: 0.5058 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01532: val_loss did not improve from 0.41762\n",
      "Epoch 1533/3000\n",
      "13/13 - 0s - loss: 0.2180 - accuracy: 0.8988 - val_loss: 0.4734 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01533: val_loss did not improve from 0.41762\n",
      "Epoch 1534/3000\n",
      "13/13 - 0s - loss: 0.2203 - accuracy: 0.8962 - val_loss: 0.4891 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01534: val_loss did not improve from 0.41762\n",
      "Epoch 1535/3000\n",
      "13/13 - 0s - loss: 0.2154 - accuracy: 0.8988 - val_loss: 0.4822 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01535: val_loss did not improve from 0.41762\n",
      "Epoch 1536/3000\n",
      "13/13 - 0s - loss: 0.2100 - accuracy: 0.8988 - val_loss: 0.4805 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01536: val_loss did not improve from 0.41762\n",
      "Epoch 1537/3000\n",
      "13/13 - 0s - loss: 0.2125 - accuracy: 0.9027 - val_loss: 0.4815 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01537: val_loss did not improve from 0.41762\n",
      "Epoch 1538/3000\n",
      "13/13 - 0s - loss: 0.2202 - accuracy: 0.9001 - val_loss: 0.4838 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01538: val_loss did not improve from 0.41762\n",
      "Epoch 1539/3000\n",
      "13/13 - 0s - loss: 0.2280 - accuracy: 0.8975 - val_loss: 0.4756 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01539: val_loss did not improve from 0.41762\n",
      "Epoch 1540/3000\n",
      "13/13 - 0s - loss: 0.2154 - accuracy: 0.9040 - val_loss: 0.4894 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01540: val_loss did not improve from 0.41762\n",
      "Epoch 1541/3000\n",
      "13/13 - 0s - loss: 0.2118 - accuracy: 0.9001 - val_loss: 0.4734 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01541: val_loss did not improve from 0.41762\n",
      "Epoch 1542/3000\n",
      "13/13 - 0s - loss: 0.2125 - accuracy: 0.8962 - val_loss: 0.4764 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01542: val_loss did not improve from 0.41762\n",
      "Epoch 1543/3000\n",
      "13/13 - 0s - loss: 0.2126 - accuracy: 0.8988 - val_loss: 0.4795 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01543: val_loss did not improve from 0.41762\n",
      "Epoch 1544/3000\n",
      "13/13 - 0s - loss: 0.2309 - accuracy: 0.8794 - val_loss: 0.4891 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01544: val_loss did not improve from 0.41762\n",
      "Epoch 1545/3000\n",
      "13/13 - 0s - loss: 0.2326 - accuracy: 0.9027 - val_loss: 0.4853 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01545: val_loss did not improve from 0.41762\n",
      "Epoch 1546/3000\n",
      "13/13 - 0s - loss: 0.2295 - accuracy: 0.8962 - val_loss: 0.4672 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01546: val_loss did not improve from 0.41762\n",
      "Epoch 1547/3000\n",
      "13/13 - 0s - loss: 0.2213 - accuracy: 0.8949 - val_loss: 0.4673 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01547: val_loss did not improve from 0.41762\n",
      "Epoch 1548/3000\n",
      "13/13 - 0s - loss: 0.2153 - accuracy: 0.9040 - val_loss: 0.4818 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01548: val_loss did not improve from 0.41762\n",
      "Epoch 1549/3000\n",
      "13/13 - 0s - loss: 0.2166 - accuracy: 0.9014 - val_loss: 0.4810 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01549: val_loss did not improve from 0.41762\n",
      "Epoch 1550/3000\n",
      "13/13 - 0s - loss: 0.2137 - accuracy: 0.9001 - val_loss: 0.4886 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01550: val_loss did not improve from 0.41762\n",
      "Epoch 1551/3000\n",
      "13/13 - 0s - loss: 0.2122 - accuracy: 0.8988 - val_loss: 0.4875 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01551: val_loss did not improve from 0.41762\n",
      "Epoch 1552/3000\n",
      "13/13 - 0s - loss: 0.2166 - accuracy: 0.9027 - val_loss: 0.4816 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01552: val_loss did not improve from 0.41762\n",
      "Epoch 1553/3000\n",
      "13/13 - 0s - loss: 0.2093 - accuracy: 0.8975 - val_loss: 0.4805 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01553: val_loss did not improve from 0.41762\n",
      "Epoch 1554/3000\n",
      "13/13 - 0s - loss: 0.2113 - accuracy: 0.9001 - val_loss: 0.4827 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01554: val_loss did not improve from 0.41762\n",
      "Epoch 1555/3000\n",
      "13/13 - 0s - loss: 0.2093 - accuracy: 0.9001 - val_loss: 0.4913 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01555: val_loss did not improve from 0.41762\n",
      "Epoch 1556/3000\n",
      "13/13 - 0s - loss: 0.2096 - accuracy: 0.9014 - val_loss: 0.4848 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01556: val_loss did not improve from 0.41762\n",
      "Epoch 1557/3000\n",
      "13/13 - 0s - loss: 0.2093 - accuracy: 0.9014 - val_loss: 0.4926 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01557: val_loss did not improve from 0.41762\n",
      "Epoch 1558/3000\n",
      "13/13 - 0s - loss: 0.2164 - accuracy: 0.8988 - val_loss: 0.4862 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01558: val_loss did not improve from 0.41762\n",
      "Epoch 1559/3000\n",
      "13/13 - 0s - loss: 0.2281 - accuracy: 0.8949 - val_loss: 0.4901 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01559: val_loss did not improve from 0.41762\n",
      "Epoch 1560/3000\n",
      "13/13 - 0s - loss: 0.2118 - accuracy: 0.9040 - val_loss: 0.4982 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01560: val_loss did not improve from 0.41762\n",
      "Epoch 1561/3000\n",
      "13/13 - 0s - loss: 0.2096 - accuracy: 0.9001 - val_loss: 0.4853 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01561: val_loss did not improve from 0.41762\n",
      "Epoch 1562/3000\n",
      "13/13 - 0s - loss: 0.2218 - accuracy: 0.8962 - val_loss: 0.5009 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01562: val_loss did not improve from 0.41762\n",
      "Epoch 1563/3000\n",
      "13/13 - 0s - loss: 0.2354 - accuracy: 0.8923 - val_loss: 0.5121 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01563: val_loss did not improve from 0.41762\n",
      "Epoch 1564/3000\n",
      "13/13 - 0s - loss: 0.2171 - accuracy: 0.8949 - val_loss: 0.4812 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01564: val_loss did not improve from 0.41762\n",
      "Epoch 1565/3000\n",
      "13/13 - 0s - loss: 0.2265 - accuracy: 0.8936 - val_loss: 0.4957 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01565: val_loss did not improve from 0.41762\n",
      "Epoch 1566/3000\n",
      "13/13 - 0s - loss: 0.2230 - accuracy: 0.8911 - val_loss: 0.4901 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01566: val_loss did not improve from 0.41762\n",
      "Epoch 1567/3000\n",
      "13/13 - 0s - loss: 0.2112 - accuracy: 0.9001 - val_loss: 0.5027 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01567: val_loss did not improve from 0.41762\n",
      "Epoch 1568/3000\n",
      "13/13 - 0s - loss: 0.2092 - accuracy: 0.9001 - val_loss: 0.4852 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01568: val_loss did not improve from 0.41762\n",
      "Epoch 1569/3000\n",
      "13/13 - 0s - loss: 0.2107 - accuracy: 0.8885 - val_loss: 0.4860 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01569: val_loss did not improve from 0.41762\n",
      "Epoch 1570/3000\n",
      "13/13 - 0s - loss: 0.2100 - accuracy: 0.9027 - val_loss: 0.4933 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01570: val_loss did not improve from 0.41762\n",
      "Epoch 1571/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.8962 - val_loss: 0.4976 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01571: val_loss did not improve from 0.41762\n",
      "Epoch 1572/3000\n",
      "13/13 - 0s - loss: 0.2310 - accuracy: 0.8988 - val_loss: 0.5222 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01572: val_loss did not improve from 0.41762\n",
      "Epoch 1573/3000\n",
      "13/13 - 0s - loss: 0.2192 - accuracy: 0.8936 - val_loss: 0.4948 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01573: val_loss did not improve from 0.41762\n",
      "Epoch 1574/3000\n",
      "13/13 - 0s - loss: 0.2119 - accuracy: 0.8988 - val_loss: 0.5089 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01574: val_loss did not improve from 0.41762\n",
      "Epoch 1575/3000\n",
      "13/13 - 0s - loss: 0.2135 - accuracy: 0.8988 - val_loss: 0.4960 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01575: val_loss did not improve from 0.41762\n",
      "Epoch 1576/3000\n",
      "13/13 - 0s - loss: 0.2246 - accuracy: 0.8898 - val_loss: 0.4960 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01576: val_loss did not improve from 0.41762\n",
      "Epoch 1577/3000\n",
      "13/13 - 0s - loss: 0.2222 - accuracy: 0.8988 - val_loss: 0.4916 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01577: val_loss did not improve from 0.41762\n",
      "Epoch 1578/3000\n",
      "13/13 - 0s - loss: 0.2184 - accuracy: 0.8975 - val_loss: 0.4970 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01578: val_loss did not improve from 0.41762\n",
      "Epoch 1579/3000\n",
      "13/13 - 0s - loss: 0.2098 - accuracy: 0.8988 - val_loss: 0.4981 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01579: val_loss did not improve from 0.41762\n",
      "Epoch 1580/3000\n",
      "13/13 - 0s - loss: 0.2065 - accuracy: 0.8988 - val_loss: 0.4850 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01580: val_loss did not improve from 0.41762\n",
      "Epoch 1581/3000\n",
      "13/13 - 0s - loss: 0.2106 - accuracy: 0.8988 - val_loss: 0.4829 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01581: val_loss did not improve from 0.41762\n",
      "Epoch 1582/3000\n",
      "13/13 - 0s - loss: 0.2333 - accuracy: 0.8923 - val_loss: 0.4897 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01582: val_loss did not improve from 0.41762\n",
      "Epoch 1583/3000\n",
      "13/13 - 0s - loss: 0.2393 - accuracy: 0.8962 - val_loss: 0.5043 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01583: val_loss did not improve from 0.41762\n",
      "Epoch 1584/3000\n",
      "13/13 - 0s - loss: 0.2198 - accuracy: 0.8962 - val_loss: 0.5303 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01584: val_loss did not improve from 0.41762\n",
      "Epoch 1585/3000\n",
      "13/13 - 0s - loss: 0.2317 - accuracy: 0.8820 - val_loss: 0.5248 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 01585: val_loss did not improve from 0.41762\n",
      "Epoch 1586/3000\n",
      "13/13 - 0s - loss: 0.2397 - accuracy: 0.8781 - val_loss: 0.4975 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01586: val_loss did not improve from 0.41762\n",
      "Epoch 1587/3000\n",
      "13/13 - 0s - loss: 0.2236 - accuracy: 0.8975 - val_loss: 0.5152 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01587: val_loss did not improve from 0.41762\n",
      "Epoch 1588/3000\n",
      "13/13 - 0s - loss: 0.2279 - accuracy: 0.9001 - val_loss: 0.5255 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01588: val_loss did not improve from 0.41762\n",
      "Epoch 1589/3000\n",
      "13/13 - 0s - loss: 0.2422 - accuracy: 0.8859 - val_loss: 0.5169 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01589: val_loss did not improve from 0.41762\n",
      "Epoch 1590/3000\n",
      "13/13 - 0s - loss: 0.2173 - accuracy: 0.8898 - val_loss: 0.5268 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01590: val_loss did not improve from 0.41762\n",
      "Epoch 1591/3000\n",
      "13/13 - 0s - loss: 0.2182 - accuracy: 0.8885 - val_loss: 0.5010 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01591: val_loss did not improve from 0.41762\n",
      "Epoch 1592/3000\n",
      "13/13 - 0s - loss: 0.2145 - accuracy: 0.8962 - val_loss: 0.5144 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01592: val_loss did not improve from 0.41762\n",
      "Epoch 1593/3000\n",
      "13/13 - 0s - loss: 0.2123 - accuracy: 0.8988 - val_loss: 0.5040 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01593: val_loss did not improve from 0.41762\n",
      "Epoch 1594/3000\n",
      "13/13 - 0s - loss: 0.2321 - accuracy: 0.8975 - val_loss: 0.4995 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01594: val_loss did not improve from 0.41762\n",
      "Epoch 1595/3000\n",
      "13/13 - 0s - loss: 0.2244 - accuracy: 0.8807 - val_loss: 0.4632 - val_accuracy: 0.8705\n",
      "\n",
      "Epoch 01595: val_loss did not improve from 0.41762\n",
      "Epoch 1596/3000\n",
      "13/13 - 0s - loss: 0.2196 - accuracy: 0.8975 - val_loss: 0.4860 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01596: val_loss did not improve from 0.41762\n",
      "Epoch 1597/3000\n",
      "13/13 - 0s - loss: 0.2189 - accuracy: 0.8988 - val_loss: 0.4791 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01597: val_loss did not improve from 0.41762\n",
      "Epoch 1598/3000\n",
      "13/13 - 0s - loss: 0.2141 - accuracy: 0.9001 - val_loss: 0.4860 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01598: val_loss did not improve from 0.41762\n",
      "Epoch 1599/3000\n",
      "13/13 - 0s - loss: 0.2117 - accuracy: 0.8988 - val_loss: 0.4931 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01599: val_loss did not improve from 0.41762\n",
      "Epoch 1600/3000\n",
      "13/13 - 0s - loss: 0.2159 - accuracy: 0.8949 - val_loss: 0.4775 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01600: val_loss did not improve from 0.41762\n",
      "Epoch 1601/3000\n",
      "13/13 - 0s - loss: 0.2095 - accuracy: 0.8988 - val_loss: 0.4849 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01601: val_loss did not improve from 0.41762\n",
      "Epoch 1602/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.9014 - val_loss: 0.4830 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01602: val_loss did not improve from 0.41762\n",
      "Epoch 1603/3000\n",
      "13/13 - 0s - loss: 0.2089 - accuracy: 0.9040 - val_loss: 0.4961 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01603: val_loss did not improve from 0.41762\n",
      "Epoch 1604/3000\n",
      "13/13 - 0s - loss: 0.2125 - accuracy: 0.8988 - val_loss: 0.5003 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01604: val_loss did not improve from 0.41762\n",
      "Epoch 1605/3000\n",
      "13/13 - 0s - loss: 0.2183 - accuracy: 0.8975 - val_loss: 0.5041 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01605: val_loss did not improve from 0.41762\n",
      "Epoch 1606/3000\n",
      "13/13 - 0s - loss: 0.2103 - accuracy: 0.9040 - val_loss: 0.5018 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01606: val_loss did not improve from 0.41762\n",
      "Epoch 1607/3000\n",
      "13/13 - 0s - loss: 0.2096 - accuracy: 0.8962 - val_loss: 0.4934 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01607: val_loss did not improve from 0.41762\n",
      "Epoch 1608/3000\n",
      "13/13 - 0s - loss: 0.2104 - accuracy: 0.8962 - val_loss: 0.5266 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01608: val_loss did not improve from 0.41762\n",
      "Epoch 1609/3000\n",
      "13/13 - 0s - loss: 0.2268 - accuracy: 0.8911 - val_loss: 0.5130 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01609: val_loss did not improve from 0.41762\n",
      "Epoch 1610/3000\n",
      "13/13 - 0s - loss: 0.2333 - accuracy: 0.8703 - val_loss: 0.5053 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01610: val_loss did not improve from 0.41762\n",
      "Epoch 1611/3000\n",
      "13/13 - 0s - loss: 0.2161 - accuracy: 0.8885 - val_loss: 0.5158 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01611: val_loss did not improve from 0.41762\n",
      "Epoch 1612/3000\n",
      "13/13 - 0s - loss: 0.2126 - accuracy: 0.8975 - val_loss: 0.5089 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01612: val_loss did not improve from 0.41762\n",
      "Epoch 1613/3000\n",
      "13/13 - 0s - loss: 0.2230 - accuracy: 0.8898 - val_loss: 0.5024 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01613: val_loss did not improve from 0.41762\n",
      "Epoch 1614/3000\n",
      "13/13 - 0s - loss: 0.2130 - accuracy: 0.9040 - val_loss: 0.4930 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01614: val_loss did not improve from 0.41762\n",
      "Epoch 1615/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.9014 - val_loss: 0.4905 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01615: val_loss did not improve from 0.41762\n",
      "Epoch 1616/3000\n",
      "13/13 - 0s - loss: 0.2086 - accuracy: 0.9027 - val_loss: 0.4843 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01616: val_loss did not improve from 0.41762\n",
      "Epoch 1617/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.9014 - val_loss: 0.5089 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01617: val_loss did not improve from 0.41762\n",
      "Epoch 1618/3000\n",
      "13/13 - 0s - loss: 0.2453 - accuracy: 0.8923 - val_loss: 0.5139 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01618: val_loss did not improve from 0.41762\n",
      "Epoch 1619/3000\n",
      "13/13 - 0s - loss: 0.2397 - accuracy: 0.8872 - val_loss: 0.4952 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01619: val_loss did not improve from 0.41762\n",
      "Epoch 1620/3000\n",
      "13/13 - 0s - loss: 0.2185 - accuracy: 0.8949 - val_loss: 0.5086 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01620: val_loss did not improve from 0.41762\n",
      "Epoch 1621/3000\n",
      "13/13 - 0s - loss: 0.2388 - accuracy: 0.8781 - val_loss: 0.4941 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01621: val_loss did not improve from 0.41762\n",
      "Epoch 1622/3000\n",
      "13/13 - 0s - loss: 0.2356 - accuracy: 0.9014 - val_loss: 0.5050 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01622: val_loss did not improve from 0.41762\n",
      "Epoch 1623/3000\n",
      "13/13 - 0s - loss: 0.2209 - accuracy: 0.9001 - val_loss: 0.5190 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01623: val_loss did not improve from 0.41762\n",
      "Epoch 1624/3000\n",
      "13/13 - 0s - loss: 0.2273 - accuracy: 0.8988 - val_loss: 0.5065 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01624: val_loss did not improve from 0.41762\n",
      "Epoch 1625/3000\n",
      "13/13 - 0s - loss: 0.2152 - accuracy: 0.9001 - val_loss: 0.5045 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01625: val_loss did not improve from 0.41762\n",
      "Epoch 1626/3000\n",
      "13/13 - 0s - loss: 0.2238 - accuracy: 0.8988 - val_loss: 0.4964 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01626: val_loss did not improve from 0.41762\n",
      "Epoch 1627/3000\n",
      "13/13 - 0s - loss: 0.2222 - accuracy: 0.9001 - val_loss: 0.4895 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01627: val_loss did not improve from 0.41762\n",
      "Epoch 1628/3000\n",
      "13/13 - 0s - loss: 0.2150 - accuracy: 0.9001 - val_loss: 0.5009 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01628: val_loss did not improve from 0.41762\n",
      "Epoch 1629/3000\n",
      "13/13 - 0s - loss: 0.2122 - accuracy: 0.9001 - val_loss: 0.4941 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01629: val_loss did not improve from 0.41762\n",
      "Epoch 1630/3000\n",
      "13/13 - 0s - loss: 0.2099 - accuracy: 0.8988 - val_loss: 0.5094 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01630: val_loss did not improve from 0.41762\n",
      "Epoch 1631/3000\n",
      "13/13 - 0s - loss: 0.2125 - accuracy: 0.8975 - val_loss: 0.4943 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01631: val_loss did not improve from 0.41762\n",
      "Epoch 1632/3000\n",
      "13/13 - 0s - loss: 0.2746 - accuracy: 0.8794 - val_loss: 0.4589 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 01632: val_loss did not improve from 0.41762\n",
      "Epoch 1633/3000\n",
      "13/13 - 0s - loss: 0.2343 - accuracy: 0.8872 - val_loss: 0.4914 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01633: val_loss did not improve from 0.41762\n",
      "Epoch 1634/3000\n",
      "13/13 - 0s - loss: 0.2224 - accuracy: 0.8962 - val_loss: 0.4735 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01634: val_loss did not improve from 0.41762\n",
      "Epoch 1635/3000\n",
      "13/13 - 0s - loss: 0.2117 - accuracy: 0.9014 - val_loss: 0.4847 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01635: val_loss did not improve from 0.41762\n",
      "Epoch 1636/3000\n",
      "13/13 - 0s - loss: 0.2128 - accuracy: 0.9014 - val_loss: 0.4848 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01636: val_loss did not improve from 0.41762\n",
      "Epoch 1637/3000\n",
      "13/13 - 0s - loss: 0.2118 - accuracy: 0.8962 - val_loss: 0.4829 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01637: val_loss did not improve from 0.41762\n",
      "Epoch 1638/3000\n",
      "13/13 - 0s - loss: 0.2100 - accuracy: 0.8988 - val_loss: 0.4836 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01638: val_loss did not improve from 0.41762\n",
      "Epoch 1639/3000\n",
      "13/13 - 0s - loss: 0.2375 - accuracy: 0.8833 - val_loss: 0.4977 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01639: val_loss did not improve from 0.41762\n",
      "Epoch 1640/3000\n",
      "13/13 - 0s - loss: 0.2413 - accuracy: 0.8703 - val_loss: 0.5197 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01640: val_loss did not improve from 0.41762\n",
      "Epoch 1641/3000\n",
      "13/13 - 0s - loss: 0.2153 - accuracy: 0.8949 - val_loss: 0.4787 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01641: val_loss did not improve from 0.41762\n",
      "Epoch 1642/3000\n",
      "13/13 - 0s - loss: 0.2192 - accuracy: 0.8911 - val_loss: 0.5023 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01642: val_loss did not improve from 0.41762\n",
      "Epoch 1643/3000\n",
      "13/13 - 0s - loss: 0.2173 - accuracy: 0.8975 - val_loss: 0.5106 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01643: val_loss did not improve from 0.41762\n",
      "Epoch 1644/3000\n",
      "13/13 - 0s - loss: 0.2183 - accuracy: 0.8936 - val_loss: 0.4891 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01644: val_loss did not improve from 0.41762\n",
      "Epoch 1645/3000\n",
      "13/13 - 0s - loss: 0.2130 - accuracy: 0.9027 - val_loss: 0.4938 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01645: val_loss did not improve from 0.41762\n",
      "Epoch 1646/3000\n",
      "13/13 - 0s - loss: 0.2091 - accuracy: 0.9027 - val_loss: 0.4990 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01646: val_loss did not improve from 0.41762\n",
      "Epoch 1647/3000\n",
      "13/13 - 0s - loss: 0.2105 - accuracy: 0.8962 - val_loss: 0.4953 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01647: val_loss did not improve from 0.41762\n",
      "Epoch 1648/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.9014 - val_loss: 0.4959 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01648: val_loss did not improve from 0.41762\n",
      "Epoch 1649/3000\n",
      "13/13 - 0s - loss: 0.2091 - accuracy: 0.9001 - val_loss: 0.4989 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01649: val_loss did not improve from 0.41762\n",
      "Epoch 1650/3000\n",
      "13/13 - 0s - loss: 0.2119 - accuracy: 0.8962 - val_loss: 0.4967 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01650: val_loss did not improve from 0.41762\n",
      "Epoch 1651/3000\n",
      "13/13 - 0s - loss: 0.2124 - accuracy: 0.8936 - val_loss: 0.4926 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01651: val_loss did not improve from 0.41762\n",
      "Epoch 1652/3000\n",
      "13/13 - 0s - loss: 0.2239 - accuracy: 0.8846 - val_loss: 0.5019 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01652: val_loss did not improve from 0.41762\n",
      "Epoch 1653/3000\n",
      "13/13 - 0s - loss: 0.2156 - accuracy: 0.8846 - val_loss: 0.5079 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01653: val_loss did not improve from 0.41762\n",
      "Epoch 1654/3000\n",
      "13/13 - 0s - loss: 0.2172 - accuracy: 0.9001 - val_loss: 0.4868 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01654: val_loss did not improve from 0.41762\n",
      "Epoch 1655/3000\n",
      "13/13 - 0s - loss: 0.2147 - accuracy: 0.9001 - val_loss: 0.4729 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01655: val_loss did not improve from 0.41762\n",
      "Epoch 1656/3000\n",
      "13/13 - 0s - loss: 0.2101 - accuracy: 0.9014 - val_loss: 0.4837 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01656: val_loss did not improve from 0.41762\n",
      "Epoch 1657/3000\n",
      "13/13 - 0s - loss: 0.2089 - accuracy: 0.9001 - val_loss: 0.4893 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01657: val_loss did not improve from 0.41762\n",
      "Epoch 1658/3000\n",
      "13/13 - 0s - loss: 0.2251 - accuracy: 0.8988 - val_loss: 0.4890 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01658: val_loss did not improve from 0.41762\n",
      "Epoch 1659/3000\n",
      "13/13 - 0s - loss: 0.2362 - accuracy: 0.8872 - val_loss: 0.4878 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01659: val_loss did not improve from 0.41762\n",
      "Epoch 1660/3000\n",
      "13/13 - 0s - loss: 0.2211 - accuracy: 0.8975 - val_loss: 0.4929 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01660: val_loss did not improve from 0.41762\n",
      "Epoch 1661/3000\n",
      "13/13 - 0s - loss: 0.2139 - accuracy: 0.9001 - val_loss: 0.4934 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01661: val_loss did not improve from 0.41762\n",
      "Epoch 1662/3000\n",
      "13/13 - 0s - loss: 0.2107 - accuracy: 0.9014 - val_loss: 0.4903 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01662: val_loss did not improve from 0.41762\n",
      "Epoch 1663/3000\n",
      "13/13 - 0s - loss: 0.2115 - accuracy: 0.8962 - val_loss: 0.4998 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01663: val_loss did not improve from 0.41762\n",
      "Epoch 1664/3000\n",
      "13/13 - 0s - loss: 0.2131 - accuracy: 0.9027 - val_loss: 0.4890 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01664: val_loss did not improve from 0.41762\n",
      "Epoch 1665/3000\n",
      "13/13 - 0s - loss: 0.2261 - accuracy: 0.8975 - val_loss: 0.4938 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01665: val_loss did not improve from 0.41762\n",
      "Epoch 1666/3000\n",
      "13/13 - 0s - loss: 0.2180 - accuracy: 0.8923 - val_loss: 0.4850 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01666: val_loss did not improve from 0.41762\n",
      "Epoch 1667/3000\n",
      "13/13 - 0s - loss: 0.2279 - accuracy: 0.8949 - val_loss: 0.5185 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01667: val_loss did not improve from 0.41762\n",
      "Epoch 1668/3000\n",
      "13/13 - 0s - loss: 0.2262 - accuracy: 0.8988 - val_loss: 0.4861 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01668: val_loss did not improve from 0.41762\n",
      "Epoch 1669/3000\n",
      "13/13 - 0s - loss: 0.2202 - accuracy: 0.8988 - val_loss: 0.5007 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01669: val_loss did not improve from 0.41762\n",
      "Epoch 1670/3000\n",
      "13/13 - 0s - loss: 0.2105 - accuracy: 0.9014 - val_loss: 0.5118 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01670: val_loss did not improve from 0.41762\n",
      "Epoch 1671/3000\n",
      "13/13 - 0s - loss: 0.2091 - accuracy: 0.9001 - val_loss: 0.5064 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01671: val_loss did not improve from 0.41762\n",
      "Epoch 1672/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.9001 - val_loss: 0.4975 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01672: val_loss did not improve from 0.41762\n",
      "Epoch 1673/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.8988 - val_loss: 0.5070 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01673: val_loss did not improve from 0.41762\n",
      "Epoch 1674/3000\n",
      "13/13 - 0s - loss: 0.2158 - accuracy: 0.8975 - val_loss: 0.5502 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01674: val_loss did not improve from 0.41762\n",
      "Epoch 1675/3000\n",
      "13/13 - 0s - loss: 0.2322 - accuracy: 0.8949 - val_loss: 0.5359 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01675: val_loss did not improve from 0.41762\n",
      "Epoch 1676/3000\n",
      "13/13 - 0s - loss: 0.2168 - accuracy: 0.9040 - val_loss: 0.5045 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01676: val_loss did not improve from 0.41762\n",
      "Epoch 1677/3000\n",
      "13/13 - 0s - loss: 0.2172 - accuracy: 0.8988 - val_loss: 0.4833 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01677: val_loss did not improve from 0.41762\n",
      "Epoch 1678/3000\n",
      "13/13 - 0s - loss: 0.2169 - accuracy: 0.8975 - val_loss: 0.4810 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01678: val_loss did not improve from 0.41762\n",
      "Epoch 1679/3000\n",
      "13/13 - 0s - loss: 0.2207 - accuracy: 0.8923 - val_loss: 0.4872 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01679: val_loss did not improve from 0.41762\n",
      "Epoch 1680/3000\n",
      "13/13 - 0s - loss: 0.2086 - accuracy: 0.8949 - val_loss: 0.4942 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01680: val_loss did not improve from 0.41762\n",
      "Epoch 1681/3000\n",
      "13/13 - 0s - loss: 0.2189 - accuracy: 0.9014 - val_loss: 0.4822 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01681: val_loss did not improve from 0.41762\n",
      "Epoch 1682/3000\n",
      "13/13 - 0s - loss: 0.2212 - accuracy: 0.8988 - val_loss: 0.4974 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01682: val_loss did not improve from 0.41762\n",
      "Epoch 1683/3000\n",
      "13/13 - 0s - loss: 0.2393 - accuracy: 0.8846 - val_loss: 0.5141 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01683: val_loss did not improve from 0.41762\n",
      "Epoch 1684/3000\n",
      "13/13 - 0s - loss: 0.2204 - accuracy: 0.8936 - val_loss: 0.4967 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01684: val_loss did not improve from 0.41762\n",
      "Epoch 1685/3000\n",
      "13/13 - 0s - loss: 0.2171 - accuracy: 0.9014 - val_loss: 0.5240 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01685: val_loss did not improve from 0.41762\n",
      "Epoch 1686/3000\n",
      "13/13 - 0s - loss: 0.2234 - accuracy: 0.8911 - val_loss: 0.4959 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01686: val_loss did not improve from 0.41762\n",
      "Epoch 1687/3000\n",
      "13/13 - 0s - loss: 0.2455 - accuracy: 0.8794 - val_loss: 0.5431 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01687: val_loss did not improve from 0.41762\n",
      "Epoch 1688/3000\n",
      "13/13 - 0s - loss: 0.2376 - accuracy: 0.8923 - val_loss: 0.4901 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01688: val_loss did not improve from 0.41762\n",
      "Epoch 1689/3000\n",
      "13/13 - 0s - loss: 0.2268 - accuracy: 0.9014 - val_loss: 0.4905 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01689: val_loss did not improve from 0.41762\n",
      "Epoch 1690/3000\n",
      "13/13 - 0s - loss: 0.2121 - accuracy: 0.8975 - val_loss: 0.4836 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01690: val_loss did not improve from 0.41762\n",
      "Epoch 1691/3000\n",
      "13/13 - 0s - loss: 0.2162 - accuracy: 0.8962 - val_loss: 0.5038 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01691: val_loss did not improve from 0.41762\n",
      "Epoch 1692/3000\n",
      "13/13 - 0s - loss: 0.2122 - accuracy: 0.9014 - val_loss: 0.4913 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01692: val_loss did not improve from 0.41762\n",
      "Epoch 1693/3000\n",
      "13/13 - 0s - loss: 0.2139 - accuracy: 0.9001 - val_loss: 0.5007 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01693: val_loss did not improve from 0.41762\n",
      "Epoch 1694/3000\n",
      "13/13 - 0s - loss: 0.2120 - accuracy: 0.9014 - val_loss: 0.4892 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01694: val_loss did not improve from 0.41762\n",
      "Epoch 1695/3000\n",
      "13/13 - 0s - loss: 0.2127 - accuracy: 0.9001 - val_loss: 0.4890 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01695: val_loss did not improve from 0.41762\n",
      "Epoch 1696/3000\n",
      "13/13 - 0s - loss: 0.2206 - accuracy: 0.9001 - val_loss: 0.4777 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01696: val_loss did not improve from 0.41762\n",
      "Epoch 1697/3000\n",
      "13/13 - 0s - loss: 0.2282 - accuracy: 0.8898 - val_loss: 0.4765 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01697: val_loss did not improve from 0.41762\n",
      "Epoch 1698/3000\n",
      "13/13 - 0s - loss: 0.2257 - accuracy: 0.8885 - val_loss: 0.4873 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01698: val_loss did not improve from 0.41762\n",
      "Epoch 1699/3000\n",
      "13/13 - 0s - loss: 0.2196 - accuracy: 0.9001 - val_loss: 0.5229 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01699: val_loss did not improve from 0.41762\n",
      "Epoch 1700/3000\n",
      "13/13 - 0s - loss: 0.2123 - accuracy: 0.8962 - val_loss: 0.4963 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01700: val_loss did not improve from 0.41762\n",
      "Epoch 1701/3000\n",
      "13/13 - 0s - loss: 0.2085 - accuracy: 0.9001 - val_loss: 0.4965 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01701: val_loss did not improve from 0.41762\n",
      "Epoch 1702/3000\n",
      "13/13 - 0s - loss: 0.2097 - accuracy: 0.9001 - val_loss: 0.5038 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01702: val_loss did not improve from 0.41762\n",
      "Epoch 1703/3000\n",
      "13/13 - 0s - loss: 0.2158 - accuracy: 0.8975 - val_loss: 0.4940 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01703: val_loss did not improve from 0.41762\n",
      "Epoch 1704/3000\n",
      "13/13 - 0s - loss: 0.2118 - accuracy: 0.8988 - val_loss: 0.4841 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01704: val_loss did not improve from 0.41762\n",
      "Epoch 1705/3000\n",
      "13/13 - 0s - loss: 0.2097 - accuracy: 0.9014 - val_loss: 0.4885 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01705: val_loss did not improve from 0.41762\n",
      "Epoch 1706/3000\n",
      "13/13 - 0s - loss: 0.2150 - accuracy: 0.8949 - val_loss: 0.4919 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01706: val_loss did not improve from 0.41762\n",
      "Epoch 1707/3000\n",
      "13/13 - 0s - loss: 0.2122 - accuracy: 0.8962 - val_loss: 0.4909 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01707: val_loss did not improve from 0.41762\n",
      "Epoch 1708/3000\n",
      "13/13 - 0s - loss: 0.2121 - accuracy: 0.8949 - val_loss: 0.5003 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01708: val_loss did not improve from 0.41762\n",
      "Epoch 1709/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.8975 - val_loss: 0.4878 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01709: val_loss did not improve from 0.41762\n",
      "Epoch 1710/3000\n",
      "13/13 - 0s - loss: 0.2096 - accuracy: 0.8975 - val_loss: 0.5161 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01710: val_loss did not improve from 0.41762\n",
      "Epoch 1711/3000\n",
      "13/13 - 0s - loss: 0.2100 - accuracy: 0.8936 - val_loss: 0.4927 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01711: val_loss did not improve from 0.41762\n",
      "Epoch 1712/3000\n",
      "13/13 - 0s - loss: 0.2096 - accuracy: 0.8936 - val_loss: 0.4939 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01712: val_loss did not improve from 0.41762\n",
      "Epoch 1713/3000\n",
      "13/13 - 0s - loss: 0.2099 - accuracy: 0.9001 - val_loss: 0.5060 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01713: val_loss did not improve from 0.41762\n",
      "Epoch 1714/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.9001 - val_loss: 0.4930 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01714: val_loss did not improve from 0.41762\n",
      "Epoch 1715/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.8988 - val_loss: 0.5043 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01715: val_loss did not improve from 0.41762\n",
      "Epoch 1716/3000\n",
      "13/13 - 0s - loss: 0.2078 - accuracy: 0.8975 - val_loss: 0.4937 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01716: val_loss did not improve from 0.41762\n",
      "Epoch 1717/3000\n",
      "13/13 - 0s - loss: 0.2165 - accuracy: 0.8885 - val_loss: 0.4868 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01717: val_loss did not improve from 0.41762\n",
      "Epoch 1718/3000\n",
      "13/13 - 0s - loss: 0.2128 - accuracy: 0.8872 - val_loss: 0.4852 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01718: val_loss did not improve from 0.41762\n",
      "Epoch 1719/3000\n",
      "13/13 - 0s - loss: 0.2121 - accuracy: 0.8988 - val_loss: 0.4929 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01719: val_loss did not improve from 0.41762\n",
      "Epoch 1720/3000\n",
      "13/13 - 0s - loss: 0.2111 - accuracy: 0.9001 - val_loss: 0.4960 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01720: val_loss did not improve from 0.41762\n",
      "Epoch 1721/3000\n",
      "13/13 - 0s - loss: 0.2077 - accuracy: 0.9014 - val_loss: 0.4956 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01721: val_loss did not improve from 0.41762\n",
      "Epoch 1722/3000\n",
      "13/13 - 0s - loss: 0.2073 - accuracy: 0.9014 - val_loss: 0.4988 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01722: val_loss did not improve from 0.41762\n",
      "Epoch 1723/3000\n",
      "13/13 - 0s - loss: 0.2130 - accuracy: 0.8911 - val_loss: 0.5260 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01723: val_loss did not improve from 0.41762\n",
      "Epoch 1724/3000\n",
      "13/13 - 0s - loss: 0.2104 - accuracy: 0.8975 - val_loss: 0.4857 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01724: val_loss did not improve from 0.41762\n",
      "Epoch 1725/3000\n",
      "13/13 - 0s - loss: 0.2309 - accuracy: 0.8988 - val_loss: 0.4512 - val_accuracy: 0.8653\n",
      "\n",
      "Epoch 01725: val_loss did not improve from 0.41762\n",
      "Epoch 1726/3000\n",
      "13/13 - 0s - loss: 0.2463 - accuracy: 0.8755 - val_loss: 0.4886 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 01726: val_loss did not improve from 0.41762\n",
      "Epoch 1727/3000\n",
      "13/13 - 0s - loss: 0.2200 - accuracy: 0.8885 - val_loss: 0.4794 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01727: val_loss did not improve from 0.41762\n",
      "Epoch 1728/3000\n",
      "13/13 - 0s - loss: 0.2112 - accuracy: 0.8962 - val_loss: 0.5023 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01728: val_loss did not improve from 0.41762\n",
      "Epoch 1729/3000\n",
      "13/13 - 0s - loss: 0.2088 - accuracy: 0.9001 - val_loss: 0.5000 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01729: val_loss did not improve from 0.41762\n",
      "Epoch 1730/3000\n",
      "13/13 - 0s - loss: 0.2092 - accuracy: 0.9014 - val_loss: 0.4904 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01730: val_loss did not improve from 0.41762\n",
      "Epoch 1731/3000\n",
      "13/13 - 0s - loss: 0.2092 - accuracy: 0.8975 - val_loss: 0.4910 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01731: val_loss did not improve from 0.41762\n",
      "Epoch 1732/3000\n",
      "13/13 - 0s - loss: 0.2086 - accuracy: 0.9027 - val_loss: 0.4987 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01732: val_loss did not improve from 0.41762\n",
      "Epoch 1733/3000\n",
      "13/13 - 0s - loss: 0.2227 - accuracy: 0.9001 - val_loss: 0.5474 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01733: val_loss did not improve from 0.41762\n",
      "Epoch 1734/3000\n",
      "13/13 - 0s - loss: 0.2184 - accuracy: 0.8962 - val_loss: 0.5130 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01734: val_loss did not improve from 0.41762\n",
      "Epoch 1735/3000\n",
      "13/13 - 0s - loss: 0.2194 - accuracy: 0.8911 - val_loss: 0.5033 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01735: val_loss did not improve from 0.41762\n",
      "Epoch 1736/3000\n",
      "13/13 - 0s - loss: 0.2161 - accuracy: 0.8975 - val_loss: 0.5023 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01736: val_loss did not improve from 0.41762\n",
      "Epoch 1737/3000\n",
      "13/13 - 0s - loss: 0.2103 - accuracy: 0.8936 - val_loss: 0.5045 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01737: val_loss did not improve from 0.41762\n",
      "Epoch 1738/3000\n",
      "13/13 - 0s - loss: 0.2089 - accuracy: 0.8975 - val_loss: 0.4983 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01738: val_loss did not improve from 0.41762\n",
      "Epoch 1739/3000\n",
      "13/13 - 0s - loss: 0.2069 - accuracy: 0.9001 - val_loss: 0.4961 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01739: val_loss did not improve from 0.41762\n",
      "Epoch 1740/3000\n",
      "13/13 - 0s - loss: 0.2194 - accuracy: 0.9027 - val_loss: 0.5195 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01740: val_loss did not improve from 0.41762\n",
      "Epoch 1741/3000\n",
      "13/13 - 0s - loss: 0.2122 - accuracy: 0.9053 - val_loss: 0.4962 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01741: val_loss did not improve from 0.41762\n",
      "Epoch 1742/3000\n",
      "13/13 - 0s - loss: 0.2086 - accuracy: 0.9001 - val_loss: 0.5048 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01742: val_loss did not improve from 0.41762\n",
      "Epoch 1743/3000\n",
      "13/13 - 0s - loss: 0.2076 - accuracy: 0.9027 - val_loss: 0.5075 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01743: val_loss did not improve from 0.41762\n",
      "Epoch 1744/3000\n",
      "13/13 - 0s - loss: 0.2132 - accuracy: 0.8975 - val_loss: 0.4948 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01744: val_loss did not improve from 0.41762\n",
      "Epoch 1745/3000\n",
      "13/13 - 0s - loss: 0.2168 - accuracy: 0.9001 - val_loss: 0.4782 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01745: val_loss did not improve from 0.41762\n",
      "Epoch 1746/3000\n",
      "13/13 - 0s - loss: 0.2436 - accuracy: 0.8846 - val_loss: 0.5085 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01746: val_loss did not improve from 0.41762\n",
      "Epoch 1747/3000\n",
      "13/13 - 0s - loss: 0.2256 - accuracy: 0.8898 - val_loss: 0.5290 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01747: val_loss did not improve from 0.41762\n",
      "Epoch 1748/3000\n",
      "13/13 - 0s - loss: 0.2159 - accuracy: 0.8936 - val_loss: 0.5011 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01748: val_loss did not improve from 0.41762\n",
      "Epoch 1749/3000\n",
      "13/13 - 0s - loss: 0.2130 - accuracy: 0.9001 - val_loss: 0.5070 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01749: val_loss did not improve from 0.41762\n",
      "Epoch 1750/3000\n",
      "13/13 - 0s - loss: 0.2099 - accuracy: 0.8975 - val_loss: 0.5019 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01750: val_loss did not improve from 0.41762\n",
      "Epoch 1751/3000\n",
      "13/13 - 0s - loss: 0.2350 - accuracy: 0.8872 - val_loss: 0.5054 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01751: val_loss did not improve from 0.41762\n",
      "Epoch 1752/3000\n",
      "13/13 - 0s - loss: 0.2119 - accuracy: 0.8949 - val_loss: 0.4767 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01752: val_loss did not improve from 0.41762\n",
      "Epoch 1753/3000\n",
      "13/13 - 0s - loss: 0.2259 - accuracy: 0.8885 - val_loss: 0.4990 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01753: val_loss did not improve from 0.41762\n",
      "Epoch 1754/3000\n",
      "13/13 - 0s - loss: 0.2388 - accuracy: 0.8833 - val_loss: 0.5226 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01754: val_loss did not improve from 0.41762\n",
      "Epoch 1755/3000\n",
      "13/13 - 0s - loss: 0.2383 - accuracy: 0.8703 - val_loss: 0.5153 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01755: val_loss did not improve from 0.41762\n",
      "Epoch 1756/3000\n",
      "13/13 - 0s - loss: 0.2309 - accuracy: 0.8703 - val_loss: 0.4752 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01756: val_loss did not improve from 0.41762\n",
      "Epoch 1757/3000\n",
      "13/13 - 0s - loss: 0.2248 - accuracy: 0.8962 - val_loss: 0.4957 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01757: val_loss did not improve from 0.41762\n",
      "Epoch 1758/3000\n",
      "13/13 - 0s - loss: 0.2106 - accuracy: 0.9027 - val_loss: 0.4766 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01758: val_loss did not improve from 0.41762\n",
      "Epoch 1759/3000\n",
      "13/13 - 0s - loss: 0.2091 - accuracy: 0.8975 - val_loss: 0.4900 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01759: val_loss did not improve from 0.41762\n",
      "Epoch 1760/3000\n",
      "13/13 - 0s - loss: 0.2083 - accuracy: 0.9001 - val_loss: 0.5008 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01760: val_loss did not improve from 0.41762\n",
      "Epoch 1761/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.9001 - val_loss: 0.5046 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01761: val_loss did not improve from 0.41762\n",
      "Epoch 1762/3000\n",
      "13/13 - 0s - loss: 0.2134 - accuracy: 0.9014 - val_loss: 0.5409 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01762: val_loss did not improve from 0.41762\n",
      "Epoch 1763/3000\n",
      "13/13 - 0s - loss: 0.2205 - accuracy: 0.9001 - val_loss: 0.5211 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01763: val_loss did not improve from 0.41762\n",
      "Epoch 1764/3000\n",
      "13/13 - 0s - loss: 0.2105 - accuracy: 0.9001 - val_loss: 0.4896 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01764: val_loss did not improve from 0.41762\n",
      "Epoch 1765/3000\n",
      "13/13 - 0s - loss: 0.2120 - accuracy: 0.8962 - val_loss: 0.4956 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01765: val_loss did not improve from 0.41762\n",
      "Epoch 1766/3000\n",
      "13/13 - 0s - loss: 0.2171 - accuracy: 0.9001 - val_loss: 0.4894 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01766: val_loss did not improve from 0.41762\n",
      "Epoch 1767/3000\n",
      "13/13 - 0s - loss: 0.2244 - accuracy: 0.9014 - val_loss: 0.5138 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01767: val_loss did not improve from 0.41762\n",
      "Epoch 1768/3000\n",
      "13/13 - 0s - loss: 0.2230 - accuracy: 0.9001 - val_loss: 0.4886 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01768: val_loss did not improve from 0.41762\n",
      "Epoch 1769/3000\n",
      "13/13 - 0s - loss: 0.2155 - accuracy: 0.8975 - val_loss: 0.4846 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01769: val_loss did not improve from 0.41762\n",
      "Epoch 1770/3000\n",
      "13/13 - 0s - loss: 0.2266 - accuracy: 0.8885 - val_loss: 0.4916 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01770: val_loss did not improve from 0.41762\n",
      "Epoch 1771/3000\n",
      "13/13 - 0s - loss: 0.2184 - accuracy: 0.9027 - val_loss: 0.5225 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01771: val_loss did not improve from 0.41762\n",
      "Epoch 1772/3000\n",
      "13/13 - 0s - loss: 0.2147 - accuracy: 0.9014 - val_loss: 0.4776 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01772: val_loss did not improve from 0.41762\n",
      "Epoch 1773/3000\n",
      "13/13 - 0s - loss: 0.2103 - accuracy: 0.9014 - val_loss: 0.4934 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01773: val_loss did not improve from 0.41762\n",
      "Epoch 1774/3000\n",
      "13/13 - 0s - loss: 0.2095 - accuracy: 0.9027 - val_loss: 0.5021 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01774: val_loss did not improve from 0.41762\n",
      "Epoch 1775/3000\n",
      "13/13 - 0s - loss: 0.2088 - accuracy: 0.8988 - val_loss: 0.5170 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01775: val_loss did not improve from 0.41762\n",
      "Epoch 1776/3000\n",
      "13/13 - 0s - loss: 0.2126 - accuracy: 0.8962 - val_loss: 0.5278 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01776: val_loss did not improve from 0.41762\n",
      "Epoch 1777/3000\n",
      "13/13 - 0s - loss: 0.2098 - accuracy: 0.8988 - val_loss: 0.5176 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01777: val_loss did not improve from 0.41762\n",
      "Epoch 1778/3000\n",
      "13/13 - 0s - loss: 0.2112 - accuracy: 0.8975 - val_loss: 0.5092 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01778: val_loss did not improve from 0.41762\n",
      "Epoch 1779/3000\n",
      "13/13 - 0s - loss: 0.2096 - accuracy: 0.8962 - val_loss: 0.5109 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01779: val_loss did not improve from 0.41762\n",
      "Epoch 1780/3000\n",
      "13/13 - 0s - loss: 0.2109 - accuracy: 0.9001 - val_loss: 0.5009 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01780: val_loss did not improve from 0.41762\n",
      "Epoch 1781/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.9001 - val_loss: 0.5166 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01781: val_loss did not improve from 0.41762\n",
      "Epoch 1782/3000\n",
      "13/13 - 0s - loss: 0.2141 - accuracy: 0.9014 - val_loss: 0.5182 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01782: val_loss did not improve from 0.41762\n",
      "Epoch 1783/3000\n",
      "13/13 - 0s - loss: 0.2197 - accuracy: 0.8949 - val_loss: 0.5145 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01783: val_loss did not improve from 0.41762\n",
      "Epoch 1784/3000\n",
      "13/13 - 0s - loss: 0.2125 - accuracy: 0.9027 - val_loss: 0.5071 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01784: val_loss did not improve from 0.41762\n",
      "Epoch 1785/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.9014 - val_loss: 0.5021 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01785: val_loss did not improve from 0.41762\n",
      "Epoch 1786/3000\n",
      "13/13 - 0s - loss: 0.2109 - accuracy: 0.8975 - val_loss: 0.5031 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01786: val_loss did not improve from 0.41762\n",
      "Epoch 1787/3000\n",
      "13/13 - 0s - loss: 0.2095 - accuracy: 0.8988 - val_loss: 0.5090 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01787: val_loss did not improve from 0.41762\n",
      "Epoch 1788/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.9001 - val_loss: 0.4949 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01788: val_loss did not improve from 0.41762\n",
      "Epoch 1789/3000\n",
      "13/13 - 0s - loss: 0.2119 - accuracy: 0.9027 - val_loss: 0.5053 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01789: val_loss did not improve from 0.41762\n",
      "Epoch 1790/3000\n",
      "13/13 - 0s - loss: 0.2243 - accuracy: 0.8988 - val_loss: 0.4933 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01790: val_loss did not improve from 0.41762\n",
      "Epoch 1791/3000\n",
      "13/13 - 0s - loss: 0.2481 - accuracy: 0.8949 - val_loss: 0.4646 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01791: val_loss did not improve from 0.41762\n",
      "Epoch 1792/3000\n",
      "13/13 - 0s - loss: 0.2431 - accuracy: 0.8898 - val_loss: 0.5047 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01792: val_loss did not improve from 0.41762\n",
      "Epoch 1793/3000\n",
      "13/13 - 0s - loss: 0.2302 - accuracy: 0.8885 - val_loss: 0.5096 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01793: val_loss did not improve from 0.41762\n",
      "Epoch 1794/3000\n",
      "13/13 - 0s - loss: 0.2178 - accuracy: 0.8911 - val_loss: 0.5431 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01794: val_loss did not improve from 0.41762\n",
      "Epoch 1795/3000\n",
      "13/13 - 0s - loss: 0.2458 - accuracy: 0.8975 - val_loss: 0.5036 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01795: val_loss did not improve from 0.41762\n",
      "Epoch 1796/3000\n",
      "13/13 - 0s - loss: 0.2184 - accuracy: 0.8962 - val_loss: 0.4819 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01796: val_loss did not improve from 0.41762\n",
      "Epoch 1797/3000\n",
      "13/13 - 0s - loss: 0.2145 - accuracy: 0.8962 - val_loss: 0.4857 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01797: val_loss did not improve from 0.41762\n",
      "Epoch 1798/3000\n",
      "13/13 - 0s - loss: 0.2106 - accuracy: 0.9014 - val_loss: 0.4905 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01798: val_loss did not improve from 0.41762\n",
      "Epoch 1799/3000\n",
      "13/13 - 0s - loss: 0.2107 - accuracy: 0.8949 - val_loss: 0.4967 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01799: val_loss did not improve from 0.41762\n",
      "Epoch 1800/3000\n",
      "13/13 - 0s - loss: 0.2357 - accuracy: 0.9001 - val_loss: 0.5041 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01800: val_loss did not improve from 0.41762\n",
      "Epoch 1801/3000\n",
      "13/13 - 0s - loss: 0.2248 - accuracy: 0.8988 - val_loss: 0.4865 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01801: val_loss did not improve from 0.41762\n",
      "Epoch 1802/3000\n",
      "13/13 - 0s - loss: 0.2210 - accuracy: 0.8859 - val_loss: 0.4815 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01802: val_loss did not improve from 0.41762\n",
      "Epoch 1803/3000\n",
      "13/13 - 0s - loss: 0.2168 - accuracy: 0.8898 - val_loss: 0.4800 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01803: val_loss did not improve from 0.41762\n",
      "Epoch 1804/3000\n",
      "13/13 - 0s - loss: 0.2112 - accuracy: 0.8949 - val_loss: 0.4857 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01804: val_loss did not improve from 0.41762\n",
      "Epoch 1805/3000\n",
      "13/13 - 0s - loss: 0.2207 - accuracy: 0.8923 - val_loss: 0.5083 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01805: val_loss did not improve from 0.41762\n",
      "Epoch 1806/3000\n",
      "13/13 - 0s - loss: 0.2766 - accuracy: 0.8638 - val_loss: 0.5924 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01806: val_loss did not improve from 0.41762\n",
      "Epoch 1807/3000\n",
      "13/13 - 0s - loss: 0.2595 - accuracy: 0.8833 - val_loss: 0.5243 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01807: val_loss did not improve from 0.41762\n",
      "Epoch 1808/3000\n",
      "13/13 - 0s - loss: 0.2545 - accuracy: 0.8949 - val_loss: 0.5733 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 01808: val_loss did not improve from 0.41762\n",
      "Epoch 1809/3000\n",
      "13/13 - 0s - loss: 0.2223 - accuracy: 0.8962 - val_loss: 0.4687 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01809: val_loss did not improve from 0.41762\n",
      "Epoch 1810/3000\n",
      "13/13 - 0s - loss: 0.2162 - accuracy: 0.8949 - val_loss: 0.4743 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01810: val_loss did not improve from 0.41762\n",
      "Epoch 1811/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.8962 - val_loss: 0.4893 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01811: val_loss did not improve from 0.41762\n",
      "Epoch 1812/3000\n",
      "13/13 - 0s - loss: 0.2236 - accuracy: 0.9014 - val_loss: 0.4941 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01812: val_loss did not improve from 0.41762\n",
      "Epoch 1813/3000\n",
      "13/13 - 0s - loss: 0.2395 - accuracy: 0.8859 - val_loss: 0.4690 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01813: val_loss did not improve from 0.41762\n",
      "Epoch 1814/3000\n",
      "13/13 - 0s - loss: 0.2264 - accuracy: 0.8962 - val_loss: 0.5173 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01814: val_loss did not improve from 0.41762\n",
      "Epoch 1815/3000\n",
      "13/13 - 0s - loss: 0.2183 - accuracy: 0.8988 - val_loss: 0.4938 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01815: val_loss did not improve from 0.41762\n",
      "Epoch 1816/3000\n",
      "13/13 - 0s - loss: 0.2134 - accuracy: 0.9001 - val_loss: 0.4981 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01816: val_loss did not improve from 0.41762\n",
      "Epoch 1817/3000\n",
      "13/13 - 0s - loss: 0.2119 - accuracy: 0.9001 - val_loss: 0.5051 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01817: val_loss did not improve from 0.41762\n",
      "Epoch 1818/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.8988 - val_loss: 0.5035 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01818: val_loss did not improve from 0.41762\n",
      "Epoch 1819/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.9001 - val_loss: 0.5083 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01819: val_loss did not improve from 0.41762\n",
      "Epoch 1820/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.9014 - val_loss: 0.5084 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01820: val_loss did not improve from 0.41762\n",
      "Epoch 1821/3000\n",
      "13/13 - 0s - loss: 0.2139 - accuracy: 0.8911 - val_loss: 0.5002 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01821: val_loss did not improve from 0.41762\n",
      "Epoch 1822/3000\n",
      "13/13 - 0s - loss: 0.2144 - accuracy: 0.8962 - val_loss: 0.5180 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01822: val_loss did not improve from 0.41762\n",
      "Epoch 1823/3000\n",
      "13/13 - 0s - loss: 0.2316 - accuracy: 0.8898 - val_loss: 0.5176 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01823: val_loss did not improve from 0.41762\n",
      "Epoch 1824/3000\n",
      "13/13 - 0s - loss: 0.2102 - accuracy: 0.9001 - val_loss: 0.4882 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01824: val_loss did not improve from 0.41762\n",
      "Epoch 1825/3000\n",
      "13/13 - 0s - loss: 0.2160 - accuracy: 0.8923 - val_loss: 0.4921 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01825: val_loss did not improve from 0.41762\n",
      "Epoch 1826/3000\n",
      "13/13 - 0s - loss: 0.2141 - accuracy: 0.8975 - val_loss: 0.4956 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01826: val_loss did not improve from 0.41762\n",
      "Epoch 1827/3000\n",
      "13/13 - 0s - loss: 0.2130 - accuracy: 0.8975 - val_loss: 0.4737 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01827: val_loss did not improve from 0.41762\n",
      "Epoch 1828/3000\n",
      "13/13 - 0s - loss: 0.2217 - accuracy: 0.8923 - val_loss: 0.4903 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01828: val_loss did not improve from 0.41762\n",
      "Epoch 1829/3000\n",
      "13/13 - 0s - loss: 0.2149 - accuracy: 0.8949 - val_loss: 0.4999 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01829: val_loss did not improve from 0.41762\n",
      "Epoch 1830/3000\n",
      "13/13 - 0s - loss: 0.2136 - accuracy: 0.9014 - val_loss: 0.4920 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01830: val_loss did not improve from 0.41762\n",
      "Epoch 1831/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.9001 - val_loss: 0.4786 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01831: val_loss did not improve from 0.41762\n",
      "Epoch 1832/3000\n",
      "13/13 - 0s - loss: 0.2124 - accuracy: 0.8975 - val_loss: 0.4958 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01832: val_loss did not improve from 0.41762\n",
      "Epoch 1833/3000\n",
      "13/13 - 0s - loss: 0.2117 - accuracy: 0.9014 - val_loss: 0.4892 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01833: val_loss did not improve from 0.41762\n",
      "Epoch 1834/3000\n",
      "13/13 - 0s - loss: 0.2315 - accuracy: 0.8911 - val_loss: 0.4541 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 01834: val_loss did not improve from 0.41762\n",
      "Epoch 1835/3000\n",
      "13/13 - 0s - loss: 0.2308 - accuracy: 0.8911 - val_loss: 0.4868 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01835: val_loss did not improve from 0.41762\n",
      "Epoch 1836/3000\n",
      "13/13 - 0s - loss: 0.2168 - accuracy: 0.8898 - val_loss: 0.4805 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01836: val_loss did not improve from 0.41762\n",
      "Epoch 1837/3000\n",
      "13/13 - 0s - loss: 0.2286 - accuracy: 0.8833 - val_loss: 0.4753 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01837: val_loss did not improve from 0.41762\n",
      "Epoch 1838/3000\n",
      "13/13 - 0s - loss: 0.2254 - accuracy: 0.8962 - val_loss: 0.5173 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01838: val_loss did not improve from 0.41762\n",
      "Epoch 1839/3000\n",
      "13/13 - 0s - loss: 0.2156 - accuracy: 0.9040 - val_loss: 0.4974 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01839: val_loss did not improve from 0.41762\n",
      "Epoch 1840/3000\n",
      "13/13 - 0s - loss: 0.2127 - accuracy: 0.9014 - val_loss: 0.4890 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01840: val_loss did not improve from 0.41762\n",
      "Epoch 1841/3000\n",
      "13/13 - 0s - loss: 0.2086 - accuracy: 0.9027 - val_loss: 0.4900 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01841: val_loss did not improve from 0.41762\n",
      "Epoch 1842/3000\n",
      "13/13 - 0s - loss: 0.2092 - accuracy: 0.9014 - val_loss: 0.4856 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01842: val_loss did not improve from 0.41762\n",
      "Epoch 1843/3000\n",
      "13/13 - 0s - loss: 0.2128 - accuracy: 0.8975 - val_loss: 0.4938 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01843: val_loss did not improve from 0.41762\n",
      "Epoch 1844/3000\n",
      "13/13 - 0s - loss: 0.2141 - accuracy: 0.8949 - val_loss: 0.5061 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01844: val_loss did not improve from 0.41762\n",
      "Epoch 1845/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.9001 - val_loss: 0.4840 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01845: val_loss did not improve from 0.41762\n",
      "Epoch 1846/3000\n",
      "13/13 - 0s - loss: 0.2089 - accuracy: 0.8962 - val_loss: 0.4876 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01846: val_loss did not improve from 0.41762\n",
      "Epoch 1847/3000\n",
      "13/13 - 0s - loss: 0.2104 - accuracy: 0.9001 - val_loss: 0.4777 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01847: val_loss did not improve from 0.41762\n",
      "Epoch 1848/3000\n",
      "13/13 - 0s - loss: 0.2157 - accuracy: 0.8988 - val_loss: 0.4849 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01848: val_loss did not improve from 0.41762\n",
      "Epoch 1849/3000\n",
      "13/13 - 0s - loss: 0.2104 - accuracy: 0.8988 - val_loss: 0.4992 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01849: val_loss did not improve from 0.41762\n",
      "Epoch 1850/3000\n",
      "13/13 - 0s - loss: 0.2068 - accuracy: 0.9014 - val_loss: 0.5011 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01850: val_loss did not improve from 0.41762\n",
      "Epoch 1851/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.9027 - val_loss: 0.5052 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01851: val_loss did not improve from 0.41762\n",
      "Epoch 1852/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.8936 - val_loss: 0.4971 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01852: val_loss did not improve from 0.41762\n",
      "Epoch 1853/3000\n",
      "13/13 - 0s - loss: 0.2187 - accuracy: 0.8859 - val_loss: 0.4712 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01853: val_loss did not improve from 0.41762\n",
      "Epoch 1854/3000\n",
      "13/13 - 0s - loss: 0.2134 - accuracy: 0.8949 - val_loss: 0.4815 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01854: val_loss did not improve from 0.41762\n",
      "Epoch 1855/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.9027 - val_loss: 0.4878 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01855: val_loss did not improve from 0.41762\n",
      "Epoch 1856/3000\n",
      "13/13 - 0s - loss: 0.2089 - accuracy: 0.8975 - val_loss: 0.4922 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01856: val_loss did not improve from 0.41762\n",
      "Epoch 1857/3000\n",
      "13/13 - 0s - loss: 0.2093 - accuracy: 0.8988 - val_loss: 0.4849 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01857: val_loss did not improve from 0.41762\n",
      "Epoch 1858/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.8975 - val_loss: 0.4917 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01858: val_loss did not improve from 0.41762\n",
      "Epoch 1859/3000\n",
      "13/13 - 0s - loss: 0.2065 - accuracy: 0.8988 - val_loss: 0.4947 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01859: val_loss did not improve from 0.41762\n",
      "Epoch 1860/3000\n",
      "13/13 - 0s - loss: 0.2092 - accuracy: 0.9014 - val_loss: 0.4847 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01860: val_loss did not improve from 0.41762\n",
      "Epoch 1861/3000\n",
      "13/13 - 0s - loss: 0.2318 - accuracy: 0.8872 - val_loss: 0.4692 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 01861: val_loss did not improve from 0.41762\n",
      "Epoch 1862/3000\n",
      "13/13 - 0s - loss: 0.2132 - accuracy: 0.8949 - val_loss: 0.4981 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01862: val_loss did not improve from 0.41762\n",
      "Epoch 1863/3000\n",
      "13/13 - 0s - loss: 0.2127 - accuracy: 0.8975 - val_loss: 0.4877 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01863: val_loss did not improve from 0.41762\n",
      "Epoch 1864/3000\n",
      "13/13 - 0s - loss: 0.2103 - accuracy: 0.8923 - val_loss: 0.4915 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01864: val_loss did not improve from 0.41762\n",
      "Epoch 1865/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.9001 - val_loss: 0.4812 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01865: val_loss did not improve from 0.41762\n",
      "Epoch 1866/3000\n",
      "13/13 - 0s - loss: 0.2577 - accuracy: 0.8898 - val_loss: 0.4644 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 01866: val_loss did not improve from 0.41762\n",
      "Epoch 1867/3000\n",
      "13/13 - 0s - loss: 0.2387 - accuracy: 0.8923 - val_loss: 0.5056 - val_accuracy: 0.8653\n",
      "\n",
      "Epoch 01867: val_loss did not improve from 0.41762\n",
      "Epoch 1868/3000\n",
      "13/13 - 0s - loss: 0.2238 - accuracy: 0.8949 - val_loss: 0.4793 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01868: val_loss did not improve from 0.41762\n",
      "Epoch 1869/3000\n",
      "13/13 - 0s - loss: 0.2231 - accuracy: 0.8885 - val_loss: 0.4746 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01869: val_loss did not improve from 0.41762\n",
      "Epoch 1870/3000\n",
      "13/13 - 0s - loss: 0.2178 - accuracy: 0.8988 - val_loss: 0.4804 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01870: val_loss did not improve from 0.41762\n",
      "Epoch 1871/3000\n",
      "13/13 - 0s - loss: 0.2080 - accuracy: 0.9014 - val_loss: 0.4762 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01871: val_loss did not improve from 0.41762\n",
      "Epoch 1872/3000\n",
      "13/13 - 0s - loss: 0.2083 - accuracy: 0.9014 - val_loss: 0.4815 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01872: val_loss did not improve from 0.41762\n",
      "Epoch 1873/3000\n",
      "13/13 - 0s - loss: 0.2070 - accuracy: 0.9014 - val_loss: 0.4964 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01873: val_loss did not improve from 0.41762\n",
      "Epoch 1874/3000\n",
      "13/13 - 0s - loss: 0.2091 - accuracy: 0.9014 - val_loss: 0.5101 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01874: val_loss did not improve from 0.41762\n",
      "Epoch 1875/3000\n",
      "13/13 - 0s - loss: 0.2097 - accuracy: 0.9014 - val_loss: 0.5112 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01875: val_loss did not improve from 0.41762\n",
      "Epoch 1876/3000\n",
      "13/13 - 0s - loss: 0.2316 - accuracy: 0.8975 - val_loss: 0.4937 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01876: val_loss did not improve from 0.41762\n",
      "Epoch 1877/3000\n",
      "13/13 - 0s - loss: 0.2112 - accuracy: 0.8859 - val_loss: 0.4766 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01877: val_loss did not improve from 0.41762\n",
      "Epoch 1878/3000\n",
      "13/13 - 0s - loss: 0.2088 - accuracy: 0.8975 - val_loss: 0.5002 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01878: val_loss did not improve from 0.41762\n",
      "Epoch 1879/3000\n",
      "13/13 - 0s - loss: 0.2191 - accuracy: 0.8859 - val_loss: 0.4988 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01879: val_loss did not improve from 0.41762\n",
      "Epoch 1880/3000\n",
      "13/13 - 0s - loss: 0.2187 - accuracy: 0.8975 - val_loss: 0.4881 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01880: val_loss did not improve from 0.41762\n",
      "Epoch 1881/3000\n",
      "13/13 - 0s - loss: 0.2111 - accuracy: 0.9014 - val_loss: 0.5077 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01881: val_loss did not improve from 0.41762\n",
      "Epoch 1882/3000\n",
      "13/13 - 0s - loss: 0.2260 - accuracy: 0.8846 - val_loss: 0.5146 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01882: val_loss did not improve from 0.41762\n",
      "Epoch 1883/3000\n",
      "13/13 - 0s - loss: 0.2127 - accuracy: 0.8949 - val_loss: 0.4963 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01883: val_loss did not improve from 0.41762\n",
      "Epoch 1884/3000\n",
      "13/13 - 0s - loss: 0.2183 - accuracy: 0.8820 - val_loss: 0.4991 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01884: val_loss did not improve from 0.41762\n",
      "Epoch 1885/3000\n",
      "13/13 - 0s - loss: 0.2154 - accuracy: 0.8975 - val_loss: 0.4999 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01885: val_loss did not improve from 0.41762\n",
      "Epoch 1886/3000\n",
      "13/13 - 0s - loss: 0.2208 - accuracy: 0.8975 - val_loss: 0.5194 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01886: val_loss did not improve from 0.41762\n",
      "Epoch 1887/3000\n",
      "13/13 - 0s - loss: 0.2147 - accuracy: 0.9001 - val_loss: 0.4767 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01887: val_loss did not improve from 0.41762\n",
      "Epoch 1888/3000\n",
      "13/13 - 0s - loss: 0.2149 - accuracy: 0.8949 - val_loss: 0.5016 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01888: val_loss did not improve from 0.41762\n",
      "Epoch 1889/3000\n",
      "13/13 - 0s - loss: 0.2158 - accuracy: 0.9001 - val_loss: 0.4921 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01889: val_loss did not improve from 0.41762\n",
      "Epoch 1890/3000\n",
      "13/13 - 0s - loss: 0.2106 - accuracy: 0.8975 - val_loss: 0.4960 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01890: val_loss did not improve from 0.41762\n",
      "Epoch 1891/3000\n",
      "13/13 - 0s - loss: 0.2108 - accuracy: 0.8923 - val_loss: 0.4935 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01891: val_loss did not improve from 0.41762\n",
      "Epoch 1892/3000\n",
      "13/13 - 0s - loss: 0.2098 - accuracy: 0.8962 - val_loss: 0.5030 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01892: val_loss did not improve from 0.41762\n",
      "Epoch 1893/3000\n",
      "13/13 - 0s - loss: 0.2156 - accuracy: 0.8911 - val_loss: 0.5108 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01893: val_loss did not improve from 0.41762\n",
      "Epoch 1894/3000\n",
      "13/13 - 0s - loss: 0.2145 - accuracy: 0.9040 - val_loss: 0.5602 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01894: val_loss did not improve from 0.41762\n",
      "Epoch 1895/3000\n",
      "13/13 - 0s - loss: 0.2688 - accuracy: 0.8833 - val_loss: 0.5387 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01895: val_loss did not improve from 0.41762\n",
      "Epoch 1896/3000\n",
      "13/13 - 0s - loss: 0.2501 - accuracy: 0.8962 - val_loss: 0.5290 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01896: val_loss did not improve from 0.41762\n",
      "Epoch 1897/3000\n",
      "13/13 - 0s - loss: 0.2345 - accuracy: 0.8975 - val_loss: 0.4927 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01897: val_loss did not improve from 0.41762\n",
      "Epoch 1898/3000\n",
      "13/13 - 0s - loss: 0.2256 - accuracy: 0.8962 - val_loss: 0.4842 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01898: val_loss did not improve from 0.41762\n",
      "Epoch 1899/3000\n",
      "13/13 - 0s - loss: 0.2198 - accuracy: 0.8949 - val_loss: 0.5007 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01899: val_loss did not improve from 0.41762\n",
      "Epoch 1900/3000\n",
      "13/13 - 0s - loss: 0.2134 - accuracy: 0.8975 - val_loss: 0.4986 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01900: val_loss did not improve from 0.41762\n",
      "Epoch 1901/3000\n",
      "13/13 - 0s - loss: 0.2111 - accuracy: 0.8975 - val_loss: 0.5008 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01901: val_loss did not improve from 0.41762\n",
      "Epoch 1902/3000\n",
      "13/13 - 0s - loss: 0.2139 - accuracy: 0.8988 - val_loss: 0.4963 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01902: val_loss did not improve from 0.41762\n",
      "Epoch 1903/3000\n",
      "13/13 - 0s - loss: 0.2128 - accuracy: 0.8962 - val_loss: 0.5048 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01903: val_loss did not improve from 0.41762\n",
      "Epoch 1904/3000\n",
      "13/13 - 0s - loss: 0.2100 - accuracy: 0.9001 - val_loss: 0.4994 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01904: val_loss did not improve from 0.41762\n",
      "Epoch 1905/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.9040 - val_loss: 0.5121 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01905: val_loss did not improve from 0.41762\n",
      "Epoch 1906/3000\n",
      "13/13 - 0s - loss: 0.2149 - accuracy: 0.8975 - val_loss: 0.5424 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01906: val_loss did not improve from 0.41762\n",
      "Epoch 1907/3000\n",
      "13/13 - 0s - loss: 0.2146 - accuracy: 0.8936 - val_loss: 0.5045 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01907: val_loss did not improve from 0.41762\n",
      "Epoch 1908/3000\n",
      "13/13 - 0s - loss: 0.2291 - accuracy: 0.8975 - val_loss: 0.4673 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 01908: val_loss did not improve from 0.41762\n",
      "Epoch 1909/3000\n",
      "13/13 - 0s - loss: 0.2193 - accuracy: 0.8975 - val_loss: 0.5010 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01909: val_loss did not improve from 0.41762\n",
      "Epoch 1910/3000\n",
      "13/13 - 0s - loss: 0.2263 - accuracy: 0.8975 - val_loss: 0.4983 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01910: val_loss did not improve from 0.41762\n",
      "Epoch 1911/3000\n",
      "13/13 - 0s - loss: 0.2250 - accuracy: 0.8962 - val_loss: 0.5132 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01911: val_loss did not improve from 0.41762\n",
      "Epoch 1912/3000\n",
      "13/13 - 0s - loss: 0.2179 - accuracy: 0.9014 - val_loss: 0.5044 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01912: val_loss did not improve from 0.41762\n",
      "Epoch 1913/3000\n",
      "13/13 - 0s - loss: 0.2113 - accuracy: 0.8988 - val_loss: 0.5176 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01913: val_loss did not improve from 0.41762\n",
      "Epoch 1914/3000\n",
      "13/13 - 0s - loss: 0.2182 - accuracy: 0.8988 - val_loss: 0.5612 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01914: val_loss did not improve from 0.41762\n",
      "Epoch 1915/3000\n",
      "13/13 - 0s - loss: 0.2154 - accuracy: 0.8962 - val_loss: 0.5279 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01915: val_loss did not improve from 0.41762\n",
      "Epoch 1916/3000\n",
      "13/13 - 0s - loss: 0.2119 - accuracy: 0.8936 - val_loss: 0.5187 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01916: val_loss did not improve from 0.41762\n",
      "Epoch 1917/3000\n",
      "13/13 - 0s - loss: 0.2170 - accuracy: 0.8988 - val_loss: 0.5220 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01917: val_loss did not improve from 0.41762\n",
      "Epoch 1918/3000\n",
      "13/13 - 0s - loss: 0.2110 - accuracy: 0.8988 - val_loss: 0.5448 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01918: val_loss did not improve from 0.41762\n",
      "Epoch 1919/3000\n",
      "13/13 - 0s - loss: 0.2169 - accuracy: 0.9014 - val_loss: 0.5253 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01919: val_loss did not improve from 0.41762\n",
      "Epoch 1920/3000\n",
      "13/13 - 0s - loss: 0.2123 - accuracy: 0.9027 - val_loss: 0.5077 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01920: val_loss did not improve from 0.41762\n",
      "Epoch 1921/3000\n",
      "13/13 - 0s - loss: 0.2127 - accuracy: 0.9040 - val_loss: 0.4955 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01921: val_loss did not improve from 0.41762\n",
      "Epoch 1922/3000\n",
      "13/13 - 0s - loss: 0.2111 - accuracy: 0.8975 - val_loss: 0.4970 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01922: val_loss did not improve from 0.41762\n",
      "Epoch 1923/3000\n",
      "13/13 - 0s - loss: 0.2117 - accuracy: 0.9014 - val_loss: 0.5040 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01923: val_loss did not improve from 0.41762\n",
      "Epoch 1924/3000\n",
      "13/13 - 0s - loss: 0.2086 - accuracy: 0.8975 - val_loss: 0.5046 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01924: val_loss did not improve from 0.41762\n",
      "Epoch 1925/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.9001 - val_loss: 0.4963 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01925: val_loss did not improve from 0.41762\n",
      "Epoch 1926/3000\n",
      "13/13 - 0s - loss: 0.2163 - accuracy: 0.8988 - val_loss: 0.5229 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 01926: val_loss did not improve from 0.41762\n",
      "Epoch 1927/3000\n",
      "13/13 - 0s - loss: 0.2195 - accuracy: 0.9014 - val_loss: 0.5107 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01927: val_loss did not improve from 0.41762\n",
      "Epoch 1928/3000\n",
      "13/13 - 0s - loss: 0.2317 - accuracy: 0.8923 - val_loss: 0.5346 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 01928: val_loss did not improve from 0.41762\n",
      "Epoch 1929/3000\n",
      "13/13 - 0s - loss: 0.2208 - accuracy: 0.8962 - val_loss: 0.5056 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01929: val_loss did not improve from 0.41762\n",
      "Epoch 1930/3000\n",
      "13/13 - 0s - loss: 0.2219 - accuracy: 0.8975 - val_loss: 0.4898 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01930: val_loss did not improve from 0.41762\n",
      "Epoch 1931/3000\n",
      "13/13 - 0s - loss: 0.2182 - accuracy: 0.9014 - val_loss: 0.4819 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01931: val_loss did not improve from 0.41762\n",
      "Epoch 1932/3000\n",
      "13/13 - 0s - loss: 0.2103 - accuracy: 0.8975 - val_loss: 0.4762 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01932: val_loss did not improve from 0.41762\n",
      "Epoch 1933/3000\n",
      "13/13 - 0s - loss: 0.2120 - accuracy: 0.9027 - val_loss: 0.4801 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01933: val_loss did not improve from 0.41762\n",
      "Epoch 1934/3000\n",
      "13/13 - 0s - loss: 0.2120 - accuracy: 0.8962 - val_loss: 0.4923 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01934: val_loss did not improve from 0.41762\n",
      "Epoch 1935/3000\n",
      "13/13 - 0s - loss: 0.2110 - accuracy: 0.8949 - val_loss: 0.4859 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01935: val_loss did not improve from 0.41762\n",
      "Epoch 1936/3000\n",
      "13/13 - 0s - loss: 0.2069 - accuracy: 0.9027 - val_loss: 0.5013 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01936: val_loss did not improve from 0.41762\n",
      "Epoch 1937/3000\n",
      "13/13 - 0s - loss: 0.2138 - accuracy: 0.8975 - val_loss: 0.4958 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01937: val_loss did not improve from 0.41762\n",
      "Epoch 1938/3000\n",
      "13/13 - 0s - loss: 0.2103 - accuracy: 0.9001 - val_loss: 0.4912 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01938: val_loss did not improve from 0.41762\n",
      "Epoch 1939/3000\n",
      "13/13 - 0s - loss: 0.2085 - accuracy: 0.8975 - val_loss: 0.5005 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01939: val_loss did not improve from 0.41762\n",
      "Epoch 1940/3000\n",
      "13/13 - 0s - loss: 0.2078 - accuracy: 0.8975 - val_loss: 0.5005 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01940: val_loss did not improve from 0.41762\n",
      "Epoch 1941/3000\n",
      "13/13 - 0s - loss: 0.2183 - accuracy: 0.8988 - val_loss: 0.5194 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01941: val_loss did not improve from 0.41762\n",
      "Epoch 1942/3000\n",
      "13/13 - 0s - loss: 0.2201 - accuracy: 0.9014 - val_loss: 0.4919 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01942: val_loss did not improve from 0.41762\n",
      "Epoch 1943/3000\n",
      "13/13 - 0s - loss: 0.2167 - accuracy: 0.8988 - val_loss: 0.5039 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01943: val_loss did not improve from 0.41762\n",
      "Epoch 1944/3000\n",
      "13/13 - 0s - loss: 0.2270 - accuracy: 0.8949 - val_loss: 0.5065 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01944: val_loss did not improve from 0.41762\n",
      "Epoch 1945/3000\n",
      "13/13 - 0s - loss: 0.2217 - accuracy: 0.8936 - val_loss: 0.5016 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01945: val_loss did not improve from 0.41762\n",
      "Epoch 1946/3000\n",
      "13/13 - 0s - loss: 0.2189 - accuracy: 0.8911 - val_loss: 0.5216 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01946: val_loss did not improve from 0.41762\n",
      "Epoch 1947/3000\n",
      "13/13 - 0s - loss: 0.2164 - accuracy: 0.8949 - val_loss: 0.5098 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01947: val_loss did not improve from 0.41762\n",
      "Epoch 1948/3000\n",
      "13/13 - 0s - loss: 0.2099 - accuracy: 0.8962 - val_loss: 0.5072 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01948: val_loss did not improve from 0.41762\n",
      "Epoch 1949/3000\n",
      "13/13 - 0s - loss: 0.2098 - accuracy: 0.9027 - val_loss: 0.5108 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01949: val_loss did not improve from 0.41762\n",
      "Epoch 1950/3000\n",
      "13/13 - 0s - loss: 0.2091 - accuracy: 0.9014 - val_loss: 0.5058 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01950: val_loss did not improve from 0.41762\n",
      "Epoch 1951/3000\n",
      "13/13 - 0s - loss: 0.2076 - accuracy: 0.9027 - val_loss: 0.5052 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01951: val_loss did not improve from 0.41762\n",
      "Epoch 1952/3000\n",
      "13/13 - 0s - loss: 0.2083 - accuracy: 0.8988 - val_loss: 0.5030 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01952: val_loss did not improve from 0.41762\n",
      "Epoch 1953/3000\n",
      "13/13 - 0s - loss: 0.2083 - accuracy: 0.9001 - val_loss: 0.5095 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01953: val_loss did not improve from 0.41762\n",
      "Epoch 1954/3000\n",
      "13/13 - 0s - loss: 0.2087 - accuracy: 0.8975 - val_loss: 0.5013 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01954: val_loss did not improve from 0.41762\n",
      "Epoch 1955/3000\n",
      "13/13 - 0s - loss: 0.2259 - accuracy: 0.8820 - val_loss: 0.5092 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01955: val_loss did not improve from 0.41762\n",
      "Epoch 1956/3000\n",
      "13/13 - 0s - loss: 0.2144 - accuracy: 0.8923 - val_loss: 0.5065 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01956: val_loss did not improve from 0.41762\n",
      "Epoch 1957/3000\n",
      "13/13 - 0s - loss: 0.2112 - accuracy: 0.8988 - val_loss: 0.5126 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01957: val_loss did not improve from 0.41762\n",
      "Epoch 1958/3000\n",
      "13/13 - 0s - loss: 0.2209 - accuracy: 0.8962 - val_loss: 0.5297 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 01958: val_loss did not improve from 0.41762\n",
      "Epoch 1959/3000\n",
      "13/13 - 0s - loss: 0.2218 - accuracy: 0.8988 - val_loss: 0.5228 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01959: val_loss did not improve from 0.41762\n",
      "Epoch 1960/3000\n",
      "13/13 - 0s - loss: 0.2166 - accuracy: 0.8962 - val_loss: 0.5009 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01960: val_loss did not improve from 0.41762\n",
      "Epoch 1961/3000\n",
      "13/13 - 0s - loss: 0.2126 - accuracy: 0.8988 - val_loss: 0.4877 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01961: val_loss did not improve from 0.41762\n",
      "Epoch 1962/3000\n",
      "13/13 - 0s - loss: 0.2229 - accuracy: 0.8936 - val_loss: 0.4967 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01962: val_loss did not improve from 0.41762\n",
      "Epoch 1963/3000\n",
      "13/13 - 0s - loss: 0.2175 - accuracy: 0.8859 - val_loss: 0.5036 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01963: val_loss did not improve from 0.41762\n",
      "Epoch 1964/3000\n",
      "13/13 - 0s - loss: 0.2125 - accuracy: 0.8949 - val_loss: 0.5126 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01964: val_loss did not improve from 0.41762\n",
      "Epoch 1965/3000\n",
      "13/13 - 0s - loss: 0.2101 - accuracy: 0.9014 - val_loss: 0.5152 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01965: val_loss did not improve from 0.41762\n",
      "Epoch 1966/3000\n",
      "13/13 - 0s - loss: 0.2112 - accuracy: 0.8988 - val_loss: 0.5182 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01966: val_loss did not improve from 0.41762\n",
      "Epoch 1967/3000\n",
      "13/13 - 0s - loss: 0.2099 - accuracy: 0.8988 - val_loss: 0.5040 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01967: val_loss did not improve from 0.41762\n",
      "Epoch 1968/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.9001 - val_loss: 0.5068 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01968: val_loss did not improve from 0.41762\n",
      "Epoch 1969/3000\n",
      "13/13 - 0s - loss: 0.2086 - accuracy: 0.9014 - val_loss: 0.5085 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01969: val_loss did not improve from 0.41762\n",
      "Epoch 1970/3000\n",
      "13/13 - 0s - loss: 0.2098 - accuracy: 0.8962 - val_loss: 0.5056 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01970: val_loss did not improve from 0.41762\n",
      "Epoch 1971/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.9014 - val_loss: 0.5029 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01971: val_loss did not improve from 0.41762\n",
      "Epoch 1972/3000\n",
      "13/13 - 0s - loss: 0.2085 - accuracy: 0.9014 - val_loss: 0.5069 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01972: val_loss did not improve from 0.41762\n",
      "Epoch 1973/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.9014 - val_loss: 0.4928 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01973: val_loss did not improve from 0.41762\n",
      "Epoch 1974/3000\n",
      "13/13 - 0s - loss: 0.2297 - accuracy: 0.8898 - val_loss: 0.4800 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 01974: val_loss did not improve from 0.41762\n",
      "Epoch 1975/3000\n",
      "13/13 - 0s - loss: 0.2197 - accuracy: 0.8949 - val_loss: 0.5230 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01975: val_loss did not improve from 0.41762\n",
      "Epoch 1976/3000\n",
      "13/13 - 0s - loss: 0.2110 - accuracy: 0.8962 - val_loss: 0.5213 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01976: val_loss did not improve from 0.41762\n",
      "Epoch 1977/3000\n",
      "13/13 - 0s - loss: 0.2228 - accuracy: 0.8898 - val_loss: 0.5742 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01977: val_loss did not improve from 0.41762\n",
      "Epoch 1978/3000\n",
      "13/13 - 0s - loss: 0.2152 - accuracy: 0.9027 - val_loss: 0.5428 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01978: val_loss did not improve from 0.41762\n",
      "Epoch 1979/3000\n",
      "13/13 - 0s - loss: 0.2170 - accuracy: 0.8975 - val_loss: 0.5361 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01979: val_loss did not improve from 0.41762\n",
      "Epoch 1980/3000\n",
      "13/13 - 0s - loss: 0.2160 - accuracy: 0.9001 - val_loss: 0.5052 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01980: val_loss did not improve from 0.41762\n",
      "Epoch 1981/3000\n",
      "13/13 - 0s - loss: 0.2102 - accuracy: 0.8936 - val_loss: 0.5136 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01981: val_loss did not improve from 0.41762\n",
      "Epoch 1982/3000\n",
      "13/13 - 0s - loss: 0.2069 - accuracy: 0.8975 - val_loss: 0.5103 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01982: val_loss did not improve from 0.41762\n",
      "Epoch 1983/3000\n",
      "13/13 - 0s - loss: 0.2065 - accuracy: 0.9014 - val_loss: 0.5188 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01983: val_loss did not improve from 0.41762\n",
      "Epoch 1984/3000\n",
      "13/13 - 0s - loss: 0.2116 - accuracy: 0.9001 - val_loss: 0.5370 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01984: val_loss did not improve from 0.41762\n",
      "Epoch 1985/3000\n",
      "13/13 - 0s - loss: 0.2141 - accuracy: 0.8975 - val_loss: 0.5223 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01985: val_loss did not improve from 0.41762\n",
      "Epoch 1986/3000\n",
      "13/13 - 0s - loss: 0.2104 - accuracy: 0.8975 - val_loss: 0.5171 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01986: val_loss did not improve from 0.41762\n",
      "Epoch 1987/3000\n",
      "13/13 - 0s - loss: 0.2048 - accuracy: 0.9001 - val_loss: 0.5058 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01987: val_loss did not improve from 0.41762\n",
      "Epoch 1988/3000\n",
      "13/13 - 0s - loss: 0.2086 - accuracy: 0.9014 - val_loss: 0.5141 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01988: val_loss did not improve from 0.41762\n",
      "Epoch 1989/3000\n",
      "13/13 - 0s - loss: 0.2233 - accuracy: 0.8898 - val_loss: 0.5503 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 01989: val_loss did not improve from 0.41762\n",
      "Epoch 1990/3000\n",
      "13/13 - 0s - loss: 0.2221 - accuracy: 0.8988 - val_loss: 0.5676 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 01990: val_loss did not improve from 0.41762\n",
      "Epoch 1991/3000\n",
      "13/13 - 0s - loss: 0.2158 - accuracy: 0.8923 - val_loss: 0.5327 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01991: val_loss did not improve from 0.41762\n",
      "Epoch 1992/3000\n",
      "13/13 - 0s - loss: 0.2156 - accuracy: 0.8988 - val_loss: 0.5464 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01992: val_loss did not improve from 0.41762\n",
      "Epoch 1993/3000\n",
      "13/13 - 0s - loss: 0.2120 - accuracy: 0.9027 - val_loss: 0.5381 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01993: val_loss did not improve from 0.41762\n",
      "Epoch 1994/3000\n",
      "13/13 - 0s - loss: 0.2215 - accuracy: 0.8923 - val_loss: 0.5068 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 01994: val_loss did not improve from 0.41762\n",
      "Epoch 1995/3000\n",
      "13/13 - 0s - loss: 0.2267 - accuracy: 0.8923 - val_loss: 0.5211 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01995: val_loss did not improve from 0.41762\n",
      "Epoch 1996/3000\n",
      "13/13 - 0s - loss: 0.2145 - accuracy: 0.9040 - val_loss: 0.5260 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01996: val_loss did not improve from 0.41762\n",
      "Epoch 1997/3000\n",
      "13/13 - 0s - loss: 0.2122 - accuracy: 0.9027 - val_loss: 0.5197 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 01997: val_loss did not improve from 0.41762\n",
      "Epoch 1998/3000\n",
      "13/13 - 0s - loss: 0.2110 - accuracy: 0.9014 - val_loss: 0.5175 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01998: val_loss did not improve from 0.41762\n",
      "Epoch 1999/3000\n",
      "13/13 - 0s - loss: 0.2096 - accuracy: 0.9027 - val_loss: 0.5162 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 01999: val_loss did not improve from 0.41762\n",
      "Epoch 2000/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.8962 - val_loss: 0.5304 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02000: val_loss did not improve from 0.41762\n",
      "Epoch 2001/3000\n",
      "13/13 - 0s - loss: 0.2266 - accuracy: 0.8885 - val_loss: 0.5485 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02001: val_loss did not improve from 0.41762\n",
      "Epoch 2002/3000\n",
      "13/13 - 0s - loss: 0.2134 - accuracy: 0.9040 - val_loss: 0.5193 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02002: val_loss did not improve from 0.41762\n",
      "Epoch 2003/3000\n",
      "13/13 - 0s - loss: 0.2105 - accuracy: 0.8988 - val_loss: 0.5195 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02003: val_loss did not improve from 0.41762\n",
      "Epoch 2004/3000\n",
      "13/13 - 0s - loss: 0.2097 - accuracy: 0.8988 - val_loss: 0.5227 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02004: val_loss did not improve from 0.41762\n",
      "Epoch 2005/3000\n",
      "13/13 - 0s - loss: 0.2269 - accuracy: 0.8975 - val_loss: 0.5340 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02005: val_loss did not improve from 0.41762\n",
      "Epoch 2006/3000\n",
      "13/13 - 0s - loss: 0.2235 - accuracy: 0.8923 - val_loss: 0.5397 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02006: val_loss did not improve from 0.41762\n",
      "Epoch 2007/3000\n",
      "13/13 - 0s - loss: 0.2114 - accuracy: 0.8988 - val_loss: 0.5336 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02007: val_loss did not improve from 0.41762\n",
      "Epoch 2008/3000\n",
      "13/13 - 0s - loss: 0.2089 - accuracy: 0.9001 - val_loss: 0.5245 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02008: val_loss did not improve from 0.41762\n",
      "Epoch 2009/3000\n",
      "13/13 - 0s - loss: 0.2097 - accuracy: 0.9014 - val_loss: 0.5287 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02009: val_loss did not improve from 0.41762\n",
      "Epoch 2010/3000\n",
      "13/13 - 0s - loss: 0.2101 - accuracy: 0.9014 - val_loss: 0.5344 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02010: val_loss did not improve from 0.41762\n",
      "Epoch 2011/3000\n",
      "13/13 - 0s - loss: 0.2131 - accuracy: 0.9001 - val_loss: 0.5508 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02011: val_loss did not improve from 0.41762\n",
      "Epoch 2012/3000\n",
      "13/13 - 0s - loss: 0.2111 - accuracy: 0.8988 - val_loss: 0.5311 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02012: val_loss did not improve from 0.41762\n",
      "Epoch 2013/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.8988 - val_loss: 0.5439 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02013: val_loss did not improve from 0.41762\n",
      "Epoch 2014/3000\n",
      "13/13 - 0s - loss: 0.2077 - accuracy: 0.8962 - val_loss: 0.5382 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02014: val_loss did not improve from 0.41762\n",
      "Epoch 2015/3000\n",
      "13/13 - 0s - loss: 0.2241 - accuracy: 0.8988 - val_loss: 0.5663 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 02015: val_loss did not improve from 0.41762\n",
      "Epoch 2016/3000\n",
      "13/13 - 0s - loss: 0.2531 - accuracy: 0.8911 - val_loss: 0.5347 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02016: val_loss did not improve from 0.41762\n",
      "Epoch 2017/3000\n",
      "13/13 - 0s - loss: 0.2224 - accuracy: 0.8923 - val_loss: 0.5173 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02017: val_loss did not improve from 0.41762\n",
      "Epoch 2018/3000\n",
      "13/13 - 0s - loss: 0.2160 - accuracy: 0.8988 - val_loss: 0.5173 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02018: val_loss did not improve from 0.41762\n",
      "Epoch 2019/3000\n",
      "13/13 - 0s - loss: 0.2104 - accuracy: 0.8962 - val_loss: 0.5084 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02019: val_loss did not improve from 0.41762\n",
      "Epoch 2020/3000\n",
      "13/13 - 0s - loss: 0.2110 - accuracy: 0.8975 - val_loss: 0.4990 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02020: val_loss did not improve from 0.41762\n",
      "Epoch 2021/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.8975 - val_loss: 0.5108 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02021: val_loss did not improve from 0.41762\n",
      "Epoch 2022/3000\n",
      "13/13 - 0s - loss: 0.2101 - accuracy: 0.8988 - val_loss: 0.5161 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02022: val_loss did not improve from 0.41762\n",
      "Epoch 2023/3000\n",
      "13/13 - 0s - loss: 0.2163 - accuracy: 0.9001 - val_loss: 0.5270 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02023: val_loss did not improve from 0.41762\n",
      "Epoch 2024/3000\n",
      "13/13 - 0s - loss: 0.2130 - accuracy: 0.8846 - val_loss: 0.5066 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02024: val_loss did not improve from 0.41762\n",
      "Epoch 2025/3000\n",
      "13/13 - 0s - loss: 0.2088 - accuracy: 0.8962 - val_loss: 0.5080 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02025: val_loss did not improve from 0.41762\n",
      "Epoch 2026/3000\n",
      "13/13 - 0s - loss: 0.2242 - accuracy: 0.9027 - val_loss: 0.5255 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02026: val_loss did not improve from 0.41762\n",
      "Epoch 2027/3000\n",
      "13/13 - 0s - loss: 0.2170 - accuracy: 0.8988 - val_loss: 0.5206 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02027: val_loss did not improve from 0.41762\n",
      "Epoch 2028/3000\n",
      "13/13 - 0s - loss: 0.2136 - accuracy: 0.9014 - val_loss: 0.5235 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02028: val_loss did not improve from 0.41762\n",
      "Epoch 2029/3000\n",
      "13/13 - 0s - loss: 0.2238 - accuracy: 0.9001 - val_loss: 0.5206 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02029: val_loss did not improve from 0.41762\n",
      "Epoch 2030/3000\n",
      "13/13 - 0s - loss: 0.2189 - accuracy: 0.9027 - val_loss: 0.5048 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02030: val_loss did not improve from 0.41762\n",
      "Epoch 2031/3000\n",
      "13/13 - 0s - loss: 0.2243 - accuracy: 0.9014 - val_loss: 0.5179 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02031: val_loss did not improve from 0.41762\n",
      "Epoch 2032/3000\n",
      "13/13 - 0s - loss: 0.2169 - accuracy: 0.8962 - val_loss: 0.5180 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02032: val_loss did not improve from 0.41762\n",
      "Epoch 2033/3000\n",
      "13/13 - 0s - loss: 0.2076 - accuracy: 0.9001 - val_loss: 0.5355 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02033: val_loss did not improve from 0.41762\n",
      "Epoch 2034/3000\n",
      "13/13 - 0s - loss: 0.2101 - accuracy: 0.9001 - val_loss: 0.5391 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02034: val_loss did not improve from 0.41762\n",
      "Epoch 2035/3000\n",
      "13/13 - 0s - loss: 0.2066 - accuracy: 0.8949 - val_loss: 0.5382 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02035: val_loss did not improve from 0.41762\n",
      "Epoch 2036/3000\n",
      "13/13 - 0s - loss: 0.2149 - accuracy: 0.9001 - val_loss: 0.5278 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02036: val_loss did not improve from 0.41762\n",
      "Epoch 2037/3000\n",
      "13/13 - 0s - loss: 0.2566 - accuracy: 0.8768 - val_loss: 0.5010 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02037: val_loss did not improve from 0.41762\n",
      "Epoch 2038/3000\n",
      "13/13 - 0s - loss: 0.2233 - accuracy: 0.8898 - val_loss: 0.5320 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02038: val_loss did not improve from 0.41762\n",
      "Epoch 2039/3000\n",
      "13/13 - 0s - loss: 0.2113 - accuracy: 0.8975 - val_loss: 0.5241 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02039: val_loss did not improve from 0.41762\n",
      "Epoch 2040/3000\n",
      "13/13 - 0s - loss: 0.2133 - accuracy: 0.8988 - val_loss: 0.5261 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02040: val_loss did not improve from 0.41762\n",
      "Epoch 2041/3000\n",
      "13/13 - 0s - loss: 0.2101 - accuracy: 0.8988 - val_loss: 0.5246 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02041: val_loss did not improve from 0.41762\n",
      "Epoch 2042/3000\n",
      "13/13 - 0s - loss: 0.2189 - accuracy: 0.8962 - val_loss: 0.5153 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02042: val_loss did not improve from 0.41762\n",
      "Epoch 2043/3000\n",
      "13/13 - 0s - loss: 0.2227 - accuracy: 0.8846 - val_loss: 0.5320 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02043: val_loss did not improve from 0.41762\n",
      "Epoch 2044/3000\n",
      "13/13 - 0s - loss: 0.2161 - accuracy: 0.8962 - val_loss: 0.5361 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02044: val_loss did not improve from 0.41762\n",
      "Epoch 2045/3000\n",
      "13/13 - 0s - loss: 0.2101 - accuracy: 0.9001 - val_loss: 0.5268 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02045: val_loss did not improve from 0.41762\n",
      "Epoch 2046/3000\n",
      "13/13 - 0s - loss: 0.2094 - accuracy: 0.8923 - val_loss: 0.5345 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02046: val_loss did not improve from 0.41762\n",
      "Epoch 2047/3000\n",
      "13/13 - 0s - loss: 0.2245 - accuracy: 0.8962 - val_loss: 0.5589 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02047: val_loss did not improve from 0.41762\n",
      "Epoch 2048/3000\n",
      "13/13 - 0s - loss: 0.2449 - accuracy: 0.8820 - val_loss: 0.5309 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02048: val_loss did not improve from 0.41762\n",
      "Epoch 2049/3000\n",
      "13/13 - 0s - loss: 0.2156 - accuracy: 0.8988 - val_loss: 0.5181 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02049: val_loss did not improve from 0.41762\n",
      "Epoch 2050/3000\n",
      "13/13 - 0s - loss: 0.2276 - accuracy: 0.8859 - val_loss: 0.4996 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02050: val_loss did not improve from 0.41762\n",
      "Epoch 2051/3000\n",
      "13/13 - 0s - loss: 0.2131 - accuracy: 0.8975 - val_loss: 0.5133 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02051: val_loss did not improve from 0.41762\n",
      "Epoch 2052/3000\n",
      "13/13 - 0s - loss: 0.2211 - accuracy: 0.8962 - val_loss: 0.5053 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02052: val_loss did not improve from 0.41762\n",
      "Epoch 2053/3000\n",
      "13/13 - 0s - loss: 0.2179 - accuracy: 0.8936 - val_loss: 0.5041 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02053: val_loss did not improve from 0.41762\n",
      "Epoch 2054/3000\n",
      "13/13 - 0s - loss: 0.2194 - accuracy: 0.8975 - val_loss: 0.4908 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02054: val_loss did not improve from 0.41762\n",
      "Epoch 2055/3000\n",
      "13/13 - 0s - loss: 0.2172 - accuracy: 0.9014 - val_loss: 0.5237 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02055: val_loss did not improve from 0.41762\n",
      "Epoch 2056/3000\n",
      "13/13 - 0s - loss: 0.2351 - accuracy: 0.8949 - val_loss: 0.5396 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02056: val_loss did not improve from 0.41762\n",
      "Epoch 2057/3000\n",
      "13/13 - 0s - loss: 0.2181 - accuracy: 0.9027 - val_loss: 0.5073 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02057: val_loss did not improve from 0.41762\n",
      "Epoch 2058/3000\n",
      "13/13 - 0s - loss: 0.2288 - accuracy: 0.8962 - val_loss: 0.5988 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02058: val_loss did not improve from 0.41762\n",
      "Epoch 2059/3000\n",
      "13/13 - 0s - loss: 0.2316 - accuracy: 0.8949 - val_loss: 0.5230 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02059: val_loss did not improve from 0.41762\n",
      "Epoch 2060/3000\n",
      "13/13 - 0s - loss: 0.2162 - accuracy: 0.9001 - val_loss: 0.5329 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02060: val_loss did not improve from 0.41762\n",
      "Epoch 2061/3000\n",
      "13/13 - 0s - loss: 0.2237 - accuracy: 0.8975 - val_loss: 0.5486 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02061: val_loss did not improve from 0.41762\n",
      "Epoch 2062/3000\n",
      "13/13 - 0s - loss: 0.2271 - accuracy: 0.8911 - val_loss: 0.5174 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02062: val_loss did not improve from 0.41762\n",
      "Epoch 2063/3000\n",
      "13/13 - 0s - loss: 0.2119 - accuracy: 0.9014 - val_loss: 0.5339 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02063: val_loss did not improve from 0.41762\n",
      "Epoch 2064/3000\n",
      "13/13 - 0s - loss: 0.2103 - accuracy: 0.8988 - val_loss: 0.5319 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02064: val_loss did not improve from 0.41762\n",
      "Epoch 2065/3000\n",
      "13/13 - 0s - loss: 0.2216 - accuracy: 0.8988 - val_loss: 0.5464 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02065: val_loss did not improve from 0.41762\n",
      "Epoch 2066/3000\n",
      "13/13 - 0s - loss: 0.2300 - accuracy: 0.8962 - val_loss: 0.5309 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02066: val_loss did not improve from 0.41762\n",
      "Epoch 2067/3000\n",
      "13/13 - 0s - loss: 0.2239 - accuracy: 0.8988 - val_loss: 0.5491 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02067: val_loss did not improve from 0.41762\n",
      "Epoch 2068/3000\n",
      "13/13 - 0s - loss: 0.2115 - accuracy: 0.8962 - val_loss: 0.5316 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02068: val_loss did not improve from 0.41762\n",
      "Epoch 2069/3000\n",
      "13/13 - 0s - loss: 0.2126 - accuracy: 0.8936 - val_loss: 0.5412 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02069: val_loss did not improve from 0.41762\n",
      "Epoch 2070/3000\n",
      "13/13 - 0s - loss: 0.2093 - accuracy: 0.8962 - val_loss: 0.5361 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02070: val_loss did not improve from 0.41762\n",
      "Epoch 2071/3000\n",
      "13/13 - 0s - loss: 0.2131 - accuracy: 0.8962 - val_loss: 0.5209 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02071: val_loss did not improve from 0.41762\n",
      "Epoch 2072/3000\n",
      "13/13 - 0s - loss: 0.2284 - accuracy: 0.8885 - val_loss: 0.5394 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02072: val_loss did not improve from 0.41762\n",
      "Epoch 2073/3000\n",
      "13/13 - 0s - loss: 0.2183 - accuracy: 0.8975 - val_loss: 0.5412 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02073: val_loss did not improve from 0.41762\n",
      "Epoch 2074/3000\n",
      "13/13 - 0s - loss: 0.2169 - accuracy: 0.8911 - val_loss: 0.5472 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02074: val_loss did not improve from 0.41762\n",
      "Epoch 2075/3000\n",
      "13/13 - 0s - loss: 0.2137 - accuracy: 0.9001 - val_loss: 0.5413 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02075: val_loss did not improve from 0.41762\n",
      "Epoch 2076/3000\n",
      "13/13 - 0s - loss: 0.2111 - accuracy: 0.9001 - val_loss: 0.5380 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02076: val_loss did not improve from 0.41762\n",
      "Epoch 2077/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.8988 - val_loss: 0.5441 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02077: val_loss did not improve from 0.41762\n",
      "Epoch 2078/3000\n",
      "13/13 - 0s - loss: 0.2167 - accuracy: 0.8885 - val_loss: 0.5478 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02078: val_loss did not improve from 0.41762\n",
      "Epoch 2079/3000\n",
      "13/13 - 0s - loss: 0.2149 - accuracy: 0.8923 - val_loss: 0.5650 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02079: val_loss did not improve from 0.41762\n",
      "Epoch 2080/3000\n",
      "13/13 - 0s - loss: 0.2161 - accuracy: 0.8988 - val_loss: 0.5489 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02080: val_loss did not improve from 0.41762\n",
      "Epoch 2081/3000\n",
      "13/13 - 0s - loss: 0.2157 - accuracy: 0.8833 - val_loss: 0.5364 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02081: val_loss did not improve from 0.41762\n",
      "Epoch 2082/3000\n",
      "13/13 - 0s - loss: 0.2201 - accuracy: 0.8794 - val_loss: 0.5459 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02082: val_loss did not improve from 0.41762\n",
      "Epoch 2083/3000\n",
      "13/13 - 0s - loss: 0.2111 - accuracy: 0.8936 - val_loss: 0.5370 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02083: val_loss did not improve from 0.41762\n",
      "Epoch 2084/3000\n",
      "13/13 - 0s - loss: 0.2108 - accuracy: 0.9001 - val_loss: 0.5464 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02084: val_loss did not improve from 0.41762\n",
      "Epoch 2085/3000\n",
      "13/13 - 0s - loss: 0.2322 - accuracy: 0.8898 - val_loss: 0.5471 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02085: val_loss did not improve from 0.41762\n",
      "Epoch 2086/3000\n",
      "13/13 - 0s - loss: 0.2169 - accuracy: 0.8923 - val_loss: 0.5448 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02086: val_loss did not improve from 0.41762\n",
      "Epoch 2087/3000\n",
      "13/13 - 0s - loss: 0.2169 - accuracy: 0.8923 - val_loss: 0.5836 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02087: val_loss did not improve from 0.41762\n",
      "Epoch 2088/3000\n",
      "13/13 - 0s - loss: 0.2235 - accuracy: 0.8975 - val_loss: 0.5823 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02088: val_loss did not improve from 0.41762\n",
      "Epoch 2089/3000\n",
      "13/13 - 0s - loss: 0.2209 - accuracy: 0.8962 - val_loss: 0.5336 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02089: val_loss did not improve from 0.41762\n",
      "Epoch 2090/3000\n",
      "13/13 - 0s - loss: 0.2162 - accuracy: 0.8923 - val_loss: 0.5355 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02090: val_loss did not improve from 0.41762\n",
      "Epoch 2091/3000\n",
      "13/13 - 0s - loss: 0.2157 - accuracy: 0.9001 - val_loss: 0.5342 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02091: val_loss did not improve from 0.41762\n",
      "Epoch 2092/3000\n",
      "13/13 - 0s - loss: 0.2091 - accuracy: 0.8988 - val_loss: 0.5236 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02092: val_loss did not improve from 0.41762\n",
      "Epoch 2093/3000\n",
      "13/13 - 0s - loss: 0.2154 - accuracy: 0.9014 - val_loss: 0.5161 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02093: val_loss did not improve from 0.41762\n",
      "Epoch 2094/3000\n",
      "13/13 - 0s - loss: 0.2182 - accuracy: 0.9040 - val_loss: 0.5211 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02094: val_loss did not improve from 0.41762\n",
      "Epoch 2095/3000\n",
      "13/13 - 0s - loss: 0.2239 - accuracy: 0.8898 - val_loss: 0.5702 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02095: val_loss did not improve from 0.41762\n",
      "Epoch 2096/3000\n",
      "13/13 - 0s - loss: 0.2133 - accuracy: 0.8962 - val_loss: 0.5244 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02096: val_loss did not improve from 0.41762\n",
      "Epoch 2097/3000\n",
      "13/13 - 0s - loss: 0.2127 - accuracy: 0.9001 - val_loss: 0.5311 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02097: val_loss did not improve from 0.41762\n",
      "Epoch 2098/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.8988 - val_loss: 0.5290 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02098: val_loss did not improve from 0.41762\n",
      "Epoch 2099/3000\n",
      "13/13 - 0s - loss: 0.2134 - accuracy: 0.9014 - val_loss: 0.5543 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02099: val_loss did not improve from 0.41762\n",
      "Epoch 2100/3000\n",
      "13/13 - 0s - loss: 0.2323 - accuracy: 0.8923 - val_loss: 0.5332 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02100: val_loss did not improve from 0.41762\n",
      "Epoch 2101/3000\n",
      "13/13 - 0s - loss: 0.2305 - accuracy: 0.8833 - val_loss: 0.5132 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02101: val_loss did not improve from 0.41762\n",
      "Epoch 2102/3000\n",
      "13/13 - 0s - loss: 0.2111 - accuracy: 0.9040 - val_loss: 0.5362 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02102: val_loss did not improve from 0.41762\n",
      "Epoch 2103/3000\n",
      "13/13 - 0s - loss: 0.2387 - accuracy: 0.8807 - val_loss: 0.5303 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02103: val_loss did not improve from 0.41762\n",
      "Epoch 2104/3000\n",
      "13/13 - 0s - loss: 0.2209 - accuracy: 0.8949 - val_loss: 0.5330 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02104: val_loss did not improve from 0.41762\n",
      "Epoch 2105/3000\n",
      "13/13 - 0s - loss: 0.2184 - accuracy: 0.8988 - val_loss: 0.5395 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02105: val_loss did not improve from 0.41762\n",
      "Epoch 2106/3000\n",
      "13/13 - 0s - loss: 0.2100 - accuracy: 0.8988 - val_loss: 0.5212 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02106: val_loss did not improve from 0.41762\n",
      "Epoch 2107/3000\n",
      "13/13 - 0s - loss: 0.2127 - accuracy: 0.9027 - val_loss: 0.5178 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02107: val_loss did not improve from 0.41762\n",
      "Epoch 2108/3000\n",
      "13/13 - 0s - loss: 0.2199 - accuracy: 0.8975 - val_loss: 0.5197 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02108: val_loss did not improve from 0.41762\n",
      "Epoch 2109/3000\n",
      "13/13 - 0s - loss: 0.2109 - accuracy: 0.9053 - val_loss: 0.5165 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02109: val_loss did not improve from 0.41762\n",
      "Epoch 2110/3000\n",
      "13/13 - 0s - loss: 0.2098 - accuracy: 0.9014 - val_loss: 0.5222 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02110: val_loss did not improve from 0.41762\n",
      "Epoch 2111/3000\n",
      "13/13 - 0s - loss: 0.2110 - accuracy: 0.8975 - val_loss: 0.5191 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02111: val_loss did not improve from 0.41762\n",
      "Epoch 2112/3000\n",
      "13/13 - 0s - loss: 0.2106 - accuracy: 0.8988 - val_loss: 0.5279 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02112: val_loss did not improve from 0.41762\n",
      "Epoch 2113/3000\n",
      "13/13 - 0s - loss: 0.2073 - accuracy: 0.8962 - val_loss: 0.5277 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02113: val_loss did not improve from 0.41762\n",
      "Epoch 2114/3000\n",
      "13/13 - 0s - loss: 0.2113 - accuracy: 0.8975 - val_loss: 0.5308 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02114: val_loss did not improve from 0.41762\n",
      "Epoch 2115/3000\n",
      "13/13 - 0s - loss: 0.2209 - accuracy: 0.8962 - val_loss: 0.5288 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02115: val_loss did not improve from 0.41762\n",
      "Epoch 2116/3000\n",
      "13/13 - 0s - loss: 0.2130 - accuracy: 0.8923 - val_loss: 0.5163 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02116: val_loss did not improve from 0.41762\n",
      "Epoch 2117/3000\n",
      "13/13 - 0s - loss: 0.2093 - accuracy: 0.9001 - val_loss: 0.5294 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02117: val_loss did not improve from 0.41762\n",
      "Epoch 2118/3000\n",
      "13/13 - 0s - loss: 0.2096 - accuracy: 0.9014 - val_loss: 0.5265 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02118: val_loss did not improve from 0.41762\n",
      "Epoch 2119/3000\n",
      "13/13 - 0s - loss: 0.2103 - accuracy: 0.9027 - val_loss: 0.5274 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02119: val_loss did not improve from 0.41762\n",
      "Epoch 2120/3000\n",
      "13/13 - 0s - loss: 0.2104 - accuracy: 0.9001 - val_loss: 0.5307 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02120: val_loss did not improve from 0.41762\n",
      "Epoch 2121/3000\n",
      "13/13 - 0s - loss: 0.2153 - accuracy: 0.9014 - val_loss: 0.5533 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02121: val_loss did not improve from 0.41762\n",
      "Epoch 2122/3000\n",
      "13/13 - 0s - loss: 0.2264 - accuracy: 0.9014 - val_loss: 0.5579 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02122: val_loss did not improve from 0.41762\n",
      "Epoch 2123/3000\n",
      "13/13 - 0s - loss: 0.2237 - accuracy: 0.8949 - val_loss: 0.5502 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02123: val_loss did not improve from 0.41762\n",
      "Epoch 2124/3000\n",
      "13/13 - 0s - loss: 0.2198 - accuracy: 0.8936 - val_loss: 0.5298 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02124: val_loss did not improve from 0.41762\n",
      "Epoch 2125/3000\n",
      "13/13 - 0s - loss: 0.2093 - accuracy: 0.8988 - val_loss: 0.5269 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02125: val_loss did not improve from 0.41762\n",
      "Epoch 2126/3000\n",
      "13/13 - 0s - loss: 0.2067 - accuracy: 0.9001 - val_loss: 0.5250 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02126: val_loss did not improve from 0.41762\n",
      "Epoch 2127/3000\n",
      "13/13 - 0s - loss: 0.2060 - accuracy: 0.9027 - val_loss: 0.5240 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02127: val_loss did not improve from 0.41762\n",
      "Epoch 2128/3000\n",
      "13/13 - 0s - loss: 0.2153 - accuracy: 0.8962 - val_loss: 0.5221 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02128: val_loss did not improve from 0.41762\n",
      "Epoch 2129/3000\n",
      "13/13 - 0s - loss: 0.2131 - accuracy: 0.9001 - val_loss: 0.5314 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02129: val_loss did not improve from 0.41762\n",
      "Epoch 2130/3000\n",
      "13/13 - 0s - loss: 0.2091 - accuracy: 0.9014 - val_loss: 0.5193 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02130: val_loss did not improve from 0.41762\n",
      "Epoch 2131/3000\n",
      "13/13 - 0s - loss: 0.2099 - accuracy: 0.9014 - val_loss: 0.5252 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02131: val_loss did not improve from 0.41762\n",
      "Epoch 2132/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.9014 - val_loss: 0.5145 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02132: val_loss did not improve from 0.41762\n",
      "Epoch 2133/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.9014 - val_loss: 0.5143 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02133: val_loss did not improve from 0.41762\n",
      "Epoch 2134/3000\n",
      "13/13 - 0s - loss: 0.2078 - accuracy: 0.9001 - val_loss: 0.5229 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02134: val_loss did not improve from 0.41762\n",
      "Epoch 2135/3000\n",
      "13/13 - 0s - loss: 0.2124 - accuracy: 0.8962 - val_loss: 0.5215 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02135: val_loss did not improve from 0.41762\n",
      "Epoch 2136/3000\n",
      "13/13 - 0s - loss: 0.2101 - accuracy: 0.9027 - val_loss: 0.5349 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02136: val_loss did not improve from 0.41762\n",
      "Epoch 2137/3000\n",
      "13/13 - 0s - loss: 0.2132 - accuracy: 0.8975 - val_loss: 0.5218 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02137: val_loss did not improve from 0.41762\n",
      "Epoch 2138/3000\n",
      "13/13 - 0s - loss: 0.2160 - accuracy: 0.8923 - val_loss: 0.5262 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02138: val_loss did not improve from 0.41762\n",
      "Epoch 2139/3000\n",
      "13/13 - 0s - loss: 0.2130 - accuracy: 0.8988 - val_loss: 0.5190 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02139: val_loss did not improve from 0.41762\n",
      "Epoch 2140/3000\n",
      "13/13 - 0s - loss: 0.2119 - accuracy: 0.8988 - val_loss: 0.5112 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02140: val_loss did not improve from 0.41762\n",
      "Epoch 2141/3000\n",
      "13/13 - 0s - loss: 0.2091 - accuracy: 0.8988 - val_loss: 0.5275 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02141: val_loss did not improve from 0.41762\n",
      "Epoch 2142/3000\n",
      "13/13 - 0s - loss: 0.2065 - accuracy: 0.9001 - val_loss: 0.5035 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02142: val_loss did not improve from 0.41762\n",
      "Epoch 2143/3000\n",
      "13/13 - 0s - loss: 0.2093 - accuracy: 0.9001 - val_loss: 0.5303 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02143: val_loss did not improve from 0.41762\n",
      "Epoch 2144/3000\n",
      "13/13 - 0s - loss: 0.2124 - accuracy: 0.9027 - val_loss: 0.5137 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02144: val_loss did not improve from 0.41762\n",
      "Epoch 2145/3000\n",
      "13/13 - 0s - loss: 0.2121 - accuracy: 0.8975 - val_loss: 0.5027 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02145: val_loss did not improve from 0.41762\n",
      "Epoch 2146/3000\n",
      "13/13 - 0s - loss: 0.2088 - accuracy: 0.9014 - val_loss: 0.5284 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02146: val_loss did not improve from 0.41762\n",
      "Epoch 2147/3000\n",
      "13/13 - 0s - loss: 0.2141 - accuracy: 0.9014 - val_loss: 0.5285 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02147: val_loss did not improve from 0.41762\n",
      "Epoch 2148/3000\n",
      "13/13 - 0s - loss: 0.2127 - accuracy: 0.9027 - val_loss: 0.5133 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02148: val_loss did not improve from 0.41762\n",
      "Epoch 2149/3000\n",
      "13/13 - 0s - loss: 0.2082 - accuracy: 0.8988 - val_loss: 0.5145 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02149: val_loss did not improve from 0.41762\n",
      "Epoch 2150/3000\n",
      "13/13 - 0s - loss: 0.2067 - accuracy: 0.8988 - val_loss: 0.5100 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02150: val_loss did not improve from 0.41762\n",
      "Epoch 2151/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.8975 - val_loss: 0.5132 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 02151: val_loss did not improve from 0.41762\n",
      "Epoch 2152/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.8975 - val_loss: 0.5116 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02152: val_loss did not improve from 0.41762\n",
      "Epoch 2153/3000\n",
      "13/13 - 0s - loss: 0.2326 - accuracy: 0.8885 - val_loss: 0.4868 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 02153: val_loss did not improve from 0.41762\n",
      "Epoch 2154/3000\n",
      "13/13 - 0s - loss: 0.2332 - accuracy: 0.8949 - val_loss: 0.5379 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 02154: val_loss did not improve from 0.41762\n",
      "Epoch 2155/3000\n",
      "13/13 - 0s - loss: 0.2117 - accuracy: 0.9014 - val_loss: 0.5279 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02155: val_loss did not improve from 0.41762\n",
      "Epoch 2156/3000\n",
      "13/13 - 0s - loss: 0.2115 - accuracy: 0.8936 - val_loss: 0.5313 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02156: val_loss did not improve from 0.41762\n",
      "Epoch 2157/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.9001 - val_loss: 0.5300 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02157: val_loss did not improve from 0.41762\n",
      "Epoch 2158/3000\n",
      "13/13 - 0s - loss: 0.2089 - accuracy: 0.8975 - val_loss: 0.5365 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02158: val_loss did not improve from 0.41762\n",
      "Epoch 2159/3000\n",
      "13/13 - 0s - loss: 0.2110 - accuracy: 0.9014 - val_loss: 0.5271 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02159: val_loss did not improve from 0.41762\n",
      "Epoch 2160/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.9014 - val_loss: 0.5500 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02160: val_loss did not improve from 0.41762\n",
      "Epoch 2161/3000\n",
      "13/13 - 0s - loss: 0.2162 - accuracy: 0.8936 - val_loss: 0.5698 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02161: val_loss did not improve from 0.41762\n",
      "Epoch 2162/3000\n",
      "13/13 - 0s - loss: 0.2197 - accuracy: 0.8936 - val_loss: 0.5451 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02162: val_loss did not improve from 0.41762\n",
      "Epoch 2163/3000\n",
      "13/13 - 0s - loss: 0.2228 - accuracy: 0.9001 - val_loss: 0.5484 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02163: val_loss did not improve from 0.41762\n",
      "Epoch 2164/3000\n",
      "13/13 - 0s - loss: 0.2186 - accuracy: 0.8975 - val_loss: 0.5493 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02164: val_loss did not improve from 0.41762\n",
      "Epoch 2165/3000\n",
      "13/13 - 0s - loss: 0.2156 - accuracy: 0.8975 - val_loss: 0.5449 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02165: val_loss did not improve from 0.41762\n",
      "Epoch 2166/3000\n",
      "13/13 - 0s - loss: 0.2110 - accuracy: 0.9027 - val_loss: 0.5261 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02166: val_loss did not improve from 0.41762\n",
      "Epoch 2167/3000\n",
      "13/13 - 0s - loss: 0.2118 - accuracy: 0.9027 - val_loss: 0.5361 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02167: val_loss did not improve from 0.41762\n",
      "Epoch 2168/3000\n",
      "13/13 - 0s - loss: 0.2173 - accuracy: 0.8975 - val_loss: 0.5389 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02168: val_loss did not improve from 0.41762\n",
      "Epoch 2169/3000\n",
      "13/13 - 0s - loss: 0.2091 - accuracy: 0.9040 - val_loss: 0.5275 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02169: val_loss did not improve from 0.41762\n",
      "Epoch 2170/3000\n",
      "13/13 - 0s - loss: 0.2120 - accuracy: 0.8936 - val_loss: 0.5413 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02170: val_loss did not improve from 0.41762\n",
      "Epoch 2171/3000\n",
      "13/13 - 0s - loss: 0.2259 - accuracy: 0.8898 - val_loss: 0.5344 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02171: val_loss did not improve from 0.41762\n",
      "Epoch 2172/3000\n",
      "13/13 - 0s - loss: 0.2220 - accuracy: 0.8975 - val_loss: 0.5456 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02172: val_loss did not improve from 0.41762\n",
      "Epoch 2173/3000\n",
      "13/13 - 0s - loss: 0.2265 - accuracy: 0.8898 - val_loss: 0.5519 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02173: val_loss did not improve from 0.41762\n",
      "Epoch 2174/3000\n",
      "13/13 - 0s - loss: 0.2195 - accuracy: 0.8923 - val_loss: 0.5289 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02174: val_loss did not improve from 0.41762\n",
      "Epoch 2175/3000\n",
      "13/13 - 0s - loss: 0.2139 - accuracy: 0.9027 - val_loss: 0.5196 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02175: val_loss did not improve from 0.41762\n",
      "Epoch 2176/3000\n",
      "13/13 - 0s - loss: 0.2119 - accuracy: 0.8923 - val_loss: 0.5226 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02176: val_loss did not improve from 0.41762\n",
      "Epoch 2177/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.9027 - val_loss: 0.5357 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02177: val_loss did not improve from 0.41762\n",
      "Epoch 2178/3000\n",
      "13/13 - 0s - loss: 0.2085 - accuracy: 0.9014 - val_loss: 0.5340 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02178: val_loss did not improve from 0.41762\n",
      "Epoch 2179/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.8988 - val_loss: 0.5295 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02179: val_loss did not improve from 0.41762\n",
      "Epoch 2180/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.9027 - val_loss: 0.5195 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02180: val_loss did not improve from 0.41762\n",
      "Epoch 2181/3000\n",
      "13/13 - 0s - loss: 0.2098 - accuracy: 0.9001 - val_loss: 0.5426 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02181: val_loss did not improve from 0.41762\n",
      "Epoch 2182/3000\n",
      "13/13 - 0s - loss: 0.2085 - accuracy: 0.8949 - val_loss: 0.5251 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02182: val_loss did not improve from 0.41762\n",
      "Epoch 2183/3000\n",
      "13/13 - 0s - loss: 0.2058 - accuracy: 0.9001 - val_loss: 0.5330 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02183: val_loss did not improve from 0.41762\n",
      "Epoch 2184/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.9027 - val_loss: 0.5401 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02184: val_loss did not improve from 0.41762\n",
      "Epoch 2185/3000\n",
      "13/13 - 0s - loss: 0.2191 - accuracy: 0.8923 - val_loss: 0.5250 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02185: val_loss did not improve from 0.41762\n",
      "Epoch 2186/3000\n",
      "13/13 - 0s - loss: 0.2152 - accuracy: 0.8872 - val_loss: 0.5233 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02186: val_loss did not improve from 0.41762\n",
      "Epoch 2187/3000\n",
      "13/13 - 0s - loss: 0.2096 - accuracy: 0.9014 - val_loss: 0.5273 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02187: val_loss did not improve from 0.41762\n",
      "Epoch 2188/3000\n",
      "13/13 - 0s - loss: 0.2085 - accuracy: 0.8975 - val_loss: 0.5153 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02188: val_loss did not improve from 0.41762\n",
      "Epoch 2189/3000\n",
      "13/13 - 0s - loss: 0.2056 - accuracy: 0.9027 - val_loss: 0.5183 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02189: val_loss did not improve from 0.41762\n",
      "Epoch 2190/3000\n",
      "13/13 - 0s - loss: 0.2153 - accuracy: 0.9001 - val_loss: 0.5048 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02190: val_loss did not improve from 0.41762\n",
      "Epoch 2191/3000\n",
      "13/13 - 0s - loss: 0.2146 - accuracy: 0.9014 - val_loss: 0.5118 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02191: val_loss did not improve from 0.41762\n",
      "Epoch 2192/3000\n",
      "13/13 - 0s - loss: 0.2224 - accuracy: 0.8923 - val_loss: 0.5225 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02192: val_loss did not improve from 0.41762\n",
      "Epoch 2193/3000\n",
      "13/13 - 0s - loss: 0.2187 - accuracy: 0.8975 - val_loss: 0.5219 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02193: val_loss did not improve from 0.41762\n",
      "Epoch 2194/3000\n",
      "13/13 - 0s - loss: 0.2145 - accuracy: 0.8975 - val_loss: 0.5026 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02194: val_loss did not improve from 0.41762\n",
      "Epoch 2195/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.9027 - val_loss: 0.5070 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02195: val_loss did not improve from 0.41762\n",
      "Epoch 2196/3000\n",
      "13/13 - 0s - loss: 0.2196 - accuracy: 0.8949 - val_loss: 0.5191 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02196: val_loss did not improve from 0.41762\n",
      "Epoch 2197/3000\n",
      "13/13 - 0s - loss: 0.2144 - accuracy: 0.9027 - val_loss: 0.5593 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02197: val_loss did not improve from 0.41762\n",
      "Epoch 2198/3000\n",
      "13/13 - 0s - loss: 0.2373 - accuracy: 0.8936 - val_loss: 0.5341 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02198: val_loss did not improve from 0.41762\n",
      "Epoch 2199/3000\n",
      "13/13 - 0s - loss: 0.2119 - accuracy: 0.9053 - val_loss: 0.4984 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02199: val_loss did not improve from 0.41762\n",
      "Epoch 2200/3000\n",
      "13/13 - 0s - loss: 0.2129 - accuracy: 0.8988 - val_loss: 0.5243 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02200: val_loss did not improve from 0.41762\n",
      "Epoch 2201/3000\n",
      "13/13 - 0s - loss: 0.2131 - accuracy: 0.8962 - val_loss: 0.5150 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02201: val_loss did not improve from 0.41762\n",
      "Epoch 2202/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.9027 - val_loss: 0.5062 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02202: val_loss did not improve from 0.41762\n",
      "Epoch 2203/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.9014 - val_loss: 0.5164 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02203: val_loss did not improve from 0.41762\n",
      "Epoch 2204/3000\n",
      "13/13 - 0s - loss: 0.2082 - accuracy: 0.8962 - val_loss: 0.5257 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02204: val_loss did not improve from 0.41762\n",
      "Epoch 2205/3000\n",
      "13/13 - 0s - loss: 0.2186 - accuracy: 0.9027 - val_loss: 0.5377 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02205: val_loss did not improve from 0.41762\n",
      "Epoch 2206/3000\n",
      "13/13 - 0s - loss: 0.2321 - accuracy: 0.9001 - val_loss: 0.5261 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02206: val_loss did not improve from 0.41762\n",
      "Epoch 2207/3000\n",
      "13/13 - 0s - loss: 0.2212 - accuracy: 0.8923 - val_loss: 0.5034 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02207: val_loss did not improve from 0.41762\n",
      "Epoch 2208/3000\n",
      "13/13 - 0s - loss: 0.2099 - accuracy: 0.8975 - val_loss: 0.4977 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02208: val_loss did not improve from 0.41762\n",
      "Epoch 2209/3000\n",
      "13/13 - 0s - loss: 0.2159 - accuracy: 0.8936 - val_loss: 0.5046 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02209: val_loss did not improve from 0.41762\n",
      "Epoch 2210/3000\n",
      "13/13 - 0s - loss: 0.2139 - accuracy: 0.8885 - val_loss: 0.5019 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02210: val_loss did not improve from 0.41762\n",
      "Epoch 2211/3000\n",
      "13/13 - 0s - loss: 0.2097 - accuracy: 0.8988 - val_loss: 0.4920 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02211: val_loss did not improve from 0.41762\n",
      "Epoch 2212/3000\n",
      "13/13 - 0s - loss: 0.2091 - accuracy: 0.9040 - val_loss: 0.5015 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02212: val_loss did not improve from 0.41762\n",
      "Epoch 2213/3000\n",
      "13/13 - 0s - loss: 0.2082 - accuracy: 0.9001 - val_loss: 0.5140 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02213: val_loss did not improve from 0.41762\n",
      "Epoch 2214/3000\n",
      "13/13 - 0s - loss: 0.2073 - accuracy: 0.9027 - val_loss: 0.5140 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02214: val_loss did not improve from 0.41762\n",
      "Epoch 2215/3000\n",
      "13/13 - 0s - loss: 0.2120 - accuracy: 0.8962 - val_loss: 0.5161 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02215: val_loss did not improve from 0.41762\n",
      "Epoch 2216/3000\n",
      "13/13 - 0s - loss: 0.2085 - accuracy: 0.8988 - val_loss: 0.5116 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02216: val_loss did not improve from 0.41762\n",
      "Epoch 2217/3000\n",
      "13/13 - 0s - loss: 0.2092 - accuracy: 0.8988 - val_loss: 0.5274 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02217: val_loss did not improve from 0.41762\n",
      "Epoch 2218/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.9014 - val_loss: 0.5134 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02218: val_loss did not improve from 0.41762\n",
      "Epoch 2219/3000\n",
      "13/13 - 0s - loss: 0.2066 - accuracy: 0.9014 - val_loss: 0.5218 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02219: val_loss did not improve from 0.41762\n",
      "Epoch 2220/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.9001 - val_loss: 0.5206 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02220: val_loss did not improve from 0.41762\n",
      "Epoch 2221/3000\n",
      "13/13 - 0s - loss: 0.2066 - accuracy: 0.8949 - val_loss: 0.5238 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02221: val_loss did not improve from 0.41762\n",
      "Epoch 2222/3000\n",
      "13/13 - 0s - loss: 0.2064 - accuracy: 0.8988 - val_loss: 0.5407 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02222: val_loss did not improve from 0.41762\n",
      "Epoch 2223/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.9027 - val_loss: 0.5281 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02223: val_loss did not improve from 0.41762\n",
      "Epoch 2224/3000\n",
      "13/13 - 0s - loss: 0.2086 - accuracy: 0.9027 - val_loss: 0.5343 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02224: val_loss did not improve from 0.41762\n",
      "Epoch 2225/3000\n",
      "13/13 - 0s - loss: 0.2078 - accuracy: 0.8975 - val_loss: 0.5308 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02225: val_loss did not improve from 0.41762\n",
      "Epoch 2226/3000\n",
      "13/13 - 0s - loss: 0.2082 - accuracy: 0.8988 - val_loss: 0.5371 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02226: val_loss did not improve from 0.41762\n",
      "Epoch 2227/3000\n",
      "13/13 - 0s - loss: 0.2108 - accuracy: 0.8962 - val_loss: 0.5438 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02227: val_loss did not improve from 0.41762\n",
      "Epoch 2228/3000\n",
      "13/13 - 0s - loss: 0.2099 - accuracy: 0.8988 - val_loss: 0.5490 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02228: val_loss did not improve from 0.41762\n",
      "Epoch 2229/3000\n",
      "13/13 - 0s - loss: 0.2131 - accuracy: 0.8988 - val_loss: 0.5322 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02229: val_loss did not improve from 0.41762\n",
      "Epoch 2230/3000\n",
      "13/13 - 0s - loss: 0.2222 - accuracy: 0.8923 - val_loss: 0.5361 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02230: val_loss did not improve from 0.41762\n",
      "Epoch 2231/3000\n",
      "13/13 - 0s - loss: 0.2129 - accuracy: 0.8911 - val_loss: 0.5508 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02231: val_loss did not improve from 0.41762\n",
      "Epoch 2232/3000\n",
      "13/13 - 0s - loss: 0.2085 - accuracy: 0.9001 - val_loss: 0.5256 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02232: val_loss did not improve from 0.41762\n",
      "Epoch 2233/3000\n",
      "13/13 - 0s - loss: 0.2133 - accuracy: 0.9014 - val_loss: 0.5394 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02233: val_loss did not improve from 0.41762\n",
      "Epoch 2234/3000\n",
      "13/13 - 0s - loss: 0.2117 - accuracy: 0.8975 - val_loss: 0.5353 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02234: val_loss did not improve from 0.41762\n",
      "Epoch 2235/3000\n",
      "13/13 - 0s - loss: 0.2100 - accuracy: 0.9001 - val_loss: 0.5287 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02235: val_loss did not improve from 0.41762\n",
      "Epoch 2236/3000\n",
      "13/13 - 0s - loss: 0.2141 - accuracy: 0.9014 - val_loss: 0.5254 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02236: val_loss did not improve from 0.41762\n",
      "Epoch 2237/3000\n",
      "13/13 - 0s - loss: 0.2098 - accuracy: 0.9014 - val_loss: 0.5189 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02237: val_loss did not improve from 0.41762\n",
      "Epoch 2238/3000\n",
      "13/13 - 0s - loss: 0.2162 - accuracy: 0.8807 - val_loss: 0.5233 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02238: val_loss did not improve from 0.41762\n",
      "Epoch 2239/3000\n",
      "13/13 - 0s - loss: 0.2175 - accuracy: 0.8923 - val_loss: 0.5270 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02239: val_loss did not improve from 0.41762\n",
      "Epoch 2240/3000\n",
      "13/13 - 0s - loss: 0.2199 - accuracy: 0.8794 - val_loss: 0.5033 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02240: val_loss did not improve from 0.41762\n",
      "Epoch 2241/3000\n",
      "13/13 - 0s - loss: 0.2119 - accuracy: 0.9001 - val_loss: 0.5143 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02241: val_loss did not improve from 0.41762\n",
      "Epoch 2242/3000\n",
      "13/13 - 0s - loss: 0.2174 - accuracy: 0.9027 - val_loss: 0.4859 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02242: val_loss did not improve from 0.41762\n",
      "Epoch 2243/3000\n",
      "13/13 - 0s - loss: 0.2141 - accuracy: 0.8988 - val_loss: 0.5051 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02243: val_loss did not improve from 0.41762\n",
      "Epoch 2244/3000\n",
      "13/13 - 0s - loss: 0.2086 - accuracy: 0.9040 - val_loss: 0.5161 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02244: val_loss did not improve from 0.41762\n",
      "Epoch 2245/3000\n",
      "13/13 - 0s - loss: 0.2094 - accuracy: 0.9001 - val_loss: 0.5231 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02245: val_loss did not improve from 0.41762\n",
      "Epoch 2246/3000\n",
      "13/13 - 0s - loss: 0.2085 - accuracy: 0.9001 - val_loss: 0.5187 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02246: val_loss did not improve from 0.41762\n",
      "Epoch 2247/3000\n",
      "13/13 - 0s - loss: 0.2156 - accuracy: 0.8975 - val_loss: 0.5175 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02247: val_loss did not improve from 0.41762\n",
      "Epoch 2248/3000\n",
      "13/13 - 0s - loss: 0.2148 - accuracy: 0.8962 - val_loss: 0.5113 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02248: val_loss did not improve from 0.41762\n",
      "Epoch 2249/3000\n",
      "13/13 - 0s - loss: 0.2265 - accuracy: 0.8859 - val_loss: 0.5284 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02249: val_loss did not improve from 0.41762\n",
      "Epoch 2250/3000\n",
      "13/13 - 0s - loss: 0.2148 - accuracy: 0.9001 - val_loss: 0.5181 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02250: val_loss did not improve from 0.41762\n",
      "Epoch 2251/3000\n",
      "13/13 - 0s - loss: 0.2104 - accuracy: 0.8975 - val_loss: 0.5263 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02251: val_loss did not improve from 0.41762\n",
      "Epoch 2252/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.8988 - val_loss: 0.5225 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02252: val_loss did not improve from 0.41762\n",
      "Epoch 2253/3000\n",
      "13/13 - 0s - loss: 0.2096 - accuracy: 0.8988 - val_loss: 0.5455 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02253: val_loss did not improve from 0.41762\n",
      "Epoch 2254/3000\n",
      "13/13 - 0s - loss: 0.2174 - accuracy: 0.8898 - val_loss: 0.5616 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02254: val_loss did not improve from 0.41762\n",
      "Epoch 2255/3000\n",
      "13/13 - 0s - loss: 0.2144 - accuracy: 0.8949 - val_loss: 0.5481 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02255: val_loss did not improve from 0.41762\n",
      "Epoch 2256/3000\n",
      "13/13 - 0s - loss: 0.2183 - accuracy: 0.8962 - val_loss: 0.5391 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02256: val_loss did not improve from 0.41762\n",
      "Epoch 2257/3000\n",
      "13/13 - 0s - loss: 0.2085 - accuracy: 0.8988 - val_loss: 0.5376 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02257: val_loss did not improve from 0.41762\n",
      "Epoch 2258/3000\n",
      "13/13 - 0s - loss: 0.2144 - accuracy: 0.8975 - val_loss: 0.5231 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02258: val_loss did not improve from 0.41762\n",
      "Epoch 2259/3000\n",
      "13/13 - 0s - loss: 0.2177 - accuracy: 0.8988 - val_loss: 0.5299 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02259: val_loss did not improve from 0.41762\n",
      "Epoch 2260/3000\n",
      "13/13 - 0s - loss: 0.2188 - accuracy: 0.8962 - val_loss: 0.5401 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02260: val_loss did not improve from 0.41762\n",
      "Epoch 2261/3000\n",
      "13/13 - 0s - loss: 0.2244 - accuracy: 0.8846 - val_loss: 0.5424 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02261: val_loss did not improve from 0.41762\n",
      "Epoch 2262/3000\n",
      "13/13 - 0s - loss: 0.2256 - accuracy: 0.8846 - val_loss: 0.5599 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02262: val_loss did not improve from 0.41762\n",
      "Epoch 2263/3000\n",
      "13/13 - 0s - loss: 0.2159 - accuracy: 0.9014 - val_loss: 0.5468 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02263: val_loss did not improve from 0.41762\n",
      "Epoch 2264/3000\n",
      "13/13 - 0s - loss: 0.2123 - accuracy: 0.9040 - val_loss: 0.5332 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02264: val_loss did not improve from 0.41762\n",
      "Epoch 2265/3000\n",
      "13/13 - 0s - loss: 0.2127 - accuracy: 0.9014 - val_loss: 0.5139 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02265: val_loss did not improve from 0.41762\n",
      "Epoch 2266/3000\n",
      "13/13 - 0s - loss: 0.2100 - accuracy: 0.8949 - val_loss: 0.5091 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02266: val_loss did not improve from 0.41762\n",
      "Epoch 2267/3000\n",
      "13/13 - 0s - loss: 0.2078 - accuracy: 0.8988 - val_loss: 0.5253 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02267: val_loss did not improve from 0.41762\n",
      "Epoch 2268/3000\n",
      "13/13 - 0s - loss: 0.2178 - accuracy: 0.8923 - val_loss: 0.5420 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02268: val_loss did not improve from 0.41762\n",
      "Epoch 2269/3000\n",
      "13/13 - 0s - loss: 0.2131 - accuracy: 0.9001 - val_loss: 0.5263 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02269: val_loss did not improve from 0.41762\n",
      "Epoch 2270/3000\n",
      "13/13 - 0s - loss: 0.2187 - accuracy: 0.8988 - val_loss: 0.5582 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02270: val_loss did not improve from 0.41762\n",
      "Epoch 2271/3000\n",
      "13/13 - 0s - loss: 0.2175 - accuracy: 0.9001 - val_loss: 0.5659 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02271: val_loss did not improve from 0.41762\n",
      "Epoch 2272/3000\n",
      "13/13 - 0s - loss: 0.2259 - accuracy: 0.8975 - val_loss: 0.5384 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02272: val_loss did not improve from 0.41762\n",
      "Epoch 2273/3000\n",
      "13/13 - 0s - loss: 0.2178 - accuracy: 0.8936 - val_loss: 0.5338 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02273: val_loss did not improve from 0.41762\n",
      "Epoch 2274/3000\n",
      "13/13 - 0s - loss: 0.2134 - accuracy: 0.8949 - val_loss: 0.5055 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02274: val_loss did not improve from 0.41762\n",
      "Epoch 2275/3000\n",
      "13/13 - 0s - loss: 0.2078 - accuracy: 0.8988 - val_loss: 0.5107 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02275: val_loss did not improve from 0.41762\n",
      "Epoch 2276/3000\n",
      "13/13 - 0s - loss: 0.2065 - accuracy: 0.9027 - val_loss: 0.5232 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02276: val_loss did not improve from 0.41762\n",
      "Epoch 2277/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.9027 - val_loss: 0.5146 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02277: val_loss did not improve from 0.41762\n",
      "Epoch 2278/3000\n",
      "13/13 - 0s - loss: 0.2195 - accuracy: 0.8911 - val_loss: 0.5260 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02278: val_loss did not improve from 0.41762\n",
      "Epoch 2279/3000\n",
      "13/13 - 0s - loss: 0.2069 - accuracy: 0.8975 - val_loss: 0.5226 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02279: val_loss did not improve from 0.41762\n",
      "Epoch 2280/3000\n",
      "13/13 - 0s - loss: 0.2112 - accuracy: 0.8988 - val_loss: 0.5247 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02280: val_loss did not improve from 0.41762\n",
      "Epoch 2281/3000\n",
      "13/13 - 0s - loss: 0.2110 - accuracy: 0.8962 - val_loss: 0.5478 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02281: val_loss did not improve from 0.41762\n",
      "Epoch 2282/3000\n",
      "13/13 - 0s - loss: 0.2096 - accuracy: 0.8936 - val_loss: 0.5407 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02282: val_loss did not improve from 0.41762\n",
      "Epoch 2283/3000\n",
      "13/13 - 0s - loss: 0.2135 - accuracy: 0.9027 - val_loss: 0.5174 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02283: val_loss did not improve from 0.41762\n",
      "Epoch 2284/3000\n",
      "13/13 - 0s - loss: 0.2261 - accuracy: 0.8962 - val_loss: 0.5296 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02284: val_loss did not improve from 0.41762\n",
      "Epoch 2285/3000\n",
      "13/13 - 0s - loss: 0.2216 - accuracy: 0.8859 - val_loss: 0.5429 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02285: val_loss did not improve from 0.41762\n",
      "Epoch 2286/3000\n",
      "13/13 - 0s - loss: 0.2139 - accuracy: 0.8975 - val_loss: 0.5557 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02286: val_loss did not improve from 0.41762\n",
      "Epoch 2287/3000\n",
      "13/13 - 0s - loss: 0.2144 - accuracy: 0.8988 - val_loss: 0.5741 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02287: val_loss did not improve from 0.41762\n",
      "Epoch 2288/3000\n",
      "13/13 - 0s - loss: 0.2121 - accuracy: 0.9001 - val_loss: 0.5619 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02288: val_loss did not improve from 0.41762\n",
      "Epoch 2289/3000\n",
      "13/13 - 0s - loss: 0.2131 - accuracy: 0.9014 - val_loss: 0.5438 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02289: val_loss did not improve from 0.41762\n",
      "Epoch 2290/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.9014 - val_loss: 0.5382 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02290: val_loss did not improve from 0.41762\n",
      "Epoch 2291/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.8962 - val_loss: 0.5356 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02291: val_loss did not improve from 0.41762\n",
      "Epoch 2292/3000\n",
      "13/13 - 0s - loss: 0.2061 - accuracy: 0.9027 - val_loss: 0.5385 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02292: val_loss did not improve from 0.41762\n",
      "Epoch 2293/3000\n",
      "13/13 - 0s - loss: 0.2073 - accuracy: 0.8975 - val_loss: 0.5425 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02293: val_loss did not improve from 0.41762\n",
      "Epoch 2294/3000\n",
      "13/13 - 0s - loss: 0.2130 - accuracy: 0.8949 - val_loss: 0.5296 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02294: val_loss did not improve from 0.41762\n",
      "Epoch 2295/3000\n",
      "13/13 - 0s - loss: 0.2118 - accuracy: 0.8988 - val_loss: 0.5415 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02295: val_loss did not improve from 0.41762\n",
      "Epoch 2296/3000\n",
      "13/13 - 0s - loss: 0.2132 - accuracy: 0.8949 - val_loss: 0.5659 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02296: val_loss did not improve from 0.41762\n",
      "Epoch 2297/3000\n",
      "13/13 - 0s - loss: 0.2119 - accuracy: 0.8949 - val_loss: 0.5973 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02297: val_loss did not improve from 0.41762\n",
      "Epoch 2298/3000\n",
      "13/13 - 0s - loss: 0.2327 - accuracy: 0.8988 - val_loss: 0.5598 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02298: val_loss did not improve from 0.41762\n",
      "Epoch 2299/3000\n",
      "13/13 - 0s - loss: 0.2152 - accuracy: 0.8975 - val_loss: 0.4995 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02299: val_loss did not improve from 0.41762\n",
      "Epoch 2300/3000\n",
      "13/13 - 0s - loss: 0.2117 - accuracy: 0.8988 - val_loss: 0.5401 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02300: val_loss did not improve from 0.41762\n",
      "Epoch 2301/3000\n",
      "13/13 - 0s - loss: 0.2095 - accuracy: 0.9014 - val_loss: 0.5248 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02301: val_loss did not improve from 0.41762\n",
      "Epoch 2302/3000\n",
      "13/13 - 0s - loss: 0.2114 - accuracy: 0.9027 - val_loss: 0.5263 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02302: val_loss did not improve from 0.41762\n",
      "Epoch 2303/3000\n",
      "13/13 - 0s - loss: 0.2080 - accuracy: 0.8988 - val_loss: 0.5242 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02303: val_loss did not improve from 0.41762\n",
      "Epoch 2304/3000\n",
      "13/13 - 0s - loss: 0.2058 - accuracy: 0.9001 - val_loss: 0.5240 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02304: val_loss did not improve from 0.41762\n",
      "Epoch 2305/3000\n",
      "13/13 - 0s - loss: 0.2051 - accuracy: 0.9027 - val_loss: 0.5262 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02305: val_loss did not improve from 0.41762\n",
      "Epoch 2306/3000\n",
      "13/13 - 0s - loss: 0.2060 - accuracy: 0.8936 - val_loss: 0.5263 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02306: val_loss did not improve from 0.41762\n",
      "Epoch 2307/3000\n",
      "13/13 - 0s - loss: 0.2154 - accuracy: 0.9001 - val_loss: 0.5421 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02307: val_loss did not improve from 0.41762\n",
      "Epoch 2308/3000\n",
      "13/13 - 0s - loss: 0.2146 - accuracy: 0.8936 - val_loss: 0.5632 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02308: val_loss did not improve from 0.41762\n",
      "Epoch 2309/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.9014 - val_loss: 0.5223 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02309: val_loss did not improve from 0.41762\n",
      "Epoch 2310/3000\n",
      "13/13 - 0s - loss: 0.2112 - accuracy: 0.8988 - val_loss: 0.5164 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02310: val_loss did not improve from 0.41762\n",
      "Epoch 2311/3000\n",
      "13/13 - 0s - loss: 0.2135 - accuracy: 0.9001 - val_loss: 0.5476 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02311: val_loss did not improve from 0.41762\n",
      "Epoch 2312/3000\n",
      "13/13 - 0s - loss: 0.2295 - accuracy: 0.9027 - val_loss: 0.5773 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02312: val_loss did not improve from 0.41762\n",
      "Epoch 2313/3000\n",
      "13/13 - 0s - loss: 0.2215 - accuracy: 0.9027 - val_loss: 0.5122 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02313: val_loss did not improve from 0.41762\n",
      "Epoch 2314/3000\n",
      "13/13 - 0s - loss: 0.2127 - accuracy: 0.9014 - val_loss: 0.5124 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02314: val_loss did not improve from 0.41762\n",
      "Epoch 2315/3000\n",
      "13/13 - 0s - loss: 0.2224 - accuracy: 0.8975 - val_loss: 0.4984 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02315: val_loss did not improve from 0.41762\n",
      "Epoch 2316/3000\n",
      "13/13 - 0s - loss: 0.2226 - accuracy: 0.8962 - val_loss: 0.5100 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02316: val_loss did not improve from 0.41762\n",
      "Epoch 2317/3000\n",
      "13/13 - 0s - loss: 0.2163 - accuracy: 0.8936 - val_loss: 0.5267 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02317: val_loss did not improve from 0.41762\n",
      "Epoch 2318/3000\n",
      "13/13 - 0s - loss: 0.2136 - accuracy: 0.8911 - val_loss: 0.5399 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02318: val_loss did not improve from 0.41762\n",
      "Epoch 2319/3000\n",
      "13/13 - 0s - loss: 0.2122 - accuracy: 0.8988 - val_loss: 0.5276 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02319: val_loss did not improve from 0.41762\n",
      "Epoch 2320/3000\n",
      "13/13 - 0s - loss: 0.2145 - accuracy: 0.8975 - val_loss: 0.5292 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02320: val_loss did not improve from 0.41762\n",
      "Epoch 2321/3000\n",
      "13/13 - 0s - loss: 0.2202 - accuracy: 0.8846 - val_loss: 0.5124 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 02321: val_loss did not improve from 0.41762\n",
      "Epoch 2322/3000\n",
      "13/13 - 0s - loss: 0.2116 - accuracy: 0.8962 - val_loss: 0.5210 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02322: val_loss did not improve from 0.41762\n",
      "Epoch 2323/3000\n",
      "13/13 - 0s - loss: 0.2099 - accuracy: 0.8962 - val_loss: 0.5301 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02323: val_loss did not improve from 0.41762\n",
      "Epoch 2324/3000\n",
      "13/13 - 0s - loss: 0.2099 - accuracy: 0.9014 - val_loss: 0.5241 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02324: val_loss did not improve from 0.41762\n",
      "Epoch 2325/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.9014 - val_loss: 0.5351 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02325: val_loss did not improve from 0.41762\n",
      "Epoch 2326/3000\n",
      "13/13 - 0s - loss: 0.2093 - accuracy: 0.9014 - val_loss: 0.5365 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02326: val_loss did not improve from 0.41762\n",
      "Epoch 2327/3000\n",
      "13/13 - 0s - loss: 0.2126 - accuracy: 0.9001 - val_loss: 0.5180 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02327: val_loss did not improve from 0.41762\n",
      "Epoch 2328/3000\n",
      "13/13 - 0s - loss: 0.2089 - accuracy: 0.8988 - val_loss: 0.5262 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02328: val_loss did not improve from 0.41762\n",
      "Epoch 2329/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.9027 - val_loss: 0.5195 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02329: val_loss did not improve from 0.41762\n",
      "Epoch 2330/3000\n",
      "13/13 - 0s - loss: 0.2190 - accuracy: 0.8859 - val_loss: 0.5308 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02330: val_loss did not improve from 0.41762\n",
      "Epoch 2331/3000\n",
      "13/13 - 0s - loss: 0.2111 - accuracy: 0.9014 - val_loss: 0.5549 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02331: val_loss did not improve from 0.41762\n",
      "Epoch 2332/3000\n",
      "13/13 - 0s - loss: 0.2156 - accuracy: 0.9001 - val_loss: 0.5425 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02332: val_loss did not improve from 0.41762\n",
      "Epoch 2333/3000\n",
      "13/13 - 0s - loss: 0.2335 - accuracy: 0.8898 - val_loss: 0.5337 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02333: val_loss did not improve from 0.41762\n",
      "Epoch 2334/3000\n",
      "13/13 - 0s - loss: 0.2154 - accuracy: 0.8911 - val_loss: 0.5564 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02334: val_loss did not improve from 0.41762\n",
      "Epoch 2335/3000\n",
      "13/13 - 0s - loss: 0.2168 - accuracy: 0.8975 - val_loss: 0.5624 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02335: val_loss did not improve from 0.41762\n",
      "Epoch 2336/3000\n",
      "13/13 - 0s - loss: 0.2112 - accuracy: 0.9027 - val_loss: 0.5274 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02336: val_loss did not improve from 0.41762\n",
      "Epoch 2337/3000\n",
      "13/13 - 0s - loss: 0.2153 - accuracy: 0.8988 - val_loss: 0.5536 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02337: val_loss did not improve from 0.41762\n",
      "Epoch 2338/3000\n",
      "13/13 - 0s - loss: 0.2278 - accuracy: 0.8949 - val_loss: 0.5547 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02338: val_loss did not improve from 0.41762\n",
      "Epoch 2339/3000\n",
      "13/13 - 0s - loss: 0.2304 - accuracy: 0.8807 - val_loss: 0.5288 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02339: val_loss did not improve from 0.41762\n",
      "Epoch 2340/3000\n",
      "13/13 - 0s - loss: 0.2330 - accuracy: 0.8677 - val_loss: 0.5292 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02340: val_loss did not improve from 0.41762\n",
      "Epoch 2341/3000\n",
      "13/13 - 0s - loss: 0.2212 - accuracy: 0.8846 - val_loss: 0.5232 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02341: val_loss did not improve from 0.41762\n",
      "Epoch 2342/3000\n",
      "13/13 - 0s - loss: 0.2225 - accuracy: 0.8898 - val_loss: 0.5604 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02342: val_loss did not improve from 0.41762\n",
      "Epoch 2343/3000\n",
      "13/13 - 0s - loss: 0.2246 - accuracy: 0.8949 - val_loss: 0.5456 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02343: val_loss did not improve from 0.41762\n",
      "Epoch 2344/3000\n",
      "13/13 - 0s - loss: 0.2148 - accuracy: 0.8975 - val_loss: 0.5236 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02344: val_loss did not improve from 0.41762\n",
      "Epoch 2345/3000\n",
      "13/13 - 0s - loss: 0.2094 - accuracy: 0.9001 - val_loss: 0.5233 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02345: val_loss did not improve from 0.41762\n",
      "Epoch 2346/3000\n",
      "13/13 - 0s - loss: 0.2124 - accuracy: 0.8962 - val_loss: 0.5173 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02346: val_loss did not improve from 0.41762\n",
      "Epoch 2347/3000\n",
      "13/13 - 0s - loss: 0.2124 - accuracy: 0.9014 - val_loss: 0.5259 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02347: val_loss did not improve from 0.41762\n",
      "Epoch 2348/3000\n",
      "13/13 - 0s - loss: 0.2070 - accuracy: 0.9001 - val_loss: 0.5151 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02348: val_loss did not improve from 0.41762\n",
      "Epoch 2349/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.8988 - val_loss: 0.5198 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02349: val_loss did not improve from 0.41762\n",
      "Epoch 2350/3000\n",
      "13/13 - 0s - loss: 0.2083 - accuracy: 0.8975 - val_loss: 0.5230 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02350: val_loss did not improve from 0.41762\n",
      "Epoch 2351/3000\n",
      "13/13 - 0s - loss: 0.2088 - accuracy: 0.8975 - val_loss: 0.5327 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02351: val_loss did not improve from 0.41762\n",
      "Epoch 2352/3000\n",
      "13/13 - 0s - loss: 0.2085 - accuracy: 0.9001 - val_loss: 0.5124 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02352: val_loss did not improve from 0.41762\n",
      "Epoch 2353/3000\n",
      "13/13 - 0s - loss: 0.2096 - accuracy: 0.8962 - val_loss: 0.5291 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02353: val_loss did not improve from 0.41762\n",
      "Epoch 2354/3000\n",
      "13/13 - 0s - loss: 0.2065 - accuracy: 0.8988 - val_loss: 0.5243 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02354: val_loss did not improve from 0.41762\n",
      "Epoch 2355/3000\n",
      "13/13 - 0s - loss: 0.2189 - accuracy: 0.8794 - val_loss: 0.5319 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02355: val_loss did not improve from 0.41762\n",
      "Epoch 2356/3000\n",
      "13/13 - 0s - loss: 0.2139 - accuracy: 0.8923 - val_loss: 0.5374 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02356: val_loss did not improve from 0.41762\n",
      "Epoch 2357/3000\n",
      "13/13 - 0s - loss: 0.2097 - accuracy: 0.9053 - val_loss: 0.5282 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02357: val_loss did not improve from 0.41762\n",
      "Epoch 2358/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.9001 - val_loss: 0.5311 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02358: val_loss did not improve from 0.41762\n",
      "Epoch 2359/3000\n",
      "13/13 - 0s - loss: 0.2059 - accuracy: 0.9014 - val_loss: 0.5288 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02359: val_loss did not improve from 0.41762\n",
      "Epoch 2360/3000\n",
      "13/13 - 0s - loss: 0.2113 - accuracy: 0.8936 - val_loss: 0.5272 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02360: val_loss did not improve from 0.41762\n",
      "Epoch 2361/3000\n",
      "13/13 - 0s - loss: 0.2178 - accuracy: 0.9001 - val_loss: 0.5857 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02361: val_loss did not improve from 0.41762\n",
      "Epoch 2362/3000\n",
      "13/13 - 0s - loss: 0.2361 - accuracy: 0.8820 - val_loss: 0.5207 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02362: val_loss did not improve from 0.41762\n",
      "Epoch 2363/3000\n",
      "13/13 - 0s - loss: 0.2185 - accuracy: 0.8846 - val_loss: 0.5240 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02363: val_loss did not improve from 0.41762\n",
      "Epoch 2364/3000\n",
      "13/13 - 0s - loss: 0.2369 - accuracy: 0.8911 - val_loss: 0.5315 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02364: val_loss did not improve from 0.41762\n",
      "Epoch 2365/3000\n",
      "13/13 - 0s - loss: 0.2304 - accuracy: 0.8911 - val_loss: 0.5554 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02365: val_loss did not improve from 0.41762\n",
      "Epoch 2366/3000\n",
      "13/13 - 0s - loss: 0.2181 - accuracy: 0.8911 - val_loss: 0.5220 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02366: val_loss did not improve from 0.41762\n",
      "Epoch 2367/3000\n",
      "13/13 - 0s - loss: 0.2154 - accuracy: 0.9027 - val_loss: 0.5158 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02367: val_loss did not improve from 0.41762\n",
      "Epoch 2368/3000\n",
      "13/13 - 0s - loss: 0.2269 - accuracy: 0.8846 - val_loss: 0.5092 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02368: val_loss did not improve from 0.41762\n",
      "Epoch 2369/3000\n",
      "13/13 - 0s - loss: 0.2300 - accuracy: 0.8820 - val_loss: 0.5124 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 02369: val_loss did not improve from 0.41762\n",
      "Epoch 2370/3000\n",
      "13/13 - 0s - loss: 0.2142 - accuracy: 0.9027 - val_loss: 0.4926 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02370: val_loss did not improve from 0.41762\n",
      "Epoch 2371/3000\n",
      "13/13 - 0s - loss: 0.2076 - accuracy: 0.9027 - val_loss: 0.4899 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02371: val_loss did not improve from 0.41762\n",
      "Epoch 2372/3000\n",
      "13/13 - 0s - loss: 0.2217 - accuracy: 0.8962 - val_loss: 0.4622 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 02372: val_loss did not improve from 0.41762\n",
      "Epoch 2373/3000\n",
      "13/13 - 0s - loss: 0.2176 - accuracy: 0.8936 - val_loss: 0.5204 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 02373: val_loss did not improve from 0.41762\n",
      "Epoch 2374/3000\n",
      "13/13 - 0s - loss: 0.2141 - accuracy: 0.8911 - val_loss: 0.5085 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02374: val_loss did not improve from 0.41762\n",
      "Epoch 2375/3000\n",
      "13/13 - 0s - loss: 0.2127 - accuracy: 0.8962 - val_loss: 0.5123 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02375: val_loss did not improve from 0.41762\n",
      "Epoch 2376/3000\n",
      "13/13 - 0s - loss: 0.2106 - accuracy: 0.9001 - val_loss: 0.5130 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02376: val_loss did not improve from 0.41762\n",
      "Epoch 2377/3000\n",
      "13/13 - 0s - loss: 0.2107 - accuracy: 0.9027 - val_loss: 0.5174 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02377: val_loss did not improve from 0.41762\n",
      "Epoch 2378/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.8988 - val_loss: 0.5056 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02378: val_loss did not improve from 0.41762\n",
      "Epoch 2379/3000\n",
      "13/13 - 0s - loss: 0.2073 - accuracy: 0.8975 - val_loss: 0.5111 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02379: val_loss did not improve from 0.41762\n",
      "Epoch 2380/3000\n",
      "13/13 - 0s - loss: 0.2087 - accuracy: 0.9001 - val_loss: 0.5259 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02380: val_loss did not improve from 0.41762\n",
      "Epoch 2381/3000\n",
      "13/13 - 0s - loss: 0.2169 - accuracy: 0.8988 - val_loss: 0.5077 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02381: val_loss did not improve from 0.41762\n",
      "Epoch 2382/3000\n",
      "13/13 - 0s - loss: 0.2240 - accuracy: 0.8859 - val_loss: 0.4938 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 02382: val_loss did not improve from 0.41762\n",
      "Epoch 2383/3000\n",
      "13/13 - 0s - loss: 0.2248 - accuracy: 0.8949 - val_loss: 0.5621 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02383: val_loss did not improve from 0.41762\n",
      "Epoch 2384/3000\n",
      "13/13 - 0s - loss: 0.2178 - accuracy: 0.9001 - val_loss: 0.5130 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02384: val_loss did not improve from 0.41762\n",
      "Epoch 2385/3000\n",
      "13/13 - 0s - loss: 0.2148 - accuracy: 0.9014 - val_loss: 0.5279 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02385: val_loss did not improve from 0.41762\n",
      "Epoch 2386/3000\n",
      "13/13 - 0s - loss: 0.2129 - accuracy: 0.9027 - val_loss: 0.5326 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02386: val_loss did not improve from 0.41762\n",
      "Epoch 2387/3000\n",
      "13/13 - 0s - loss: 0.2120 - accuracy: 0.9014 - val_loss: 0.5290 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02387: val_loss did not improve from 0.41762\n",
      "Epoch 2388/3000\n",
      "13/13 - 0s - loss: 0.2292 - accuracy: 0.8975 - val_loss: 0.5626 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 02388: val_loss did not improve from 0.41762\n",
      "Epoch 2389/3000\n",
      "13/13 - 0s - loss: 0.2353 - accuracy: 0.8768 - val_loss: 0.4792 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02389: val_loss did not improve from 0.41762\n",
      "Epoch 2390/3000\n",
      "13/13 - 0s - loss: 0.2447 - accuracy: 0.8898 - val_loss: 0.5214 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02390: val_loss did not improve from 0.41762\n",
      "Epoch 2391/3000\n",
      "13/13 - 0s - loss: 0.2262 - accuracy: 0.9001 - val_loss: 0.5533 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02391: val_loss did not improve from 0.41762\n",
      "Epoch 2392/3000\n",
      "13/13 - 0s - loss: 0.2196 - accuracy: 0.9040 - val_loss: 0.5274 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02392: val_loss did not improve from 0.41762\n",
      "Epoch 2393/3000\n",
      "13/13 - 0s - loss: 0.2130 - accuracy: 0.9027 - val_loss: 0.5066 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02393: val_loss did not improve from 0.41762\n",
      "Epoch 2394/3000\n",
      "13/13 - 0s - loss: 0.2111 - accuracy: 0.9014 - val_loss: 0.5016 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02394: val_loss did not improve from 0.41762\n",
      "Epoch 2395/3000\n",
      "13/13 - 0s - loss: 0.2089 - accuracy: 0.8988 - val_loss: 0.5031 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02395: val_loss did not improve from 0.41762\n",
      "Epoch 2396/3000\n",
      "13/13 - 0s - loss: 0.2066 - accuracy: 0.9027 - val_loss: 0.5030 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02396: val_loss did not improve from 0.41762\n",
      "Epoch 2397/3000\n",
      "13/13 - 0s - loss: 0.2065 - accuracy: 0.9001 - val_loss: 0.5010 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02397: val_loss did not improve from 0.41762\n",
      "Epoch 2398/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.9001 - val_loss: 0.4994 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02398: val_loss did not improve from 0.41762\n",
      "Epoch 2399/3000\n",
      "13/13 - 0s - loss: 0.2125 - accuracy: 0.8988 - val_loss: 0.5142 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02399: val_loss did not improve from 0.41762\n",
      "Epoch 2400/3000\n",
      "13/13 - 0s - loss: 0.2092 - accuracy: 0.8962 - val_loss: 0.5155 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02400: val_loss did not improve from 0.41762\n",
      "Epoch 2401/3000\n",
      "13/13 - 0s - loss: 0.2064 - accuracy: 0.9014 - val_loss: 0.5187 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02401: val_loss did not improve from 0.41762\n",
      "Epoch 2402/3000\n",
      "13/13 - 0s - loss: 0.2245 - accuracy: 0.8885 - val_loss: 0.5328 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02402: val_loss did not improve from 0.41762\n",
      "Epoch 2403/3000\n",
      "13/13 - 0s - loss: 0.2197 - accuracy: 0.8923 - val_loss: 0.4822 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02403: val_loss did not improve from 0.41762\n",
      "Epoch 2404/3000\n",
      "13/13 - 0s - loss: 0.2231 - accuracy: 0.8975 - val_loss: 0.5017 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 02404: val_loss did not improve from 0.41762\n",
      "Epoch 2405/3000\n",
      "13/13 - 0s - loss: 0.2138 - accuracy: 0.8911 - val_loss: 0.4923 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02405: val_loss did not improve from 0.41762\n",
      "Epoch 2406/3000\n",
      "13/13 - 0s - loss: 0.2110 - accuracy: 0.8949 - val_loss: 0.5136 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02406: val_loss did not improve from 0.41762\n",
      "Epoch 2407/3000\n",
      "13/13 - 0s - loss: 0.2182 - accuracy: 0.8975 - val_loss: 0.5277 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 02407: val_loss did not improve from 0.41762\n",
      "Epoch 2408/3000\n",
      "13/13 - 0s - loss: 0.2123 - accuracy: 0.8936 - val_loss: 0.5028 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 02408: val_loss did not improve from 0.41762\n",
      "Epoch 2409/3000\n",
      "13/13 - 0s - loss: 0.2125 - accuracy: 0.8936 - val_loss: 0.5177 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02409: val_loss did not improve from 0.41762\n",
      "Epoch 2410/3000\n",
      "13/13 - 0s - loss: 0.2092 - accuracy: 0.9027 - val_loss: 0.5111 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02410: val_loss did not improve from 0.41762\n",
      "Epoch 2411/3000\n",
      "13/13 - 0s - loss: 0.2140 - accuracy: 0.8898 - val_loss: 0.5080 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 02411: val_loss did not improve from 0.41762\n",
      "Epoch 2412/3000\n",
      "13/13 - 0s - loss: 0.2141 - accuracy: 0.8962 - val_loss: 0.5159 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02412: val_loss did not improve from 0.41762\n",
      "Epoch 2413/3000\n",
      "13/13 - 0s - loss: 0.2147 - accuracy: 0.8898 - val_loss: 0.5130 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02413: val_loss did not improve from 0.41762\n",
      "Epoch 2414/3000\n",
      "13/13 - 0s - loss: 0.2117 - accuracy: 0.8975 - val_loss: 0.5013 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02414: val_loss did not improve from 0.41762\n",
      "Epoch 2415/3000\n",
      "13/13 - 0s - loss: 0.2108 - accuracy: 0.8975 - val_loss: 0.5342 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02415: val_loss did not improve from 0.41762\n",
      "Epoch 2416/3000\n",
      "13/13 - 0s - loss: 0.2159 - accuracy: 0.8911 - val_loss: 0.5081 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02416: val_loss did not improve from 0.41762\n",
      "Epoch 2417/3000\n",
      "13/13 - 0s - loss: 0.2174 - accuracy: 0.8923 - val_loss: 0.5210 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02417: val_loss did not improve from 0.41762\n",
      "Epoch 2418/3000\n",
      "13/13 - 0s - loss: 0.2146 - accuracy: 0.9040 - val_loss: 0.5477 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02418: val_loss did not improve from 0.41762\n",
      "Epoch 2419/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.9027 - val_loss: 0.5296 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02419: val_loss did not improve from 0.41762\n",
      "Epoch 2420/3000\n",
      "13/13 - 0s - loss: 0.2064 - accuracy: 0.9027 - val_loss: 0.5181 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02420: val_loss did not improve from 0.41762\n",
      "Epoch 2421/3000\n",
      "13/13 - 0s - loss: 0.2064 - accuracy: 0.9027 - val_loss: 0.5215 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02421: val_loss did not improve from 0.41762\n",
      "Epoch 2422/3000\n",
      "13/13 - 0s - loss: 0.2112 - accuracy: 0.9027 - val_loss: 0.5227 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02422: val_loss did not improve from 0.41762\n",
      "Epoch 2423/3000\n",
      "13/13 - 0s - loss: 0.2131 - accuracy: 0.8962 - val_loss: 0.5330 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02423: val_loss did not improve from 0.41762\n",
      "Epoch 2424/3000\n",
      "13/13 - 0s - loss: 0.2143 - accuracy: 0.8975 - val_loss: 0.5391 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02424: val_loss did not improve from 0.41762\n",
      "Epoch 2425/3000\n",
      "13/13 - 0s - loss: 0.2106 - accuracy: 0.9001 - val_loss: 0.5529 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02425: val_loss did not improve from 0.41762\n",
      "Epoch 2426/3000\n",
      "13/13 - 0s - loss: 0.2465 - accuracy: 0.8898 - val_loss: 0.5542 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02426: val_loss did not improve from 0.41762\n",
      "Epoch 2427/3000\n",
      "13/13 - 0s - loss: 0.2137 - accuracy: 0.8936 - val_loss: 0.5533 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02427: val_loss did not improve from 0.41762\n",
      "Epoch 2428/3000\n",
      "13/13 - 0s - loss: 0.2148 - accuracy: 0.8898 - val_loss: 0.5636 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02428: val_loss did not improve from 0.41762\n",
      "Epoch 2429/3000\n",
      "13/13 - 0s - loss: 0.2092 - accuracy: 0.8962 - val_loss: 0.5595 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02429: val_loss did not improve from 0.41762\n",
      "Epoch 2430/3000\n",
      "13/13 - 0s - loss: 0.2091 - accuracy: 0.8962 - val_loss: 0.5534 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02430: val_loss did not improve from 0.41762\n",
      "Epoch 2431/3000\n",
      "13/13 - 0s - loss: 0.2178 - accuracy: 0.8898 - val_loss: 0.5494 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02431: val_loss did not improve from 0.41762\n",
      "Epoch 2432/3000\n",
      "13/13 - 0s - loss: 0.2173 - accuracy: 0.8872 - val_loss: 0.5464 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02432: val_loss did not improve from 0.41762\n",
      "Epoch 2433/3000\n",
      "13/13 - 0s - loss: 0.2125 - accuracy: 0.8911 - val_loss: 0.5452 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02433: val_loss did not improve from 0.41762\n",
      "Epoch 2434/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.8988 - val_loss: 0.5600 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02434: val_loss did not improve from 0.41762\n",
      "Epoch 2435/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.9014 - val_loss: 0.5514 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02435: val_loss did not improve from 0.41762\n",
      "Epoch 2436/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.9001 - val_loss: 0.5519 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02436: val_loss did not improve from 0.41762\n",
      "Epoch 2437/3000\n",
      "13/13 - 0s - loss: 0.2112 - accuracy: 0.9027 - val_loss: 0.5478 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02437: val_loss did not improve from 0.41762\n",
      "Epoch 2438/3000\n",
      "13/13 - 0s - loss: 0.2125 - accuracy: 0.8949 - val_loss: 0.5581 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02438: val_loss did not improve from 0.41762\n",
      "Epoch 2439/3000\n",
      "13/13 - 0s - loss: 0.2114 - accuracy: 0.8949 - val_loss: 0.5389 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02439: val_loss did not improve from 0.41762\n",
      "Epoch 2440/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.8962 - val_loss: 0.5452 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02440: val_loss did not improve from 0.41762\n",
      "Epoch 2441/3000\n",
      "13/13 - 0s - loss: 0.2128 - accuracy: 0.9027 - val_loss: 0.5763 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02441: val_loss did not improve from 0.41762\n",
      "Epoch 2442/3000\n",
      "13/13 - 0s - loss: 0.2155 - accuracy: 0.8988 - val_loss: 0.5606 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02442: val_loss did not improve from 0.41762\n",
      "Epoch 2443/3000\n",
      "13/13 - 0s - loss: 0.2106 - accuracy: 0.8962 - val_loss: 0.5520 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02443: val_loss did not improve from 0.41762\n",
      "Epoch 2444/3000\n",
      "13/13 - 0s - loss: 0.2182 - accuracy: 0.9001 - val_loss: 0.5506 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02444: val_loss did not improve from 0.41762\n",
      "Epoch 2445/3000\n",
      "13/13 - 0s - loss: 0.2137 - accuracy: 0.8988 - val_loss: 0.5366 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02445: val_loss did not improve from 0.41762\n",
      "Epoch 2446/3000\n",
      "13/13 - 0s - loss: 0.2089 - accuracy: 0.9014 - val_loss: 0.5456 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02446: val_loss did not improve from 0.41762\n",
      "Epoch 2447/3000\n",
      "13/13 - 0s - loss: 0.2083 - accuracy: 0.8988 - val_loss: 0.5533 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02447: val_loss did not improve from 0.41762\n",
      "Epoch 2448/3000\n",
      "13/13 - 0s - loss: 0.2115 - accuracy: 0.9001 - val_loss: 0.5648 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02448: val_loss did not improve from 0.41762\n",
      "Epoch 2449/3000\n",
      "13/13 - 0s - loss: 0.2106 - accuracy: 0.8988 - val_loss: 0.5229 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02449: val_loss did not improve from 0.41762\n",
      "Epoch 2450/3000\n",
      "13/13 - 0s - loss: 0.2246 - accuracy: 0.8820 - val_loss: 0.5366 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02450: val_loss did not improve from 0.41762\n",
      "Epoch 2451/3000\n",
      "13/13 - 0s - loss: 0.2171 - accuracy: 0.8949 - val_loss: 0.5426 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02451: val_loss did not improve from 0.41762\n",
      "Epoch 2452/3000\n",
      "13/13 - 0s - loss: 0.2073 - accuracy: 0.9027 - val_loss: 0.5326 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02452: val_loss did not improve from 0.41762\n",
      "Epoch 2453/3000\n",
      "13/13 - 0s - loss: 0.2069 - accuracy: 0.9014 - val_loss: 0.5264 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02453: val_loss did not improve from 0.41762\n",
      "Epoch 2454/3000\n",
      "13/13 - 0s - loss: 0.2099 - accuracy: 0.8962 - val_loss: 0.5271 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02454: val_loss did not improve from 0.41762\n",
      "Epoch 2455/3000\n",
      "13/13 - 0s - loss: 0.2200 - accuracy: 0.8911 - val_loss: 0.5269 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02455: val_loss did not improve from 0.41762\n",
      "Epoch 2456/3000\n",
      "13/13 - 0s - loss: 0.2119 - accuracy: 0.8911 - val_loss: 0.5241 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02456: val_loss did not improve from 0.41762\n",
      "Epoch 2457/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.8988 - val_loss: 0.5227 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02457: val_loss did not improve from 0.41762\n",
      "Epoch 2458/3000\n",
      "13/13 - 0s - loss: 0.2145 - accuracy: 0.8975 - val_loss: 0.5318 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02458: val_loss did not improve from 0.41762\n",
      "Epoch 2459/3000\n",
      "13/13 - 0s - loss: 0.2204 - accuracy: 0.8949 - val_loss: 0.5001 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 02459: val_loss did not improve from 0.41762\n",
      "Epoch 2460/3000\n",
      "13/13 - 0s - loss: 0.2185 - accuracy: 0.8988 - val_loss: 0.5170 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 02460: val_loss did not improve from 0.41762\n",
      "Epoch 2461/3000\n",
      "13/13 - 0s - loss: 0.2106 - accuracy: 0.8988 - val_loss: 0.5314 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02461: val_loss did not improve from 0.41762\n",
      "Epoch 2462/3000\n",
      "13/13 - 0s - loss: 0.2111 - accuracy: 0.8923 - val_loss: 0.5098 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 02462: val_loss did not improve from 0.41762\n",
      "Epoch 2463/3000\n",
      "13/13 - 0s - loss: 0.2229 - accuracy: 0.8962 - val_loss: 0.5456 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02463: val_loss did not improve from 0.41762\n",
      "Epoch 2464/3000\n",
      "13/13 - 0s - loss: 0.2260 - accuracy: 0.9001 - val_loss: 0.5417 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02464: val_loss did not improve from 0.41762\n",
      "Epoch 2465/3000\n",
      "13/13 - 0s - loss: 0.2193 - accuracy: 0.8949 - val_loss: 0.5452 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02465: val_loss did not improve from 0.41762\n",
      "Epoch 2466/3000\n",
      "13/13 - 0s - loss: 0.2156 - accuracy: 0.8911 - val_loss: 0.5367 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02466: val_loss did not improve from 0.41762\n",
      "Epoch 2467/3000\n",
      "13/13 - 0s - loss: 0.2293 - accuracy: 0.8885 - val_loss: 0.5407 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02467: val_loss did not improve from 0.41762\n",
      "Epoch 2468/3000\n",
      "13/13 - 0s - loss: 0.2283 - accuracy: 0.8923 - val_loss: 0.5600 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02468: val_loss did not improve from 0.41762\n",
      "Epoch 2469/3000\n",
      "13/13 - 0s - loss: 0.2155 - accuracy: 0.8962 - val_loss: 0.5479 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02469: val_loss did not improve from 0.41762\n",
      "Epoch 2470/3000\n",
      "13/13 - 0s - loss: 0.2144 - accuracy: 0.8949 - val_loss: 0.5557 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02470: val_loss did not improve from 0.41762\n",
      "Epoch 2471/3000\n",
      "13/13 - 0s - loss: 0.2157 - accuracy: 0.8949 - val_loss: 0.5354 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02471: val_loss did not improve from 0.41762\n",
      "Epoch 2472/3000\n",
      "13/13 - 0s - loss: 0.2108 - accuracy: 0.8936 - val_loss: 0.5178 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02472: val_loss did not improve from 0.41762\n",
      "Epoch 2473/3000\n",
      "13/13 - 0s - loss: 0.2076 - accuracy: 0.9027 - val_loss: 0.5263 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02473: val_loss did not improve from 0.41762\n",
      "Epoch 2474/3000\n",
      "13/13 - 0s - loss: 0.2065 - accuracy: 0.9027 - val_loss: 0.5362 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02474: val_loss did not improve from 0.41762\n",
      "Epoch 2475/3000\n",
      "13/13 - 0s - loss: 0.2102 - accuracy: 0.8975 - val_loss: 0.5403 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02475: val_loss did not improve from 0.41762\n",
      "Epoch 2476/3000\n",
      "13/13 - 0s - loss: 0.2154 - accuracy: 0.8975 - val_loss: 0.5517 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02476: val_loss did not improve from 0.41762\n",
      "Epoch 2477/3000\n",
      "13/13 - 0s - loss: 0.2172 - accuracy: 0.8936 - val_loss: 0.5423 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02477: val_loss did not improve from 0.41762\n",
      "Epoch 2478/3000\n",
      "13/13 - 0s - loss: 0.2080 - accuracy: 0.8885 - val_loss: 0.5285 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02478: val_loss did not improve from 0.41762\n",
      "Epoch 2479/3000\n",
      "13/13 - 0s - loss: 0.2123 - accuracy: 0.8949 - val_loss: 0.5472 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02479: val_loss did not improve from 0.41762\n",
      "Epoch 2480/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.8872 - val_loss: 0.5473 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02480: val_loss did not improve from 0.41762\n",
      "Epoch 2481/3000\n",
      "13/13 - 0s - loss: 0.2087 - accuracy: 0.8923 - val_loss: 0.5444 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02481: val_loss did not improve from 0.41762\n",
      "Epoch 2482/3000\n",
      "13/13 - 0s - loss: 0.2109 - accuracy: 0.8949 - val_loss: 0.5709 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 02482: val_loss did not improve from 0.41762\n",
      "Epoch 2483/3000\n",
      "13/13 - 0s - loss: 0.2182 - accuracy: 0.8846 - val_loss: 0.5284 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02483: val_loss did not improve from 0.41762\n",
      "Epoch 2484/3000\n",
      "13/13 - 0s - loss: 0.2140 - accuracy: 0.8936 - val_loss: 0.5202 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02484: val_loss did not improve from 0.41762\n",
      "Epoch 2485/3000\n",
      "13/13 - 0s - loss: 0.2130 - accuracy: 0.9027 - val_loss: 0.5365 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02485: val_loss did not improve from 0.41762\n",
      "Epoch 2486/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.8988 - val_loss: 0.5492 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02486: val_loss did not improve from 0.41762\n",
      "Epoch 2487/3000\n",
      "13/13 - 0s - loss: 0.2166 - accuracy: 0.8988 - val_loss: 0.5551 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02487: val_loss did not improve from 0.41762\n",
      "Epoch 2488/3000\n",
      "13/13 - 0s - loss: 0.2146 - accuracy: 0.8911 - val_loss: 0.5170 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02488: val_loss did not improve from 0.41762\n",
      "Epoch 2489/3000\n",
      "13/13 - 0s - loss: 0.2142 - accuracy: 0.8911 - val_loss: 0.5022 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02489: val_loss did not improve from 0.41762\n",
      "Epoch 2490/3000\n",
      "13/13 - 0s - loss: 0.2117 - accuracy: 0.8936 - val_loss: 0.5074 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02490: val_loss did not improve from 0.41762\n",
      "Epoch 2491/3000\n",
      "13/13 - 0s - loss: 0.2179 - accuracy: 0.8949 - val_loss: 0.5194 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02491: val_loss did not improve from 0.41762\n",
      "Epoch 2492/3000\n",
      "13/13 - 0s - loss: 0.2155 - accuracy: 0.8975 - val_loss: 0.5339 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 02492: val_loss did not improve from 0.41762\n",
      "Epoch 2493/3000\n",
      "13/13 - 0s - loss: 0.2154 - accuracy: 0.8936 - val_loss: 0.4890 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02493: val_loss did not improve from 0.41762\n",
      "Epoch 2494/3000\n",
      "13/13 - 0s - loss: 0.2129 - accuracy: 0.8949 - val_loss: 0.5140 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02494: val_loss did not improve from 0.41762\n",
      "Epoch 2495/3000\n",
      "13/13 - 0s - loss: 0.2138 - accuracy: 0.8975 - val_loss: 0.5199 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02495: val_loss did not improve from 0.41762\n",
      "Epoch 2496/3000\n",
      "13/13 - 0s - loss: 0.2106 - accuracy: 0.9053 - val_loss: 0.5148 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02496: val_loss did not improve from 0.41762\n",
      "Epoch 2497/3000\n",
      "13/13 - 0s - loss: 0.2082 - accuracy: 0.9027 - val_loss: 0.5222 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02497: val_loss did not improve from 0.41762\n",
      "Epoch 2498/3000\n",
      "13/13 - 0s - loss: 0.2131 - accuracy: 0.8949 - val_loss: 0.5081 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02498: val_loss did not improve from 0.41762\n",
      "Epoch 2499/3000\n",
      "13/13 - 0s - loss: 0.2099 - accuracy: 0.9027 - val_loss: 0.5279 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02499: val_loss did not improve from 0.41762\n",
      "Epoch 2500/3000\n",
      "13/13 - 0s - loss: 0.2099 - accuracy: 0.9001 - val_loss: 0.5300 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02500: val_loss did not improve from 0.41762\n",
      "Epoch 2501/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.8975 - val_loss: 0.5307 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02501: val_loss did not improve from 0.41762\n",
      "Epoch 2502/3000\n",
      "13/13 - 0s - loss: 0.2099 - accuracy: 0.8949 - val_loss: 0.5247 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02502: val_loss did not improve from 0.41762\n",
      "Epoch 2503/3000\n",
      "13/13 - 0s - loss: 0.2200 - accuracy: 0.8833 - val_loss: 0.5154 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02503: val_loss did not improve from 0.41762\n",
      "Epoch 2504/3000\n",
      "13/13 - 0s - loss: 0.2168 - accuracy: 0.8833 - val_loss: 0.5349 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02504: val_loss did not improve from 0.41762\n",
      "Epoch 2505/3000\n",
      "13/13 - 0s - loss: 0.2277 - accuracy: 0.9014 - val_loss: 0.5672 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02505: val_loss did not improve from 0.41762\n",
      "Epoch 2506/3000\n",
      "13/13 - 0s - loss: 0.2219 - accuracy: 0.8975 - val_loss: 0.5134 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02506: val_loss did not improve from 0.41762\n",
      "Epoch 2507/3000\n",
      "13/13 - 0s - loss: 0.2157 - accuracy: 0.8962 - val_loss: 0.5126 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02507: val_loss did not improve from 0.41762\n",
      "Epoch 2508/3000\n",
      "13/13 - 0s - loss: 0.2124 - accuracy: 0.8949 - val_loss: 0.4995 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02508: val_loss did not improve from 0.41762\n",
      "Epoch 2509/3000\n",
      "13/13 - 0s - loss: 0.2204 - accuracy: 0.8898 - val_loss: 0.5139 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02509: val_loss did not improve from 0.41762\n",
      "Epoch 2510/3000\n",
      "13/13 - 0s - loss: 0.2236 - accuracy: 0.9014 - val_loss: 0.5983 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02510: val_loss did not improve from 0.41762\n",
      "Epoch 2511/3000\n",
      "13/13 - 0s - loss: 0.2181 - accuracy: 0.8962 - val_loss: 0.5430 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02511: val_loss did not improve from 0.41762\n",
      "Epoch 2512/3000\n",
      "13/13 - 0s - loss: 0.2150 - accuracy: 0.8975 - val_loss: 0.5471 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02512: val_loss did not improve from 0.41762\n",
      "Epoch 2513/3000\n",
      "13/13 - 0s - loss: 0.2105 - accuracy: 0.9014 - val_loss: 0.5125 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02513: val_loss did not improve from 0.41762\n",
      "Epoch 2514/3000\n",
      "13/13 - 0s - loss: 0.2134 - accuracy: 0.8962 - val_loss: 0.5167 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02514: val_loss did not improve from 0.41762\n",
      "Epoch 2515/3000\n",
      "13/13 - 0s - loss: 0.2103 - accuracy: 0.9014 - val_loss: 0.5400 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02515: val_loss did not improve from 0.41762\n",
      "Epoch 2516/3000\n",
      "13/13 - 0s - loss: 0.2145 - accuracy: 0.9027 - val_loss: 0.5288 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02516: val_loss did not improve from 0.41762\n",
      "Epoch 2517/3000\n",
      "13/13 - 0s - loss: 0.2162 - accuracy: 0.8975 - val_loss: 0.5377 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02517: val_loss did not improve from 0.41762\n",
      "Epoch 2518/3000\n",
      "13/13 - 0s - loss: 0.2186 - accuracy: 0.8949 - val_loss: 0.5438 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02518: val_loss did not improve from 0.41762\n",
      "Epoch 2519/3000\n",
      "13/13 - 0s - loss: 0.2152 - accuracy: 0.8859 - val_loss: 0.5451 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02519: val_loss did not improve from 0.41762\n",
      "Epoch 2520/3000\n",
      "13/13 - 0s - loss: 0.2096 - accuracy: 0.8949 - val_loss: 0.5276 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02520: val_loss did not improve from 0.41762\n",
      "Epoch 2521/3000\n",
      "13/13 - 0s - loss: 0.2113 - accuracy: 0.8923 - val_loss: 0.5274 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02521: val_loss did not improve from 0.41762\n",
      "Epoch 2522/3000\n",
      "13/13 - 0s - loss: 0.2189 - accuracy: 0.8962 - val_loss: 0.5345 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02522: val_loss did not improve from 0.41762\n",
      "Epoch 2523/3000\n",
      "13/13 - 0s - loss: 0.2274 - accuracy: 0.8794 - val_loss: 0.5131 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02523: val_loss did not improve from 0.41762\n",
      "Epoch 2524/3000\n",
      "13/13 - 0s - loss: 0.2150 - accuracy: 0.8885 - val_loss: 0.5322 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02524: val_loss did not improve from 0.41762\n",
      "Epoch 2525/3000\n",
      "13/13 - 0s - loss: 0.2180 - accuracy: 0.8962 - val_loss: 0.5381 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02525: val_loss did not improve from 0.41762\n",
      "Epoch 2526/3000\n",
      "13/13 - 0s - loss: 0.2126 - accuracy: 0.8962 - val_loss: 0.5416 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02526: val_loss did not improve from 0.41762\n",
      "Epoch 2527/3000\n",
      "13/13 - 0s - loss: 0.2097 - accuracy: 0.8962 - val_loss: 0.5351 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02527: val_loss did not improve from 0.41762\n",
      "Epoch 2528/3000\n",
      "13/13 - 0s - loss: 0.2078 - accuracy: 0.9014 - val_loss: 0.5162 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02528: val_loss did not improve from 0.41762\n",
      "Epoch 2529/3000\n",
      "13/13 - 0s - loss: 0.2060 - accuracy: 0.9027 - val_loss: 0.5222 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02529: val_loss did not improve from 0.41762\n",
      "Epoch 2530/3000\n",
      "13/13 - 0s - loss: 0.2083 - accuracy: 0.9001 - val_loss: 0.5284 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02530: val_loss did not improve from 0.41762\n",
      "Epoch 2531/3000\n",
      "13/13 - 0s - loss: 0.2103 - accuracy: 0.9014 - val_loss: 0.5414 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02531: val_loss did not improve from 0.41762\n",
      "Epoch 2532/3000\n",
      "13/13 - 0s - loss: 0.2116 - accuracy: 0.9014 - val_loss: 0.5367 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02532: val_loss did not improve from 0.41762\n",
      "Epoch 2533/3000\n",
      "13/13 - 0s - loss: 0.2156 - accuracy: 0.8975 - val_loss: 0.5299 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02533: val_loss did not improve from 0.41762\n",
      "Epoch 2534/3000\n",
      "13/13 - 0s - loss: 0.2192 - accuracy: 0.8936 - val_loss: 0.5526 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02534: val_loss did not improve from 0.41762\n",
      "Epoch 2535/3000\n",
      "13/13 - 0s - loss: 0.2229 - accuracy: 0.8988 - val_loss: 0.5563 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02535: val_loss did not improve from 0.41762\n",
      "Epoch 2536/3000\n",
      "13/13 - 0s - loss: 0.2257 - accuracy: 0.9027 - val_loss: 0.5547 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02536: val_loss did not improve from 0.41762\n",
      "Epoch 2537/3000\n",
      "13/13 - 0s - loss: 0.2165 - accuracy: 0.9001 - val_loss: 0.5332 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02537: val_loss did not improve from 0.41762\n",
      "Epoch 2538/3000\n",
      "13/13 - 0s - loss: 0.2118 - accuracy: 0.9014 - val_loss: 0.5305 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02538: val_loss did not improve from 0.41762\n",
      "Epoch 2539/3000\n",
      "13/13 - 0s - loss: 0.2092 - accuracy: 0.9027 - val_loss: 0.5407 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02539: val_loss did not improve from 0.41762\n",
      "Epoch 2540/3000\n",
      "13/13 - 0s - loss: 0.2146 - accuracy: 0.9027 - val_loss: 0.5383 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02540: val_loss did not improve from 0.41762\n",
      "Epoch 2541/3000\n",
      "13/13 - 0s - loss: 0.2066 - accuracy: 0.9001 - val_loss: 0.5334 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02541: val_loss did not improve from 0.41762\n",
      "Epoch 2542/3000\n",
      "13/13 - 0s - loss: 0.2213 - accuracy: 0.8859 - val_loss: 0.5211 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02542: val_loss did not improve from 0.41762\n",
      "Epoch 2543/3000\n",
      "13/13 - 0s - loss: 0.2125 - accuracy: 0.9014 - val_loss: 0.5152 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02543: val_loss did not improve from 0.41762\n",
      "Epoch 2544/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.9014 - val_loss: 0.5288 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02544: val_loss did not improve from 0.41762\n",
      "Epoch 2545/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.9014 - val_loss: 0.5252 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02545: val_loss did not improve from 0.41762\n",
      "Epoch 2546/3000\n",
      "13/13 - 0s - loss: 0.2077 - accuracy: 0.9001 - val_loss: 0.5234 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02546: val_loss did not improve from 0.41762\n",
      "Epoch 2547/3000\n",
      "13/13 - 0s - loss: 0.2065 - accuracy: 0.9027 - val_loss: 0.5302 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02547: val_loss did not improve from 0.41762\n",
      "Epoch 2548/3000\n",
      "13/13 - 0s - loss: 0.2076 - accuracy: 0.8975 - val_loss: 0.5315 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02548: val_loss did not improve from 0.41762\n",
      "Epoch 2549/3000\n",
      "13/13 - 0s - loss: 0.2056 - accuracy: 0.9027 - val_loss: 0.5456 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02549: val_loss did not improve from 0.41762\n",
      "Epoch 2550/3000\n",
      "13/13 - 0s - loss: 0.2083 - accuracy: 0.9014 - val_loss: 0.5327 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02550: val_loss did not improve from 0.41762\n",
      "Epoch 2551/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.9040 - val_loss: 0.5455 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02551: val_loss did not improve from 0.41762\n",
      "Epoch 2552/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.9014 - val_loss: 0.5368 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02552: val_loss did not improve from 0.41762\n",
      "Epoch 2553/3000\n",
      "13/13 - 0s - loss: 0.2077 - accuracy: 0.9027 - val_loss: 0.5261 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02553: val_loss did not improve from 0.41762\n",
      "Epoch 2554/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.9014 - val_loss: 0.5227 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02554: val_loss did not improve from 0.41762\n",
      "Epoch 2555/3000\n",
      "13/13 - 0s - loss: 0.2112 - accuracy: 0.8962 - val_loss: 0.5418 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02555: val_loss did not improve from 0.41762\n",
      "Epoch 2556/3000\n",
      "13/13 - 0s - loss: 0.2080 - accuracy: 0.9001 - val_loss: 0.5394 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02556: val_loss did not improve from 0.41762\n",
      "Epoch 2557/3000\n",
      "13/13 - 0s - loss: 0.2141 - accuracy: 0.9014 - val_loss: 0.5827 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02557: val_loss did not improve from 0.41762\n",
      "Epoch 2558/3000\n",
      "13/13 - 0s - loss: 0.2155 - accuracy: 0.9001 - val_loss: 0.5498 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02558: val_loss did not improve from 0.41762\n",
      "Epoch 2559/3000\n",
      "13/13 - 0s - loss: 0.2094 - accuracy: 0.9014 - val_loss: 0.5231 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02559: val_loss did not improve from 0.41762\n",
      "Epoch 2560/3000\n",
      "13/13 - 0s - loss: 0.2133 - accuracy: 0.8988 - val_loss: 0.5185 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02560: val_loss did not improve from 0.41762\n",
      "Epoch 2561/3000\n",
      "13/13 - 0s - loss: 0.2150 - accuracy: 0.9014 - val_loss: 0.5273 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02561: val_loss did not improve from 0.41762\n",
      "Epoch 2562/3000\n",
      "13/13 - 0s - loss: 0.2193 - accuracy: 0.8975 - val_loss: 0.5424 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02562: val_loss did not improve from 0.41762\n",
      "Epoch 2563/3000\n",
      "13/13 - 0s - loss: 0.2192 - accuracy: 0.9014 - val_loss: 0.5336 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02563: val_loss did not improve from 0.41762\n",
      "Epoch 2564/3000\n",
      "13/13 - 0s - loss: 0.2354 - accuracy: 0.8768 - val_loss: 0.5424 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02564: val_loss did not improve from 0.41762\n",
      "Epoch 2565/3000\n",
      "13/13 - 0s - loss: 0.2207 - accuracy: 0.8923 - val_loss: 0.5546 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02565: val_loss did not improve from 0.41762\n",
      "Epoch 2566/3000\n",
      "13/13 - 0s - loss: 0.2114 - accuracy: 0.8962 - val_loss: 0.5432 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02566: val_loss did not improve from 0.41762\n",
      "Epoch 2567/3000\n",
      "13/13 - 0s - loss: 0.2080 - accuracy: 0.9001 - val_loss: 0.5419 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02567: val_loss did not improve from 0.41762\n",
      "Epoch 2568/3000\n",
      "13/13 - 0s - loss: 0.2101 - accuracy: 0.9027 - val_loss: 0.5508 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02568: val_loss did not improve from 0.41762\n",
      "Epoch 2569/3000\n",
      "13/13 - 0s - loss: 0.2129 - accuracy: 0.9014 - val_loss: 0.5312 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02569: val_loss did not improve from 0.41762\n",
      "Epoch 2570/3000\n",
      "13/13 - 0s - loss: 0.2148 - accuracy: 0.8962 - val_loss: 0.5152 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02570: val_loss did not improve from 0.41762\n",
      "Epoch 2571/3000\n",
      "13/13 - 0s - loss: 0.2140 - accuracy: 0.8962 - val_loss: 0.5425 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02571: val_loss did not improve from 0.41762\n",
      "Epoch 2572/3000\n",
      "13/13 - 0s - loss: 0.2078 - accuracy: 0.9014 - val_loss: 0.5241 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02572: val_loss did not improve from 0.41762\n",
      "Epoch 2573/3000\n",
      "13/13 - 0s - loss: 0.2121 - accuracy: 0.8911 - val_loss: 0.5167 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02573: val_loss did not improve from 0.41762\n",
      "Epoch 2574/3000\n",
      "13/13 - 0s - loss: 0.2104 - accuracy: 0.9001 - val_loss: 0.5153 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02574: val_loss did not improve from 0.41762\n",
      "Epoch 2575/3000\n",
      "13/13 - 0s - loss: 0.2106 - accuracy: 0.9014 - val_loss: 0.5467 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02575: val_loss did not improve from 0.41762\n",
      "Epoch 2576/3000\n",
      "13/13 - 0s - loss: 0.2185 - accuracy: 0.9014 - val_loss: 0.5333 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02576: val_loss did not improve from 0.41762\n",
      "Epoch 2577/3000\n",
      "13/13 - 0s - loss: 0.2161 - accuracy: 0.9001 - val_loss: 0.5160 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02577: val_loss did not improve from 0.41762\n",
      "Epoch 2578/3000\n",
      "13/13 - 0s - loss: 0.2108 - accuracy: 0.8975 - val_loss: 0.5269 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02578: val_loss did not improve from 0.41762\n",
      "Epoch 2579/3000\n",
      "13/13 - 0s - loss: 0.2086 - accuracy: 0.8988 - val_loss: 0.5319 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02579: val_loss did not improve from 0.41762\n",
      "Epoch 2580/3000\n",
      "13/13 - 0s - loss: 0.2058 - accuracy: 0.9001 - val_loss: 0.5286 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02580: val_loss did not improve from 0.41762\n",
      "Epoch 2581/3000\n",
      "13/13 - 0s - loss: 0.2066 - accuracy: 0.8975 - val_loss: 0.5307 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02581: val_loss did not improve from 0.41762\n",
      "Epoch 2582/3000\n",
      "13/13 - 0s - loss: 0.2059 - accuracy: 0.9001 - val_loss: 0.5303 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02582: val_loss did not improve from 0.41762\n",
      "Epoch 2583/3000\n",
      "13/13 - 0s - loss: 0.2064 - accuracy: 0.8988 - val_loss: 0.5361 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02583: val_loss did not improve from 0.41762\n",
      "Epoch 2584/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.9001 - val_loss: 0.5461 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02584: val_loss did not improve from 0.41762\n",
      "Epoch 2585/3000\n",
      "13/13 - 0s - loss: 0.2085 - accuracy: 0.9014 - val_loss: 0.5444 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02585: val_loss did not improve from 0.41762\n",
      "Epoch 2586/3000\n",
      "13/13 - 0s - loss: 0.2088 - accuracy: 0.9014 - val_loss: 0.5344 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02586: val_loss did not improve from 0.41762\n",
      "Epoch 2587/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.9001 - val_loss: 0.5443 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02587: val_loss did not improve from 0.41762\n",
      "Epoch 2588/3000\n",
      "13/13 - 0s - loss: 0.2158 - accuracy: 0.9027 - val_loss: 0.5579 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02588: val_loss did not improve from 0.41762\n",
      "Epoch 2589/3000\n",
      "13/13 - 0s - loss: 0.2142 - accuracy: 0.8949 - val_loss: 0.5703 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02589: val_loss did not improve from 0.41762\n",
      "Epoch 2590/3000\n",
      "13/13 - 0s - loss: 0.2161 - accuracy: 0.8949 - val_loss: 0.5665 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02590: val_loss did not improve from 0.41762\n",
      "Epoch 2591/3000\n",
      "13/13 - 0s - loss: 0.2116 - accuracy: 0.8936 - val_loss: 0.5280 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02591: val_loss did not improve from 0.41762\n",
      "Epoch 2592/3000\n",
      "13/13 - 0s - loss: 0.2048 - accuracy: 0.9001 - val_loss: 0.5287 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02592: val_loss did not improve from 0.41762\n",
      "Epoch 2593/3000\n",
      "13/13 - 0s - loss: 0.2210 - accuracy: 0.8911 - val_loss: 0.5328 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02593: val_loss did not improve from 0.41762\n",
      "Epoch 2594/3000\n",
      "13/13 - 0s - loss: 0.2200 - accuracy: 0.8872 - val_loss: 0.5397 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02594: val_loss did not improve from 0.41762\n",
      "Epoch 2595/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.8988 - val_loss: 0.5333 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02595: val_loss did not improve from 0.41762\n",
      "Epoch 2596/3000\n",
      "13/13 - 0s - loss: 0.2121 - accuracy: 0.8988 - val_loss: 0.5265 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 02596: val_loss did not improve from 0.41762\n",
      "Epoch 2597/3000\n",
      "13/13 - 0s - loss: 0.2164 - accuracy: 0.8975 - val_loss: 0.5646 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02597: val_loss did not improve from 0.41762\n",
      "Epoch 2598/3000\n",
      "13/13 - 0s - loss: 0.2244 - accuracy: 0.8988 - val_loss: 0.5464 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02598: val_loss did not improve from 0.41762\n",
      "Epoch 2599/3000\n",
      "13/13 - 0s - loss: 0.2159 - accuracy: 0.9001 - val_loss: 0.5416 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02599: val_loss did not improve from 0.41762\n",
      "Epoch 2600/3000\n",
      "13/13 - 0s - loss: 0.2110 - accuracy: 0.8975 - val_loss: 0.5252 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02600: val_loss did not improve from 0.41762\n",
      "Epoch 2601/3000\n",
      "13/13 - 0s - loss: 0.2198 - accuracy: 0.9001 - val_loss: 0.5359 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02601: val_loss did not improve from 0.41762\n",
      "Epoch 2602/3000\n",
      "13/13 - 0s - loss: 0.2142 - accuracy: 0.9001 - val_loss: 0.5109 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02602: val_loss did not improve from 0.41762\n",
      "Epoch 2603/3000\n",
      "13/13 - 0s - loss: 0.2103 - accuracy: 0.9014 - val_loss: 0.5029 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02603: val_loss did not improve from 0.41762\n",
      "Epoch 2604/3000\n",
      "13/13 - 0s - loss: 0.2087 - accuracy: 0.9014 - val_loss: 0.5020 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02604: val_loss did not improve from 0.41762\n",
      "Epoch 2605/3000\n",
      "13/13 - 0s - loss: 0.2097 - accuracy: 0.8962 - val_loss: 0.5273 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02605: val_loss did not improve from 0.41762\n",
      "Epoch 2606/3000\n",
      "13/13 - 0s - loss: 0.2101 - accuracy: 0.8962 - val_loss: 0.5406 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02606: val_loss did not improve from 0.41762\n",
      "Epoch 2607/3000\n",
      "13/13 - 0s - loss: 0.2069 - accuracy: 0.8975 - val_loss: 0.5252 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02607: val_loss did not improve from 0.41762\n",
      "Epoch 2608/3000\n",
      "13/13 - 0s - loss: 0.2060 - accuracy: 0.8988 - val_loss: 0.5262 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02608: val_loss did not improve from 0.41762\n",
      "Epoch 2609/3000\n",
      "13/13 - 0s - loss: 0.2095 - accuracy: 0.9001 - val_loss: 0.5668 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02609: val_loss did not improve from 0.41762\n",
      "Epoch 2610/3000\n",
      "13/13 - 0s - loss: 0.2211 - accuracy: 0.8988 - val_loss: 0.5651 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02610: val_loss did not improve from 0.41762\n",
      "Epoch 2611/3000\n",
      "13/13 - 0s - loss: 0.2137 - accuracy: 0.8833 - val_loss: 0.5317 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02611: val_loss did not improve from 0.41762\n",
      "Epoch 2612/3000\n",
      "13/13 - 0s - loss: 0.2145 - accuracy: 0.8898 - val_loss: 0.5621 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02612: val_loss did not improve from 0.41762\n",
      "Epoch 2613/3000\n",
      "13/13 - 0s - loss: 0.2159 - accuracy: 0.8911 - val_loss: 0.5408 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02613: val_loss did not improve from 0.41762\n",
      "Epoch 2614/3000\n",
      "13/13 - 0s - loss: 0.2386 - accuracy: 0.8833 - val_loss: 0.5432 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02614: val_loss did not improve from 0.41762\n",
      "Epoch 2615/3000\n",
      "13/13 - 0s - loss: 0.2111 - accuracy: 0.8962 - val_loss: 0.5477 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02615: val_loss did not improve from 0.41762\n",
      "Epoch 2616/3000\n",
      "13/13 - 0s - loss: 0.2185 - accuracy: 0.8988 - val_loss: 0.5672 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02616: val_loss did not improve from 0.41762\n",
      "Epoch 2617/3000\n",
      "13/13 - 0s - loss: 0.2144 - accuracy: 0.8988 - val_loss: 0.5421 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02617: val_loss did not improve from 0.41762\n",
      "Epoch 2618/3000\n",
      "13/13 - 0s - loss: 0.2104 - accuracy: 0.8962 - val_loss: 0.5561 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02618: val_loss did not improve from 0.41762\n",
      "Epoch 2619/3000\n",
      "13/13 - 0s - loss: 0.2118 - accuracy: 0.8949 - val_loss: 0.5600 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 02619: val_loss did not improve from 0.41762\n",
      "Epoch 2620/3000\n",
      "13/13 - 0s - loss: 0.2114 - accuracy: 0.8911 - val_loss: 0.5550 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02620: val_loss did not improve from 0.41762\n",
      "Epoch 2621/3000\n",
      "13/13 - 0s - loss: 0.2225 - accuracy: 0.8885 - val_loss: 0.5449 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02621: val_loss did not improve from 0.41762\n",
      "Epoch 2622/3000\n",
      "13/13 - 0s - loss: 0.2136 - accuracy: 0.8872 - val_loss: 0.5397 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02622: val_loss did not improve from 0.41762\n",
      "Epoch 2623/3000\n",
      "13/13 - 0s - loss: 0.2077 - accuracy: 0.9027 - val_loss: 0.5557 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02623: val_loss did not improve from 0.41762\n",
      "Epoch 2624/3000\n",
      "13/13 - 0s - loss: 0.2134 - accuracy: 0.8975 - val_loss: 0.5710 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02624: val_loss did not improve from 0.41762\n",
      "Epoch 2625/3000\n",
      "13/13 - 0s - loss: 0.2102 - accuracy: 0.8975 - val_loss: 0.5433 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02625: val_loss did not improve from 0.41762\n",
      "Epoch 2626/3000\n",
      "13/13 - 0s - loss: 0.2069 - accuracy: 0.9027 - val_loss: 0.5418 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02626: val_loss did not improve from 0.41762\n",
      "Epoch 2627/3000\n",
      "13/13 - 0s - loss: 0.2161 - accuracy: 0.8885 - val_loss: 0.5413 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02627: val_loss did not improve from 0.41762\n",
      "Epoch 2628/3000\n",
      "13/13 - 0s - loss: 0.2196 - accuracy: 0.8936 - val_loss: 0.5805 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 02628: val_loss did not improve from 0.41762\n",
      "Epoch 2629/3000\n",
      "13/13 - 0s - loss: 0.2204 - accuracy: 0.8911 - val_loss: 0.5456 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 02629: val_loss did not improve from 0.41762\n",
      "Epoch 2630/3000\n",
      "13/13 - 0s - loss: 0.2140 - accuracy: 0.9027 - val_loss: 0.5427 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02630: val_loss did not improve from 0.41762\n",
      "Epoch 2631/3000\n",
      "13/13 - 0s - loss: 0.2094 - accuracy: 0.8962 - val_loss: 0.5522 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02631: val_loss did not improve from 0.41762\n",
      "Epoch 2632/3000\n",
      "13/13 - 0s - loss: 0.2144 - accuracy: 0.8975 - val_loss: 0.5433 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 02632: val_loss did not improve from 0.41762\n",
      "Epoch 2633/3000\n",
      "13/13 - 0s - loss: 0.2078 - accuracy: 0.8936 - val_loss: 0.5359 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 02633: val_loss did not improve from 0.41762\n",
      "Epoch 2634/3000\n",
      "13/13 - 0s - loss: 0.2082 - accuracy: 0.8949 - val_loss: 0.5210 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02634: val_loss did not improve from 0.41762\n",
      "Epoch 2635/3000\n",
      "13/13 - 0s - loss: 0.2064 - accuracy: 0.8975 - val_loss: 0.5408 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 02635: val_loss did not improve from 0.41762\n",
      "Epoch 2636/3000\n",
      "13/13 - 0s - loss: 0.2171 - accuracy: 0.8975 - val_loss: 0.5218 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02636: val_loss did not improve from 0.41762\n",
      "Epoch 2637/3000\n",
      "13/13 - 0s - loss: 0.2159 - accuracy: 0.8885 - val_loss: 0.5151 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02637: val_loss did not improve from 0.41762\n",
      "Epoch 2638/3000\n",
      "13/13 - 0s - loss: 0.2088 - accuracy: 0.9014 - val_loss: 0.5533 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02638: val_loss did not improve from 0.41762\n",
      "Epoch 2639/3000\n",
      "13/13 - 0s - loss: 0.2180 - accuracy: 0.8949 - val_loss: 0.5496 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02639: val_loss did not improve from 0.41762\n",
      "Epoch 2640/3000\n",
      "13/13 - 0s - loss: 0.2174 - accuracy: 0.8872 - val_loss: 0.5465 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02640: val_loss did not improve from 0.41762\n",
      "Epoch 2641/3000\n",
      "13/13 - 0s - loss: 0.2146 - accuracy: 0.8988 - val_loss: 0.5482 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02641: val_loss did not improve from 0.41762\n",
      "Epoch 2642/3000\n",
      "13/13 - 0s - loss: 0.2228 - accuracy: 0.8794 - val_loss: 0.5637 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02642: val_loss did not improve from 0.41762\n",
      "Epoch 2643/3000\n",
      "13/13 - 0s - loss: 0.2134 - accuracy: 0.9001 - val_loss: 0.5482 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02643: val_loss did not improve from 0.41762\n",
      "Epoch 2644/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.9014 - val_loss: 0.5554 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02644: val_loss did not improve from 0.41762\n",
      "Epoch 2645/3000\n",
      "13/13 - 0s - loss: 0.2086 - accuracy: 0.9027 - val_loss: 0.5493 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02645: val_loss did not improve from 0.41762\n",
      "Epoch 2646/3000\n",
      "13/13 - 0s - loss: 0.2096 - accuracy: 0.9014 - val_loss: 0.5438 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02646: val_loss did not improve from 0.41762\n",
      "Epoch 2647/3000\n",
      "13/13 - 0s - loss: 0.2182 - accuracy: 0.8936 - val_loss: 0.5505 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02647: val_loss did not improve from 0.41762\n",
      "Epoch 2648/3000\n",
      "13/13 - 0s - loss: 0.2186 - accuracy: 0.8833 - val_loss: 0.5519 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02648: val_loss did not improve from 0.41762\n",
      "Epoch 2649/3000\n",
      "13/13 - 0s - loss: 0.2198 - accuracy: 0.8936 - val_loss: 0.5242 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02649: val_loss did not improve from 0.41762\n",
      "Epoch 2650/3000\n",
      "13/13 - 0s - loss: 0.2215 - accuracy: 0.8936 - val_loss: 0.5000 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 02650: val_loss did not improve from 0.41762\n",
      "Epoch 2651/3000\n",
      "13/13 - 0s - loss: 0.2145 - accuracy: 0.8936 - val_loss: 0.5412 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02651: val_loss did not improve from 0.41762\n",
      "Epoch 2652/3000\n",
      "13/13 - 0s - loss: 0.2227 - accuracy: 0.8911 - val_loss: 0.5182 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02652: val_loss did not improve from 0.41762\n",
      "Epoch 2653/3000\n",
      "13/13 - 0s - loss: 0.2216 - accuracy: 0.8911 - val_loss: 0.4992 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02653: val_loss did not improve from 0.41762\n",
      "Epoch 2654/3000\n",
      "13/13 - 0s - loss: 0.2164 - accuracy: 0.8975 - val_loss: 0.5048 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02654: val_loss did not improve from 0.41762\n",
      "Epoch 2655/3000\n",
      "13/13 - 0s - loss: 0.2249 - accuracy: 0.8936 - val_loss: 0.5766 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02655: val_loss did not improve from 0.41762\n",
      "Epoch 2656/3000\n",
      "13/13 - 0s - loss: 0.2181 - accuracy: 0.8988 - val_loss: 0.5804 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02656: val_loss did not improve from 0.41762\n",
      "Epoch 2657/3000\n",
      "13/13 - 0s - loss: 0.2143 - accuracy: 0.9014 - val_loss: 0.5197 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02657: val_loss did not improve from 0.41762\n",
      "Epoch 2658/3000\n",
      "13/13 - 0s - loss: 0.2086 - accuracy: 0.9001 - val_loss: 0.5178 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02658: val_loss did not improve from 0.41762\n",
      "Epoch 2659/3000\n",
      "13/13 - 0s - loss: 0.2086 - accuracy: 0.9027 - val_loss: 0.5274 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02659: val_loss did not improve from 0.41762\n",
      "Epoch 2660/3000\n",
      "13/13 - 0s - loss: 0.2195 - accuracy: 0.8988 - val_loss: 0.5802 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02660: val_loss did not improve from 0.41762\n",
      "Epoch 2661/3000\n",
      "13/13 - 0s - loss: 0.2196 - accuracy: 0.8962 - val_loss: 0.5514 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02661: val_loss did not improve from 0.41762\n",
      "Epoch 2662/3000\n",
      "13/13 - 0s - loss: 0.2164 - accuracy: 0.8885 - val_loss: 0.5388 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02662: val_loss did not improve from 0.41762\n",
      "Epoch 2663/3000\n",
      "13/13 - 0s - loss: 0.2119 - accuracy: 0.8975 - val_loss: 0.5550 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02663: val_loss did not improve from 0.41762\n",
      "Epoch 2664/3000\n",
      "13/13 - 0s - loss: 0.2111 - accuracy: 0.9014 - val_loss: 0.5818 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02664: val_loss did not improve from 0.41762\n",
      "Epoch 2665/3000\n",
      "13/13 - 0s - loss: 0.2159 - accuracy: 0.8988 - val_loss: 0.5648 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02665: val_loss did not improve from 0.41762\n",
      "Epoch 2666/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.8923 - val_loss: 0.5584 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02666: val_loss did not improve from 0.41762\n",
      "Epoch 2667/3000\n",
      "13/13 - 0s - loss: 0.2083 - accuracy: 0.8949 - val_loss: 0.5676 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02667: val_loss did not improve from 0.41762\n",
      "Epoch 2668/3000\n",
      "13/13 - 0s - loss: 0.2068 - accuracy: 0.9027 - val_loss: 0.5678 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02668: val_loss did not improve from 0.41762\n",
      "Epoch 2669/3000\n",
      "13/13 - 0s - loss: 0.2078 - accuracy: 0.9014 - val_loss: 0.5677 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02669: val_loss did not improve from 0.41762\n",
      "Epoch 2670/3000\n",
      "13/13 - 0s - loss: 0.2093 - accuracy: 0.9001 - val_loss: 0.5745 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02670: val_loss did not improve from 0.41762\n",
      "Epoch 2671/3000\n",
      "13/13 - 0s - loss: 0.2109 - accuracy: 0.8988 - val_loss: 0.5919 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02671: val_loss did not improve from 0.41762\n",
      "Epoch 2672/3000\n",
      "13/13 - 0s - loss: 0.2095 - accuracy: 0.9001 - val_loss: 0.5798 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02672: val_loss did not improve from 0.41762\n",
      "Epoch 2673/3000\n",
      "13/13 - 0s - loss: 0.2102 - accuracy: 0.8949 - val_loss: 0.5682 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02673: val_loss did not improve from 0.41762\n",
      "Epoch 2674/3000\n",
      "13/13 - 0s - loss: 0.2105 - accuracy: 0.8975 - val_loss: 0.5661 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02674: val_loss did not improve from 0.41762\n",
      "Epoch 2675/3000\n",
      "13/13 - 0s - loss: 0.2109 - accuracy: 0.9001 - val_loss: 0.5589 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02675: val_loss did not improve from 0.41762\n",
      "Epoch 2676/3000\n",
      "13/13 - 0s - loss: 0.2127 - accuracy: 0.9014 - val_loss: 0.5799 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02676: val_loss did not improve from 0.41762\n",
      "Epoch 2677/3000\n",
      "13/13 - 0s - loss: 0.2131 - accuracy: 0.9001 - val_loss: 0.5671 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02677: val_loss did not improve from 0.41762\n",
      "Epoch 2678/3000\n",
      "13/13 - 0s - loss: 0.2103 - accuracy: 0.9001 - val_loss: 0.5706 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02678: val_loss did not improve from 0.41762\n",
      "Epoch 2679/3000\n",
      "13/13 - 0s - loss: 0.2134 - accuracy: 0.9027 - val_loss: 0.6177 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02679: val_loss did not improve from 0.41762\n",
      "Epoch 2680/3000\n",
      "13/13 - 0s - loss: 0.2319 - accuracy: 0.8975 - val_loss: 0.5760 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02680: val_loss did not improve from 0.41762\n",
      "Epoch 2681/3000\n",
      "13/13 - 0s - loss: 0.2248 - accuracy: 0.8975 - val_loss: 0.5728 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02681: val_loss did not improve from 0.41762\n",
      "Epoch 2682/3000\n",
      "13/13 - 0s - loss: 0.2103 - accuracy: 0.8988 - val_loss: 0.5650 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02682: val_loss did not improve from 0.41762\n",
      "Epoch 2683/3000\n",
      "13/13 - 0s - loss: 0.2064 - accuracy: 0.9001 - val_loss: 0.5729 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02683: val_loss did not improve from 0.41762\n",
      "Epoch 2684/3000\n",
      "13/13 - 0s - loss: 0.2049 - accuracy: 0.8988 - val_loss: 0.6005 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02684: val_loss did not improve from 0.41762\n",
      "Epoch 2685/3000\n",
      "13/13 - 0s - loss: 0.2086 - accuracy: 0.9027 - val_loss: 0.5831 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02685: val_loss did not improve from 0.41762\n",
      "Epoch 2686/3000\n",
      "13/13 - 0s - loss: 0.2179 - accuracy: 0.9001 - val_loss: 0.5893 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 02686: val_loss did not improve from 0.41762\n",
      "Epoch 2687/3000\n",
      "13/13 - 0s - loss: 0.2137 - accuracy: 0.8859 - val_loss: 0.5563 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02687: val_loss did not improve from 0.41762\n",
      "Epoch 2688/3000\n",
      "13/13 - 0s - loss: 0.2166 - accuracy: 0.8872 - val_loss: 0.6040 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02688: val_loss did not improve from 0.41762\n",
      "Epoch 2689/3000\n",
      "13/13 - 0s - loss: 0.2217 - accuracy: 0.8885 - val_loss: 0.5506 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02689: val_loss did not improve from 0.41762\n",
      "Epoch 2690/3000\n",
      "13/13 - 0s - loss: 0.2148 - accuracy: 0.8949 - val_loss: 0.5449 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02690: val_loss did not improve from 0.41762\n",
      "Epoch 2691/3000\n",
      "13/13 - 0s - loss: 0.2089 - accuracy: 0.8975 - val_loss: 0.5338 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02691: val_loss did not improve from 0.41762\n",
      "Epoch 2692/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.9014 - val_loss: 0.5376 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02692: val_loss did not improve from 0.41762\n",
      "Epoch 2693/3000\n",
      "13/13 - 0s - loss: 0.2144 - accuracy: 0.8962 - val_loss: 0.5432 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02693: val_loss did not improve from 0.41762\n",
      "Epoch 2694/3000\n",
      "13/13 - 0s - loss: 0.2100 - accuracy: 0.8962 - val_loss: 0.5540 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02694: val_loss did not improve from 0.41762\n",
      "Epoch 2695/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.8962 - val_loss: 0.5467 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02695: val_loss did not improve from 0.41762\n",
      "Epoch 2696/3000\n",
      "13/13 - 0s - loss: 0.2060 - accuracy: 0.9001 - val_loss: 0.5367 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02696: val_loss did not improve from 0.41762\n",
      "Epoch 2697/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.9001 - val_loss: 0.5473 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02697: val_loss did not improve from 0.41762\n",
      "Epoch 2698/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.8949 - val_loss: 0.5460 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02698: val_loss did not improve from 0.41762\n",
      "Epoch 2699/3000\n",
      "13/13 - 0s - loss: 0.2088 - accuracy: 0.8988 - val_loss: 0.5389 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02699: val_loss did not improve from 0.41762\n",
      "Epoch 2700/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.8962 - val_loss: 0.5429 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02700: val_loss did not improve from 0.41762\n",
      "Epoch 2701/3000\n",
      "13/13 - 0s - loss: 0.2208 - accuracy: 0.8898 - val_loss: 0.5615 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02701: val_loss did not improve from 0.41762\n",
      "Epoch 2702/3000\n",
      "13/13 - 0s - loss: 0.2284 - accuracy: 0.8988 - val_loss: 0.5926 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02702: val_loss did not improve from 0.41762\n",
      "Epoch 2703/3000\n",
      "13/13 - 0s - loss: 0.2127 - accuracy: 0.9001 - val_loss: 0.5466 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02703: val_loss did not improve from 0.41762\n",
      "Epoch 2704/3000\n",
      "13/13 - 0s - loss: 0.2085 - accuracy: 0.9014 - val_loss: 0.5483 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02704: val_loss did not improve from 0.41762\n",
      "Epoch 2705/3000\n",
      "13/13 - 0s - loss: 0.2133 - accuracy: 0.8988 - val_loss: 0.5576 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02705: val_loss did not improve from 0.41762\n",
      "Epoch 2706/3000\n",
      "13/13 - 0s - loss: 0.2076 - accuracy: 0.9027 - val_loss: 0.5447 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02706: val_loss did not improve from 0.41762\n",
      "Epoch 2707/3000\n",
      "13/13 - 0s - loss: 0.2112 - accuracy: 0.8988 - val_loss: 0.5243 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02707: val_loss did not improve from 0.41762\n",
      "Epoch 2708/3000\n",
      "13/13 - 0s - loss: 0.2243 - accuracy: 0.8911 - val_loss: 0.5088 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 02708: val_loss did not improve from 0.41762\n",
      "Epoch 2709/3000\n",
      "13/13 - 0s - loss: 0.2115 - accuracy: 0.8988 - val_loss: 0.5393 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 02709: val_loss did not improve from 0.41762\n",
      "Epoch 2710/3000\n",
      "13/13 - 0s - loss: 0.2083 - accuracy: 0.8949 - val_loss: 0.5493 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02710: val_loss did not improve from 0.41762\n",
      "Epoch 2711/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.8988 - val_loss: 0.5586 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02711: val_loss did not improve from 0.41762\n",
      "Epoch 2712/3000\n",
      "13/13 - 0s - loss: 0.2095 - accuracy: 0.9027 - val_loss: 0.5571 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02712: val_loss did not improve from 0.41762\n",
      "Epoch 2713/3000\n",
      "13/13 - 0s - loss: 0.2258 - accuracy: 0.8846 - val_loss: 0.5335 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02713: val_loss did not improve from 0.41762\n",
      "Epoch 2714/3000\n",
      "13/13 - 0s - loss: 0.2192 - accuracy: 0.8820 - val_loss: 0.5528 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02714: val_loss did not improve from 0.41762\n",
      "Epoch 2715/3000\n",
      "13/13 - 0s - loss: 0.2177 - accuracy: 0.8885 - val_loss: 0.5499 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02715: val_loss did not improve from 0.41762\n",
      "Epoch 2716/3000\n",
      "13/13 - 0s - loss: 0.2274 - accuracy: 0.8936 - val_loss: 0.5518 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02716: val_loss did not improve from 0.41762\n",
      "Epoch 2717/3000\n",
      "13/13 - 0s - loss: 0.2119 - accuracy: 0.9001 - val_loss: 0.5647 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02717: val_loss did not improve from 0.41762\n",
      "Epoch 2718/3000\n",
      "13/13 - 0s - loss: 0.2110 - accuracy: 0.9027 - val_loss: 0.5503 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02718: val_loss did not improve from 0.41762\n",
      "Epoch 2719/3000\n",
      "13/13 - 0s - loss: 0.2125 - accuracy: 0.9014 - val_loss: 0.5453 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02719: val_loss did not improve from 0.41762\n",
      "Epoch 2720/3000\n",
      "13/13 - 0s - loss: 0.2161 - accuracy: 0.8949 - val_loss: 0.5436 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02720: val_loss did not improve from 0.41762\n",
      "Epoch 2721/3000\n",
      "13/13 - 0s - loss: 0.2126 - accuracy: 0.8949 - val_loss: 0.5476 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02721: val_loss did not improve from 0.41762\n",
      "Epoch 2722/3000\n",
      "13/13 - 0s - loss: 0.2070 - accuracy: 0.9001 - val_loss: 0.5473 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02722: val_loss did not improve from 0.41762\n",
      "Epoch 2723/3000\n",
      "13/13 - 0s - loss: 0.2078 - accuracy: 0.8975 - val_loss: 0.5393 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02723: val_loss did not improve from 0.41762\n",
      "Epoch 2724/3000\n",
      "13/13 - 0s - loss: 0.2216 - accuracy: 0.8936 - val_loss: 0.5363 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02724: val_loss did not improve from 0.41762\n",
      "Epoch 2725/3000\n",
      "13/13 - 0s - loss: 0.2268 - accuracy: 0.8781 - val_loss: 0.5502 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02725: val_loss did not improve from 0.41762\n",
      "Epoch 2726/3000\n",
      "13/13 - 0s - loss: 0.2177 - accuracy: 0.8885 - val_loss: 0.5918 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 02726: val_loss did not improve from 0.41762\n",
      "Epoch 2727/3000\n",
      "13/13 - 0s - loss: 0.2129 - accuracy: 0.8975 - val_loss: 0.5418 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02727: val_loss did not improve from 0.41762\n",
      "Epoch 2728/3000\n",
      "13/13 - 0s - loss: 0.2209 - accuracy: 0.8898 - val_loss: 0.5396 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02728: val_loss did not improve from 0.41762\n",
      "Epoch 2729/3000\n",
      "13/13 - 0s - loss: 0.2144 - accuracy: 0.9014 - val_loss: 0.5630 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02729: val_loss did not improve from 0.41762\n",
      "Epoch 2730/3000\n",
      "13/13 - 0s - loss: 0.2198 - accuracy: 0.8975 - val_loss: 0.5616 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02730: val_loss did not improve from 0.41762\n",
      "Epoch 2731/3000\n",
      "13/13 - 0s - loss: 0.2155 - accuracy: 0.8911 - val_loss: 0.5288 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02731: val_loss did not improve from 0.41762\n",
      "Epoch 2732/3000\n",
      "13/13 - 0s - loss: 0.2140 - accuracy: 0.9001 - val_loss: 0.5365 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02732: val_loss did not improve from 0.41762\n",
      "Epoch 2733/3000\n",
      "13/13 - 0s - loss: 0.2066 - accuracy: 0.9014 - val_loss: 0.5461 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02733: val_loss did not improve from 0.41762\n",
      "Epoch 2734/3000\n",
      "13/13 - 0s - loss: 0.2136 - accuracy: 0.9001 - val_loss: 0.5468 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02734: val_loss did not improve from 0.41762\n",
      "Epoch 2735/3000\n",
      "13/13 - 0s - loss: 0.2144 - accuracy: 0.8962 - val_loss: 0.5822 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02735: val_loss did not improve from 0.41762\n",
      "Epoch 2736/3000\n",
      "13/13 - 0s - loss: 0.2181 - accuracy: 0.8898 - val_loss: 0.5585 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02736: val_loss did not improve from 0.41762\n",
      "Epoch 2737/3000\n",
      "13/13 - 0s - loss: 0.2169 - accuracy: 0.8885 - val_loss: 0.5681 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02737: val_loss did not improve from 0.41762\n",
      "Epoch 2738/3000\n",
      "13/13 - 0s - loss: 0.2166 - accuracy: 0.8949 - val_loss: 0.5486 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02738: val_loss did not improve from 0.41762\n",
      "Epoch 2739/3000\n",
      "13/13 - 0s - loss: 0.2129 - accuracy: 0.8911 - val_loss: 0.5334 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02739: val_loss did not improve from 0.41762\n",
      "Epoch 2740/3000\n",
      "13/13 - 0s - loss: 0.2164 - accuracy: 0.8988 - val_loss: 0.5323 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02740: val_loss did not improve from 0.41762\n",
      "Epoch 2741/3000\n",
      "13/13 - 0s - loss: 0.2191 - accuracy: 0.8988 - val_loss: 0.5491 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02741: val_loss did not improve from 0.41762\n",
      "Epoch 2742/3000\n",
      "13/13 - 0s - loss: 0.2286 - accuracy: 0.8885 - val_loss: 0.6012 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02742: val_loss did not improve from 0.41762\n",
      "Epoch 2743/3000\n",
      "13/13 - 0s - loss: 0.2182 - accuracy: 0.8923 - val_loss: 0.5612 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02743: val_loss did not improve from 0.41762\n",
      "Epoch 2744/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.9027 - val_loss: 0.5480 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02744: val_loss did not improve from 0.41762\n",
      "Epoch 2745/3000\n",
      "13/13 - 0s - loss: 0.2080 - accuracy: 0.8975 - val_loss: 0.5441 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02745: val_loss did not improve from 0.41762\n",
      "Epoch 2746/3000\n",
      "13/13 - 0s - loss: 0.2127 - accuracy: 0.9027 - val_loss: 0.5426 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02746: val_loss did not improve from 0.41762\n",
      "Epoch 2747/3000\n",
      "13/13 - 0s - loss: 0.2070 - accuracy: 0.9001 - val_loss: 0.5310 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02747: val_loss did not improve from 0.41762\n",
      "Epoch 2748/3000\n",
      "13/13 - 0s - loss: 0.2078 - accuracy: 0.8975 - val_loss: 0.5385 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02748: val_loss did not improve from 0.41762\n",
      "Epoch 2749/3000\n",
      "13/13 - 0s - loss: 0.2069 - accuracy: 0.9001 - val_loss: 0.5379 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02749: val_loss did not improve from 0.41762\n",
      "Epoch 2750/3000\n",
      "13/13 - 0s - loss: 0.2068 - accuracy: 0.9027 - val_loss: 0.5406 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02750: val_loss did not improve from 0.41762\n",
      "Epoch 2751/3000\n",
      "13/13 - 0s - loss: 0.2060 - accuracy: 0.9014 - val_loss: 0.5401 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02751: val_loss did not improve from 0.41762\n",
      "Epoch 2752/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.8923 - val_loss: 0.5449 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02752: val_loss did not improve from 0.41762\n",
      "Epoch 2753/3000\n",
      "13/13 - 0s - loss: 0.2068 - accuracy: 0.9027 - val_loss: 0.5456 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02753: val_loss did not improve from 0.41762\n",
      "Epoch 2754/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.8988 - val_loss: 0.5641 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02754: val_loss did not improve from 0.41762\n",
      "Epoch 2755/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.9001 - val_loss: 0.5567 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02755: val_loss did not improve from 0.41762\n",
      "Epoch 2756/3000\n",
      "13/13 - 0s - loss: 0.2068 - accuracy: 0.9027 - val_loss: 0.5490 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02756: val_loss did not improve from 0.41762\n",
      "Epoch 2757/3000\n",
      "13/13 - 0s - loss: 0.2083 - accuracy: 0.9001 - val_loss: 0.5713 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02757: val_loss did not improve from 0.41762\n",
      "Epoch 2758/3000\n",
      "13/13 - 0s - loss: 0.2114 - accuracy: 0.9027 - val_loss: 0.5508 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02758: val_loss did not improve from 0.41762\n",
      "Epoch 2759/3000\n",
      "13/13 - 0s - loss: 0.2112 - accuracy: 0.9001 - val_loss: 0.5441 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02759: val_loss did not improve from 0.41762\n",
      "Epoch 2760/3000\n",
      "13/13 - 0s - loss: 0.2192 - accuracy: 0.8975 - val_loss: 0.5042 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02760: val_loss did not improve from 0.41762\n",
      "Epoch 2761/3000\n",
      "13/13 - 0s - loss: 0.2185 - accuracy: 0.8962 - val_loss: 0.5378 - val_accuracy: 0.8653\n",
      "\n",
      "Epoch 02761: val_loss did not improve from 0.41762\n",
      "Epoch 2762/3000\n",
      "13/13 - 0s - loss: 0.2097 - accuracy: 0.9001 - val_loss: 0.5537 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 02762: val_loss did not improve from 0.41762\n",
      "Epoch 2763/3000\n",
      "13/13 - 0s - loss: 0.2059 - accuracy: 0.9027 - val_loss: 0.5513 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02763: val_loss did not improve from 0.41762\n",
      "Epoch 2764/3000\n",
      "13/13 - 0s - loss: 0.2136 - accuracy: 0.8911 - val_loss: 0.5387 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02764: val_loss did not improve from 0.41762\n",
      "Epoch 2765/3000\n",
      "13/13 - 0s - loss: 0.2145 - accuracy: 0.8859 - val_loss: 0.5503 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02765: val_loss did not improve from 0.41762\n",
      "Epoch 2766/3000\n",
      "13/13 - 0s - loss: 0.2082 - accuracy: 0.9027 - val_loss: 0.5783 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02766: val_loss did not improve from 0.41762\n",
      "Epoch 2767/3000\n",
      "13/13 - 0s - loss: 0.2163 - accuracy: 0.8988 - val_loss: 0.5696 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02767: val_loss did not improve from 0.41762\n",
      "Epoch 2768/3000\n",
      "13/13 - 0s - loss: 0.2159 - accuracy: 0.8949 - val_loss: 0.5563 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02768: val_loss did not improve from 0.41762\n",
      "Epoch 2769/3000\n",
      "13/13 - 0s - loss: 0.2080 - accuracy: 0.8936 - val_loss: 0.5472 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02769: val_loss did not improve from 0.41762\n",
      "Epoch 2770/3000\n",
      "13/13 - 0s - loss: 0.2085 - accuracy: 0.9014 - val_loss: 0.5570 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 02770: val_loss did not improve from 0.41762\n",
      "Epoch 2771/3000\n",
      "13/13 - 0s - loss: 0.2150 - accuracy: 0.8923 - val_loss: 0.5285 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02771: val_loss did not improve from 0.41762\n",
      "Epoch 2772/3000\n",
      "13/13 - 0s - loss: 0.2152 - accuracy: 0.8923 - val_loss: 0.5324 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02772: val_loss did not improve from 0.41762\n",
      "Epoch 2773/3000\n",
      "13/13 - 0s - loss: 0.2065 - accuracy: 0.9027 - val_loss: 0.5456 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 02773: val_loss did not improve from 0.41762\n",
      "Epoch 2774/3000\n",
      "13/13 - 0s - loss: 0.2067 - accuracy: 0.8975 - val_loss: 0.5351 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02774: val_loss did not improve from 0.41762\n",
      "Epoch 2775/3000\n",
      "13/13 - 0s - loss: 0.2234 - accuracy: 0.8846 - val_loss: 0.5252 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02775: val_loss did not improve from 0.41762\n",
      "Epoch 2776/3000\n",
      "13/13 - 0s - loss: 0.2101 - accuracy: 0.8923 - val_loss: 0.5453 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02776: val_loss did not improve from 0.41762\n",
      "Epoch 2777/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.9001 - val_loss: 0.5515 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02777: val_loss did not improve from 0.41762\n",
      "Epoch 2778/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.9014 - val_loss: 0.5280 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02778: val_loss did not improve from 0.41762\n",
      "Epoch 2779/3000\n",
      "13/13 - 0s - loss: 0.2345 - accuracy: 0.8794 - val_loss: 0.5283 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02779: val_loss did not improve from 0.41762\n",
      "Epoch 2780/3000\n",
      "13/13 - 0s - loss: 0.2245 - accuracy: 0.8859 - val_loss: 0.5487 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02780: val_loss did not improve from 0.41762\n",
      "Epoch 2781/3000\n",
      "13/13 - 0s - loss: 0.2126 - accuracy: 0.8975 - val_loss: 0.5509 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02781: val_loss did not improve from 0.41762\n",
      "Epoch 2782/3000\n",
      "13/13 - 0s - loss: 0.2144 - accuracy: 0.8975 - val_loss: 0.5600 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02782: val_loss did not improve from 0.41762\n",
      "Epoch 2783/3000\n",
      "13/13 - 0s - loss: 0.2098 - accuracy: 0.9014 - val_loss: 0.5472 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02783: val_loss did not improve from 0.41762\n",
      "Epoch 2784/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.8975 - val_loss: 0.5433 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02784: val_loss did not improve from 0.41762\n",
      "Epoch 2785/3000\n",
      "13/13 - 0s - loss: 0.2105 - accuracy: 0.9027 - val_loss: 0.5560 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02785: val_loss did not improve from 0.41762\n",
      "Epoch 2786/3000\n",
      "13/13 - 0s - loss: 0.2073 - accuracy: 0.8975 - val_loss: 0.5571 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02786: val_loss did not improve from 0.41762\n",
      "Epoch 2787/3000\n",
      "13/13 - 0s - loss: 0.2073 - accuracy: 0.9001 - val_loss: 0.5591 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02787: val_loss did not improve from 0.41762\n",
      "Epoch 2788/3000\n",
      "13/13 - 0s - loss: 0.2115 - accuracy: 0.9027 - val_loss: 0.5768 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02788: val_loss did not improve from 0.41762\n",
      "Epoch 2789/3000\n",
      "13/13 - 0s - loss: 0.2064 - accuracy: 0.9027 - val_loss: 0.5611 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02789: val_loss did not improve from 0.41762\n",
      "Epoch 2790/3000\n",
      "13/13 - 0s - loss: 0.2059 - accuracy: 0.8936 - val_loss: 0.5501 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02790: val_loss did not improve from 0.41762\n",
      "Epoch 2791/3000\n",
      "13/13 - 0s - loss: 0.2056 - accuracy: 0.9014 - val_loss: 0.5471 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02791: val_loss did not improve from 0.41762\n",
      "Epoch 2792/3000\n",
      "13/13 - 0s - loss: 0.2094 - accuracy: 0.8962 - val_loss: 0.5661 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02792: val_loss did not improve from 0.41762\n",
      "Epoch 2793/3000\n",
      "13/13 - 0s - loss: 0.2130 - accuracy: 0.8975 - val_loss: 0.5570 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02793: val_loss did not improve from 0.41762\n",
      "Epoch 2794/3000\n",
      "13/13 - 0s - loss: 0.2143 - accuracy: 0.8936 - val_loss: 0.5650 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02794: val_loss did not improve from 0.41762\n",
      "Epoch 2795/3000\n",
      "13/13 - 0s - loss: 0.2114 - accuracy: 0.9001 - val_loss: 0.5865 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02795: val_loss did not improve from 0.41762\n",
      "Epoch 2796/3000\n",
      "13/13 - 0s - loss: 0.2112 - accuracy: 0.9014 - val_loss: 0.5730 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02796: val_loss did not improve from 0.41762\n",
      "Epoch 2797/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.9014 - val_loss: 0.5527 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02797: val_loss did not improve from 0.41762\n",
      "Epoch 2798/3000\n",
      "13/13 - 0s - loss: 0.2096 - accuracy: 0.9014 - val_loss: 0.5723 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02798: val_loss did not improve from 0.41762\n",
      "Epoch 2799/3000\n",
      "13/13 - 0s - loss: 0.2065 - accuracy: 0.9001 - val_loss: 0.5553 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02799: val_loss did not improve from 0.41762\n",
      "Epoch 2800/3000\n",
      "13/13 - 0s - loss: 0.2080 - accuracy: 0.9014 - val_loss: 0.5509 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02800: val_loss did not improve from 0.41762\n",
      "Epoch 2801/3000\n",
      "13/13 - 0s - loss: 0.2047 - accuracy: 0.8975 - val_loss: 0.5505 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02801: val_loss did not improve from 0.41762\n",
      "Epoch 2802/3000\n",
      "13/13 - 0s - loss: 0.2156 - accuracy: 0.8923 - val_loss: 0.5631 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02802: val_loss did not improve from 0.41762\n",
      "Epoch 2803/3000\n",
      "13/13 - 0s - loss: 0.2248 - accuracy: 0.8911 - val_loss: 0.5545 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02803: val_loss did not improve from 0.41762\n",
      "Epoch 2804/3000\n",
      "13/13 - 0s - loss: 0.2132 - accuracy: 0.8962 - val_loss: 0.5664 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02804: val_loss did not improve from 0.41762\n",
      "Epoch 2805/3000\n",
      "13/13 - 0s - loss: 0.2224 - accuracy: 0.8885 - val_loss: 0.5553 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02805: val_loss did not improve from 0.41762\n",
      "Epoch 2806/3000\n",
      "13/13 - 0s - loss: 0.2282 - accuracy: 0.8923 - val_loss: 0.5425 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02806: val_loss did not improve from 0.41762\n",
      "Epoch 2807/3000\n",
      "13/13 - 0s - loss: 0.2120 - accuracy: 0.8975 - val_loss: 0.5745 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02807: val_loss did not improve from 0.41762\n",
      "Epoch 2808/3000\n",
      "13/13 - 0s - loss: 0.2095 - accuracy: 0.9027 - val_loss: 0.5563 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02808: val_loss did not improve from 0.41762\n",
      "Epoch 2809/3000\n",
      "13/13 - 0s - loss: 0.2100 - accuracy: 0.9027 - val_loss: 0.5516 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02809: val_loss did not improve from 0.41762\n",
      "Epoch 2810/3000\n",
      "13/13 - 0s - loss: 0.2118 - accuracy: 0.9001 - val_loss: 0.5483 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02810: val_loss did not improve from 0.41762\n",
      "Epoch 2811/3000\n",
      "13/13 - 0s - loss: 0.2089 - accuracy: 0.9027 - val_loss: 0.5415 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02811: val_loss did not improve from 0.41762\n",
      "Epoch 2812/3000\n",
      "13/13 - 0s - loss: 0.2082 - accuracy: 0.9040 - val_loss: 0.5519 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02812: val_loss did not improve from 0.41762\n",
      "Epoch 2813/3000\n",
      "13/13 - 0s - loss: 0.2080 - accuracy: 0.8988 - val_loss: 0.5519 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02813: val_loss did not improve from 0.41762\n",
      "Epoch 2814/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.8988 - val_loss: 0.5460 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02814: val_loss did not improve from 0.41762\n",
      "Epoch 2815/3000\n",
      "13/13 - 0s - loss: 0.2058 - accuracy: 0.9027 - val_loss: 0.5641 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02815: val_loss did not improve from 0.41762\n",
      "Epoch 2816/3000\n",
      "13/13 - 0s - loss: 0.2073 - accuracy: 0.9027 - val_loss: 0.5759 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02816: val_loss did not improve from 0.41762\n",
      "Epoch 2817/3000\n",
      "13/13 - 0s - loss: 0.2076 - accuracy: 0.9001 - val_loss: 0.5688 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02817: val_loss did not improve from 0.41762\n",
      "Epoch 2818/3000\n",
      "13/13 - 0s - loss: 0.2076 - accuracy: 0.9001 - val_loss: 0.5701 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02818: val_loss did not improve from 0.41762\n",
      "Epoch 2819/3000\n",
      "13/13 - 0s - loss: 0.2066 - accuracy: 0.9027 - val_loss: 0.5690 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02819: val_loss did not improve from 0.41762\n",
      "Epoch 2820/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.9001 - val_loss: 0.5727 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02820: val_loss did not improve from 0.41762\n",
      "Epoch 2821/3000\n",
      "13/13 - 0s - loss: 0.2109 - accuracy: 0.8988 - val_loss: 0.5499 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02821: val_loss did not improve from 0.41762\n",
      "Epoch 2822/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.8988 - val_loss: 0.5592 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02822: val_loss did not improve from 0.41762\n",
      "Epoch 2823/3000\n",
      "13/13 - 0s - loss: 0.2063 - accuracy: 0.9001 - val_loss: 0.5515 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02823: val_loss did not improve from 0.41762\n",
      "Epoch 2824/3000\n",
      "13/13 - 0s - loss: 0.2069 - accuracy: 0.9014 - val_loss: 0.5655 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02824: val_loss did not improve from 0.41762\n",
      "Epoch 2825/3000\n",
      "13/13 - 0s - loss: 0.2054 - accuracy: 0.9014 - val_loss: 0.5520 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02825: val_loss did not improve from 0.41762\n",
      "Epoch 2826/3000\n",
      "13/13 - 0s - loss: 0.2132 - accuracy: 0.8936 - val_loss: 0.5420 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02826: val_loss did not improve from 0.41762\n",
      "Epoch 2827/3000\n",
      "13/13 - 0s - loss: 0.2142 - accuracy: 0.8859 - val_loss: 0.5476 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02827: val_loss did not improve from 0.41762\n",
      "Epoch 2828/3000\n",
      "13/13 - 0s - loss: 0.2121 - accuracy: 0.8975 - val_loss: 0.5445 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02828: val_loss did not improve from 0.41762\n",
      "Epoch 2829/3000\n",
      "13/13 - 0s - loss: 0.2175 - accuracy: 0.8911 - val_loss: 0.5434 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02829: val_loss did not improve from 0.41762\n",
      "Epoch 2830/3000\n",
      "13/13 - 0s - loss: 0.2120 - accuracy: 0.9027 - val_loss: 0.5698 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02830: val_loss did not improve from 0.41762\n",
      "Epoch 2831/3000\n",
      "13/13 - 0s - loss: 0.2119 - accuracy: 0.8988 - val_loss: 0.5476 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02831: val_loss did not improve from 0.41762\n",
      "Epoch 2832/3000\n",
      "13/13 - 0s - loss: 0.2087 - accuracy: 0.8975 - val_loss: 0.5460 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02832: val_loss did not improve from 0.41762\n",
      "Epoch 2833/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.9001 - val_loss: 0.5606 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02833: val_loss did not improve from 0.41762\n",
      "Epoch 2834/3000\n",
      "13/13 - 0s - loss: 0.2049 - accuracy: 0.9014 - val_loss: 0.5547 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02834: val_loss did not improve from 0.41762\n",
      "Epoch 2835/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.9001 - val_loss: 0.5588 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02835: val_loss did not improve from 0.41762\n",
      "Epoch 2836/3000\n",
      "13/13 - 0s - loss: 0.2082 - accuracy: 0.8975 - val_loss: 0.5564 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02836: val_loss did not improve from 0.41762\n",
      "Epoch 2837/3000\n",
      "13/13 - 0s - loss: 0.2064 - accuracy: 0.9027 - val_loss: 0.5712 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02837: val_loss did not improve from 0.41762\n",
      "Epoch 2838/3000\n",
      "13/13 - 0s - loss: 0.2091 - accuracy: 0.9027 - val_loss: 0.5667 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02838: val_loss did not improve from 0.41762\n",
      "Epoch 2839/3000\n",
      "13/13 - 0s - loss: 0.2061 - accuracy: 0.8962 - val_loss: 0.5478 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02839: val_loss did not improve from 0.41762\n",
      "Epoch 2840/3000\n",
      "13/13 - 0s - loss: 0.2127 - accuracy: 0.9001 - val_loss: 0.5676 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02840: val_loss did not improve from 0.41762\n",
      "Epoch 2841/3000\n",
      "13/13 - 0s - loss: 0.2052 - accuracy: 0.9040 - val_loss: 0.5889 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02841: val_loss did not improve from 0.41762\n",
      "Epoch 2842/3000\n",
      "13/13 - 0s - loss: 0.2111 - accuracy: 0.9001 - val_loss: 0.5920 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02842: val_loss did not improve from 0.41762\n",
      "Epoch 2843/3000\n",
      "13/13 - 0s - loss: 0.2123 - accuracy: 0.9040 - val_loss: 0.5691 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02843: val_loss did not improve from 0.41762\n",
      "Epoch 2844/3000\n",
      "13/13 - 0s - loss: 0.2116 - accuracy: 0.8911 - val_loss: 0.5751 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02844: val_loss did not improve from 0.41762\n",
      "Epoch 2845/3000\n",
      "13/13 - 0s - loss: 0.2166 - accuracy: 0.8923 - val_loss: 0.5678 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02845: val_loss did not improve from 0.41762\n",
      "Epoch 2846/3000\n",
      "13/13 - 0s - loss: 0.2091 - accuracy: 0.9001 - val_loss: 0.5840 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02846: val_loss did not improve from 0.41762\n",
      "Epoch 2847/3000\n",
      "13/13 - 0s - loss: 0.2077 - accuracy: 0.8988 - val_loss: 0.5787 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02847: val_loss did not improve from 0.41762\n",
      "Epoch 2848/3000\n",
      "13/13 - 0s - loss: 0.2051 - accuracy: 0.9014 - val_loss: 0.5743 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02848: val_loss did not improve from 0.41762\n",
      "Epoch 2849/3000\n",
      "13/13 - 0s - loss: 0.2050 - accuracy: 0.9001 - val_loss: 0.5785 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02849: val_loss did not improve from 0.41762\n",
      "Epoch 2850/3000\n",
      "13/13 - 0s - loss: 0.2043 - accuracy: 0.8975 - val_loss: 0.5746 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02850: val_loss did not improve from 0.41762\n",
      "Epoch 2851/3000\n",
      "13/13 - 0s - loss: 0.2049 - accuracy: 0.9001 - val_loss: 0.5604 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02851: val_loss did not improve from 0.41762\n",
      "Epoch 2852/3000\n",
      "13/13 - 0s - loss: 0.2209 - accuracy: 0.8898 - val_loss: 0.5817 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02852: val_loss did not improve from 0.41762\n",
      "Epoch 2853/3000\n",
      "13/13 - 0s - loss: 0.2271 - accuracy: 0.8988 - val_loss: 0.6689 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02853: val_loss did not improve from 0.41762\n",
      "Epoch 2854/3000\n",
      "13/13 - 0s - loss: 0.2172 - accuracy: 0.9001 - val_loss: 0.5924 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02854: val_loss did not improve from 0.41762\n",
      "Epoch 2855/3000\n",
      "13/13 - 0s - loss: 0.2102 - accuracy: 0.8988 - val_loss: 0.5770 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02855: val_loss did not improve from 0.41762\n",
      "Epoch 2856/3000\n",
      "13/13 - 0s - loss: 0.2082 - accuracy: 0.8962 - val_loss: 0.5653 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02856: val_loss did not improve from 0.41762\n",
      "Epoch 2857/3000\n",
      "13/13 - 0s - loss: 0.2075 - accuracy: 0.9014 - val_loss: 0.5490 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02857: val_loss did not improve from 0.41762\n",
      "Epoch 2858/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.8988 - val_loss: 0.5532 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02858: val_loss did not improve from 0.41762\n",
      "Epoch 2859/3000\n",
      "13/13 - 0s - loss: 0.2082 - accuracy: 0.8988 - val_loss: 0.5761 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02859: val_loss did not improve from 0.41762\n",
      "Epoch 2860/3000\n",
      "13/13 - 0s - loss: 0.2076 - accuracy: 0.9001 - val_loss: 0.5612 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02860: val_loss did not improve from 0.41762\n",
      "Epoch 2861/3000\n",
      "13/13 - 0s - loss: 0.2104 - accuracy: 0.8923 - val_loss: 0.5502 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02861: val_loss did not improve from 0.41762\n",
      "Epoch 2862/3000\n",
      "13/13 - 0s - loss: 0.2140 - accuracy: 0.8911 - val_loss: 0.5599 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02862: val_loss did not improve from 0.41762\n",
      "Epoch 2863/3000\n",
      "13/13 - 0s - loss: 0.2192 - accuracy: 0.8962 - val_loss: 0.5331 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 02863: val_loss did not improve from 0.41762\n",
      "Epoch 2864/3000\n",
      "13/13 - 0s - loss: 0.2266 - accuracy: 0.8936 - val_loss: 0.6131 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02864: val_loss did not improve from 0.41762\n",
      "Epoch 2865/3000\n",
      "13/13 - 0s - loss: 0.2270 - accuracy: 0.8923 - val_loss: 0.5919 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02865: val_loss did not improve from 0.41762\n",
      "Epoch 2866/3000\n",
      "13/13 - 0s - loss: 0.2211 - accuracy: 0.8962 - val_loss: 0.5697 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02866: val_loss did not improve from 0.41762\n",
      "Epoch 2867/3000\n",
      "13/13 - 0s - loss: 0.2213 - accuracy: 0.8936 - val_loss: 0.5821 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02867: val_loss did not improve from 0.41762\n",
      "Epoch 2868/3000\n",
      "13/13 - 0s - loss: 0.2190 - accuracy: 0.8898 - val_loss: 0.5952 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02868: val_loss did not improve from 0.41762\n",
      "Epoch 2869/3000\n",
      "13/13 - 0s - loss: 0.2104 - accuracy: 0.9027 - val_loss: 0.5779 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02869: val_loss did not improve from 0.41762\n",
      "Epoch 2870/3000\n",
      "13/13 - 0s - loss: 0.2183 - accuracy: 0.8949 - val_loss: 0.5753 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02870: val_loss did not improve from 0.41762\n",
      "Epoch 2871/3000\n",
      "13/13 - 0s - loss: 0.2123 - accuracy: 0.8988 - val_loss: 0.6059 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02871: val_loss did not improve from 0.41762\n",
      "Epoch 2872/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.8975 - val_loss: 0.5829 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02872: val_loss did not improve from 0.41762\n",
      "Epoch 2873/3000\n",
      "13/13 - 0s - loss: 0.2061 - accuracy: 0.9014 - val_loss: 0.5821 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02873: val_loss did not improve from 0.41762\n",
      "Epoch 2874/3000\n",
      "13/13 - 0s - loss: 0.2061 - accuracy: 0.9001 - val_loss: 0.5939 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02874: val_loss did not improve from 0.41762\n",
      "Epoch 2875/3000\n",
      "13/13 - 0s - loss: 0.2052 - accuracy: 0.9014 - val_loss: 0.5978 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02875: val_loss did not improve from 0.41762\n",
      "Epoch 2876/3000\n",
      "13/13 - 0s - loss: 0.2057 - accuracy: 0.9027 - val_loss: 0.5914 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02876: val_loss did not improve from 0.41762\n",
      "Epoch 2877/3000\n",
      "13/13 - 0s - loss: 0.2077 - accuracy: 0.9014 - val_loss: 0.5944 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02877: val_loss did not improve from 0.41762\n",
      "Epoch 2878/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.9001 - val_loss: 0.5940 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02878: val_loss did not improve from 0.41762\n",
      "Epoch 2879/3000\n",
      "13/13 - 0s - loss: 0.2119 - accuracy: 0.8936 - val_loss: 0.5779 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02879: val_loss did not improve from 0.41762\n",
      "Epoch 2880/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.8988 - val_loss: 0.5943 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02880: val_loss did not improve from 0.41762\n",
      "Epoch 2881/3000\n",
      "13/13 - 0s - loss: 0.2076 - accuracy: 0.8975 - val_loss: 0.5778 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02881: val_loss did not improve from 0.41762\n",
      "Epoch 2882/3000\n",
      "13/13 - 0s - loss: 0.2107 - accuracy: 0.9014 - val_loss: 0.6002 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02882: val_loss did not improve from 0.41762\n",
      "Epoch 2883/3000\n",
      "13/13 - 0s - loss: 0.2162 - accuracy: 0.9014 - val_loss: 0.5866 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02883: val_loss did not improve from 0.41762\n",
      "Epoch 2884/3000\n",
      "13/13 - 0s - loss: 0.2091 - accuracy: 0.9001 - val_loss: 0.5648 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02884: val_loss did not improve from 0.41762\n",
      "Epoch 2885/3000\n",
      "13/13 - 0s - loss: 0.2122 - accuracy: 0.9027 - val_loss: 0.5801 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02885: val_loss did not improve from 0.41762\n",
      "Epoch 2886/3000\n",
      "13/13 - 0s - loss: 0.2236 - accuracy: 0.9001 - val_loss: 0.6269 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02886: val_loss did not improve from 0.41762\n",
      "Epoch 2887/3000\n",
      "13/13 - 0s - loss: 0.2199 - accuracy: 0.8962 - val_loss: 0.5534 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02887: val_loss did not improve from 0.41762\n",
      "Epoch 2888/3000\n",
      "13/13 - 0s - loss: 0.2230 - accuracy: 0.8962 - val_loss: 0.5704 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02888: val_loss did not improve from 0.41762\n",
      "Epoch 2889/3000\n",
      "13/13 - 0s - loss: 0.2122 - accuracy: 0.9001 - val_loss: 0.5485 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02889: val_loss did not improve from 0.41762\n",
      "Epoch 2890/3000\n",
      "13/13 - 0s - loss: 0.2226 - accuracy: 0.8949 - val_loss: 0.5854 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02890: val_loss did not improve from 0.41762\n",
      "Epoch 2891/3000\n",
      "13/13 - 0s - loss: 0.2163 - accuracy: 0.9001 - val_loss: 0.5721 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02891: val_loss did not improve from 0.41762\n",
      "Epoch 2892/3000\n",
      "13/13 - 0s - loss: 0.2126 - accuracy: 0.8988 - val_loss: 0.5590 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02892: val_loss did not improve from 0.41762\n",
      "Epoch 2893/3000\n",
      "13/13 - 0s - loss: 0.2087 - accuracy: 0.9014 - val_loss: 0.5741 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02893: val_loss did not improve from 0.41762\n",
      "Epoch 2894/3000\n",
      "13/13 - 0s - loss: 0.2073 - accuracy: 0.9001 - val_loss: 0.5705 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02894: val_loss did not improve from 0.41762\n",
      "Epoch 2895/3000\n",
      "13/13 - 0s - loss: 0.2077 - accuracy: 0.9027 - val_loss: 0.5665 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02895: val_loss did not improve from 0.41762\n",
      "Epoch 2896/3000\n",
      "13/13 - 0s - loss: 0.2122 - accuracy: 0.8872 - val_loss: 0.5580 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02896: val_loss did not improve from 0.41762\n",
      "Epoch 2897/3000\n",
      "13/13 - 0s - loss: 0.2139 - accuracy: 0.8936 - val_loss: 0.5733 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02897: val_loss did not improve from 0.41762\n",
      "Epoch 2898/3000\n",
      "13/13 - 0s - loss: 0.2135 - accuracy: 0.8872 - val_loss: 0.5653 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02898: val_loss did not improve from 0.41762\n",
      "Epoch 2899/3000\n",
      "13/13 - 0s - loss: 0.2124 - accuracy: 0.8988 - val_loss: 0.5786 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02899: val_loss did not improve from 0.41762\n",
      "Epoch 2900/3000\n",
      "13/13 - 0s - loss: 0.2068 - accuracy: 0.8975 - val_loss: 0.5861 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02900: val_loss did not improve from 0.41762\n",
      "Epoch 2901/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.9027 - val_loss: 0.5766 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02901: val_loss did not improve from 0.41762\n",
      "Epoch 2902/3000\n",
      "13/13 - 0s - loss: 0.2102 - accuracy: 0.8975 - val_loss: 0.5659 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02902: val_loss did not improve from 0.41762\n",
      "Epoch 2903/3000\n",
      "13/13 - 0s - loss: 0.2138 - accuracy: 0.8962 - val_loss: 0.5820 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02903: val_loss did not improve from 0.41762\n",
      "Epoch 2904/3000\n",
      "13/13 - 0s - loss: 0.2128 - accuracy: 0.8949 - val_loss: 0.6192 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02904: val_loss did not improve from 0.41762\n",
      "Epoch 2905/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.8949 - val_loss: 0.5855 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02905: val_loss did not improve from 0.41762\n",
      "Epoch 2906/3000\n",
      "13/13 - 0s - loss: 0.2082 - accuracy: 0.8975 - val_loss: 0.5759 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02906: val_loss did not improve from 0.41762\n",
      "Epoch 2907/3000\n",
      "13/13 - 0s - loss: 0.2110 - accuracy: 0.9014 - val_loss: 0.5922 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02907: val_loss did not improve from 0.41762\n",
      "Epoch 2908/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.9040 - val_loss: 0.5905 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02908: val_loss did not improve from 0.41762\n",
      "Epoch 2909/3000\n",
      "13/13 - 0s - loss: 0.2168 - accuracy: 0.8923 - val_loss: 0.5931 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02909: val_loss did not improve from 0.41762\n",
      "Epoch 2910/3000\n",
      "13/13 - 0s - loss: 0.2137 - accuracy: 0.8975 - val_loss: 0.6064 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02910: val_loss did not improve from 0.41762\n",
      "Epoch 2911/3000\n",
      "13/13 - 0s - loss: 0.2133 - accuracy: 0.8936 - val_loss: 0.5857 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02911: val_loss did not improve from 0.41762\n",
      "Epoch 2912/3000\n",
      "13/13 - 0s - loss: 0.2138 - accuracy: 0.9001 - val_loss: 0.5976 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02912: val_loss did not improve from 0.41762\n",
      "Epoch 2913/3000\n",
      "13/13 - 0s - loss: 0.2115 - accuracy: 0.8988 - val_loss: 0.6093 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02913: val_loss did not improve from 0.41762\n",
      "Epoch 2914/3000\n",
      "13/13 - 0s - loss: 0.2081 - accuracy: 0.9014 - val_loss: 0.5884 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02914: val_loss did not improve from 0.41762\n",
      "Epoch 2915/3000\n",
      "13/13 - 0s - loss: 0.2176 - accuracy: 0.8911 - val_loss: 0.5573 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02915: val_loss did not improve from 0.41762\n",
      "Epoch 2916/3000\n",
      "13/13 - 0s - loss: 0.2290 - accuracy: 0.8911 - val_loss: 0.5912 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02916: val_loss did not improve from 0.41762\n",
      "Epoch 2917/3000\n",
      "13/13 - 0s - loss: 0.2164 - accuracy: 0.8936 - val_loss: 0.6227 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02917: val_loss did not improve from 0.41762\n",
      "Epoch 2918/3000\n",
      "13/13 - 0s - loss: 0.2179 - accuracy: 0.8936 - val_loss: 0.6074 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02918: val_loss did not improve from 0.41762\n",
      "Epoch 2919/3000\n",
      "13/13 - 0s - loss: 0.2102 - accuracy: 0.8975 - val_loss: 0.5905 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02919: val_loss did not improve from 0.41762\n",
      "Epoch 2920/3000\n",
      "13/13 - 0s - loss: 0.2228 - accuracy: 0.8898 - val_loss: 0.6082 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02920: val_loss did not improve from 0.41762\n",
      "Epoch 2921/3000\n",
      "13/13 - 0s - loss: 0.2235 - accuracy: 0.9001 - val_loss: 0.6920 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02921: val_loss did not improve from 0.41762\n",
      "Epoch 2922/3000\n",
      "13/13 - 0s - loss: 0.2256 - accuracy: 0.8962 - val_loss: 0.6350 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02922: val_loss did not improve from 0.41762\n",
      "Epoch 2923/3000\n",
      "13/13 - 0s - loss: 0.2210 - accuracy: 0.8859 - val_loss: 0.6003 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02923: val_loss did not improve from 0.41762\n",
      "Epoch 2924/3000\n",
      "13/13 - 0s - loss: 0.2134 - accuracy: 0.9027 - val_loss: 0.5994 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02924: val_loss did not improve from 0.41762\n",
      "Epoch 2925/3000\n",
      "13/13 - 0s - loss: 0.2066 - accuracy: 0.8949 - val_loss: 0.5762 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02925: val_loss did not improve from 0.41762\n",
      "Epoch 2926/3000\n",
      "13/13 - 0s - loss: 0.2171 - accuracy: 0.8936 - val_loss: 0.5854 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02926: val_loss did not improve from 0.41762\n",
      "Epoch 2927/3000\n",
      "13/13 - 0s - loss: 0.2109 - accuracy: 0.9001 - val_loss: 0.6062 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02927: val_loss did not improve from 0.41762\n",
      "Epoch 2928/3000\n",
      "13/13 - 0s - loss: 0.2076 - accuracy: 0.9014 - val_loss: 0.6020 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02928: val_loss did not improve from 0.41762\n",
      "Epoch 2929/3000\n",
      "13/13 - 0s - loss: 0.2106 - accuracy: 0.8975 - val_loss: 0.5994 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02929: val_loss did not improve from 0.41762\n",
      "Epoch 2930/3000\n",
      "13/13 - 0s - loss: 0.2143 - accuracy: 0.8885 - val_loss: 0.5928 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02930: val_loss did not improve from 0.41762\n",
      "Epoch 2931/3000\n",
      "13/13 - 0s - loss: 0.2086 - accuracy: 0.9014 - val_loss: 0.6155 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02931: val_loss did not improve from 0.41762\n",
      "Epoch 2932/3000\n",
      "13/13 - 0s - loss: 0.2113 - accuracy: 0.8962 - val_loss: 0.6108 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02932: val_loss did not improve from 0.41762\n",
      "Epoch 2933/3000\n",
      "13/13 - 0s - loss: 0.2066 - accuracy: 0.8962 - val_loss: 0.6016 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02933: val_loss did not improve from 0.41762\n",
      "Epoch 2934/3000\n",
      "13/13 - 0s - loss: 0.2061 - accuracy: 0.9001 - val_loss: 0.6152 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02934: val_loss did not improve from 0.41762\n",
      "Epoch 2935/3000\n",
      "13/13 - 0s - loss: 0.2065 - accuracy: 0.9001 - val_loss: 0.6165 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02935: val_loss did not improve from 0.41762\n",
      "Epoch 2936/3000\n",
      "13/13 - 0s - loss: 0.2052 - accuracy: 0.9014 - val_loss: 0.6179 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02936: val_loss did not improve from 0.41762\n",
      "Epoch 2937/3000\n",
      "13/13 - 0s - loss: 0.2074 - accuracy: 0.9001 - val_loss: 0.6324 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02937: val_loss did not improve from 0.41762\n",
      "Epoch 2938/3000\n",
      "13/13 - 0s - loss: 0.2083 - accuracy: 0.9001 - val_loss: 0.6048 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02938: val_loss did not improve from 0.41762\n",
      "Epoch 2939/3000\n",
      "13/13 - 0s - loss: 0.2044 - accuracy: 0.9001 - val_loss: 0.5947 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02939: val_loss did not improve from 0.41762\n",
      "Epoch 2940/3000\n",
      "13/13 - 0s - loss: 0.2055 - accuracy: 0.9014 - val_loss: 0.5993 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02940: val_loss did not improve from 0.41762\n",
      "Epoch 2941/3000\n",
      "13/13 - 0s - loss: 0.2060 - accuracy: 0.8975 - val_loss: 0.6124 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02941: val_loss did not improve from 0.41762\n",
      "Epoch 2942/3000\n",
      "13/13 - 0s - loss: 0.2161 - accuracy: 0.8911 - val_loss: 0.5891 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02942: val_loss did not improve from 0.41762\n",
      "Epoch 2943/3000\n",
      "13/13 - 0s - loss: 0.2129 - accuracy: 0.8962 - val_loss: 0.5755 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02943: val_loss did not improve from 0.41762\n",
      "Epoch 2944/3000\n",
      "13/13 - 0s - loss: 0.2245 - accuracy: 0.8859 - val_loss: 0.5781 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02944: val_loss did not improve from 0.41762\n",
      "Epoch 2945/3000\n",
      "13/13 - 0s - loss: 0.2202 - accuracy: 0.9014 - val_loss: 0.5869 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02945: val_loss did not improve from 0.41762\n",
      "Epoch 2946/3000\n",
      "13/13 - 0s - loss: 0.2114 - accuracy: 0.8949 - val_loss: 0.5891 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02946: val_loss did not improve from 0.41762\n",
      "Epoch 2947/3000\n",
      "13/13 - 0s - loss: 0.2101 - accuracy: 0.9014 - val_loss: 0.6036 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02947: val_loss did not improve from 0.41762\n",
      "Epoch 2948/3000\n",
      "13/13 - 0s - loss: 0.2176 - accuracy: 0.8949 - val_loss: 0.6096 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02948: val_loss did not improve from 0.41762\n",
      "Epoch 2949/3000\n",
      "13/13 - 0s - loss: 0.2099 - accuracy: 0.9001 - val_loss: 0.5949 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02949: val_loss did not improve from 0.41762\n",
      "Epoch 2950/3000\n",
      "13/13 - 0s - loss: 0.2084 - accuracy: 0.8988 - val_loss: 0.5875 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 02950: val_loss did not improve from 0.41762\n",
      "Epoch 2951/3000\n",
      "13/13 - 0s - loss: 0.2124 - accuracy: 0.8936 - val_loss: 0.5788 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02951: val_loss did not improve from 0.41762\n",
      "Epoch 2952/3000\n",
      "13/13 - 0s - loss: 0.2104 - accuracy: 0.8962 - val_loss: 0.5876 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02952: val_loss did not improve from 0.41762\n",
      "Epoch 2953/3000\n",
      "13/13 - 0s - loss: 0.2105 - accuracy: 0.9001 - val_loss: 0.5847 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02953: val_loss did not improve from 0.41762\n",
      "Epoch 2954/3000\n",
      "13/13 - 0s - loss: 0.2064 - accuracy: 0.9014 - val_loss: 0.5961 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02954: val_loss did not improve from 0.41762\n",
      "Epoch 2955/3000\n",
      "13/13 - 0s - loss: 0.2125 - accuracy: 0.8975 - val_loss: 0.5678 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02955: val_loss did not improve from 0.41762\n",
      "Epoch 2956/3000\n",
      "13/13 - 0s - loss: 0.2165 - accuracy: 0.8936 - val_loss: 0.5790 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02956: val_loss did not improve from 0.41762\n",
      "Epoch 2957/3000\n",
      "13/13 - 0s - loss: 0.2133 - accuracy: 0.8949 - val_loss: 0.6015 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02957: val_loss did not improve from 0.41762\n",
      "Epoch 2958/3000\n",
      "13/13 - 0s - loss: 0.2091 - accuracy: 0.9001 - val_loss: 0.6283 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02958: val_loss did not improve from 0.41762\n",
      "Epoch 2959/3000\n",
      "13/13 - 0s - loss: 0.2150 - accuracy: 0.8962 - val_loss: 0.6128 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02959: val_loss did not improve from 0.41762\n",
      "Epoch 2960/3000\n",
      "13/13 - 0s - loss: 0.2124 - accuracy: 0.8988 - val_loss: 0.6372 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02960: val_loss did not improve from 0.41762\n",
      "Epoch 2961/3000\n",
      "13/13 - 0s - loss: 0.2090 - accuracy: 0.9014 - val_loss: 0.6327 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02961: val_loss did not improve from 0.41762\n",
      "Epoch 2962/3000\n",
      "13/13 - 0s - loss: 0.2058 - accuracy: 0.9014 - val_loss: 0.6199 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02962: val_loss did not improve from 0.41762\n",
      "Epoch 2963/3000\n",
      "13/13 - 0s - loss: 0.2093 - accuracy: 0.8962 - val_loss: 0.6307 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02963: val_loss did not improve from 0.41762\n",
      "Epoch 2964/3000\n",
      "13/13 - 0s - loss: 0.2205 - accuracy: 0.8885 - val_loss: 0.6091 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02964: val_loss did not improve from 0.41762\n",
      "Epoch 2965/3000\n",
      "13/13 - 0s - loss: 0.2162 - accuracy: 0.8975 - val_loss: 0.6243 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02965: val_loss did not improve from 0.41762\n",
      "Epoch 2966/3000\n",
      "13/13 - 0s - loss: 0.2071 - accuracy: 0.9001 - val_loss: 0.6110 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02966: val_loss did not improve from 0.41762\n",
      "Epoch 2967/3000\n",
      "13/13 - 0s - loss: 0.2076 - accuracy: 0.8936 - val_loss: 0.6158 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02967: val_loss did not improve from 0.41762\n",
      "Epoch 2968/3000\n",
      "13/13 - 0s - loss: 0.2171 - accuracy: 0.8911 - val_loss: 0.6308 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02968: val_loss did not improve from 0.41762\n",
      "Epoch 2969/3000\n",
      "13/13 - 0s - loss: 0.2128 - accuracy: 0.8872 - val_loss: 0.5877 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02969: val_loss did not improve from 0.41762\n",
      "Epoch 2970/3000\n",
      "13/13 - 0s - loss: 0.2112 - accuracy: 0.8898 - val_loss: 0.6114 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02970: val_loss did not improve from 0.41762\n",
      "Epoch 2971/3000\n",
      "13/13 - 0s - loss: 0.2085 - accuracy: 0.9027 - val_loss: 0.6273 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02971: val_loss did not improve from 0.41762\n",
      "Epoch 2972/3000\n",
      "13/13 - 0s - loss: 0.2113 - accuracy: 0.9027 - val_loss: 0.6276 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 02972: val_loss did not improve from 0.41762\n",
      "Epoch 2973/3000\n",
      "13/13 - 0s - loss: 0.2102 - accuracy: 0.8936 - val_loss: 0.6339 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02973: val_loss did not improve from 0.41762\n",
      "Epoch 2974/3000\n",
      "13/13 - 0s - loss: 0.2175 - accuracy: 0.8833 - val_loss: 0.6311 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 02974: val_loss did not improve from 0.41762\n",
      "Epoch 2975/3000\n",
      "13/13 - 0s - loss: 0.2093 - accuracy: 0.8975 - val_loss: 0.6204 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02975: val_loss did not improve from 0.41762\n",
      "Epoch 2976/3000\n",
      "13/13 - 0s - loss: 0.2072 - accuracy: 0.9001 - val_loss: 0.6199 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02976: val_loss did not improve from 0.41762\n",
      "Epoch 2977/3000\n",
      "13/13 - 0s - loss: 0.2056 - accuracy: 0.9027 - val_loss: 0.6053 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02977: val_loss did not improve from 0.41762\n",
      "Epoch 2978/3000\n",
      "13/13 - 0s - loss: 0.2067 - accuracy: 0.8975 - val_loss: 0.6189 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02978: val_loss did not improve from 0.41762\n",
      "Epoch 2979/3000\n",
      "13/13 - 0s - loss: 0.2064 - accuracy: 0.9001 - val_loss: 0.6163 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02979: val_loss did not improve from 0.41762\n",
      "Epoch 2980/3000\n",
      "13/13 - 0s - loss: 0.2083 - accuracy: 0.9014 - val_loss: 0.6123 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02980: val_loss did not improve from 0.41762\n",
      "Epoch 2981/3000\n",
      "13/13 - 0s - loss: 0.2073 - accuracy: 0.9001 - val_loss: 0.5997 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02981: val_loss did not improve from 0.41762\n",
      "Epoch 2982/3000\n",
      "13/13 - 0s - loss: 0.2099 - accuracy: 0.8923 - val_loss: 0.6233 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02982: val_loss did not improve from 0.41762\n",
      "Epoch 2983/3000\n",
      "13/13 - 0s - loss: 0.2062 - accuracy: 0.9040 - val_loss: 0.6026 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02983: val_loss did not improve from 0.41762\n",
      "Epoch 2984/3000\n",
      "13/13 - 0s - loss: 0.2066 - accuracy: 0.9001 - val_loss: 0.5969 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02984: val_loss did not improve from 0.41762\n",
      "Epoch 2985/3000\n",
      "13/13 - 0s - loss: 0.2441 - accuracy: 0.8859 - val_loss: 0.5613 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 02985: val_loss did not improve from 0.41762\n",
      "Epoch 2986/3000\n",
      "13/13 - 0s - loss: 0.2240 - accuracy: 0.8923 - val_loss: 0.6187 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 02986: val_loss did not improve from 0.41762\n",
      "Epoch 2987/3000\n",
      "13/13 - 0s - loss: 0.2113 - accuracy: 0.8975 - val_loss: 0.5965 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02987: val_loss did not improve from 0.41762\n",
      "Epoch 2988/3000\n",
      "13/13 - 0s - loss: 0.2078 - accuracy: 0.8988 - val_loss: 0.6000 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 02988: val_loss did not improve from 0.41762\n",
      "Epoch 2989/3000\n",
      "13/13 - 0s - loss: 0.2068 - accuracy: 0.8962 - val_loss: 0.6129 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02989: val_loss did not improve from 0.41762\n",
      "Epoch 2990/3000\n",
      "13/13 - 0s - loss: 0.2209 - accuracy: 0.8949 - val_loss: 0.6583 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02990: val_loss did not improve from 0.41762\n",
      "Epoch 2991/3000\n",
      "13/13 - 0s - loss: 0.2097 - accuracy: 0.8988 - val_loss: 0.5913 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02991: val_loss did not improve from 0.41762\n",
      "Epoch 2992/3000\n",
      "13/13 - 0s - loss: 0.2076 - accuracy: 0.9001 - val_loss: 0.6120 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02992: val_loss did not improve from 0.41762\n",
      "Epoch 2993/3000\n",
      "13/13 - 0s - loss: 0.2133 - accuracy: 0.8923 - val_loss: 0.5902 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02993: val_loss did not improve from 0.41762\n",
      "Epoch 2994/3000\n",
      "13/13 - 0s - loss: 0.2118 - accuracy: 0.8936 - val_loss: 0.5954 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02994: val_loss did not improve from 0.41762\n",
      "Epoch 2995/3000\n",
      "13/13 - 0s - loss: 0.2240 - accuracy: 0.8911 - val_loss: 0.6166 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 02995: val_loss did not improve from 0.41762\n",
      "Epoch 2996/3000\n",
      "13/13 - 0s - loss: 0.2355 - accuracy: 0.8872 - val_loss: 0.6283 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 02996: val_loss did not improve from 0.41762\n",
      "Epoch 2997/3000\n",
      "13/13 - 0s - loss: 0.2263 - accuracy: 0.8833 - val_loss: 0.5746 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 02997: val_loss did not improve from 0.41762\n",
      "Epoch 2998/3000\n",
      "13/13 - 0s - loss: 0.2121 - accuracy: 0.8975 - val_loss: 0.5912 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 02998: val_loss did not improve from 0.41762\n",
      "Epoch 2999/3000\n",
      "13/13 - 0s - loss: 0.2079 - accuracy: 0.8962 - val_loss: 0.5785 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 02999: val_loss did not improve from 0.41762\n",
      "Epoch 3000/3000\n",
      "13/13 - 0s - loss: 0.2381 - accuracy: 0.8885 - val_loss: 0.5527 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 03000: val_loss did not improve from 0.41762\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                512       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 1,379\n",
      "Trainable params: 1,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([      \n",
    "      tf.keras.layers.Dense(16, activation='relu'),\n",
    "      tf.keras.layers.Dense(16, activation='relu'),\n",
    "       tf.keras.layers.Dense(16, activation='relu'),\n",
    "      tf.keras.layers.Dense(16, activation='relu'),\n",
    "      tf.keras.layers.Dense(3)\n",
    "    ])\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "metrics = ['accuracy']\n",
    "model_filename = 'models/model_4L_v4'\n",
    "model_l_v_e_filename = 'loss_vs_epochs_images/model_4L_v4_le.png'\n",
    "model_l_v_e_title = 'model_4L_v4'\n",
    "model_history_filename = 'history/history_model_4L_v4'\n",
    "\n",
    "model.compile(optimizer, loss_fn, metrics)\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(model_filename, monitor='val_loss', verbose=1,save_best_only=True, mode='min')\n",
    "model.fit(X_train, y_train, epochs = 3000,  validation_data=(X_test, y_test),batch_size = batch_size,callbacks=[checkpoint], verbose=2)\n",
    "model.summary()\n",
    "graph_loss_vs_epochs(model.history, model_l_v_e_filename, model_l_v_e_title)\n",
    "save_history(model_history_filename, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:\n",
      "7/7 [==============================] - 1s 3ms/step - loss: 0.4176 - accuracy: 0.8705\n",
      "\n",
      "Test accuracy: 87.0%, test loss: 0.417625\n"
     ]
    }
   ],
   "source": [
    "best_m4L_v4 = load_model(model_filename)\n",
    "evaluate_model(best_m4L_v4, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241\n"
     ]
    }
   ],
   "source": [
    "test_ds_filename = '../test-ds.csv'\n",
    "output_filename_test_ds_labeled = 'test-ds-m4L_v4.csv'\n",
    "fill_test_ds_labels(model, test_ds_filename, output_filename_test_ds_labeled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: V5\n",
    "#### Model 4 consists in 4 hidden Dense layers:\n",
    "    learning_rate = 0.005\n",
    "    batch_size = 32\n",
    "    loss_fn = CategoricalCrossentropy\n",
    "    optimizer = Adam\n",
    "    Hidden layers:\n",
    "        1. units = 16, activation = sigmoid\n",
    "        2. units = 16, activation = sigmoid\n",
    "        3. units = 32, activation = sigmoid\n",
    "        4. units = 32, activation = sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "25/25 - 2s - loss: 0.9718 - accuracy: 0.4643 - val_loss: 0.9288 - val_accuracy: 0.5648\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.92883, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 2/1000\n",
      "25/25 - 0s - loss: 0.9398 - accuracy: 0.4773 - val_loss: 0.9302 - val_accuracy: 0.5648\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.92883\n",
      "Epoch 3/1000\n",
      "25/25 - 0s - loss: 0.9296 - accuracy: 0.5032 - val_loss: 0.9147 - val_accuracy: 0.5648\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.92883 to 0.91468, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 4/1000\n",
      "25/25 - 0s - loss: 0.9194 - accuracy: 0.5097 - val_loss: 0.9243 - val_accuracy: 0.6528\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.91468\n",
      "Epoch 5/1000\n",
      "25/25 - 0s - loss: 0.9059 - accuracy: 0.5512 - val_loss: 0.8787 - val_accuracy: 0.6321\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.91468 to 0.87870, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 6/1000\n",
      "25/25 - 0s - loss: 0.8593 - accuracy: 0.6278 - val_loss: 0.8577 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.87870 to 0.85773, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 7/1000\n",
      "25/25 - 0s - loss: 0.8211 - accuracy: 0.6602 - val_loss: 0.7538 - val_accuracy: 0.6943\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.85773 to 0.75385, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 8/1000\n",
      "25/25 - 0s - loss: 0.8012 - accuracy: 0.6757 - val_loss: 0.7282 - val_accuracy: 0.7306\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.75385 to 0.72816, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 9/1000\n",
      "25/25 - 0s - loss: 0.7880 - accuracy: 0.6952 - val_loss: 0.7281 - val_accuracy: 0.7358\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.72816 to 0.72809, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 10/1000\n",
      "25/25 - 0s - loss: 0.7885 - accuracy: 0.6874 - val_loss: 0.7311 - val_accuracy: 0.7409\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.72809\n",
      "Epoch 11/1000\n",
      "25/25 - 0s - loss: 0.8047 - accuracy: 0.6796 - val_loss: 0.7921 - val_accuracy: 0.6943\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.72809\n",
      "Epoch 12/1000\n",
      "25/25 - 0s - loss: 0.8032 - accuracy: 0.6706 - val_loss: 0.7870 - val_accuracy: 0.6995\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.72809\n",
      "Epoch 13/1000\n",
      "25/25 - 0s - loss: 0.7824 - accuracy: 0.6913 - val_loss: 0.7140 - val_accuracy: 0.7409\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.72809 to 0.71405, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 14/1000\n",
      "25/25 - 0s - loss: 0.7736 - accuracy: 0.6965 - val_loss: 0.7081 - val_accuracy: 0.7358\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.71405 to 0.70812, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 15/1000\n",
      "25/25 - 0s - loss: 0.7729 - accuracy: 0.6978 - val_loss: 0.7014 - val_accuracy: 0.7306\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.70812 to 0.70140, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 16/1000\n",
      "25/25 - 0s - loss: 0.7680 - accuracy: 0.7108 - val_loss: 0.7007 - val_accuracy: 0.7254\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.70140 to 0.70066, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 17/1000\n",
      "25/25 - 0s - loss: 0.7643 - accuracy: 0.7017 - val_loss: 0.7003 - val_accuracy: 0.7306\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.70066 to 0.70026, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 18/1000\n",
      "25/25 - 0s - loss: 0.7709 - accuracy: 0.7043 - val_loss: 0.7202 - val_accuracy: 0.7565\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.70026\n",
      "Epoch 19/1000\n",
      "25/25 - 0s - loss: 0.7624 - accuracy: 0.6965 - val_loss: 0.6963 - val_accuracy: 0.7150\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.70026 to 0.69632, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 20/1000\n",
      "25/25 - 1s - loss: 0.7589 - accuracy: 0.7082 - val_loss: 0.6975 - val_accuracy: 0.7254\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.69632\n",
      "Epoch 21/1000\n",
      "25/25 - 0s - loss: 0.7547 - accuracy: 0.7095 - val_loss: 0.7012 - val_accuracy: 0.7461\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.69632\n",
      "Epoch 22/1000\n",
      "25/25 - 0s - loss: 0.7567 - accuracy: 0.7017 - val_loss: 0.7327 - val_accuracy: 0.7358\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.69632\n",
      "Epoch 23/1000\n",
      "25/25 - 0s - loss: 0.7607 - accuracy: 0.7056 - val_loss: 0.7001 - val_accuracy: 0.7306\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.69632\n",
      "Epoch 24/1000\n",
      "25/25 - 0s - loss: 0.7506 - accuracy: 0.7173 - val_loss: 0.6942 - val_accuracy: 0.7150\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.69632 to 0.69423, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 25/1000\n",
      "25/25 - 0s - loss: 0.7425 - accuracy: 0.7198 - val_loss: 0.7081 - val_accuracy: 0.7358\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.69423\n",
      "Epoch 26/1000\n",
      "25/25 - 0s - loss: 0.7432 - accuracy: 0.7211 - val_loss: 0.6884 - val_accuracy: 0.7150\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.69423 to 0.68839, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 27/1000\n",
      "25/25 - 0s - loss: 0.7360 - accuracy: 0.7198 - val_loss: 0.6971 - val_accuracy: 0.7306\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.68839\n",
      "Epoch 28/1000\n",
      "25/25 - 0s - loss: 0.7331 - accuracy: 0.7185 - val_loss: 0.6920 - val_accuracy: 0.7202\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.68839\n",
      "Epoch 29/1000\n",
      "25/25 - 0s - loss: 0.7314 - accuracy: 0.7211 - val_loss: 0.6931 - val_accuracy: 0.6995\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.68839\n",
      "Epoch 30/1000\n",
      "25/25 - 0s - loss: 0.7375 - accuracy: 0.6965 - val_loss: 0.6880 - val_accuracy: 0.7306\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.68839 to 0.68798, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 31/1000\n",
      "25/25 - 0s - loss: 0.7152 - accuracy: 0.7224 - val_loss: 0.6801 - val_accuracy: 0.7202\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.68798 to 0.68011, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 32/1000\n",
      "25/25 - 0s - loss: 0.7225 - accuracy: 0.7095 - val_loss: 0.6835 - val_accuracy: 0.6943\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.68011\n",
      "Epoch 33/1000\n",
      "25/25 - 0s - loss: 0.7113 - accuracy: 0.7134 - val_loss: 0.6611 - val_accuracy: 0.7150\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.68011 to 0.66106, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 34/1000\n",
      "25/25 - 0s - loss: 0.6916 - accuracy: 0.7198 - val_loss: 0.6577 - val_accuracy: 0.7306\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.66106 to 0.65770, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 35/1000\n",
      "25/25 - 0s - loss: 0.6773 - accuracy: 0.7250 - val_loss: 0.6465 - val_accuracy: 0.7098\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.65770 to 0.64652, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 36/1000\n",
      "25/25 - 0s - loss: 0.6758 - accuracy: 0.7160 - val_loss: 0.6311 - val_accuracy: 0.7202\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.64652 to 0.63107, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 37/1000\n",
      "25/25 - 0s - loss: 0.6866 - accuracy: 0.7069 - val_loss: 0.6395 - val_accuracy: 0.7202\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.63107\n",
      "Epoch 38/1000\n",
      "25/25 - 0s - loss: 0.6503 - accuracy: 0.7263 - val_loss: 0.6386 - val_accuracy: 0.7565\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.63107\n",
      "Epoch 39/1000\n",
      "25/25 - 0s - loss: 0.6472 - accuracy: 0.7250 - val_loss: 0.6252 - val_accuracy: 0.7461\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.63107 to 0.62517, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 40/1000\n",
      "25/25 - 0s - loss: 0.6482 - accuracy: 0.7302 - val_loss: 0.6535 - val_accuracy: 0.6995\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.62517\n",
      "Epoch 41/1000\n",
      "25/25 - 0s - loss: 0.6465 - accuracy: 0.7198 - val_loss: 0.6163 - val_accuracy: 0.7409\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.62517 to 0.61632, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 42/1000\n",
      "25/25 - 0s - loss: 0.6332 - accuracy: 0.7354 - val_loss: 0.6119 - val_accuracy: 0.7565\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.61632 to 0.61187, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 43/1000\n",
      "25/25 - 0s - loss: 0.6222 - accuracy: 0.7341 - val_loss: 0.6217 - val_accuracy: 0.7565\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.61187\n",
      "Epoch 44/1000\n",
      "25/25 - 0s - loss: 0.6312 - accuracy: 0.7315 - val_loss: 0.6294 - val_accuracy: 0.7461\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.61187\n",
      "Epoch 45/1000\n",
      "25/25 - 0s - loss: 0.6135 - accuracy: 0.7497 - val_loss: 0.6119 - val_accuracy: 0.7461\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.61187 to 0.61187, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 46/1000\n",
      "25/25 - 0s - loss: 0.6094 - accuracy: 0.7484 - val_loss: 0.6005 - val_accuracy: 0.7617\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.61187 to 0.60048, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 47/1000\n",
      "25/25 - 0s - loss: 0.6095 - accuracy: 0.7341 - val_loss: 0.6069 - val_accuracy: 0.7565\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.60048\n",
      "Epoch 48/1000\n",
      "25/25 - 0s - loss: 0.6011 - accuracy: 0.7393 - val_loss: 0.6142 - val_accuracy: 0.7513\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.60048\n",
      "Epoch 49/1000\n",
      "25/25 - 0s - loss: 0.6045 - accuracy: 0.7406 - val_loss: 0.6207 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.60048\n",
      "Epoch 50/1000\n",
      "25/25 - 0s - loss: 0.5903 - accuracy: 0.7562 - val_loss: 0.5979 - val_accuracy: 0.7668\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.60048 to 0.59790, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 51/1000\n",
      "25/25 - 0s - loss: 0.5918 - accuracy: 0.7354 - val_loss: 0.5958 - val_accuracy: 0.7409\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.59790 to 0.59577, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 52/1000\n",
      "25/25 - 0s - loss: 0.5880 - accuracy: 0.7445 - val_loss: 0.6109 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.59577\n",
      "Epoch 53/1000\n",
      "25/25 - 0s - loss: 0.5853 - accuracy: 0.7458 - val_loss: 0.6185 - val_accuracy: 0.7565\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.59577\n",
      "Epoch 54/1000\n",
      "25/25 - 0s - loss: 0.5769 - accuracy: 0.7613 - val_loss: 0.5936 - val_accuracy: 0.7565\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.59577 to 0.59363, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 55/1000\n",
      "25/25 - 0s - loss: 0.5688 - accuracy: 0.7652 - val_loss: 0.5974 - val_accuracy: 0.7513\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.59363\n",
      "Epoch 56/1000\n",
      "25/25 - 0s - loss: 0.5696 - accuracy: 0.7393 - val_loss: 0.5889 - val_accuracy: 0.7565\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.59363 to 0.58891, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 57/1000\n",
      "25/25 - 0s - loss: 0.5600 - accuracy: 0.7575 - val_loss: 0.5930 - val_accuracy: 0.7668\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.58891\n",
      "Epoch 58/1000\n",
      "25/25 - 0s - loss: 0.5612 - accuracy: 0.7601 - val_loss: 0.5971 - val_accuracy: 0.7617\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.58891\n",
      "Epoch 59/1000\n",
      "25/25 - 0s - loss: 0.5525 - accuracy: 0.7613 - val_loss: 0.5876 - val_accuracy: 0.7617\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.58891 to 0.58763, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 60/1000\n",
      "25/25 - 0s - loss: 0.5752 - accuracy: 0.7562 - val_loss: 0.6001 - val_accuracy: 0.7358\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.58763\n",
      "Epoch 61/1000\n",
      "25/25 - 0s - loss: 0.5537 - accuracy: 0.7601 - val_loss: 0.5927 - val_accuracy: 0.7513\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.58763\n",
      "Epoch 62/1000\n",
      "25/25 - 0s - loss: 0.5456 - accuracy: 0.7730 - val_loss: 0.5903 - val_accuracy: 0.7513\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.58763\n",
      "Epoch 63/1000\n",
      "25/25 - 0s - loss: 0.5448 - accuracy: 0.7730 - val_loss: 0.5808 - val_accuracy: 0.7617\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.58763 to 0.58084, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 64/1000\n",
      "25/25 - 0s - loss: 0.5353 - accuracy: 0.7691 - val_loss: 0.6009 - val_accuracy: 0.7565\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.58084\n",
      "Epoch 65/1000\n",
      "25/25 - 0s - loss: 0.5408 - accuracy: 0.7678 - val_loss: 0.5771 - val_accuracy: 0.7617\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.58084 to 0.57715, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 66/1000\n",
      "25/25 - 0s - loss: 0.5470 - accuracy: 0.7665 - val_loss: 0.6133 - val_accuracy: 0.7513\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.57715\n",
      "Epoch 67/1000\n",
      "25/25 - 0s - loss: 0.5422 - accuracy: 0.7601 - val_loss: 0.5896 - val_accuracy: 0.7565\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.57715\n",
      "Epoch 68/1000\n",
      "25/25 - 0s - loss: 0.5365 - accuracy: 0.7613 - val_loss: 0.5781 - val_accuracy: 0.7513\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.57715\n",
      "Epoch 69/1000\n",
      "25/25 - 0s - loss: 0.5284 - accuracy: 0.7678 - val_loss: 0.5981 - val_accuracy: 0.7565\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.57715\n",
      "Epoch 70/1000\n",
      "25/25 - 0s - loss: 0.5260 - accuracy: 0.7834 - val_loss: 0.5926 - val_accuracy: 0.7513\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.57715\n",
      "Epoch 71/1000\n",
      "25/25 - 0s - loss: 0.5303 - accuracy: 0.7691 - val_loss: 0.6013 - val_accuracy: 0.7306\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.57715\n",
      "Epoch 72/1000\n",
      "25/25 - 0s - loss: 0.5436 - accuracy: 0.7601 - val_loss: 0.5924 - val_accuracy: 0.7565\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.57715\n",
      "Epoch 73/1000\n",
      "25/25 - 0s - loss: 0.5153 - accuracy: 0.7782 - val_loss: 0.5788 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.57715\n",
      "Epoch 74/1000\n",
      "25/25 - 0s - loss: 0.5157 - accuracy: 0.7847 - val_loss: 0.5798 - val_accuracy: 0.7409\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.57715\n",
      "Epoch 75/1000\n",
      "25/25 - 0s - loss: 0.5159 - accuracy: 0.7704 - val_loss: 0.5738 - val_accuracy: 0.7306\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.57715 to 0.57380, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 76/1000\n",
      "25/25 - 0s - loss: 0.5107 - accuracy: 0.7639 - val_loss: 0.5930 - val_accuracy: 0.7306\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.57380\n",
      "Epoch 77/1000\n",
      "25/25 - 0s - loss: 0.5072 - accuracy: 0.7756 - val_loss: 0.5724 - val_accuracy: 0.7565\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.57380 to 0.57245, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 78/1000\n",
      "25/25 - 0s - loss: 0.5071 - accuracy: 0.7756 - val_loss: 0.5907 - val_accuracy: 0.7565\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.57245\n",
      "Epoch 79/1000\n",
      "25/25 - 0s - loss: 0.5016 - accuracy: 0.7756 - val_loss: 0.5851 - val_accuracy: 0.7461\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.57245\n",
      "Epoch 80/1000\n",
      "25/25 - 0s - loss: 0.5249 - accuracy: 0.7795 - val_loss: 0.5889 - val_accuracy: 0.7565\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.57245\n",
      "Epoch 81/1000\n",
      "25/25 - 0s - loss: 0.5159 - accuracy: 0.7782 - val_loss: 0.5632 - val_accuracy: 0.7617\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.57245 to 0.56319, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 82/1000\n",
      "25/25 - 0s - loss: 0.4999 - accuracy: 0.7808 - val_loss: 0.6126 - val_accuracy: 0.7358\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.56319\n",
      "Epoch 83/1000\n",
      "25/25 - 0s - loss: 0.4941 - accuracy: 0.7808 - val_loss: 0.5663 - val_accuracy: 0.7358\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.56319\n",
      "Epoch 84/1000\n",
      "25/25 - 0s - loss: 0.4894 - accuracy: 0.7886 - val_loss: 0.5594 - val_accuracy: 0.7617\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.56319 to 0.55940, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 85/1000\n",
      "25/25 - 0s - loss: 0.4857 - accuracy: 0.7938 - val_loss: 0.5708 - val_accuracy: 0.7513\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.55940\n",
      "Epoch 86/1000\n",
      "25/25 - 0s - loss: 0.4969 - accuracy: 0.7821 - val_loss: 0.5971 - val_accuracy: 0.7513\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.55940\n",
      "Epoch 87/1000\n",
      "25/25 - 0s - loss: 0.5032 - accuracy: 0.7912 - val_loss: 0.5537 - val_accuracy: 0.7617\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.55940 to 0.55373, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 88/1000\n",
      "25/25 - 0s - loss: 0.4836 - accuracy: 0.8016 - val_loss: 0.5457 - val_accuracy: 0.7409\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.55373 to 0.54573, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 89/1000\n",
      "25/25 - 0s - loss: 0.4816 - accuracy: 0.7925 - val_loss: 0.5462 - val_accuracy: 0.7461\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.54573\n",
      "Epoch 90/1000\n",
      "25/25 - 0s - loss: 0.4829 - accuracy: 0.8054 - val_loss: 0.5541 - val_accuracy: 0.7668\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.54573\n",
      "Epoch 91/1000\n",
      "25/25 - 0s - loss: 0.4792 - accuracy: 0.7912 - val_loss: 0.5531 - val_accuracy: 0.7617\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.54573\n",
      "Epoch 92/1000\n",
      "25/25 - 0s - loss: 0.4875 - accuracy: 0.7886 - val_loss: 0.5416 - val_accuracy: 0.7617\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.54573 to 0.54163, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 93/1000\n",
      "25/25 - 0s - loss: 0.4664 - accuracy: 0.8054 - val_loss: 0.5463 - val_accuracy: 0.7668\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.54163\n",
      "Epoch 94/1000\n",
      "25/25 - 0s - loss: 0.4669 - accuracy: 0.8003 - val_loss: 0.5397 - val_accuracy: 0.7772\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.54163 to 0.53969, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 95/1000\n",
      "25/25 - 0s - loss: 0.4847 - accuracy: 0.7899 - val_loss: 0.5542 - val_accuracy: 0.7772\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.53969\n",
      "Epoch 96/1000\n",
      "25/25 - 0s - loss: 0.4820 - accuracy: 0.7873 - val_loss: 0.5457 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.53969\n",
      "Epoch 97/1000\n",
      "25/25 - 0s - loss: 0.4597 - accuracy: 0.8171 - val_loss: 0.5454 - val_accuracy: 0.7668\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.53969\n",
      "Epoch 98/1000\n",
      "25/25 - 0s - loss: 0.4652 - accuracy: 0.8016 - val_loss: 0.5429 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.53969\n",
      "Epoch 99/1000\n",
      "25/25 - 0s - loss: 0.4783 - accuracy: 0.7899 - val_loss: 0.5467 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.53969\n",
      "Epoch 100/1000\n",
      "25/25 - 0s - loss: 0.4595 - accuracy: 0.8042 - val_loss: 0.5476 - val_accuracy: 0.7772\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.53969\n",
      "Epoch 101/1000\n",
      "25/25 - 0s - loss: 0.4597 - accuracy: 0.8054 - val_loss: 0.5256 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.53969 to 0.52558, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 102/1000\n",
      "25/25 - 0s - loss: 0.4637 - accuracy: 0.8042 - val_loss: 0.5305 - val_accuracy: 0.7565\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.52558\n",
      "Epoch 103/1000\n",
      "25/25 - 0s - loss: 0.4622 - accuracy: 0.8106 - val_loss: 0.5123 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.52558 to 0.51232, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 104/1000\n",
      "25/25 - 0s - loss: 0.4627 - accuracy: 0.8106 - val_loss: 0.5123 - val_accuracy: 0.7772\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.51232\n",
      "Epoch 105/1000\n",
      "25/25 - 0s - loss: 0.4595 - accuracy: 0.8042 - val_loss: 0.5241 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.51232\n",
      "Epoch 106/1000\n",
      "25/25 - 0s - loss: 0.4463 - accuracy: 0.8119 - val_loss: 0.5118 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.51232 to 0.51176, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 107/1000\n",
      "25/25 - 0s - loss: 0.4441 - accuracy: 0.8132 - val_loss: 0.5207 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.51176\n",
      "Epoch 108/1000\n",
      "25/25 - 0s - loss: 0.4579 - accuracy: 0.8067 - val_loss: 0.5256 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.51176\n",
      "Epoch 109/1000\n",
      "25/25 - 0s - loss: 0.4681 - accuracy: 0.7977 - val_loss: 0.5551 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.51176\n",
      "Epoch 110/1000\n",
      "25/25 - 0s - loss: 0.4566 - accuracy: 0.8119 - val_loss: 0.5197 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.51176\n",
      "Epoch 111/1000\n",
      "25/25 - 0s - loss: 0.4371 - accuracy: 0.8067 - val_loss: 0.5486 - val_accuracy: 0.7772\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.51176\n",
      "Epoch 112/1000\n",
      "25/25 - 0s - loss: 0.4476 - accuracy: 0.8029 - val_loss: 0.5141 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.51176\n",
      "Epoch 113/1000\n",
      "25/25 - 0s - loss: 0.4402 - accuracy: 0.8210 - val_loss: 0.5106 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.51176 to 0.51061, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 114/1000\n",
      "25/25 - 0s - loss: 0.4403 - accuracy: 0.8119 - val_loss: 0.5090 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.51061 to 0.50903, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 115/1000\n",
      "25/25 - 0s - loss: 0.4308 - accuracy: 0.8236 - val_loss: 0.5018 - val_accuracy: 0.7772\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.50903 to 0.50175, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 116/1000\n",
      "25/25 - 0s - loss: 0.4421 - accuracy: 0.8132 - val_loss: 0.5145 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.50175\n",
      "Epoch 117/1000\n",
      "25/25 - 0s - loss: 0.4314 - accuracy: 0.8262 - val_loss: 0.5340 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.50175\n",
      "Epoch 118/1000\n",
      "25/25 - 0s - loss: 0.4357 - accuracy: 0.8236 - val_loss: 0.5334 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.50175\n",
      "Epoch 119/1000\n",
      "25/25 - 0s - loss: 0.4317 - accuracy: 0.8210 - val_loss: 0.5265 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.50175\n",
      "Epoch 120/1000\n",
      "25/25 - 0s - loss: 0.4231 - accuracy: 0.8236 - val_loss: 0.5220 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.50175\n",
      "Epoch 121/1000\n",
      "25/25 - 0s - loss: 0.4211 - accuracy: 0.8262 - val_loss: 0.5160 - val_accuracy: 0.7668\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.50175\n",
      "Epoch 122/1000\n",
      "25/25 - 0s - loss: 0.4274 - accuracy: 0.8236 - val_loss: 0.5179 - val_accuracy: 0.7668\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.50175\n",
      "Epoch 123/1000\n",
      "25/25 - 0s - loss: 0.4171 - accuracy: 0.8236 - val_loss: 0.5067 - val_accuracy: 0.7772\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.50175\n",
      "Epoch 124/1000\n",
      "25/25 - 0s - loss: 0.4489 - accuracy: 0.8029 - val_loss: 0.5699 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.50175\n",
      "Epoch 125/1000\n",
      "25/25 - 0s - loss: 0.4264 - accuracy: 0.8236 - val_loss: 0.5052 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.50175\n",
      "Epoch 126/1000\n",
      "25/25 - 0s - loss: 0.4187 - accuracy: 0.8262 - val_loss: 0.5258 - val_accuracy: 0.7772\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.50175\n",
      "Epoch 127/1000\n",
      "25/25 - 0s - loss: 0.4493 - accuracy: 0.8145 - val_loss: 0.5393 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.50175\n",
      "Epoch 128/1000\n",
      "25/25 - 0s - loss: 0.4142 - accuracy: 0.8262 - val_loss: 0.5165 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.50175\n",
      "Epoch 129/1000\n",
      "25/25 - 0s - loss: 0.4028 - accuracy: 0.8210 - val_loss: 0.5127 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.50175\n",
      "Epoch 130/1000\n",
      "25/25 - 0s - loss: 0.4188 - accuracy: 0.8314 - val_loss: 0.5067 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.50175\n",
      "Epoch 131/1000\n",
      "25/25 - 0s - loss: 0.4160 - accuracy: 0.8249 - val_loss: 0.5651 - val_accuracy: 0.7668\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.50175\n",
      "Epoch 132/1000\n",
      "25/25 - 0s - loss: 0.4183 - accuracy: 0.8275 - val_loss: 0.5220 - val_accuracy: 0.7617\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.50175\n",
      "Epoch 133/1000\n",
      "25/25 - 0s - loss: 0.4056 - accuracy: 0.8249 - val_loss: 0.5392 - val_accuracy: 0.7772\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.50175\n",
      "Epoch 134/1000\n",
      "25/25 - 0s - loss: 0.4046 - accuracy: 0.8223 - val_loss: 0.5294 - val_accuracy: 0.7668\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.50175\n",
      "Epoch 135/1000\n",
      "25/25 - 0s - loss: 0.4124 - accuracy: 0.8223 - val_loss: 0.5310 - val_accuracy: 0.7668\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.50175\n",
      "Epoch 136/1000\n",
      "25/25 - 0s - loss: 0.4062 - accuracy: 0.8249 - val_loss: 0.4996 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.50175 to 0.49960, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 137/1000\n",
      "25/25 - 0s - loss: 0.4008 - accuracy: 0.8288 - val_loss: 0.5241 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.49960\n",
      "Epoch 138/1000\n",
      "25/25 - 0s - loss: 0.4105 - accuracy: 0.8379 - val_loss: 0.5938 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.49960\n",
      "Epoch 139/1000\n",
      "25/25 - 0s - loss: 0.4276 - accuracy: 0.8106 - val_loss: 0.5140 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.49960\n",
      "Epoch 140/1000\n",
      "25/25 - 0s - loss: 0.4082 - accuracy: 0.8353 - val_loss: 0.4941 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.49960 to 0.49408, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 141/1000\n",
      "25/25 - 0s - loss: 0.4079 - accuracy: 0.8327 - val_loss: 0.5117 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.49408\n",
      "Epoch 142/1000\n",
      "25/25 - 0s - loss: 0.3915 - accuracy: 0.8340 - val_loss: 0.4943 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.49408\n",
      "Epoch 143/1000\n",
      "25/25 - 0s - loss: 0.4016 - accuracy: 0.8288 - val_loss: 0.5093 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.49408\n",
      "Epoch 144/1000\n",
      "25/25 - 0s - loss: 0.3855 - accuracy: 0.8301 - val_loss: 0.5455 - val_accuracy: 0.7772\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.49408\n",
      "Epoch 145/1000\n",
      "25/25 - 0s - loss: 0.3922 - accuracy: 0.8431 - val_loss: 0.5201 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.49408\n",
      "Epoch 146/1000\n",
      "25/25 - 0s - loss: 0.4010 - accuracy: 0.8314 - val_loss: 0.5162 - val_accuracy: 0.7876\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.49408\n",
      "Epoch 147/1000\n",
      "25/25 - 0s - loss: 0.3794 - accuracy: 0.8353 - val_loss: 0.5412 - val_accuracy: 0.7668\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.49408\n",
      "Epoch 148/1000\n",
      "25/25 - 0s - loss: 0.3870 - accuracy: 0.8275 - val_loss: 0.5074 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.49408\n",
      "Epoch 149/1000\n",
      "25/25 - 0s - loss: 0.3816 - accuracy: 0.8210 - val_loss: 0.4939 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.49408 to 0.49388, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 150/1000\n",
      "25/25 - 0s - loss: 0.3755 - accuracy: 0.8327 - val_loss: 0.4882 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.49388 to 0.48816, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 151/1000\n",
      "25/25 - 0s - loss: 0.3711 - accuracy: 0.8418 - val_loss: 0.4832 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.48816 to 0.48323, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 152/1000\n",
      "25/25 - 0s - loss: 0.3885 - accuracy: 0.8249 - val_loss: 0.5194 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.48323\n",
      "Epoch 153/1000\n",
      "25/25 - 0s - loss: 0.3780 - accuracy: 0.8249 - val_loss: 0.4995 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.48323\n",
      "Epoch 154/1000\n",
      "25/25 - 0s - loss: 0.4043 - accuracy: 0.8275 - val_loss: 0.5023 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.48323\n",
      "Epoch 155/1000\n",
      "25/25 - 0s - loss: 0.3829 - accuracy: 0.8275 - val_loss: 0.4825 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.48323 to 0.48253, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 156/1000\n",
      "25/25 - 0s - loss: 0.3741 - accuracy: 0.8495 - val_loss: 0.5118 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.48253\n",
      "Epoch 157/1000\n",
      "25/25 - 0s - loss: 0.3699 - accuracy: 0.8405 - val_loss: 0.4654 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.48253 to 0.46545, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 158/1000\n",
      "25/25 - 0s - loss: 0.3615 - accuracy: 0.8379 - val_loss: 0.4587 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.46545 to 0.45869, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 159/1000\n",
      "25/25 - 0s - loss: 0.3722 - accuracy: 0.8405 - val_loss: 0.4767 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.45869\n",
      "Epoch 160/1000\n",
      "25/25 - 0s - loss: 0.3625 - accuracy: 0.8431 - val_loss: 0.4706 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.45869\n",
      "Epoch 161/1000\n",
      "25/25 - 0s - loss: 0.3481 - accuracy: 0.8560 - val_loss: 0.5053 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.45869\n",
      "Epoch 162/1000\n",
      "25/25 - 0s - loss: 0.3554 - accuracy: 0.8470 - val_loss: 0.4922 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.45869\n",
      "Epoch 163/1000\n",
      "25/25 - 0s - loss: 0.3634 - accuracy: 0.8495 - val_loss: 0.4611 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.45869\n",
      "Epoch 164/1000\n",
      "25/25 - 0s - loss: 0.3554 - accuracy: 0.8482 - val_loss: 0.4813 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.45869\n",
      "Epoch 165/1000\n",
      "25/25 - 0s - loss: 0.3478 - accuracy: 0.8521 - val_loss: 0.4644 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.45869\n",
      "Epoch 166/1000\n",
      "25/25 - 0s - loss: 0.3563 - accuracy: 0.8482 - val_loss: 0.4642 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.45869\n",
      "Epoch 167/1000\n",
      "25/25 - 0s - loss: 0.3406 - accuracy: 0.8495 - val_loss: 0.4612 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.45869\n",
      "Epoch 168/1000\n",
      "25/25 - 0s - loss: 0.3576 - accuracy: 0.8470 - val_loss: 0.4766 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.45869\n",
      "Epoch 169/1000\n",
      "25/25 - 0s - loss: 0.3854 - accuracy: 0.8457 - val_loss: 0.5007 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.45869\n",
      "Epoch 170/1000\n",
      "25/25 - 0s - loss: 0.3534 - accuracy: 0.8560 - val_loss: 0.4566 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.45869 to 0.45657, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 171/1000\n",
      "25/25 - 0s - loss: 0.3424 - accuracy: 0.8560 - val_loss: 0.4522 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.45657 to 0.45222, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 172/1000\n",
      "25/25 - 0s - loss: 0.3433 - accuracy: 0.8534 - val_loss: 0.4646 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.45222\n",
      "Epoch 173/1000\n",
      "25/25 - 0s - loss: 0.3357 - accuracy: 0.8664 - val_loss: 0.4589 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.45222\n",
      "Epoch 174/1000\n",
      "25/25 - 0s - loss: 0.3570 - accuracy: 0.8599 - val_loss: 0.4898 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.45222\n",
      "Epoch 175/1000\n",
      "25/25 - 0s - loss: 0.3650 - accuracy: 0.8586 - val_loss: 0.4903 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.45222\n",
      "Epoch 176/1000\n",
      "25/25 - 0s - loss: 0.3692 - accuracy: 0.8560 - val_loss: 0.5194 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.45222\n",
      "Epoch 177/1000\n",
      "25/25 - 0s - loss: 0.3628 - accuracy: 0.8495 - val_loss: 0.5216 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.45222\n",
      "Epoch 178/1000\n",
      "25/25 - 0s - loss: 0.3543 - accuracy: 0.8586 - val_loss: 0.4700 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.45222\n",
      "Epoch 179/1000\n",
      "25/25 - 0s - loss: 0.3552 - accuracy: 0.8560 - val_loss: 0.4971 - val_accuracy: 0.7927\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.45222\n",
      "Epoch 180/1000\n",
      "25/25 - 0s - loss: 0.3447 - accuracy: 0.8638 - val_loss: 0.4672 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.45222\n",
      "Epoch 181/1000\n",
      "25/25 - 0s - loss: 0.3375 - accuracy: 0.8625 - val_loss: 0.4665 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.45222\n",
      "Epoch 182/1000\n",
      "25/25 - 0s - loss: 0.3396 - accuracy: 0.8677 - val_loss: 0.5145 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.45222\n",
      "Epoch 183/1000\n",
      "25/25 - 0s - loss: 0.3240 - accuracy: 0.8729 - val_loss: 0.4673 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.45222\n",
      "Epoch 184/1000\n",
      "25/25 - 0s - loss: 0.3281 - accuracy: 0.8599 - val_loss: 0.4516 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00184: val_loss improved from 0.45222 to 0.45162, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 185/1000\n",
      "25/25 - 0s - loss: 0.3354 - accuracy: 0.8664 - val_loss: 0.4904 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.45162\n",
      "Epoch 186/1000\n",
      "25/25 - 0s - loss: 0.3227 - accuracy: 0.8703 - val_loss: 0.4802 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.45162\n",
      "Epoch 187/1000\n",
      "25/25 - 0s - loss: 0.3706 - accuracy: 0.8470 - val_loss: 0.5087 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.45162\n",
      "Epoch 188/1000\n",
      "25/25 - 0s - loss: 0.3527 - accuracy: 0.8521 - val_loss: 0.5159 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.45162\n",
      "Epoch 189/1000\n",
      "25/25 - 0s - loss: 0.3307 - accuracy: 0.8742 - val_loss: 0.4764 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.45162\n",
      "Epoch 190/1000\n",
      "25/25 - 0s - loss: 0.3127 - accuracy: 0.8807 - val_loss: 0.4626 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.45162\n",
      "Epoch 191/1000\n",
      "25/25 - 0s - loss: 0.3146 - accuracy: 0.8729 - val_loss: 0.4604 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.45162\n",
      "Epoch 192/1000\n",
      "25/25 - 0s - loss: 0.3158 - accuracy: 0.8638 - val_loss: 0.4597 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.45162\n",
      "Epoch 193/1000\n",
      "25/25 - 0s - loss: 0.3123 - accuracy: 0.8716 - val_loss: 0.4839 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.45162\n",
      "Epoch 194/1000\n",
      "25/25 - 0s - loss: 0.3100 - accuracy: 0.8807 - val_loss: 0.4469 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00194: val_loss improved from 0.45162 to 0.44692, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 195/1000\n",
      "25/25 - 0s - loss: 0.3169 - accuracy: 0.8703 - val_loss: 0.4648 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.44692\n",
      "Epoch 196/1000\n",
      "25/25 - 0s - loss: 0.3050 - accuracy: 0.8781 - val_loss: 0.4534 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.44692\n",
      "Epoch 197/1000\n",
      "25/25 - 0s - loss: 0.3025 - accuracy: 0.8833 - val_loss: 0.4602 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.44692\n",
      "Epoch 198/1000\n",
      "25/25 - 0s - loss: 0.3061 - accuracy: 0.8703 - val_loss: 0.4360 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.44692 to 0.43597, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 199/1000\n",
      "25/25 - 0s - loss: 0.3230 - accuracy: 0.8625 - val_loss: 0.4755 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.43597\n",
      "Epoch 200/1000\n",
      "25/25 - 0s - loss: 0.3145 - accuracy: 0.8794 - val_loss: 0.4928 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.43597\n",
      "Epoch 201/1000\n",
      "25/25 - 0s - loss: 0.3121 - accuracy: 0.8768 - val_loss: 0.4532 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.43597\n",
      "Epoch 202/1000\n",
      "25/25 - 0s - loss: 0.2970 - accuracy: 0.8923 - val_loss: 0.4432 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.43597\n",
      "Epoch 203/1000\n",
      "25/25 - 0s - loss: 0.3146 - accuracy: 0.8664 - val_loss: 0.4507 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.43597\n",
      "Epoch 204/1000\n",
      "25/25 - 0s - loss: 0.3171 - accuracy: 0.8807 - val_loss: 0.4415 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.43597\n",
      "Epoch 205/1000\n",
      "25/25 - 0s - loss: 0.3015 - accuracy: 0.8781 - val_loss: 0.4696 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.43597\n",
      "Epoch 206/1000\n",
      "25/25 - 0s - loss: 0.2920 - accuracy: 0.8885 - val_loss: 0.4516 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.43597\n",
      "Epoch 207/1000\n",
      "25/25 - 0s - loss: 0.2955 - accuracy: 0.8807 - val_loss: 0.4494 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.43597\n",
      "Epoch 208/1000\n",
      "25/25 - 0s - loss: 0.3021 - accuracy: 0.8742 - val_loss: 0.4565 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.43597\n",
      "Epoch 209/1000\n",
      "25/25 - 0s - loss: 0.3079 - accuracy: 0.8729 - val_loss: 0.4813 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.43597\n",
      "Epoch 210/1000\n",
      "25/25 - 0s - loss: 0.2914 - accuracy: 0.8807 - val_loss: 0.4342 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00210: val_loss improved from 0.43597 to 0.43421, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 211/1000\n",
      "25/25 - 0s - loss: 0.2745 - accuracy: 0.8949 - val_loss: 0.4495 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.43421\n",
      "Epoch 212/1000\n",
      "25/25 - 0s - loss: 0.2755 - accuracy: 0.8859 - val_loss: 0.4526 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.43421\n",
      "Epoch 213/1000\n",
      "25/25 - 0s - loss: 0.2795 - accuracy: 0.8859 - val_loss: 0.4527 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.43421\n",
      "Epoch 214/1000\n",
      "25/25 - 0s - loss: 0.2732 - accuracy: 0.8949 - val_loss: 0.4349 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.43421\n",
      "Epoch 215/1000\n",
      "25/25 - 0s - loss: 0.2887 - accuracy: 0.8872 - val_loss: 0.4406 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.43421\n",
      "Epoch 216/1000\n",
      "25/25 - 0s - loss: 0.2879 - accuracy: 0.8846 - val_loss: 0.4350 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.43421\n",
      "Epoch 217/1000\n",
      "25/25 - 0s - loss: 0.3018 - accuracy: 0.8794 - val_loss: 0.4871 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.43421\n",
      "Epoch 218/1000\n",
      "25/25 - 0s - loss: 0.2947 - accuracy: 0.8911 - val_loss: 0.4647 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.43421\n",
      "Epoch 219/1000\n",
      "25/25 - 0s - loss: 0.2904 - accuracy: 0.8936 - val_loss: 0.4496 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.43421\n",
      "Epoch 220/1000\n",
      "25/25 - 0s - loss: 0.2775 - accuracy: 0.8911 - val_loss: 0.4612 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.43421\n",
      "Epoch 221/1000\n",
      "25/25 - 0s - loss: 0.2707 - accuracy: 0.8911 - val_loss: 0.4536 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.43421\n",
      "Epoch 222/1000\n",
      "25/25 - 0s - loss: 0.2672 - accuracy: 0.8923 - val_loss: 0.4522 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.43421\n",
      "Epoch 223/1000\n",
      "25/25 - 0s - loss: 0.2643 - accuracy: 0.8936 - val_loss: 0.4319 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00223: val_loss improved from 0.43421 to 0.43187, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 224/1000\n",
      "25/25 - 0s - loss: 0.2600 - accuracy: 0.8923 - val_loss: 0.4388 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.43187\n",
      "Epoch 225/1000\n",
      "25/25 - 0s - loss: 0.2646 - accuracy: 0.8988 - val_loss: 0.4946 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.43187\n",
      "Epoch 226/1000\n",
      "25/25 - 0s - loss: 0.2792 - accuracy: 0.8872 - val_loss: 0.4428 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.43187\n",
      "Epoch 227/1000\n",
      "25/25 - 0s - loss: 0.2657 - accuracy: 0.8936 - val_loss: 0.4303 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00227: val_loss improved from 0.43187 to 0.43026, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 228/1000\n",
      "25/25 - 0s - loss: 0.2754 - accuracy: 0.8949 - val_loss: 0.4439 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.43026\n",
      "Epoch 229/1000\n",
      "25/25 - 0s - loss: 0.2805 - accuracy: 0.8872 - val_loss: 0.4592 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.43026\n",
      "Epoch 230/1000\n",
      "25/25 - 0s - loss: 0.2618 - accuracy: 0.8949 - val_loss: 0.4550 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.43026\n",
      "Epoch 231/1000\n",
      "25/25 - 0s - loss: 0.2797 - accuracy: 0.8898 - val_loss: 0.5425 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.43026\n",
      "Epoch 232/1000\n",
      "25/25 - 0s - loss: 0.2856 - accuracy: 0.8781 - val_loss: 0.4621 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.43026\n",
      "Epoch 233/1000\n",
      "25/25 - 0s - loss: 0.2621 - accuracy: 0.8936 - val_loss: 0.4689 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.43026\n",
      "Epoch 234/1000\n",
      "25/25 - 0s - loss: 0.2637 - accuracy: 0.8936 - val_loss: 0.4723 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.43026\n",
      "Epoch 235/1000\n",
      "25/25 - 0s - loss: 0.2640 - accuracy: 0.8936 - val_loss: 0.4401 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.43026\n",
      "Epoch 236/1000\n",
      "25/25 - 0s - loss: 0.2581 - accuracy: 0.8872 - val_loss: 0.4519 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.43026\n",
      "Epoch 237/1000\n",
      "25/25 - 0s - loss: 0.2561 - accuracy: 0.8949 - val_loss: 0.4731 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.43026\n",
      "Epoch 238/1000\n",
      "25/25 - 0s - loss: 0.2665 - accuracy: 0.8911 - val_loss: 0.4463 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.43026\n",
      "Epoch 239/1000\n",
      "25/25 - 0s - loss: 0.2636 - accuracy: 0.8898 - val_loss: 0.4427 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.43026\n",
      "Epoch 240/1000\n",
      "25/25 - 0s - loss: 0.2805 - accuracy: 0.8846 - val_loss: 0.4673 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.43026\n",
      "Epoch 241/1000\n",
      "25/25 - 0s - loss: 0.2643 - accuracy: 0.8949 - val_loss: 0.4656 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.43026\n",
      "Epoch 242/1000\n",
      "25/25 - 0s - loss: 0.2655 - accuracy: 0.8898 - val_loss: 0.4406 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.43026\n",
      "Epoch 243/1000\n",
      "25/25 - 0s - loss: 0.2703 - accuracy: 0.8820 - val_loss: 0.4736 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.43026\n",
      "Epoch 244/1000\n",
      "25/25 - 0s - loss: 0.2563 - accuracy: 0.9001 - val_loss: 0.4714 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.43026\n",
      "Epoch 245/1000\n",
      "25/25 - 0s - loss: 0.2758 - accuracy: 0.8833 - val_loss: 0.4751 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.43026\n",
      "Epoch 246/1000\n",
      "25/25 - 0s - loss: 0.2668 - accuracy: 0.8962 - val_loss: 0.4577 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.43026\n",
      "Epoch 247/1000\n",
      "25/25 - 0s - loss: 0.2758 - accuracy: 0.8872 - val_loss: 0.5353 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.43026\n",
      "Epoch 248/1000\n",
      "25/25 - 0s - loss: 0.2721 - accuracy: 0.8923 - val_loss: 0.4613 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.43026\n",
      "Epoch 249/1000\n",
      "25/25 - 0s - loss: 0.2491 - accuracy: 0.8975 - val_loss: 0.4456 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.43026\n",
      "Epoch 250/1000\n",
      "25/25 - 0s - loss: 0.2702 - accuracy: 0.9001 - val_loss: 0.4656 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.43026\n",
      "Epoch 251/1000\n",
      "25/25 - 0s - loss: 0.2506 - accuracy: 0.8975 - val_loss: 0.4606 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.43026\n",
      "Epoch 252/1000\n",
      "25/25 - 0s - loss: 0.2484 - accuracy: 0.9040 - val_loss: 0.4557 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.43026\n",
      "Epoch 253/1000\n",
      "25/25 - 0s - loss: 0.2542 - accuracy: 0.9014 - val_loss: 0.4576 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.43026\n",
      "Epoch 254/1000\n",
      "25/25 - 0s - loss: 0.2586 - accuracy: 0.8936 - val_loss: 0.4672 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.43026\n",
      "Epoch 255/1000\n",
      "25/25 - 0s - loss: 0.2553 - accuracy: 0.8936 - val_loss: 0.4552 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.43026\n",
      "Epoch 256/1000\n",
      "25/25 - 0s - loss: 0.2618 - accuracy: 0.8975 - val_loss: 0.4628 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.43026\n",
      "Epoch 257/1000\n",
      "25/25 - 0s - loss: 0.2630 - accuracy: 0.8936 - val_loss: 0.4666 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.43026\n",
      "Epoch 258/1000\n",
      "25/25 - 0s - loss: 0.2490 - accuracy: 0.8975 - val_loss: 0.4536 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.43026\n",
      "Epoch 259/1000\n",
      "25/25 - 0s - loss: 0.2478 - accuracy: 0.8859 - val_loss: 0.4907 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.43026\n",
      "Epoch 260/1000\n",
      "25/25 - 0s - loss: 0.2502 - accuracy: 0.8988 - val_loss: 0.4622 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.43026\n",
      "Epoch 261/1000\n",
      "25/25 - 0s - loss: 0.2483 - accuracy: 0.8962 - val_loss: 0.4625 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.43026\n",
      "Epoch 262/1000\n",
      "25/25 - 0s - loss: 0.2496 - accuracy: 0.8975 - val_loss: 0.4592 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.43026\n",
      "Epoch 263/1000\n",
      "25/25 - 0s - loss: 0.2557 - accuracy: 0.8988 - val_loss: 0.4643 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.43026\n",
      "Epoch 264/1000\n",
      "25/25 - 0s - loss: 0.2698 - accuracy: 0.8975 - val_loss: 0.4572 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.43026\n",
      "Epoch 265/1000\n",
      "25/25 - 0s - loss: 0.2534 - accuracy: 0.8911 - val_loss: 0.4761 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.43026\n",
      "Epoch 266/1000\n",
      "25/25 - 0s - loss: 0.2548 - accuracy: 0.8988 - val_loss: 0.4548 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.43026\n",
      "Epoch 267/1000\n",
      "25/25 - 0s - loss: 0.2475 - accuracy: 0.9001 - val_loss: 0.4901 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.43026\n",
      "Epoch 268/1000\n",
      "25/25 - 0s - loss: 0.2447 - accuracy: 0.9014 - val_loss: 0.4814 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.43026\n",
      "Epoch 269/1000\n",
      "25/25 - 0s - loss: 0.2625 - accuracy: 0.8833 - val_loss: 0.4676 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.43026\n",
      "Epoch 270/1000\n",
      "25/25 - 0s - loss: 0.2449 - accuracy: 0.8962 - val_loss: 0.4651 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.43026\n",
      "Epoch 271/1000\n",
      "25/25 - 0s - loss: 0.2519 - accuracy: 0.8936 - val_loss: 0.4868 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.43026\n",
      "Epoch 272/1000\n",
      "25/25 - 0s - loss: 0.2496 - accuracy: 0.8923 - val_loss: 0.4799 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.43026\n",
      "Epoch 273/1000\n",
      "25/25 - 0s - loss: 0.2532 - accuracy: 0.8898 - val_loss: 0.4894 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.43026\n",
      "Epoch 274/1000\n",
      "25/25 - 0s - loss: 0.2469 - accuracy: 0.8949 - val_loss: 0.5091 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.43026\n",
      "Epoch 275/1000\n",
      "25/25 - 0s - loss: 0.2503 - accuracy: 0.8885 - val_loss: 0.4947 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.43026\n",
      "Epoch 276/1000\n",
      "25/25 - 0s - loss: 0.2530 - accuracy: 0.9001 - val_loss: 0.4805 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.43026\n",
      "Epoch 277/1000\n",
      "25/25 - 0s - loss: 0.2555 - accuracy: 0.8923 - val_loss: 0.4605 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.43026\n",
      "Epoch 278/1000\n",
      "25/25 - 0s - loss: 0.2427 - accuracy: 0.8988 - val_loss: 0.4592 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.43026\n",
      "Epoch 279/1000\n",
      "25/25 - 0s - loss: 0.2463 - accuracy: 0.8962 - val_loss: 0.4545 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.43026\n",
      "Epoch 280/1000\n",
      "25/25 - 0s - loss: 0.2413 - accuracy: 0.8988 - val_loss: 0.4571 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.43026\n",
      "Epoch 281/1000\n",
      "25/25 - 0s - loss: 0.2432 - accuracy: 0.8975 - val_loss: 0.4544 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.43026\n",
      "Epoch 282/1000\n",
      "25/25 - 0s - loss: 0.2421 - accuracy: 0.8988 - val_loss: 0.4742 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.43026\n",
      "Epoch 283/1000\n",
      "25/25 - 0s - loss: 0.2440 - accuracy: 0.8975 - val_loss: 0.4598 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.43026\n",
      "Epoch 284/1000\n",
      "25/25 - 0s - loss: 0.2489 - accuracy: 0.9001 - val_loss: 0.4881 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.43026\n",
      "Epoch 285/1000\n",
      "25/25 - 0s - loss: 0.2412 - accuracy: 0.9014 - val_loss: 0.4600 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.43026\n",
      "Epoch 286/1000\n",
      "25/25 - 0s - loss: 0.2408 - accuracy: 0.8923 - val_loss: 0.4779 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.43026\n",
      "Epoch 287/1000\n",
      "25/25 - 0s - loss: 0.2456 - accuracy: 0.8975 - val_loss: 0.4554 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.43026\n",
      "Epoch 288/1000\n",
      "25/25 - 0s - loss: 0.2506 - accuracy: 0.8872 - val_loss: 0.4898 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.43026\n",
      "Epoch 289/1000\n",
      "25/25 - 0s - loss: 0.2440 - accuracy: 0.8923 - val_loss: 0.4837 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.43026\n",
      "Epoch 290/1000\n",
      "25/25 - 0s - loss: 0.2621 - accuracy: 0.8949 - val_loss: 0.4738 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.43026\n",
      "Epoch 291/1000\n",
      "25/25 - 0s - loss: 0.2436 - accuracy: 0.8975 - val_loss: 0.4771 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.43026\n",
      "Epoch 292/1000\n",
      "25/25 - 0s - loss: 0.2395 - accuracy: 0.9014 - val_loss: 0.4849 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.43026\n",
      "Epoch 293/1000\n",
      "25/25 - 0s - loss: 0.2434 - accuracy: 0.8949 - val_loss: 0.4752 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.43026\n",
      "Epoch 294/1000\n",
      "25/25 - 0s - loss: 0.2388 - accuracy: 0.8936 - val_loss: 0.4492 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.43026\n",
      "Epoch 295/1000\n",
      "25/25 - 0s - loss: 0.2727 - accuracy: 0.8898 - val_loss: 0.5036 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.43026\n",
      "Epoch 296/1000\n",
      "25/25 - 0s - loss: 0.2481 - accuracy: 0.8962 - val_loss: 0.4899 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.43026\n",
      "Epoch 297/1000\n",
      "25/25 - 0s - loss: 0.2419 - accuracy: 0.8975 - val_loss: 0.4611 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.43026\n",
      "Epoch 298/1000\n",
      "25/25 - 0s - loss: 0.2493 - accuracy: 0.8898 - val_loss: 0.4596 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.43026\n",
      "Epoch 299/1000\n",
      "25/25 - 0s - loss: 0.2413 - accuracy: 0.8923 - val_loss: 0.4962 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.43026\n",
      "Epoch 300/1000\n",
      "25/25 - 0s - loss: 0.2496 - accuracy: 0.8923 - val_loss: 0.4787 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.43026\n",
      "Epoch 301/1000\n",
      "25/25 - 0s - loss: 0.2595 - accuracy: 0.8975 - val_loss: 0.4489 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.43026\n",
      "Epoch 302/1000\n",
      "25/25 - 0s - loss: 0.2546 - accuracy: 0.8923 - val_loss: 0.4680 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.43026\n",
      "Epoch 303/1000\n",
      "25/25 - 0s - loss: 0.2409 - accuracy: 0.8975 - val_loss: 0.4551 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.43026\n",
      "Epoch 304/1000\n",
      "25/25 - 0s - loss: 0.2484 - accuracy: 0.8846 - val_loss: 0.4563 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.43026\n",
      "Epoch 305/1000\n",
      "25/25 - 0s - loss: 0.2574 - accuracy: 0.9040 - val_loss: 0.4998 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.43026\n",
      "Epoch 306/1000\n",
      "25/25 - 0s - loss: 0.2485 - accuracy: 0.8898 - val_loss: 0.4654 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.43026\n",
      "Epoch 307/1000\n",
      "25/25 - 0s - loss: 0.2412 - accuracy: 0.8923 - val_loss: 0.4588 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.43026\n",
      "Epoch 308/1000\n",
      "25/25 - 0s - loss: 0.2486 - accuracy: 0.8936 - val_loss: 0.4525 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.43026\n",
      "Epoch 309/1000\n",
      "25/25 - 0s - loss: 0.2451 - accuracy: 0.9040 - val_loss: 0.4737 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.43026\n",
      "Epoch 310/1000\n",
      "25/25 - 0s - loss: 0.2360 - accuracy: 0.8988 - val_loss: 0.4938 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.43026\n",
      "Epoch 311/1000\n",
      "25/25 - 0s - loss: 0.2631 - accuracy: 0.8846 - val_loss: 0.5273 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.43026\n",
      "Epoch 312/1000\n",
      "25/25 - 0s - loss: 0.2411 - accuracy: 0.9053 - val_loss: 0.4673 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.43026\n",
      "Epoch 313/1000\n",
      "25/25 - 0s - loss: 0.2344 - accuracy: 0.8962 - val_loss: 0.4632 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.43026\n",
      "Epoch 314/1000\n",
      "25/25 - 0s - loss: 0.2352 - accuracy: 0.8975 - val_loss: 0.4638 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.43026\n",
      "Epoch 315/1000\n",
      "25/25 - 0s - loss: 0.2314 - accuracy: 0.9014 - val_loss: 0.4656 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.43026\n",
      "Epoch 316/1000\n",
      "25/25 - 0s - loss: 0.2820 - accuracy: 0.8729 - val_loss: 0.4789 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.43026\n",
      "Epoch 317/1000\n",
      "25/25 - 0s - loss: 0.2702 - accuracy: 0.8885 - val_loss: 0.4727 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.43026\n",
      "Epoch 318/1000\n",
      "25/25 - 0s - loss: 0.2500 - accuracy: 0.8820 - val_loss: 0.4676 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.43026\n",
      "Epoch 319/1000\n",
      "25/25 - 0s - loss: 0.2389 - accuracy: 0.8988 - val_loss: 0.4565 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.43026\n",
      "Epoch 320/1000\n",
      "25/25 - 0s - loss: 0.2538 - accuracy: 0.8846 - val_loss: 0.4548 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.43026\n",
      "Epoch 321/1000\n",
      "25/25 - 0s - loss: 0.2374 - accuracy: 0.8898 - val_loss: 0.4503 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.43026\n",
      "Epoch 322/1000\n",
      "25/25 - 0s - loss: 0.2371 - accuracy: 0.8911 - val_loss: 0.4694 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.43026\n",
      "Epoch 323/1000\n",
      "25/25 - 0s - loss: 0.2309 - accuracy: 0.8962 - val_loss: 0.4903 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.43026\n",
      "Epoch 324/1000\n",
      "25/25 - 0s - loss: 0.2383 - accuracy: 0.8962 - val_loss: 0.4621 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.43026\n",
      "Epoch 325/1000\n",
      "25/25 - 0s - loss: 0.2305 - accuracy: 0.9001 - val_loss: 0.4606 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.43026\n",
      "Epoch 326/1000\n",
      "25/25 - 0s - loss: 0.2311 - accuracy: 0.8975 - val_loss: 0.4757 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.43026\n",
      "Epoch 327/1000\n",
      "25/25 - 0s - loss: 0.2381 - accuracy: 0.8923 - val_loss: 0.4717 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.43026\n",
      "Epoch 328/1000\n",
      "25/25 - 0s - loss: 0.2404 - accuracy: 0.9001 - val_loss: 0.4582 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.43026\n",
      "Epoch 329/1000\n",
      "25/25 - 0s - loss: 0.2352 - accuracy: 0.8962 - val_loss: 0.4676 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.43026\n",
      "Epoch 330/1000\n",
      "25/25 - 0s - loss: 0.2370 - accuracy: 0.9001 - val_loss: 0.4680 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.43026\n",
      "Epoch 331/1000\n",
      "25/25 - 0s - loss: 0.2352 - accuracy: 0.8988 - val_loss: 0.4611 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.43026\n",
      "Epoch 332/1000\n",
      "25/25 - 0s - loss: 0.2285 - accuracy: 0.9001 - val_loss: 0.4735 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.43026\n",
      "Epoch 333/1000\n",
      "25/25 - 0s - loss: 0.2296 - accuracy: 0.8936 - val_loss: 0.4605 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.43026\n",
      "Epoch 334/1000\n",
      "25/25 - 0s - loss: 0.2272 - accuracy: 0.8936 - val_loss: 0.4980 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.43026\n",
      "Epoch 335/1000\n",
      "25/25 - 0s - loss: 0.2494 - accuracy: 0.8898 - val_loss: 0.4949 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.43026\n",
      "Epoch 336/1000\n",
      "25/25 - 0s - loss: 0.2543 - accuracy: 0.8807 - val_loss: 0.4746 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.43026\n",
      "Epoch 337/1000\n",
      "25/25 - 0s - loss: 0.2411 - accuracy: 0.8872 - val_loss: 0.4992 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.43026\n",
      "Epoch 338/1000\n",
      "25/25 - 0s - loss: 0.2409 - accuracy: 0.9001 - val_loss: 0.4617 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.43026\n",
      "Epoch 339/1000\n",
      "25/25 - 0s - loss: 0.2365 - accuracy: 0.8885 - val_loss: 0.5510 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.43026\n",
      "Epoch 340/1000\n",
      "25/25 - 0s - loss: 0.2551 - accuracy: 0.8936 - val_loss: 0.5287 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.43026\n",
      "Epoch 341/1000\n",
      "25/25 - 0s - loss: 0.2324 - accuracy: 0.8923 - val_loss: 0.4606 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.43026\n",
      "Epoch 342/1000\n",
      "25/25 - 0s - loss: 0.2417 - accuracy: 0.8988 - val_loss: 0.4514 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.43026\n",
      "Epoch 343/1000\n",
      "25/25 - 0s - loss: 0.2351 - accuracy: 0.9014 - val_loss: 0.4767 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.43026\n",
      "Epoch 344/1000\n",
      "25/25 - 0s - loss: 0.2304 - accuracy: 0.9053 - val_loss: 0.4559 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.43026\n",
      "Epoch 345/1000\n",
      "25/25 - 0s - loss: 0.2312 - accuracy: 0.9001 - val_loss: 0.4763 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.43026\n",
      "Epoch 346/1000\n",
      "25/25 - 0s - loss: 0.2334 - accuracy: 0.8975 - val_loss: 0.4653 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.43026\n",
      "Epoch 347/1000\n",
      "25/25 - 0s - loss: 0.2372 - accuracy: 0.9001 - val_loss: 0.4748 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.43026\n",
      "Epoch 348/1000\n",
      "25/25 - 0s - loss: 0.2361 - accuracy: 0.8975 - val_loss: 0.4689 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.43026\n",
      "Epoch 349/1000\n",
      "25/25 - 0s - loss: 0.2408 - accuracy: 0.8936 - val_loss: 0.4534 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.43026\n",
      "Epoch 350/1000\n",
      "25/25 - 0s - loss: 0.2413 - accuracy: 0.8911 - val_loss: 0.4762 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.43026\n",
      "Epoch 351/1000\n",
      "25/25 - 0s - loss: 0.2277 - accuracy: 0.8936 - val_loss: 0.4697 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.43026\n",
      "Epoch 352/1000\n",
      "25/25 - 0s - loss: 0.2298 - accuracy: 0.8911 - val_loss: 0.4534 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.43026\n",
      "Epoch 353/1000\n",
      "25/25 - 0s - loss: 0.2350 - accuracy: 0.8911 - val_loss: 0.4502 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.43026\n",
      "Epoch 354/1000\n",
      "25/25 - 0s - loss: 0.2430 - accuracy: 0.8923 - val_loss: 0.4462 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.43026\n",
      "Epoch 355/1000\n",
      "25/25 - 0s - loss: 0.2290 - accuracy: 0.9001 - val_loss: 0.4708 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.43026\n",
      "Epoch 356/1000\n",
      "25/25 - 0s - loss: 0.2365 - accuracy: 0.8975 - val_loss: 0.4800 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.43026\n",
      "Epoch 357/1000\n",
      "25/25 - 0s - loss: 0.2286 - accuracy: 0.8975 - val_loss: 0.4646 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.43026\n",
      "Epoch 358/1000\n",
      "25/25 - 0s - loss: 0.2351 - accuracy: 0.8898 - val_loss: 0.4684 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.43026\n",
      "Epoch 359/1000\n",
      "25/25 - 0s - loss: 0.2275 - accuracy: 0.9040 - val_loss: 0.4725 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.43026\n",
      "Epoch 360/1000\n",
      "25/25 - 0s - loss: 0.2274 - accuracy: 0.9053 - val_loss: 0.4648 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.43026\n",
      "Epoch 361/1000\n",
      "25/25 - 0s - loss: 0.2254 - accuracy: 0.8936 - val_loss: 0.5125 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.43026\n",
      "Epoch 362/1000\n",
      "25/25 - 0s - loss: 0.2468 - accuracy: 0.8936 - val_loss: 0.4973 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.43026\n",
      "Epoch 363/1000\n",
      "25/25 - 0s - loss: 0.2307 - accuracy: 0.8975 - val_loss: 0.4626 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 0.43026\n",
      "Epoch 364/1000\n",
      "25/25 - 0s - loss: 0.2368 - accuracy: 0.8975 - val_loss: 0.4691 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.43026\n",
      "Epoch 365/1000\n",
      "25/25 - 0s - loss: 0.2299 - accuracy: 0.9014 - val_loss: 0.4617 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.43026\n",
      "Epoch 366/1000\n",
      "25/25 - 0s - loss: 0.2302 - accuracy: 0.8949 - val_loss: 0.4781 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.43026\n",
      "Epoch 367/1000\n",
      "25/25 - 0s - loss: 0.2300 - accuracy: 0.8988 - val_loss: 0.4793 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.43026\n",
      "Epoch 368/1000\n",
      "25/25 - 0s - loss: 0.2355 - accuracy: 0.9014 - val_loss: 0.4981 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.43026\n",
      "Epoch 369/1000\n",
      "25/25 - 0s - loss: 0.2336 - accuracy: 0.8962 - val_loss: 0.4629 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.43026\n",
      "Epoch 370/1000\n",
      "25/25 - 0s - loss: 0.2419 - accuracy: 0.8962 - val_loss: 0.4794 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.43026\n",
      "Epoch 371/1000\n",
      "25/25 - 0s - loss: 0.2332 - accuracy: 0.9014 - val_loss: 0.4615 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.43026\n",
      "Epoch 372/1000\n",
      "25/25 - 0s - loss: 0.2256 - accuracy: 0.8962 - val_loss: 0.4659 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.43026\n",
      "Epoch 373/1000\n",
      "25/25 - 0s - loss: 0.2274 - accuracy: 0.8988 - val_loss: 0.4611 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.43026\n",
      "Epoch 374/1000\n",
      "25/25 - 0s - loss: 0.2241 - accuracy: 0.8988 - val_loss: 0.4909 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.43026\n",
      "Epoch 375/1000\n",
      "25/25 - 0s - loss: 0.2331 - accuracy: 0.8923 - val_loss: 0.4641 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.43026\n",
      "Epoch 376/1000\n",
      "25/25 - 0s - loss: 0.2348 - accuracy: 0.8936 - val_loss: 0.5055 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.43026\n",
      "Epoch 377/1000\n",
      "25/25 - 0s - loss: 0.2263 - accuracy: 0.8949 - val_loss: 0.4804 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.43026\n",
      "Epoch 378/1000\n",
      "25/25 - 0s - loss: 0.2331 - accuracy: 0.8936 - val_loss: 0.5002 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.43026\n",
      "Epoch 379/1000\n",
      "25/25 - 0s - loss: 0.2335 - accuracy: 0.8975 - val_loss: 0.4520 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.43026\n",
      "Epoch 380/1000\n",
      "25/25 - 0s - loss: 0.2302 - accuracy: 0.9014 - val_loss: 0.5372 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.43026\n",
      "Epoch 381/1000\n",
      "25/25 - 0s - loss: 0.2466 - accuracy: 0.8911 - val_loss: 0.5132 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 0.43026\n",
      "Epoch 382/1000\n",
      "25/25 - 0s - loss: 0.2391 - accuracy: 0.8936 - val_loss: 0.4964 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 0.43026\n",
      "Epoch 383/1000\n",
      "25/25 - 0s - loss: 0.2268 - accuracy: 0.8975 - val_loss: 0.4722 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 0.43026\n",
      "Epoch 384/1000\n",
      "25/25 - 0s - loss: 0.2296 - accuracy: 0.8988 - val_loss: 0.4594 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 0.43026\n",
      "Epoch 385/1000\n",
      "25/25 - 0s - loss: 0.2225 - accuracy: 0.9014 - val_loss: 0.4874 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 0.43026\n",
      "Epoch 386/1000\n",
      "25/25 - 0s - loss: 0.2250 - accuracy: 0.9001 - val_loss: 0.4724 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.43026\n",
      "Epoch 387/1000\n",
      "25/25 - 0s - loss: 0.2255 - accuracy: 0.8975 - val_loss: 0.4680 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 0.43026\n",
      "Epoch 388/1000\n",
      "25/25 - 0s - loss: 0.2379 - accuracy: 0.8962 - val_loss: 0.4426 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.43026\n",
      "Epoch 389/1000\n",
      "25/25 - 0s - loss: 0.2618 - accuracy: 0.8794 - val_loss: 0.4564 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 0.43026\n",
      "Epoch 390/1000\n",
      "25/25 - 0s - loss: 0.2292 - accuracy: 0.9027 - val_loss: 0.4422 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.43026\n",
      "Epoch 391/1000\n",
      "25/25 - 0s - loss: 0.2357 - accuracy: 0.8988 - val_loss: 0.4749 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.43026\n",
      "Epoch 392/1000\n",
      "25/25 - 0s - loss: 0.2301 - accuracy: 0.8975 - val_loss: 0.4577 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.43026\n",
      "Epoch 393/1000\n",
      "25/25 - 0s - loss: 0.2267 - accuracy: 0.8962 - val_loss: 0.4677 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.43026\n",
      "Epoch 394/1000\n",
      "25/25 - 0s - loss: 0.2231 - accuracy: 0.9001 - val_loss: 0.4606 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 0.43026\n",
      "Epoch 395/1000\n",
      "25/25 - 0s - loss: 0.2239 - accuracy: 0.8975 - val_loss: 0.4592 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 0.43026\n",
      "Epoch 396/1000\n",
      "25/25 - 0s - loss: 0.2259 - accuracy: 0.8949 - val_loss: 0.4592 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 0.43026\n",
      "Epoch 397/1000\n",
      "25/25 - 0s - loss: 0.2241 - accuracy: 0.8975 - val_loss: 0.4578 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.43026\n",
      "Epoch 398/1000\n",
      "25/25 - 0s - loss: 0.2305 - accuracy: 0.9027 - val_loss: 0.4932 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 0.43026\n",
      "Epoch 399/1000\n",
      "25/25 - 0s - loss: 0.2252 - accuracy: 0.8949 - val_loss: 0.5481 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 0.43026\n",
      "Epoch 400/1000\n",
      "25/25 - 0s - loss: 0.2416 - accuracy: 0.8923 - val_loss: 0.5192 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.43026\n",
      "Epoch 401/1000\n",
      "25/25 - 0s - loss: 0.2304 - accuracy: 0.9001 - val_loss: 0.4815 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 0.43026\n",
      "Epoch 402/1000\n",
      "25/25 - 0s - loss: 0.2246 - accuracy: 0.8936 - val_loss: 0.4759 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 0.43026\n",
      "Epoch 403/1000\n",
      "25/25 - 0s - loss: 0.2350 - accuracy: 0.8975 - val_loss: 0.4630 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 0.43026\n",
      "Epoch 404/1000\n",
      "25/25 - 0s - loss: 0.2358 - accuracy: 0.8923 - val_loss: 0.4526 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 0.43026\n",
      "Epoch 405/1000\n",
      "25/25 - 0s - loss: 0.2680 - accuracy: 0.8885 - val_loss: 0.4917 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 0.43026\n",
      "Epoch 406/1000\n",
      "25/25 - 0s - loss: 0.2314 - accuracy: 0.9001 - val_loss: 0.5001 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 0.43026\n",
      "Epoch 407/1000\n",
      "25/25 - 0s - loss: 0.2231 - accuracy: 0.8962 - val_loss: 0.4707 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 0.43026\n",
      "Epoch 408/1000\n",
      "25/25 - 0s - loss: 0.2489 - accuracy: 0.8936 - val_loss: 0.4496 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 0.43026\n",
      "Epoch 409/1000\n",
      "25/25 - 0s - loss: 0.2381 - accuracy: 0.8885 - val_loss: 0.4931 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 0.43026\n",
      "Epoch 410/1000\n",
      "25/25 - 0s - loss: 0.2390 - accuracy: 0.8923 - val_loss: 0.4682 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 0.43026\n",
      "Epoch 411/1000\n",
      "25/25 - 0s - loss: 0.2255 - accuracy: 0.9001 - val_loss: 0.4903 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 0.43026\n",
      "Epoch 412/1000\n",
      "25/25 - 0s - loss: 0.2257 - accuracy: 0.8936 - val_loss: 0.4807 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 0.43026\n",
      "Epoch 413/1000\n",
      "25/25 - 0s - loss: 0.2270 - accuracy: 0.8975 - val_loss: 0.4839 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 0.43026\n",
      "Epoch 414/1000\n",
      "25/25 - 0s - loss: 0.2292 - accuracy: 0.8911 - val_loss: 0.4627 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 0.43026\n",
      "Epoch 415/1000\n",
      "25/25 - 0s - loss: 0.2224 - accuracy: 0.8988 - val_loss: 0.4783 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 0.43026\n",
      "Epoch 416/1000\n",
      "25/25 - 0s - loss: 0.2292 - accuracy: 0.8988 - val_loss: 0.4493 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.43026\n",
      "Epoch 417/1000\n",
      "25/25 - 0s - loss: 0.2816 - accuracy: 0.8833 - val_loss: 0.4554 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.43026\n",
      "Epoch 418/1000\n",
      "25/25 - 0s - loss: 0.2458 - accuracy: 0.8859 - val_loss: 0.4699 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 0.43026\n",
      "Epoch 419/1000\n",
      "25/25 - 0s - loss: 0.2333 - accuracy: 0.8923 - val_loss: 0.4784 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 0.43026\n",
      "Epoch 420/1000\n",
      "25/25 - 0s - loss: 0.2238 - accuracy: 0.9001 - val_loss: 0.5026 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 0.43026\n",
      "Epoch 421/1000\n",
      "25/25 - 0s - loss: 0.2289 - accuracy: 0.8923 - val_loss: 0.4770 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 0.43026\n",
      "Epoch 422/1000\n",
      "25/25 - 0s - loss: 0.2280 - accuracy: 0.8975 - val_loss: 0.4576 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 0.43026\n",
      "Epoch 423/1000\n",
      "25/25 - 0s - loss: 0.2325 - accuracy: 0.8936 - val_loss: 0.4555 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 0.43026\n",
      "Epoch 424/1000\n",
      "25/25 - 0s - loss: 0.2211 - accuracy: 0.8988 - val_loss: 0.4708 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 0.43026\n",
      "Epoch 425/1000\n",
      "25/25 - 0s - loss: 0.2254 - accuracy: 0.9001 - val_loss: 0.4517 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 0.43026\n",
      "Epoch 426/1000\n",
      "25/25 - 0s - loss: 0.2213 - accuracy: 0.8975 - val_loss: 0.4649 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 0.43026\n",
      "Epoch 427/1000\n",
      "25/25 - 0s - loss: 0.2215 - accuracy: 0.8962 - val_loss: 0.4826 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 0.43026\n",
      "Epoch 428/1000\n",
      "25/25 - 0s - loss: 0.2273 - accuracy: 0.9001 - val_loss: 0.4778 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 0.43026\n",
      "Epoch 429/1000\n",
      "25/25 - 0s - loss: 0.2242 - accuracy: 0.8949 - val_loss: 0.4577 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 0.43026\n",
      "Epoch 430/1000\n",
      "25/25 - 0s - loss: 0.2265 - accuracy: 0.8988 - val_loss: 0.4599 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.43026\n",
      "Epoch 431/1000\n",
      "25/25 - 0s - loss: 0.2321 - accuracy: 0.9014 - val_loss: 0.4931 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 0.43026\n",
      "Epoch 432/1000\n",
      "25/25 - 0s - loss: 0.2239 - accuracy: 0.9001 - val_loss: 0.4488 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.43026\n",
      "Epoch 433/1000\n",
      "25/25 - 0s - loss: 0.2481 - accuracy: 0.8794 - val_loss: 0.4775 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.43026\n",
      "Epoch 434/1000\n",
      "25/25 - 0s - loss: 0.2272 - accuracy: 0.9001 - val_loss: 0.4729 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 0.43026\n",
      "Epoch 435/1000\n",
      "25/25 - 0s - loss: 0.2189 - accuracy: 0.9014 - val_loss: 0.4538 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 0.43026\n",
      "Epoch 436/1000\n",
      "25/25 - 0s - loss: 0.2351 - accuracy: 0.8911 - val_loss: 0.4500 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 0.43026\n",
      "Epoch 437/1000\n",
      "25/25 - 0s - loss: 0.2381 - accuracy: 0.8885 - val_loss: 0.4584 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 0.43026\n",
      "Epoch 438/1000\n",
      "25/25 - 0s - loss: 0.2247 - accuracy: 0.9001 - val_loss: 0.4806 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 0.43026\n",
      "Epoch 439/1000\n",
      "25/25 - 0s - loss: 0.2239 - accuracy: 0.9040 - val_loss: 0.4917 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 0.43026\n",
      "Epoch 440/1000\n",
      "25/25 - 0s - loss: 0.2224 - accuracy: 0.9001 - val_loss: 0.4670 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.43026\n",
      "Epoch 441/1000\n",
      "25/25 - 0s - loss: 0.2179 - accuracy: 0.8988 - val_loss: 0.4583 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 0.43026\n",
      "Epoch 442/1000\n",
      "25/25 - 0s - loss: 0.2241 - accuracy: 0.8988 - val_loss: 0.4620 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.43026\n",
      "Epoch 443/1000\n",
      "25/25 - 0s - loss: 0.2176 - accuracy: 0.8975 - val_loss: 0.4725 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.43026\n",
      "Epoch 444/1000\n",
      "25/25 - 0s - loss: 0.2164 - accuracy: 0.8988 - val_loss: 0.4681 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.43026\n",
      "Epoch 445/1000\n",
      "25/25 - 0s - loss: 0.2197 - accuracy: 0.9001 - val_loss: 0.4733 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.43026\n",
      "Epoch 446/1000\n",
      "25/25 - 0s - loss: 0.2195 - accuracy: 0.8975 - val_loss: 0.4629 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.43026\n",
      "Epoch 447/1000\n",
      "25/25 - 0s - loss: 0.2177 - accuracy: 0.8988 - val_loss: 0.5085 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 0.43026\n",
      "Epoch 448/1000\n",
      "25/25 - 0s - loss: 0.2271 - accuracy: 0.8975 - val_loss: 0.4772 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 0.43026\n",
      "Epoch 449/1000\n",
      "25/25 - 0s - loss: 0.2219 - accuracy: 0.8988 - val_loss: 0.4635 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 0.43026\n",
      "Epoch 450/1000\n",
      "25/25 - 0s - loss: 0.2204 - accuracy: 0.9001 - val_loss: 0.4628 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 0.43026\n",
      "Epoch 451/1000\n",
      "25/25 - 0s - loss: 0.2223 - accuracy: 0.8975 - val_loss: 0.4540 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 0.43026\n",
      "Epoch 452/1000\n",
      "25/25 - 0s - loss: 0.2187 - accuracy: 0.8988 - val_loss: 0.5182 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 0.43026\n",
      "Epoch 453/1000\n",
      "25/25 - 0s - loss: 0.2347 - accuracy: 0.8962 - val_loss: 0.4732 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 0.43026\n",
      "Epoch 454/1000\n",
      "25/25 - 0s - loss: 0.2223 - accuracy: 0.8962 - val_loss: 0.4888 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 0.43026\n",
      "Epoch 455/1000\n",
      "25/25 - 0s - loss: 0.2244 - accuracy: 0.8988 - val_loss: 0.4492 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 0.43026\n",
      "Epoch 456/1000\n",
      "25/25 - 0s - loss: 0.2215 - accuracy: 0.8975 - val_loss: 0.4775 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.43026\n",
      "Epoch 457/1000\n",
      "25/25 - 0s - loss: 0.2198 - accuracy: 0.8988 - val_loss: 0.4631 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 0.43026\n",
      "Epoch 458/1000\n",
      "25/25 - 0s - loss: 0.2163 - accuracy: 0.9027 - val_loss: 0.4617 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 0.43026\n",
      "Epoch 459/1000\n",
      "25/25 - 0s - loss: 0.2256 - accuracy: 0.8975 - val_loss: 0.4662 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 0.43026\n",
      "Epoch 460/1000\n",
      "25/25 - 0s - loss: 0.2198 - accuracy: 0.9001 - val_loss: 0.4556 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 0.43026\n",
      "Epoch 461/1000\n",
      "25/25 - 0s - loss: 0.2185 - accuracy: 0.9014 - val_loss: 0.4645 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 0.43026\n",
      "Epoch 462/1000\n",
      "25/25 - 0s - loss: 0.2173 - accuracy: 0.8988 - val_loss: 0.4771 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 0.43026\n",
      "Epoch 463/1000\n",
      "25/25 - 0s - loss: 0.2203 - accuracy: 0.8962 - val_loss: 0.4751 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 0.43026\n",
      "Epoch 464/1000\n",
      "25/25 - 0s - loss: 0.2271 - accuracy: 0.8988 - val_loss: 0.4544 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 0.43026\n",
      "Epoch 465/1000\n",
      "25/25 - 0s - loss: 0.2158 - accuracy: 0.9001 - val_loss: 0.4817 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 0.43026\n",
      "Epoch 466/1000\n",
      "25/25 - 0s - loss: 0.2204 - accuracy: 0.8975 - val_loss: 0.4886 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 0.43026\n",
      "Epoch 467/1000\n",
      "25/25 - 0s - loss: 0.2214 - accuracy: 0.9001 - val_loss: 0.4626 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.43026\n",
      "Epoch 468/1000\n",
      "25/25 - 0s - loss: 0.2161 - accuracy: 0.8988 - val_loss: 0.4980 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 0.43026\n",
      "Epoch 469/1000\n",
      "25/25 - 0s - loss: 0.2167 - accuracy: 0.9014 - val_loss: 0.4709 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 0.43026\n",
      "Epoch 470/1000\n",
      "25/25 - 0s - loss: 0.2206 - accuracy: 0.8975 - val_loss: 0.4624 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.43026\n",
      "Epoch 471/1000\n",
      "25/25 - 0s - loss: 0.2175 - accuracy: 0.9027 - val_loss: 0.4617 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 0.43026\n",
      "Epoch 472/1000\n",
      "25/25 - 0s - loss: 0.2244 - accuracy: 0.8988 - val_loss: 0.4798 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.43026\n",
      "Epoch 473/1000\n",
      "25/25 - 0s - loss: 0.2624 - accuracy: 0.8898 - val_loss: 0.4923 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 0.43026\n",
      "Epoch 474/1000\n",
      "25/25 - 0s - loss: 0.2302 - accuracy: 0.8898 - val_loss: 0.5500 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 0.43026\n",
      "Epoch 475/1000\n",
      "25/25 - 0s - loss: 0.2314 - accuracy: 0.8898 - val_loss: 0.4769 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.43026\n",
      "Epoch 476/1000\n",
      "25/25 - 0s - loss: 0.2203 - accuracy: 0.9014 - val_loss: 0.4484 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 0.43026\n",
      "Epoch 477/1000\n",
      "25/25 - 0s - loss: 0.2238 - accuracy: 0.8923 - val_loss: 0.4904 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 0.43026\n",
      "Epoch 478/1000\n",
      "25/25 - 0s - loss: 0.2298 - accuracy: 0.8988 - val_loss: 0.4574 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 0.43026\n",
      "Epoch 479/1000\n",
      "25/25 - 0s - loss: 0.2275 - accuracy: 0.8962 - val_loss: 0.4641 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 0.43026\n",
      "Epoch 480/1000\n",
      "25/25 - 0s - loss: 0.2181 - accuracy: 0.9014 - val_loss: 0.4750 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.43026\n",
      "Epoch 481/1000\n",
      "25/25 - 0s - loss: 0.2217 - accuracy: 0.8975 - val_loss: 0.4572 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 0.43026\n",
      "Epoch 482/1000\n",
      "25/25 - 0s - loss: 0.2185 - accuracy: 0.9014 - val_loss: 0.5019 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 0.43026\n",
      "Epoch 483/1000\n",
      "25/25 - 0s - loss: 0.2162 - accuracy: 0.8936 - val_loss: 0.4665 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 0.43026\n",
      "Epoch 484/1000\n",
      "25/25 - 0s - loss: 0.2189 - accuracy: 0.8975 - val_loss: 0.4861 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.43026\n",
      "Epoch 485/1000\n",
      "25/25 - 0s - loss: 0.2183 - accuracy: 0.8975 - val_loss: 0.4819 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 0.43026\n",
      "Epoch 486/1000\n",
      "25/25 - 0s - loss: 0.2221 - accuracy: 0.8975 - val_loss: 0.4692 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.43026\n",
      "Epoch 487/1000\n",
      "25/25 - 0s - loss: 0.2196 - accuracy: 0.8988 - val_loss: 0.4680 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.43026\n",
      "Epoch 488/1000\n",
      "25/25 - 0s - loss: 0.2318 - accuracy: 0.8923 - val_loss: 0.4609 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 0.43026\n",
      "Epoch 489/1000\n",
      "25/25 - 0s - loss: 0.2327 - accuracy: 0.8859 - val_loss: 0.5105 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 0.43026\n",
      "Epoch 490/1000\n",
      "25/25 - 0s - loss: 0.2195 - accuracy: 0.8988 - val_loss: 0.4685 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.43026\n",
      "Epoch 491/1000\n",
      "25/25 - 0s - loss: 0.2179 - accuracy: 0.8988 - val_loss: 0.4729 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 0.43026\n",
      "Epoch 492/1000\n",
      "25/25 - 0s - loss: 0.2130 - accuracy: 0.9001 - val_loss: 0.4735 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 0.43026\n",
      "Epoch 493/1000\n",
      "25/25 - 0s - loss: 0.2161 - accuracy: 0.9027 - val_loss: 0.4699 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 0.43026\n",
      "Epoch 494/1000\n",
      "25/25 - 0s - loss: 0.2178 - accuracy: 0.9027 - val_loss: 0.4730 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 0.43026\n",
      "Epoch 495/1000\n",
      "25/25 - 0s - loss: 0.2186 - accuracy: 0.8936 - val_loss: 0.4874 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.43026\n",
      "Epoch 496/1000\n",
      "25/25 - 0s - loss: 0.2211 - accuracy: 0.8988 - val_loss: 0.4759 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.43026\n",
      "Epoch 497/1000\n",
      "25/25 - 0s - loss: 0.2234 - accuracy: 0.8988 - val_loss: 0.4694 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 0.43026\n",
      "Epoch 498/1000\n",
      "25/25 - 0s - loss: 0.2209 - accuracy: 0.8949 - val_loss: 0.4741 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 0.43026\n",
      "Epoch 499/1000\n",
      "25/25 - 0s - loss: 0.2192 - accuracy: 0.9014 - val_loss: 0.4689 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 0.43026\n",
      "Epoch 500/1000\n",
      "25/25 - 0s - loss: 0.2213 - accuracy: 0.8949 - val_loss: 0.4888 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.43026\n",
      "Epoch 501/1000\n",
      "25/25 - 0s - loss: 0.2130 - accuracy: 0.8988 - val_loss: 0.4723 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 0.43026\n",
      "Epoch 502/1000\n",
      "25/25 - 0s - loss: 0.2133 - accuracy: 0.8962 - val_loss: 0.4777 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 0.43026\n",
      "Epoch 503/1000\n",
      "25/25 - 0s - loss: 0.2161 - accuracy: 0.8962 - val_loss: 0.4603 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 0.43026\n",
      "Epoch 504/1000\n",
      "25/25 - 0s - loss: 0.2206 - accuracy: 0.8962 - val_loss: 0.4725 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 0.43026\n",
      "Epoch 505/1000\n",
      "25/25 - 0s - loss: 0.2352 - accuracy: 0.8898 - val_loss: 0.4818 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 0.43026\n",
      "Epoch 506/1000\n",
      "25/25 - 0s - loss: 0.2212 - accuracy: 0.8988 - val_loss: 0.4700 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 0.43026\n",
      "Epoch 507/1000\n",
      "25/25 - 0s - loss: 0.2239 - accuracy: 0.8975 - val_loss: 0.4906 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 0.43026\n",
      "Epoch 508/1000\n",
      "25/25 - 0s - loss: 0.2173 - accuracy: 0.9040 - val_loss: 0.4767 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 0.43026\n",
      "Epoch 509/1000\n",
      "25/25 - 0s - loss: 0.2336 - accuracy: 0.8975 - val_loss: 0.5125 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 0.43026\n",
      "Epoch 510/1000\n",
      "25/25 - 0s - loss: 0.2295 - accuracy: 0.8898 - val_loss: 0.5170 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 0.43026\n",
      "Epoch 511/1000\n",
      "25/25 - 0s - loss: 0.2222 - accuracy: 0.9040 - val_loss: 0.4627 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 0.43026\n",
      "Epoch 512/1000\n",
      "25/25 - 0s - loss: 0.2187 - accuracy: 0.8949 - val_loss: 0.4852 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 0.43026\n",
      "Epoch 513/1000\n",
      "25/25 - 0s - loss: 0.2155 - accuracy: 0.9001 - val_loss: 0.4743 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 0.43026\n",
      "Epoch 514/1000\n",
      "25/25 - 0s - loss: 0.2144 - accuracy: 0.8975 - val_loss: 0.4821 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 0.43026\n",
      "Epoch 515/1000\n",
      "25/25 - 0s - loss: 0.2221 - accuracy: 0.8962 - val_loss: 0.4676 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 0.43026\n",
      "Epoch 516/1000\n",
      "25/25 - 0s - loss: 0.2215 - accuracy: 0.9014 - val_loss: 0.4667 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 0.43026\n",
      "Epoch 517/1000\n",
      "25/25 - 0s - loss: 0.2253 - accuracy: 0.8949 - val_loss: 0.4923 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 0.43026\n",
      "Epoch 518/1000\n",
      "25/25 - 0s - loss: 0.2191 - accuracy: 0.8988 - val_loss: 0.4879 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 0.43026\n",
      "Epoch 519/1000\n",
      "25/25 - 0s - loss: 0.2173 - accuracy: 0.8898 - val_loss: 0.4980 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 0.43026\n",
      "Epoch 520/1000\n",
      "25/25 - 0s - loss: 0.2262 - accuracy: 0.9001 - val_loss: 0.4748 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 0.43026\n",
      "Epoch 521/1000\n",
      "25/25 - 0s - loss: 0.2144 - accuracy: 0.9001 - val_loss: 0.4633 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 0.43026\n",
      "Epoch 522/1000\n",
      "25/25 - 0s - loss: 0.2187 - accuracy: 0.8923 - val_loss: 0.4896 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 0.43026\n",
      "Epoch 523/1000\n",
      "25/25 - 0s - loss: 0.2181 - accuracy: 0.9027 - val_loss: 0.4678 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 0.43026\n",
      "Epoch 524/1000\n",
      "25/25 - 0s - loss: 0.2115 - accuracy: 0.8988 - val_loss: 0.5108 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 0.43026\n",
      "Epoch 525/1000\n",
      "25/25 - 0s - loss: 0.2259 - accuracy: 0.8949 - val_loss: 0.5027 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 0.43026\n",
      "Epoch 526/1000\n",
      "25/25 - 0s - loss: 0.2218 - accuracy: 0.8949 - val_loss: 0.4657 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 0.43026\n",
      "Epoch 527/1000\n",
      "25/25 - 0s - loss: 0.2151 - accuracy: 0.8962 - val_loss: 0.4721 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 0.43026\n",
      "Epoch 528/1000\n",
      "25/25 - 0s - loss: 0.2227 - accuracy: 0.8975 - val_loss: 0.4774 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 0.43026\n",
      "Epoch 529/1000\n",
      "25/25 - 0s - loss: 0.2170 - accuracy: 0.8988 - val_loss: 0.4892 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 0.43026\n",
      "Epoch 530/1000\n",
      "25/25 - 0s - loss: 0.2165 - accuracy: 0.8936 - val_loss: 0.4580 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 0.43026\n",
      "Epoch 531/1000\n",
      "25/25 - 0s - loss: 0.2165 - accuracy: 0.8988 - val_loss: 0.4779 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 0.43026\n",
      "Epoch 532/1000\n",
      "25/25 - 0s - loss: 0.2152 - accuracy: 0.9001 - val_loss: 0.4528 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 0.43026\n",
      "Epoch 533/1000\n",
      "25/25 - 0s - loss: 0.2234 - accuracy: 0.8988 - val_loss: 0.4716 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 0.43026\n",
      "Epoch 534/1000\n",
      "25/25 - 0s - loss: 0.2208 - accuracy: 0.8962 - val_loss: 0.4838 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 0.43026\n",
      "Epoch 535/1000\n",
      "25/25 - 0s - loss: 0.2234 - accuracy: 0.8975 - val_loss: 0.4693 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 0.43026\n",
      "Epoch 536/1000\n",
      "25/25 - 0s - loss: 0.2312 - accuracy: 0.8911 - val_loss: 0.4958 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 0.43026\n",
      "Epoch 537/1000\n",
      "25/25 - 0s - loss: 0.2171 - accuracy: 0.8949 - val_loss: 0.4655 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 0.43026\n",
      "Epoch 538/1000\n",
      "25/25 - 0s - loss: 0.2132 - accuracy: 0.8988 - val_loss: 0.4648 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 0.43026\n",
      "Epoch 539/1000\n",
      "25/25 - 0s - loss: 0.2170 - accuracy: 0.9001 - val_loss: 0.4513 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 0.43026\n",
      "Epoch 540/1000\n",
      "25/25 - 0s - loss: 0.2243 - accuracy: 0.9001 - val_loss: 0.4998 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 0.43026\n",
      "Epoch 541/1000\n",
      "25/25 - 0s - loss: 0.2151 - accuracy: 0.8962 - val_loss: 0.4717 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 0.43026\n",
      "Epoch 542/1000\n",
      "25/25 - 0s - loss: 0.2135 - accuracy: 0.9027 - val_loss: 0.4905 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 0.43026\n",
      "Epoch 543/1000\n",
      "25/25 - 0s - loss: 0.2206 - accuracy: 0.8885 - val_loss: 0.4584 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 0.43026\n",
      "Epoch 544/1000\n",
      "25/25 - 0s - loss: 0.2211 - accuracy: 0.9053 - val_loss: 0.4682 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 0.43026\n",
      "Epoch 545/1000\n",
      "25/25 - 0s - loss: 0.2235 - accuracy: 0.8962 - val_loss: 0.4663 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 0.43026\n",
      "Epoch 546/1000\n",
      "25/25 - 0s - loss: 0.2238 - accuracy: 0.8936 - val_loss: 0.4827 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 0.43026\n",
      "Epoch 547/1000\n",
      "25/25 - 0s - loss: 0.2150 - accuracy: 0.8923 - val_loss: 0.4921 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 0.43026\n",
      "Epoch 548/1000\n",
      "25/25 - 0s - loss: 0.2197 - accuracy: 0.8911 - val_loss: 0.4674 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 0.43026\n",
      "Epoch 549/1000\n",
      "25/25 - 0s - loss: 0.2235 - accuracy: 0.8936 - val_loss: 0.4510 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 0.43026\n",
      "Epoch 550/1000\n",
      "25/25 - 0s - loss: 0.2118 - accuracy: 0.8962 - val_loss: 0.4659 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 0.43026\n",
      "Epoch 551/1000\n",
      "25/25 - 0s - loss: 0.2158 - accuracy: 0.9001 - val_loss: 0.4686 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00551: val_loss did not improve from 0.43026\n",
      "Epoch 552/1000\n",
      "25/25 - 0s - loss: 0.2179 - accuracy: 0.8988 - val_loss: 0.4598 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00552: val_loss did not improve from 0.43026\n",
      "Epoch 553/1000\n",
      "25/25 - 0s - loss: 0.2202 - accuracy: 0.8975 - val_loss: 0.4653 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00553: val_loss did not improve from 0.43026\n",
      "Epoch 554/1000\n",
      "25/25 - 0s - loss: 0.2220 - accuracy: 0.8949 - val_loss: 0.4610 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00554: val_loss did not improve from 0.43026\n",
      "Epoch 555/1000\n",
      "25/25 - 0s - loss: 0.2146 - accuracy: 0.8962 - val_loss: 0.4618 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00555: val_loss did not improve from 0.43026\n",
      "Epoch 556/1000\n",
      "25/25 - 0s - loss: 0.2185 - accuracy: 0.8988 - val_loss: 0.4660 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00556: val_loss did not improve from 0.43026\n",
      "Epoch 557/1000\n",
      "25/25 - 0s - loss: 0.2195 - accuracy: 0.8988 - val_loss: 0.4610 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00557: val_loss did not improve from 0.43026\n",
      "Epoch 558/1000\n",
      "25/25 - 0s - loss: 0.2273 - accuracy: 0.8975 - val_loss: 0.4412 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00558: val_loss did not improve from 0.43026\n",
      "Epoch 559/1000\n",
      "25/25 - 0s - loss: 0.2617 - accuracy: 0.8807 - val_loss: 0.4359 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00559: val_loss did not improve from 0.43026\n",
      "Epoch 560/1000\n",
      "25/25 - 0s - loss: 0.2245 - accuracy: 0.9001 - val_loss: 0.4351 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 0.43026\n",
      "Epoch 561/1000\n",
      "25/25 - 0s - loss: 0.2228 - accuracy: 0.8975 - val_loss: 0.4408 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00561: val_loss did not improve from 0.43026\n",
      "Epoch 562/1000\n",
      "25/25 - 0s - loss: 0.2219 - accuracy: 0.8975 - val_loss: 0.4418 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00562: val_loss did not improve from 0.43026\n",
      "Epoch 563/1000\n",
      "25/25 - 0s - loss: 0.2164 - accuracy: 0.9001 - val_loss: 0.4355 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00563: val_loss did not improve from 0.43026\n",
      "Epoch 564/1000\n",
      "25/25 - 0s - loss: 0.2164 - accuracy: 0.9001 - val_loss: 0.4487 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00564: val_loss did not improve from 0.43026\n",
      "Epoch 565/1000\n",
      "25/25 - 0s - loss: 0.2184 - accuracy: 0.9027 - val_loss: 0.4366 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00565: val_loss did not improve from 0.43026\n",
      "Epoch 566/1000\n",
      "25/25 - 0s - loss: 0.2153 - accuracy: 0.9027 - val_loss: 0.4389 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00566: val_loss did not improve from 0.43026\n",
      "Epoch 567/1000\n",
      "25/25 - 0s - loss: 0.2188 - accuracy: 0.9001 - val_loss: 0.4423 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00567: val_loss did not improve from 0.43026\n",
      "Epoch 568/1000\n",
      "25/25 - 0s - loss: 0.2171 - accuracy: 0.8975 - val_loss: 0.4430 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00568: val_loss did not improve from 0.43026\n",
      "Epoch 569/1000\n",
      "25/25 - 0s - loss: 0.2154 - accuracy: 0.9014 - val_loss: 0.4644 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00569: val_loss did not improve from 0.43026\n",
      "Epoch 570/1000\n",
      "25/25 - 0s - loss: 0.2135 - accuracy: 0.9014 - val_loss: 0.4545 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00570: val_loss did not improve from 0.43026\n",
      "Epoch 571/1000\n",
      "25/25 - 0s - loss: 0.2231 - accuracy: 0.9001 - val_loss: 0.4469 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00571: val_loss did not improve from 0.43026\n",
      "Epoch 572/1000\n",
      "25/25 - 0s - loss: 0.2222 - accuracy: 0.8898 - val_loss: 0.4561 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00572: val_loss did not improve from 0.43026\n",
      "Epoch 573/1000\n",
      "25/25 - 0s - loss: 0.2188 - accuracy: 0.9001 - val_loss: 0.4331 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00573: val_loss did not improve from 0.43026\n",
      "Epoch 574/1000\n",
      "25/25 - 0s - loss: 0.2156 - accuracy: 0.8962 - val_loss: 0.4325 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00574: val_loss did not improve from 0.43026\n",
      "Epoch 575/1000\n",
      "25/25 - 0s - loss: 0.2159 - accuracy: 0.8988 - val_loss: 0.4362 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00575: val_loss did not improve from 0.43026\n",
      "Epoch 576/1000\n",
      "25/25 - 0s - loss: 0.2153 - accuracy: 0.8975 - val_loss: 0.4505 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00576: val_loss did not improve from 0.43026\n",
      "Epoch 577/1000\n",
      "25/25 - 0s - loss: 0.2195 - accuracy: 0.8911 - val_loss: 0.4451 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00577: val_loss did not improve from 0.43026\n",
      "Epoch 578/1000\n",
      "25/25 - 0s - loss: 0.2128 - accuracy: 0.9001 - val_loss: 0.4460 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00578: val_loss did not improve from 0.43026\n",
      "Epoch 579/1000\n",
      "25/25 - 0s - loss: 0.2173 - accuracy: 0.9001 - val_loss: 0.4328 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00579: val_loss did not improve from 0.43026\n",
      "Epoch 580/1000\n",
      "25/25 - 0s - loss: 0.2148 - accuracy: 0.8975 - val_loss: 0.4346 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00580: val_loss did not improve from 0.43026\n",
      "Epoch 581/1000\n",
      "25/25 - 0s - loss: 0.2108 - accuracy: 0.8988 - val_loss: 0.4355 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00581: val_loss did not improve from 0.43026\n",
      "Epoch 582/1000\n",
      "25/25 - 0s - loss: 0.2170 - accuracy: 0.9001 - val_loss: 0.4301 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00582: val_loss improved from 0.43026 to 0.43014, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 583/1000\n",
      "25/25 - 0s - loss: 0.2101 - accuracy: 0.9001 - val_loss: 0.4597 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00583: val_loss did not improve from 0.43014\n",
      "Epoch 584/1000\n",
      "25/25 - 0s - loss: 0.2192 - accuracy: 0.8949 - val_loss: 0.4479 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00584: val_loss did not improve from 0.43014\n",
      "Epoch 585/1000\n",
      "25/25 - 0s - loss: 0.2128 - accuracy: 0.9040 - val_loss: 0.4436 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00585: val_loss did not improve from 0.43014\n",
      "Epoch 586/1000\n",
      "25/25 - 0s - loss: 0.2188 - accuracy: 0.8936 - val_loss: 0.4190 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00586: val_loss improved from 0.43014 to 0.41899, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 587/1000\n",
      "25/25 - 0s - loss: 0.2131 - accuracy: 0.9001 - val_loss: 0.4871 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00587: val_loss did not improve from 0.41899\n",
      "Epoch 588/1000\n",
      "25/25 - 0s - loss: 0.2207 - accuracy: 0.8949 - val_loss: 0.4307 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00588: val_loss did not improve from 0.41899\n",
      "Epoch 589/1000\n",
      "25/25 - 0s - loss: 0.2140 - accuracy: 0.9014 - val_loss: 0.4454 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00589: val_loss did not improve from 0.41899\n",
      "Epoch 590/1000\n",
      "25/25 - 0s - loss: 0.2170 - accuracy: 0.8962 - val_loss: 0.4320 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00590: val_loss did not improve from 0.41899\n",
      "Epoch 591/1000\n",
      "25/25 - 0s - loss: 0.2184 - accuracy: 0.8936 - val_loss: 0.4618 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00591: val_loss did not improve from 0.41899\n",
      "Epoch 592/1000\n",
      "25/25 - 0s - loss: 0.2115 - accuracy: 0.8962 - val_loss: 0.4346 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00592: val_loss did not improve from 0.41899\n",
      "Epoch 593/1000\n",
      "25/25 - 0s - loss: 0.2153 - accuracy: 0.9001 - val_loss: 0.4550 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00593: val_loss did not improve from 0.41899\n",
      "Epoch 594/1000\n",
      "25/25 - 0s - loss: 0.2149 - accuracy: 0.8988 - val_loss: 0.4332 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00594: val_loss did not improve from 0.41899\n",
      "Epoch 595/1000\n",
      "25/25 - 0s - loss: 0.2153 - accuracy: 0.8988 - val_loss: 0.4428 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00595: val_loss did not improve from 0.41899\n",
      "Epoch 596/1000\n",
      "25/25 - 0s - loss: 0.2112 - accuracy: 0.8975 - val_loss: 0.4522 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00596: val_loss did not improve from 0.41899\n",
      "Epoch 597/1000\n",
      "25/25 - 0s - loss: 0.2131 - accuracy: 0.8975 - val_loss: 0.4335 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00597: val_loss did not improve from 0.41899\n",
      "Epoch 598/1000\n",
      "25/25 - 0s - loss: 0.2146 - accuracy: 0.9001 - val_loss: 0.4363 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00598: val_loss did not improve from 0.41899\n",
      "Epoch 599/1000\n",
      "25/25 - 0s - loss: 0.2152 - accuracy: 0.8988 - val_loss: 0.4428 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00599: val_loss did not improve from 0.41899\n",
      "Epoch 600/1000\n",
      "25/25 - 0s - loss: 0.2134 - accuracy: 0.8949 - val_loss: 0.4452 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00600: val_loss did not improve from 0.41899\n",
      "Epoch 601/1000\n",
      "25/25 - 0s - loss: 0.2168 - accuracy: 0.8949 - val_loss: 0.4446 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00601: val_loss did not improve from 0.41899\n",
      "Epoch 602/1000\n",
      "25/25 - 0s - loss: 0.2149 - accuracy: 0.9001 - val_loss: 0.4215 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00602: val_loss did not improve from 0.41899\n",
      "Epoch 603/1000\n",
      "25/25 - 0s - loss: 0.2191 - accuracy: 0.8885 - val_loss: 0.4455 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00603: val_loss did not improve from 0.41899\n",
      "Epoch 604/1000\n",
      "25/25 - 0s - loss: 0.2126 - accuracy: 0.8975 - val_loss: 0.4564 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00604: val_loss did not improve from 0.41899\n",
      "Epoch 605/1000\n",
      "25/25 - 0s - loss: 0.2128 - accuracy: 0.9014 - val_loss: 0.4275 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00605: val_loss did not improve from 0.41899\n",
      "Epoch 606/1000\n",
      "25/25 - 0s - loss: 0.2165 - accuracy: 0.8962 - val_loss: 0.4532 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00606: val_loss did not improve from 0.41899\n",
      "Epoch 607/1000\n",
      "25/25 - 0s - loss: 0.2214 - accuracy: 0.8949 - val_loss: 0.4430 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00607: val_loss did not improve from 0.41899\n",
      "Epoch 608/1000\n",
      "25/25 - 0s - loss: 0.2184 - accuracy: 0.8949 - val_loss: 0.4223 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00608: val_loss did not improve from 0.41899\n",
      "Epoch 609/1000\n",
      "25/25 - 0s - loss: 0.2187 - accuracy: 0.8975 - val_loss: 0.4448 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00609: val_loss did not improve from 0.41899\n",
      "Epoch 610/1000\n",
      "25/25 - 0s - loss: 0.2124 - accuracy: 0.9014 - val_loss: 0.4450 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00610: val_loss did not improve from 0.41899\n",
      "Epoch 611/1000\n",
      "25/25 - 0s - loss: 0.2134 - accuracy: 0.9040 - val_loss: 0.4361 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00611: val_loss did not improve from 0.41899\n",
      "Epoch 612/1000\n",
      "25/25 - 0s - loss: 0.2136 - accuracy: 0.9014 - val_loss: 0.4422 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00612: val_loss did not improve from 0.41899\n",
      "Epoch 613/1000\n",
      "25/25 - 0s - loss: 0.2129 - accuracy: 0.8962 - val_loss: 0.4391 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00613: val_loss did not improve from 0.41899\n",
      "Epoch 614/1000\n",
      "25/25 - 0s - loss: 0.2146 - accuracy: 0.9014 - val_loss: 0.4339 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00614: val_loss did not improve from 0.41899\n",
      "Epoch 615/1000\n",
      "25/25 - 0s - loss: 0.2519 - accuracy: 0.8949 - val_loss: 0.4657 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00615: val_loss did not improve from 0.41899\n",
      "Epoch 616/1000\n",
      "25/25 - 0s - loss: 0.2178 - accuracy: 0.9014 - val_loss: 0.4345 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00616: val_loss did not improve from 0.41899\n",
      "Epoch 617/1000\n",
      "25/25 - 0s - loss: 0.2142 - accuracy: 0.9027 - val_loss: 0.4402 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00617: val_loss did not improve from 0.41899\n",
      "Epoch 618/1000\n",
      "25/25 - 0s - loss: 0.2194 - accuracy: 0.8988 - val_loss: 0.4332 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00618: val_loss did not improve from 0.41899\n",
      "Epoch 619/1000\n",
      "25/25 - 0s - loss: 0.2144 - accuracy: 0.8962 - val_loss: 0.4538 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00619: val_loss did not improve from 0.41899\n",
      "Epoch 620/1000\n",
      "25/25 - 0s - loss: 0.2152 - accuracy: 0.8988 - val_loss: 0.4345 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00620: val_loss did not improve from 0.41899\n",
      "Epoch 621/1000\n",
      "25/25 - 0s - loss: 0.2146 - accuracy: 0.8988 - val_loss: 0.4273 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00621: val_loss did not improve from 0.41899\n",
      "Epoch 622/1000\n",
      "25/25 - 0s - loss: 0.2165 - accuracy: 0.8988 - val_loss: 0.4449 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00622: val_loss did not improve from 0.41899\n",
      "Epoch 623/1000\n",
      "25/25 - 0s - loss: 0.2135 - accuracy: 0.8949 - val_loss: 0.4422 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00623: val_loss did not improve from 0.41899\n",
      "Epoch 624/1000\n",
      "25/25 - 0s - loss: 0.2135 - accuracy: 0.8872 - val_loss: 0.4445 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00624: val_loss did not improve from 0.41899\n",
      "Epoch 625/1000\n",
      "25/25 - 0s - loss: 0.2090 - accuracy: 0.9014 - val_loss: 0.4383 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00625: val_loss did not improve from 0.41899\n",
      "Epoch 626/1000\n",
      "25/25 - 0s - loss: 0.2110 - accuracy: 0.9001 - val_loss: 0.4361 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00626: val_loss did not improve from 0.41899\n",
      "Epoch 627/1000\n",
      "25/25 - 0s - loss: 0.2117 - accuracy: 0.9001 - val_loss: 0.4221 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00627: val_loss did not improve from 0.41899\n",
      "Epoch 628/1000\n",
      "25/25 - 0s - loss: 0.2116 - accuracy: 0.8975 - val_loss: 0.4369 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00628: val_loss did not improve from 0.41899\n",
      "Epoch 629/1000\n",
      "25/25 - 0s - loss: 0.2167 - accuracy: 0.8936 - val_loss: 0.4260 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00629: val_loss did not improve from 0.41899\n",
      "Epoch 630/1000\n",
      "25/25 - 0s - loss: 0.2127 - accuracy: 0.8962 - val_loss: 0.4332 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00630: val_loss did not improve from 0.41899\n",
      "Epoch 631/1000\n",
      "25/25 - 0s - loss: 0.2123 - accuracy: 0.8962 - val_loss: 0.4332 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00631: val_loss did not improve from 0.41899\n",
      "Epoch 632/1000\n",
      "25/25 - 0s - loss: 0.2107 - accuracy: 0.8923 - val_loss: 0.4601 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00632: val_loss did not improve from 0.41899\n",
      "Epoch 633/1000\n",
      "25/25 - 0s - loss: 0.2129 - accuracy: 0.8962 - val_loss: 0.4466 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00633: val_loss did not improve from 0.41899\n",
      "Epoch 634/1000\n",
      "25/25 - 0s - loss: 0.2110 - accuracy: 0.9014 - val_loss: 0.4504 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00634: val_loss did not improve from 0.41899\n",
      "Epoch 635/1000\n",
      "25/25 - 0s - loss: 0.2117 - accuracy: 0.9014 - val_loss: 0.4342 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00635: val_loss did not improve from 0.41899\n",
      "Epoch 636/1000\n",
      "25/25 - 0s - loss: 0.2102 - accuracy: 0.8949 - val_loss: 0.4330 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00636: val_loss did not improve from 0.41899\n",
      "Epoch 637/1000\n",
      "25/25 - 0s - loss: 0.2166 - accuracy: 0.9014 - val_loss: 0.4473 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00637: val_loss did not improve from 0.41899\n",
      "Epoch 638/1000\n",
      "25/25 - 0s - loss: 0.2100 - accuracy: 0.9053 - val_loss: 0.4431 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00638: val_loss did not improve from 0.41899\n",
      "Epoch 639/1000\n",
      "25/25 - 0s - loss: 0.2138 - accuracy: 0.8975 - val_loss: 0.4264 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00639: val_loss did not improve from 0.41899\n",
      "Epoch 640/1000\n",
      "25/25 - 0s - loss: 0.2119 - accuracy: 0.9001 - val_loss: 0.4258 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00640: val_loss did not improve from 0.41899\n",
      "Epoch 641/1000\n",
      "25/25 - 0s - loss: 0.2428 - accuracy: 0.8885 - val_loss: 0.4359 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00641: val_loss did not improve from 0.41899\n",
      "Epoch 642/1000\n",
      "25/25 - 0s - loss: 0.2294 - accuracy: 0.8885 - val_loss: 0.4542 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00642: val_loss did not improve from 0.41899\n",
      "Epoch 643/1000\n",
      "25/25 - 0s - loss: 0.2218 - accuracy: 0.9001 - val_loss: 0.4485 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00643: val_loss did not improve from 0.41899\n",
      "Epoch 644/1000\n",
      "25/25 - 0s - loss: 0.2235 - accuracy: 0.8975 - val_loss: 0.4747 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00644: val_loss did not improve from 0.41899\n",
      "Epoch 645/1000\n",
      "25/25 - 0s - loss: 0.2151 - accuracy: 0.8936 - val_loss: 0.4340 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00645: val_loss did not improve from 0.41899\n",
      "Epoch 646/1000\n",
      "25/25 - 0s - loss: 0.2107 - accuracy: 0.8962 - val_loss: 0.4168 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00646: val_loss improved from 0.41899 to 0.41683, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 647/1000\n",
      "25/25 - 0s - loss: 0.2155 - accuracy: 0.9001 - val_loss: 0.4466 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00647: val_loss did not improve from 0.41683\n",
      "Epoch 648/1000\n",
      "25/25 - 0s - loss: 0.2086 - accuracy: 0.8962 - val_loss: 0.4149 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00648: val_loss improved from 0.41683 to 0.41492, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 649/1000\n",
      "25/25 - 0s - loss: 0.2100 - accuracy: 0.8936 - val_loss: 0.4410 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00649: val_loss did not improve from 0.41492\n",
      "Epoch 650/1000\n",
      "25/25 - 0s - loss: 0.2107 - accuracy: 0.8975 - val_loss: 0.4449 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00650: val_loss did not improve from 0.41492\n",
      "Epoch 651/1000\n",
      "25/25 - 0s - loss: 0.2097 - accuracy: 0.9014 - val_loss: 0.4675 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00651: val_loss did not improve from 0.41492\n",
      "Epoch 652/1000\n",
      "25/25 - 0s - loss: 0.2144 - accuracy: 0.9040 - val_loss: 0.4209 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00652: val_loss did not improve from 0.41492\n",
      "Epoch 653/1000\n",
      "25/25 - 0s - loss: 0.2153 - accuracy: 0.8962 - val_loss: 0.4375 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00653: val_loss did not improve from 0.41492\n",
      "Epoch 654/1000\n",
      "25/25 - 0s - loss: 0.2146 - accuracy: 0.9027 - val_loss: 0.4456 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00654: val_loss did not improve from 0.41492\n",
      "Epoch 655/1000\n",
      "25/25 - 0s - loss: 0.2113 - accuracy: 0.9001 - val_loss: 0.4343 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00655: val_loss did not improve from 0.41492\n",
      "Epoch 656/1000\n",
      "25/25 - 0s - loss: 0.2113 - accuracy: 0.8988 - val_loss: 0.4243 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00656: val_loss did not improve from 0.41492\n",
      "Epoch 657/1000\n",
      "25/25 - 0s - loss: 0.2209 - accuracy: 0.9001 - val_loss: 0.4910 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00657: val_loss did not improve from 0.41492\n",
      "Epoch 658/1000\n",
      "25/25 - 0s - loss: 0.2115 - accuracy: 0.8975 - val_loss: 0.4442 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00658: val_loss did not improve from 0.41492\n",
      "Epoch 659/1000\n",
      "25/25 - 0s - loss: 0.2095 - accuracy: 0.8988 - val_loss: 0.4841 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00659: val_loss did not improve from 0.41492\n",
      "Epoch 660/1000\n",
      "25/25 - 0s - loss: 0.2205 - accuracy: 0.8962 - val_loss: 0.4453 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00660: val_loss did not improve from 0.41492\n",
      "Epoch 661/1000\n",
      "25/25 - 0s - loss: 0.2126 - accuracy: 0.9001 - val_loss: 0.4286 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00661: val_loss did not improve from 0.41492\n",
      "Epoch 662/1000\n",
      "25/25 - 0s - loss: 0.2216 - accuracy: 0.8988 - val_loss: 0.4740 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00662: val_loss did not improve from 0.41492\n",
      "Epoch 663/1000\n",
      "25/25 - 0s - loss: 0.2124 - accuracy: 0.8988 - val_loss: 0.4739 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00663: val_loss did not improve from 0.41492\n",
      "Epoch 664/1000\n",
      "25/25 - 0s - loss: 0.2118 - accuracy: 0.9027 - val_loss: 0.4423 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00664: val_loss did not improve from 0.41492\n",
      "Epoch 665/1000\n",
      "25/25 - 0s - loss: 0.2145 - accuracy: 0.8962 - val_loss: 0.4572 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00665: val_loss did not improve from 0.41492\n",
      "Epoch 666/1000\n",
      "25/25 - 0s - loss: 0.2192 - accuracy: 0.8962 - val_loss: 0.4228 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00666: val_loss did not improve from 0.41492\n",
      "Epoch 667/1000\n",
      "25/25 - 0s - loss: 0.2103 - accuracy: 0.8988 - val_loss: 0.4374 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00667: val_loss did not improve from 0.41492\n",
      "Epoch 668/1000\n",
      "25/25 - 0s - loss: 0.2087 - accuracy: 0.9001 - val_loss: 0.4563 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00668: val_loss did not improve from 0.41492\n",
      "Epoch 669/1000\n",
      "25/25 - 0s - loss: 0.2117 - accuracy: 0.9001 - val_loss: 0.4332 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00669: val_loss did not improve from 0.41492\n",
      "Epoch 670/1000\n",
      "25/25 - 0s - loss: 0.2116 - accuracy: 0.9014 - val_loss: 0.4462 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00670: val_loss did not improve from 0.41492\n",
      "Epoch 671/1000\n",
      "25/25 - 0s - loss: 0.2096 - accuracy: 0.9001 - val_loss: 0.4639 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00671: val_loss did not improve from 0.41492\n",
      "Epoch 672/1000\n",
      "25/25 - 0s - loss: 0.2155 - accuracy: 0.8975 - val_loss: 0.4553 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00672: val_loss did not improve from 0.41492\n",
      "Epoch 673/1000\n",
      "25/25 - 0s - loss: 0.2142 - accuracy: 0.8885 - val_loss: 0.4515 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00673: val_loss did not improve from 0.41492\n",
      "Epoch 674/1000\n",
      "25/25 - 0s - loss: 0.2118 - accuracy: 0.8962 - val_loss: 0.4556 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00674: val_loss did not improve from 0.41492\n",
      "Epoch 675/1000\n",
      "25/25 - 0s - loss: 0.2088 - accuracy: 0.9027 - val_loss: 0.4440 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00675: val_loss did not improve from 0.41492\n",
      "Epoch 676/1000\n",
      "25/25 - 0s - loss: 0.2139 - accuracy: 0.8988 - val_loss: 0.4342 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00676: val_loss did not improve from 0.41492\n",
      "Epoch 677/1000\n",
      "25/25 - 0s - loss: 0.2103 - accuracy: 0.9027 - val_loss: 0.4543 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00677: val_loss did not improve from 0.41492\n",
      "Epoch 678/1000\n",
      "25/25 - 0s - loss: 0.2134 - accuracy: 0.9040 - val_loss: 0.4237 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00678: val_loss did not improve from 0.41492\n",
      "Epoch 679/1000\n",
      "25/25 - 0s - loss: 0.2145 - accuracy: 0.8975 - val_loss: 0.4659 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00679: val_loss did not improve from 0.41492\n",
      "Epoch 680/1000\n",
      "25/25 - 0s - loss: 0.2113 - accuracy: 0.8949 - val_loss: 0.4579 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00680: val_loss did not improve from 0.41492\n",
      "Epoch 681/1000\n",
      "25/25 - 0s - loss: 0.2121 - accuracy: 0.9014 - val_loss: 0.4403 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00681: val_loss did not improve from 0.41492\n",
      "Epoch 682/1000\n",
      "25/25 - 0s - loss: 0.2176 - accuracy: 0.8898 - val_loss: 0.4723 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00682: val_loss did not improve from 0.41492\n",
      "Epoch 683/1000\n",
      "25/25 - 0s - loss: 0.2138 - accuracy: 0.8988 - val_loss: 0.4532 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00683: val_loss did not improve from 0.41492\n",
      "Epoch 684/1000\n",
      "25/25 - 0s - loss: 0.2248 - accuracy: 0.8949 - val_loss: 0.4617 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00684: val_loss did not improve from 0.41492\n",
      "Epoch 685/1000\n",
      "25/25 - 0s - loss: 0.2132 - accuracy: 0.8975 - val_loss: 0.4488 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00685: val_loss did not improve from 0.41492\n",
      "Epoch 686/1000\n",
      "25/25 - 0s - loss: 0.2183 - accuracy: 0.8923 - val_loss: 0.4338 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00686: val_loss did not improve from 0.41492\n",
      "Epoch 687/1000\n",
      "25/25 - 0s - loss: 0.2098 - accuracy: 0.9053 - val_loss: 0.4508 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00687: val_loss did not improve from 0.41492\n",
      "Epoch 688/1000\n",
      "25/25 - 0s - loss: 0.2100 - accuracy: 0.9001 - val_loss: 0.4401 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00688: val_loss did not improve from 0.41492\n",
      "Epoch 689/1000\n",
      "25/25 - 0s - loss: 0.2132 - accuracy: 0.8975 - val_loss: 0.4452 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00689: val_loss did not improve from 0.41492\n",
      "Epoch 690/1000\n",
      "25/25 - 0s - loss: 0.2139 - accuracy: 0.8975 - val_loss: 0.4373 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00690: val_loss did not improve from 0.41492\n",
      "Epoch 691/1000\n",
      "25/25 - 0s - loss: 0.2103 - accuracy: 0.8988 - val_loss: 0.4508 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00691: val_loss did not improve from 0.41492\n",
      "Epoch 692/1000\n",
      "25/25 - 0s - loss: 0.2103 - accuracy: 0.8936 - val_loss: 0.4530 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00692: val_loss did not improve from 0.41492\n",
      "Epoch 693/1000\n",
      "25/25 - 0s - loss: 0.2155 - accuracy: 0.8923 - val_loss: 0.4364 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00693: val_loss did not improve from 0.41492\n",
      "Epoch 694/1000\n",
      "25/25 - 0s - loss: 0.2098 - accuracy: 0.9001 - val_loss: 0.4392 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00694: val_loss did not improve from 0.41492\n",
      "Epoch 695/1000\n",
      "25/25 - 0s - loss: 0.2086 - accuracy: 0.9001 - val_loss: 0.4555 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00695: val_loss did not improve from 0.41492\n",
      "Epoch 696/1000\n",
      "25/25 - 0s - loss: 0.2103 - accuracy: 0.9001 - val_loss: 0.4425 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00696: val_loss did not improve from 0.41492\n",
      "Epoch 697/1000\n",
      "25/25 - 0s - loss: 0.2077 - accuracy: 0.9027 - val_loss: 0.4580 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00697: val_loss did not improve from 0.41492\n",
      "Epoch 698/1000\n",
      "25/25 - 0s - loss: 0.2131 - accuracy: 0.9027 - val_loss: 0.4321 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00698: val_loss did not improve from 0.41492\n",
      "Epoch 699/1000\n",
      "25/25 - 0s - loss: 0.2112 - accuracy: 0.9027 - val_loss: 0.4309 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00699: val_loss did not improve from 0.41492\n",
      "Epoch 700/1000\n",
      "25/25 - 0s - loss: 0.2227 - accuracy: 0.8885 - val_loss: 0.4628 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00700: val_loss did not improve from 0.41492\n",
      "Epoch 701/1000\n",
      "25/25 - 0s - loss: 0.2129 - accuracy: 0.9014 - val_loss: 0.4412 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00701: val_loss did not improve from 0.41492\n",
      "Epoch 702/1000\n",
      "25/25 - 0s - loss: 0.2529 - accuracy: 0.8936 - val_loss: 0.4416 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00702: val_loss did not improve from 0.41492\n",
      "Epoch 703/1000\n",
      "25/25 - 0s - loss: 0.2356 - accuracy: 0.8885 - val_loss: 0.4311 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00703: val_loss did not improve from 0.41492\n",
      "Epoch 704/1000\n",
      "25/25 - 0s - loss: 0.2335 - accuracy: 0.8885 - val_loss: 0.4301 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00704: val_loss did not improve from 0.41492\n",
      "Epoch 705/1000\n",
      "25/25 - 0s - loss: 0.2147 - accuracy: 0.8975 - val_loss: 0.4514 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00705: val_loss did not improve from 0.41492\n",
      "Epoch 706/1000\n",
      "25/25 - 0s - loss: 0.2105 - accuracy: 0.9014 - val_loss: 0.4592 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00706: val_loss did not improve from 0.41492\n",
      "Epoch 707/1000\n",
      "25/25 - 0s - loss: 0.2098 - accuracy: 0.9001 - val_loss: 0.4552 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00707: val_loss did not improve from 0.41492\n",
      "Epoch 708/1000\n",
      "25/25 - 0s - loss: 0.2106 - accuracy: 0.8936 - val_loss: 0.4497 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00708: val_loss did not improve from 0.41492\n",
      "Epoch 709/1000\n",
      "25/25 - 0s - loss: 0.2093 - accuracy: 0.9014 - val_loss: 0.4614 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00709: val_loss did not improve from 0.41492\n",
      "Epoch 710/1000\n",
      "25/25 - 0s - loss: 0.2104 - accuracy: 0.9014 - val_loss: 0.4502 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00710: val_loss did not improve from 0.41492\n",
      "Epoch 711/1000\n",
      "25/25 - 0s - loss: 0.2212 - accuracy: 0.8988 - val_loss: 0.4449 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00711: val_loss did not improve from 0.41492\n",
      "Epoch 712/1000\n",
      "25/25 - 0s - loss: 0.2111 - accuracy: 0.9027 - val_loss: 0.4525 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00712: val_loss did not improve from 0.41492\n",
      "Epoch 713/1000\n",
      "25/25 - 0s - loss: 0.2168 - accuracy: 0.9027 - val_loss: 0.4455 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00713: val_loss did not improve from 0.41492\n",
      "Epoch 714/1000\n",
      "25/25 - 0s - loss: 0.2095 - accuracy: 0.9027 - val_loss: 0.4603 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00714: val_loss did not improve from 0.41492\n",
      "Epoch 715/1000\n",
      "25/25 - 0s - loss: 0.2383 - accuracy: 0.8898 - val_loss: 0.4222 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00715: val_loss did not improve from 0.41492\n",
      "Epoch 716/1000\n",
      "25/25 - 0s - loss: 0.2174 - accuracy: 0.8949 - val_loss: 0.4654 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00716: val_loss did not improve from 0.41492\n",
      "Epoch 717/1000\n",
      "25/25 - 0s - loss: 0.2116 - accuracy: 0.8936 - val_loss: 0.4581 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00717: val_loss did not improve from 0.41492\n",
      "Epoch 718/1000\n",
      "25/25 - 0s - loss: 0.2098 - accuracy: 0.9001 - val_loss: 0.4591 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00718: val_loss did not improve from 0.41492\n",
      "Epoch 719/1000\n",
      "25/25 - 0s - loss: 0.2066 - accuracy: 0.8975 - val_loss: 0.4485 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00719: val_loss did not improve from 0.41492\n",
      "Epoch 720/1000\n",
      "25/25 - 0s - loss: 0.2114 - accuracy: 0.9001 - val_loss: 0.4666 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00720: val_loss did not improve from 0.41492\n",
      "Epoch 721/1000\n",
      "25/25 - 0s - loss: 0.2090 - accuracy: 0.9014 - val_loss: 0.4540 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00721: val_loss did not improve from 0.41492\n",
      "Epoch 722/1000\n",
      "25/25 - 0s - loss: 0.2085 - accuracy: 0.8988 - val_loss: 0.4526 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00722: val_loss did not improve from 0.41492\n",
      "Epoch 723/1000\n",
      "25/25 - 0s - loss: 0.2102 - accuracy: 0.8988 - val_loss: 0.4385 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00723: val_loss did not improve from 0.41492\n",
      "Epoch 724/1000\n",
      "25/25 - 0s - loss: 0.2081 - accuracy: 0.8988 - val_loss: 0.4691 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00724: val_loss did not improve from 0.41492\n",
      "Epoch 725/1000\n",
      "25/25 - 0s - loss: 0.2112 - accuracy: 0.8988 - val_loss: 0.4540 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00725: val_loss did not improve from 0.41492\n",
      "Epoch 726/1000\n",
      "25/25 - 0s - loss: 0.2097 - accuracy: 0.8988 - val_loss: 0.4597 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00726: val_loss did not improve from 0.41492\n",
      "Epoch 727/1000\n",
      "25/25 - 0s - loss: 0.2095 - accuracy: 0.9027 - val_loss: 0.4585 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00727: val_loss did not improve from 0.41492\n",
      "Epoch 728/1000\n",
      "25/25 - 0s - loss: 0.2071 - accuracy: 0.9001 - val_loss: 0.4632 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00728: val_loss did not improve from 0.41492\n",
      "Epoch 729/1000\n",
      "25/25 - 0s - loss: 0.2234 - accuracy: 0.8975 - val_loss: 0.4175 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00729: val_loss did not improve from 0.41492\n",
      "Epoch 730/1000\n",
      "25/25 - 0s - loss: 0.2183 - accuracy: 0.8962 - val_loss: 0.4053 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00730: val_loss improved from 0.41492 to 0.40529, saving model to models\\model_4L_v5\n",
      "INFO:tensorflow:Assets written to: models\\model_4L_v5\\assets\n",
      "Epoch 731/1000\n",
      "25/25 - 0s - loss: 0.2165 - accuracy: 0.8923 - val_loss: 0.4505 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00731: val_loss did not improve from 0.40529\n",
      "Epoch 732/1000\n",
      "25/25 - 0s - loss: 0.2156 - accuracy: 0.8988 - val_loss: 0.4291 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00732: val_loss did not improve from 0.40529\n",
      "Epoch 733/1000\n",
      "25/25 - 0s - loss: 0.2098 - accuracy: 0.8988 - val_loss: 0.4556 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00733: val_loss did not improve from 0.40529\n",
      "Epoch 734/1000\n",
      "25/25 - 0s - loss: 0.2127 - accuracy: 0.8975 - val_loss: 0.4576 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00734: val_loss did not improve from 0.40529\n",
      "Epoch 735/1000\n",
      "25/25 - 0s - loss: 0.2122 - accuracy: 0.8988 - val_loss: 0.4494 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00735: val_loss did not improve from 0.40529\n",
      "Epoch 736/1000\n",
      "25/25 - 0s - loss: 0.2099 - accuracy: 0.8988 - val_loss: 0.4933 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00736: val_loss did not improve from 0.40529\n",
      "Epoch 737/1000\n",
      "25/25 - 0s - loss: 0.2182 - accuracy: 0.8975 - val_loss: 0.4641 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00737: val_loss did not improve from 0.40529\n",
      "Epoch 738/1000\n",
      "25/25 - 0s - loss: 0.2304 - accuracy: 0.9001 - val_loss: 0.4560 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00738: val_loss did not improve from 0.40529\n",
      "Epoch 739/1000\n",
      "25/25 - 0s - loss: 0.2264 - accuracy: 0.8988 - val_loss: 0.4453 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00739: val_loss did not improve from 0.40529\n",
      "Epoch 740/1000\n",
      "25/25 - 0s - loss: 0.2123 - accuracy: 0.9040 - val_loss: 0.4495 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00740: val_loss did not improve from 0.40529\n",
      "Epoch 741/1000\n",
      "25/25 - 0s - loss: 0.2124 - accuracy: 0.8975 - val_loss: 0.4659 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00741: val_loss did not improve from 0.40529\n",
      "Epoch 742/1000\n",
      "25/25 - 0s - loss: 0.2079 - accuracy: 0.9040 - val_loss: 0.4492 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00742: val_loss did not improve from 0.40529\n",
      "Epoch 743/1000\n",
      "25/25 - 0s - loss: 0.2086 - accuracy: 0.9001 - val_loss: 0.4623 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00743: val_loss did not improve from 0.40529\n",
      "Epoch 744/1000\n",
      "25/25 - 0s - loss: 0.2088 - accuracy: 0.9001 - val_loss: 0.4726 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00744: val_loss did not improve from 0.40529\n",
      "Epoch 745/1000\n",
      "25/25 - 0s - loss: 0.2083 - accuracy: 0.8975 - val_loss: 0.4633 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00745: val_loss did not improve from 0.40529\n",
      "Epoch 746/1000\n",
      "25/25 - 0s - loss: 0.2101 - accuracy: 0.9001 - val_loss: 0.4669 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00746: val_loss did not improve from 0.40529\n",
      "Epoch 747/1000\n",
      "25/25 - 0s - loss: 0.2104 - accuracy: 0.9014 - val_loss: 0.4543 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00747: val_loss did not improve from 0.40529\n",
      "Epoch 748/1000\n",
      "25/25 - 0s - loss: 0.2072 - accuracy: 0.9027 - val_loss: 0.4628 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00748: val_loss did not improve from 0.40529\n",
      "Epoch 749/1000\n",
      "25/25 - 0s - loss: 0.2093 - accuracy: 0.8988 - val_loss: 0.4530 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00749: val_loss did not improve from 0.40529\n",
      "Epoch 750/1000\n",
      "25/25 - 0s - loss: 0.2091 - accuracy: 0.9001 - val_loss: 0.4731 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00750: val_loss did not improve from 0.40529\n",
      "Epoch 751/1000\n",
      "25/25 - 0s - loss: 0.2098 - accuracy: 0.9027 - val_loss: 0.4672 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00751: val_loss did not improve from 0.40529\n",
      "Epoch 752/1000\n",
      "25/25 - 0s - loss: 0.2143 - accuracy: 0.9001 - val_loss: 0.4646 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00752: val_loss did not improve from 0.40529\n",
      "Epoch 753/1000\n",
      "25/25 - 0s - loss: 0.2097 - accuracy: 0.9001 - val_loss: 0.4837 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00753: val_loss did not improve from 0.40529\n",
      "Epoch 754/1000\n",
      "25/25 - 0s - loss: 0.2051 - accuracy: 0.9001 - val_loss: 0.4582 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00754: val_loss did not improve from 0.40529\n",
      "Epoch 755/1000\n",
      "25/25 - 0s - loss: 0.2151 - accuracy: 0.8962 - val_loss: 0.4803 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00755: val_loss did not improve from 0.40529\n",
      "Epoch 756/1000\n",
      "25/25 - 0s - loss: 0.2093 - accuracy: 0.8975 - val_loss: 0.4816 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00756: val_loss did not improve from 0.40529\n",
      "Epoch 757/1000\n",
      "25/25 - 0s - loss: 0.2093 - accuracy: 0.8949 - val_loss: 0.4590 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00757: val_loss did not improve from 0.40529\n",
      "Epoch 758/1000\n",
      "25/25 - 0s - loss: 0.2058 - accuracy: 0.9027 - val_loss: 0.4671 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00758: val_loss did not improve from 0.40529\n",
      "Epoch 759/1000\n",
      "25/25 - 0s - loss: 0.2075 - accuracy: 0.9001 - val_loss: 0.4804 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00759: val_loss did not improve from 0.40529\n",
      "Epoch 760/1000\n",
      "25/25 - 0s - loss: 0.2157 - accuracy: 0.9001 - val_loss: 0.4743 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00760: val_loss did not improve from 0.40529\n",
      "Epoch 761/1000\n",
      "25/25 - 0s - loss: 0.2095 - accuracy: 0.9001 - val_loss: 0.4361 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00761: val_loss did not improve from 0.40529\n",
      "Epoch 762/1000\n",
      "25/25 - 0s - loss: 0.2107 - accuracy: 0.8962 - val_loss: 0.4758 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00762: val_loss did not improve from 0.40529\n",
      "Epoch 763/1000\n",
      "25/25 - 0s - loss: 0.2107 - accuracy: 0.9014 - val_loss: 0.4629 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00763: val_loss did not improve from 0.40529\n",
      "Epoch 764/1000\n",
      "25/25 - 0s - loss: 0.2089 - accuracy: 0.8975 - val_loss: 0.4576 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00764: val_loss did not improve from 0.40529\n",
      "Epoch 765/1000\n",
      "25/25 - 0s - loss: 0.2213 - accuracy: 0.8975 - val_loss: 0.4695 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00765: val_loss did not improve from 0.40529\n",
      "Epoch 766/1000\n",
      "25/25 - 0s - loss: 0.2106 - accuracy: 0.9014 - val_loss: 0.4623 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00766: val_loss did not improve from 0.40529\n",
      "Epoch 767/1000\n",
      "25/25 - 0s - loss: 0.2087 - accuracy: 0.8975 - val_loss: 0.4542 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00767: val_loss did not improve from 0.40529\n",
      "Epoch 768/1000\n",
      "25/25 - 0s - loss: 0.2106 - accuracy: 0.9001 - val_loss: 0.4858 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00768: val_loss did not improve from 0.40529\n",
      "Epoch 769/1000\n",
      "25/25 - 0s - loss: 0.2096 - accuracy: 0.8923 - val_loss: 0.4678 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00769: val_loss did not improve from 0.40529\n",
      "Epoch 770/1000\n",
      "25/25 - 0s - loss: 0.2074 - accuracy: 0.9014 - val_loss: 0.4695 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00770: val_loss did not improve from 0.40529\n",
      "Epoch 771/1000\n",
      "25/25 - 0s - loss: 0.2105 - accuracy: 0.8988 - val_loss: 0.4655 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00771: val_loss did not improve from 0.40529\n",
      "Epoch 772/1000\n",
      "25/25 - 0s - loss: 0.2115 - accuracy: 0.8975 - val_loss: 0.4674 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00772: val_loss did not improve from 0.40529\n",
      "Epoch 773/1000\n",
      "25/25 - 0s - loss: 0.2169 - accuracy: 0.9014 - val_loss: 0.4362 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00773: val_loss did not improve from 0.40529\n",
      "Epoch 774/1000\n",
      "25/25 - 0s - loss: 0.2126 - accuracy: 0.8936 - val_loss: 0.4694 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00774: val_loss did not improve from 0.40529\n",
      "Epoch 775/1000\n",
      "25/25 - 0s - loss: 0.2113 - accuracy: 0.8962 - val_loss: 0.4664 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00775: val_loss did not improve from 0.40529\n",
      "Epoch 776/1000\n",
      "25/25 - 0s - loss: 0.2071 - accuracy: 0.9014 - val_loss: 0.4559 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00776: val_loss did not improve from 0.40529\n",
      "Epoch 777/1000\n",
      "25/25 - 0s - loss: 0.2109 - accuracy: 0.8975 - val_loss: 0.4639 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00777: val_loss did not improve from 0.40529\n",
      "Epoch 778/1000\n",
      "25/25 - 0s - loss: 0.2085 - accuracy: 0.9040 - val_loss: 0.4431 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00778: val_loss did not improve from 0.40529\n",
      "Epoch 779/1000\n",
      "25/25 - 0s - loss: 0.2083 - accuracy: 0.8975 - val_loss: 0.4567 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00779: val_loss did not improve from 0.40529\n",
      "Epoch 780/1000\n",
      "25/25 - 0s - loss: 0.2087 - accuracy: 0.9001 - val_loss: 0.4522 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00780: val_loss did not improve from 0.40529\n",
      "Epoch 781/1000\n",
      "25/25 - 0s - loss: 0.2073 - accuracy: 0.9027 - val_loss: 0.4795 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00781: val_loss did not improve from 0.40529\n",
      "Epoch 782/1000\n",
      "25/25 - 0s - loss: 0.2072 - accuracy: 0.8962 - val_loss: 0.4491 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00782: val_loss did not improve from 0.40529\n",
      "Epoch 783/1000\n",
      "25/25 - 0s - loss: 0.2167 - accuracy: 0.8988 - val_loss: 0.4594 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00783: val_loss did not improve from 0.40529\n",
      "Epoch 784/1000\n",
      "25/25 - 0s - loss: 0.2093 - accuracy: 0.9001 - val_loss: 0.4586 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00784: val_loss did not improve from 0.40529\n",
      "Epoch 785/1000\n",
      "25/25 - 0s - loss: 0.2411 - accuracy: 0.8911 - val_loss: 0.4225 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00785: val_loss did not improve from 0.40529\n",
      "Epoch 786/1000\n",
      "25/25 - 0s - loss: 0.2186 - accuracy: 0.9001 - val_loss: 0.4594 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00786: val_loss did not improve from 0.40529\n",
      "Epoch 787/1000\n",
      "25/25 - 0s - loss: 0.2091 - accuracy: 0.9014 - val_loss: 0.4588 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00787: val_loss did not improve from 0.40529\n",
      "Epoch 788/1000\n",
      "25/25 - 0s - loss: 0.2093 - accuracy: 0.8988 - val_loss: 0.4648 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00788: val_loss did not improve from 0.40529\n",
      "Epoch 789/1000\n",
      "25/25 - 0s - loss: 0.2158 - accuracy: 0.8949 - val_loss: 0.4662 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00789: val_loss did not improve from 0.40529\n",
      "Epoch 790/1000\n",
      "25/25 - 0s - loss: 0.2167 - accuracy: 0.9040 - val_loss: 0.4635 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00790: val_loss did not improve from 0.40529\n",
      "Epoch 791/1000\n",
      "25/25 - 0s - loss: 0.2119 - accuracy: 0.9027 - val_loss: 0.4594 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00791: val_loss did not improve from 0.40529\n",
      "Epoch 792/1000\n",
      "25/25 - 0s - loss: 0.2113 - accuracy: 0.9001 - val_loss: 0.4848 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00792: val_loss did not improve from 0.40529\n",
      "Epoch 793/1000\n",
      "25/25 - 0s - loss: 0.2132 - accuracy: 0.8949 - val_loss: 0.4780 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00793: val_loss did not improve from 0.40529\n",
      "Epoch 794/1000\n",
      "25/25 - 0s - loss: 0.2123 - accuracy: 0.9027 - val_loss: 0.4697 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00794: val_loss did not improve from 0.40529\n",
      "Epoch 795/1000\n",
      "25/25 - 0s - loss: 0.2103 - accuracy: 0.9014 - val_loss: 0.4566 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00795: val_loss did not improve from 0.40529\n",
      "Epoch 796/1000\n",
      "25/25 - 0s - loss: 0.2085 - accuracy: 0.8988 - val_loss: 0.4791 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00796: val_loss did not improve from 0.40529\n",
      "Epoch 797/1000\n",
      "25/25 - 0s - loss: 0.2074 - accuracy: 0.9001 - val_loss: 0.4604 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00797: val_loss did not improve from 0.40529\n",
      "Epoch 798/1000\n",
      "25/25 - 0s - loss: 0.2078 - accuracy: 0.8988 - val_loss: 0.4717 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00798: val_loss did not improve from 0.40529\n",
      "Epoch 799/1000\n",
      "25/25 - 0s - loss: 0.2067 - accuracy: 0.8962 - val_loss: 0.4724 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00799: val_loss did not improve from 0.40529\n",
      "Epoch 800/1000\n",
      "25/25 - 0s - loss: 0.2104 - accuracy: 0.8988 - val_loss: 0.4759 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00800: val_loss did not improve from 0.40529\n",
      "Epoch 801/1000\n",
      "25/25 - 0s - loss: 0.2104 - accuracy: 0.9040 - val_loss: 0.4591 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00801: val_loss did not improve from 0.40529\n",
      "Epoch 802/1000\n",
      "25/25 - 0s - loss: 0.2188 - accuracy: 0.8962 - val_loss: 0.5029 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00802: val_loss did not improve from 0.40529\n",
      "Epoch 803/1000\n",
      "25/25 - 0s - loss: 0.2079 - accuracy: 0.9001 - val_loss: 0.4711 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00803: val_loss did not improve from 0.40529\n",
      "Epoch 804/1000\n",
      "25/25 - 0s - loss: 0.2129 - accuracy: 0.8988 - val_loss: 0.4819 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00804: val_loss did not improve from 0.40529\n",
      "Epoch 805/1000\n",
      "25/25 - 0s - loss: 0.2137 - accuracy: 0.8949 - val_loss: 0.4903 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00805: val_loss did not improve from 0.40529\n",
      "Epoch 806/1000\n",
      "25/25 - 0s - loss: 0.2077 - accuracy: 0.8975 - val_loss: 0.4730 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00806: val_loss did not improve from 0.40529\n",
      "Epoch 807/1000\n",
      "25/25 - 0s - loss: 0.2087 - accuracy: 0.9014 - val_loss: 0.4833 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00807: val_loss did not improve from 0.40529\n",
      "Epoch 808/1000\n",
      "25/25 - 0s - loss: 0.2055 - accuracy: 0.9027 - val_loss: 0.4685 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00808: val_loss did not improve from 0.40529\n",
      "Epoch 809/1000\n",
      "25/25 - 0s - loss: 0.2066 - accuracy: 0.9014 - val_loss: 0.4796 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00809: val_loss did not improve from 0.40529\n",
      "Epoch 810/1000\n",
      "25/25 - 0s - loss: 0.2185 - accuracy: 0.9001 - val_loss: 0.4813 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00810: val_loss did not improve from 0.40529\n",
      "Epoch 811/1000\n",
      "25/25 - 0s - loss: 0.2087 - accuracy: 0.9027 - val_loss: 0.4802 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00811: val_loss did not improve from 0.40529\n",
      "Epoch 812/1000\n",
      "25/25 - 0s - loss: 0.2083 - accuracy: 0.9027 - val_loss: 0.4730 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00812: val_loss did not improve from 0.40529\n",
      "Epoch 813/1000\n",
      "25/25 - 0s - loss: 0.2123 - accuracy: 0.9027 - val_loss: 0.4764 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00813: val_loss did not improve from 0.40529\n",
      "Epoch 814/1000\n",
      "25/25 - 0s - loss: 0.2076 - accuracy: 0.9001 - val_loss: 0.4758 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00814: val_loss did not improve from 0.40529\n",
      "Epoch 815/1000\n",
      "25/25 - 0s - loss: 0.2098 - accuracy: 0.8975 - val_loss: 0.4763 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00815: val_loss did not improve from 0.40529\n",
      "Epoch 816/1000\n",
      "25/25 - 0s - loss: 0.2072 - accuracy: 0.8975 - val_loss: 0.4633 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00816: val_loss did not improve from 0.40529\n",
      "Epoch 817/1000\n",
      "25/25 - 0s - loss: 0.2114 - accuracy: 0.8936 - val_loss: 0.4903 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00817: val_loss did not improve from 0.40529\n",
      "Epoch 818/1000\n",
      "25/25 - 0s - loss: 0.2199 - accuracy: 0.8962 - val_loss: 0.4472 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00818: val_loss did not improve from 0.40529\n",
      "Epoch 819/1000\n",
      "25/25 - 0s - loss: 0.2176 - accuracy: 0.9001 - val_loss: 0.4512 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00819: val_loss did not improve from 0.40529\n",
      "Epoch 820/1000\n",
      "25/25 - 0s - loss: 0.2068 - accuracy: 0.9001 - val_loss: 0.4978 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00820: val_loss did not improve from 0.40529\n",
      "Epoch 821/1000\n",
      "25/25 - 0s - loss: 0.2165 - accuracy: 0.9001 - val_loss: 0.4706 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00821: val_loss did not improve from 0.40529\n",
      "Epoch 822/1000\n",
      "25/25 - 0s - loss: 0.2182 - accuracy: 0.8975 - val_loss: 0.4610 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00822: val_loss did not improve from 0.40529\n",
      "Epoch 823/1000\n",
      "25/25 - 0s - loss: 0.2110 - accuracy: 0.8988 - val_loss: 0.4889 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00823: val_loss did not improve from 0.40529\n",
      "Epoch 824/1000\n",
      "25/25 - 0s - loss: 0.2076 - accuracy: 0.9001 - val_loss: 0.4640 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00824: val_loss did not improve from 0.40529\n",
      "Epoch 825/1000\n",
      "25/25 - 0s - loss: 0.2118 - accuracy: 0.8975 - val_loss: 0.4740 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00825: val_loss did not improve from 0.40529\n",
      "Epoch 826/1000\n",
      "25/25 - 0s - loss: 0.2067 - accuracy: 0.9001 - val_loss: 0.4751 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00826: val_loss did not improve from 0.40529\n",
      "Epoch 827/1000\n",
      "25/25 - 0s - loss: 0.2087 - accuracy: 0.9001 - val_loss: 0.4582 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00827: val_loss did not improve from 0.40529\n",
      "Epoch 828/1000\n",
      "25/25 - 0s - loss: 0.2103 - accuracy: 0.9014 - val_loss: 0.4667 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00828: val_loss did not improve from 0.40529\n",
      "Epoch 829/1000\n",
      "25/25 - 0s - loss: 0.2086 - accuracy: 0.9001 - val_loss: 0.4787 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00829: val_loss did not improve from 0.40529\n",
      "Epoch 830/1000\n",
      "25/25 - 0s - loss: 0.2064 - accuracy: 0.9001 - val_loss: 0.4799 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00830: val_loss did not improve from 0.40529\n",
      "Epoch 831/1000\n",
      "25/25 - 0s - loss: 0.2065 - accuracy: 0.8962 - val_loss: 0.4748 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00831: val_loss did not improve from 0.40529\n",
      "Epoch 832/1000\n",
      "25/25 - 0s - loss: 0.2078 - accuracy: 0.8988 - val_loss: 0.4826 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00832: val_loss did not improve from 0.40529\n",
      "Epoch 833/1000\n",
      "25/25 - 0s - loss: 0.2066 - accuracy: 0.8988 - val_loss: 0.4730 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00833: val_loss did not improve from 0.40529\n",
      "Epoch 834/1000\n",
      "25/25 - 0s - loss: 0.2103 - accuracy: 0.8962 - val_loss: 0.4709 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00834: val_loss did not improve from 0.40529\n",
      "Epoch 835/1000\n",
      "25/25 - 0s - loss: 0.2115 - accuracy: 0.9014 - val_loss: 0.5089 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00835: val_loss did not improve from 0.40529\n",
      "Epoch 836/1000\n",
      "25/25 - 0s - loss: 0.2113 - accuracy: 0.9001 - val_loss: 0.4678 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00836: val_loss did not improve from 0.40529\n",
      "Epoch 837/1000\n",
      "25/25 - 0s - loss: 0.2116 - accuracy: 0.8936 - val_loss: 0.4716 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00837: val_loss did not improve from 0.40529\n",
      "Epoch 838/1000\n",
      "25/25 - 0s - loss: 0.2083 - accuracy: 0.9027 - val_loss: 0.4682 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00838: val_loss did not improve from 0.40529\n",
      "Epoch 839/1000\n",
      "25/25 - 0s - loss: 0.2071 - accuracy: 0.8962 - val_loss: 0.4771 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00839: val_loss did not improve from 0.40529\n",
      "Epoch 840/1000\n",
      "25/25 - 0s - loss: 0.2090 - accuracy: 0.8988 - val_loss: 0.4652 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00840: val_loss did not improve from 0.40529\n",
      "Epoch 841/1000\n",
      "25/25 - 0s - loss: 0.2088 - accuracy: 0.8975 - val_loss: 0.4899 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00841: val_loss did not improve from 0.40529\n",
      "Epoch 842/1000\n",
      "25/25 - 0s - loss: 0.2134 - accuracy: 0.8923 - val_loss: 0.4575 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00842: val_loss did not improve from 0.40529\n",
      "Epoch 843/1000\n",
      "25/25 - 0s - loss: 0.2097 - accuracy: 0.8988 - val_loss: 0.4582 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00843: val_loss did not improve from 0.40529\n",
      "Epoch 844/1000\n",
      "25/25 - 0s - loss: 0.2067 - accuracy: 0.9014 - val_loss: 0.4829 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00844: val_loss did not improve from 0.40529\n",
      "Epoch 845/1000\n",
      "25/25 - 0s - loss: 0.2069 - accuracy: 0.8988 - val_loss: 0.4815 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00845: val_loss did not improve from 0.40529\n",
      "Epoch 846/1000\n",
      "25/25 - 0s - loss: 0.2066 - accuracy: 0.9001 - val_loss: 0.4777 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00846: val_loss did not improve from 0.40529\n",
      "Epoch 847/1000\n",
      "25/25 - 0s - loss: 0.2063 - accuracy: 0.8975 - val_loss: 0.4761 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00847: val_loss did not improve from 0.40529\n",
      "Epoch 848/1000\n",
      "25/25 - 0s - loss: 0.2075 - accuracy: 0.9027 - val_loss: 0.4719 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00848: val_loss did not improve from 0.40529\n",
      "Epoch 849/1000\n",
      "25/25 - 0s - loss: 0.2188 - accuracy: 0.8962 - val_loss: 0.4646 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00849: val_loss did not improve from 0.40529\n",
      "Epoch 850/1000\n",
      "25/25 - 0s - loss: 0.2108 - accuracy: 0.9014 - val_loss: 0.4851 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00850: val_loss did not improve from 0.40529\n",
      "Epoch 851/1000\n",
      "25/25 - 0s - loss: 0.2081 - accuracy: 0.9027 - val_loss: 0.4776 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00851: val_loss did not improve from 0.40529\n",
      "Epoch 852/1000\n",
      "25/25 - 0s - loss: 0.2087 - accuracy: 0.9001 - val_loss: 0.4856 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00852: val_loss did not improve from 0.40529\n",
      "Epoch 853/1000\n",
      "25/25 - 0s - loss: 0.2054 - accuracy: 0.9014 - val_loss: 0.4627 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00853: val_loss did not improve from 0.40529\n",
      "Epoch 854/1000\n",
      "25/25 - 0s - loss: 0.2072 - accuracy: 0.9014 - val_loss: 0.4749 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00854: val_loss did not improve from 0.40529\n",
      "Epoch 855/1000\n",
      "25/25 - 0s - loss: 0.2061 - accuracy: 0.8962 - val_loss: 0.4660 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00855: val_loss did not improve from 0.40529\n",
      "Epoch 856/1000\n",
      "25/25 - 0s - loss: 0.2084 - accuracy: 0.9001 - val_loss: 0.4791 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00856: val_loss did not improve from 0.40529\n",
      "Epoch 857/1000\n",
      "25/25 - 0s - loss: 0.2090 - accuracy: 0.8962 - val_loss: 0.4698 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00857: val_loss did not improve from 0.40529\n",
      "Epoch 858/1000\n",
      "25/25 - 0s - loss: 0.2068 - accuracy: 0.9001 - val_loss: 0.4892 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00858: val_loss did not improve from 0.40529\n",
      "Epoch 859/1000\n",
      "25/25 - 0s - loss: 0.2089 - accuracy: 0.9027 - val_loss: 0.4585 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00859: val_loss did not improve from 0.40529\n",
      "Epoch 860/1000\n",
      "25/25 - 0s - loss: 0.2100 - accuracy: 0.9001 - val_loss: 0.4754 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00860: val_loss did not improve from 0.40529\n",
      "Epoch 861/1000\n",
      "25/25 - 0s - loss: 0.2095 - accuracy: 0.9027 - val_loss: 0.4504 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00861: val_loss did not improve from 0.40529\n",
      "Epoch 862/1000\n",
      "25/25 - 0s - loss: 0.2154 - accuracy: 0.8962 - val_loss: 0.4513 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00862: val_loss did not improve from 0.40529\n",
      "Epoch 863/1000\n",
      "25/25 - 0s - loss: 0.2130 - accuracy: 0.8975 - val_loss: 0.4531 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00863: val_loss did not improve from 0.40529\n",
      "Epoch 864/1000\n",
      "25/25 - 0s - loss: 0.2083 - accuracy: 0.9001 - val_loss: 0.4588 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00864: val_loss did not improve from 0.40529\n",
      "Epoch 865/1000\n",
      "25/25 - 0s - loss: 0.2080 - accuracy: 0.8975 - val_loss: 0.4970 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00865: val_loss did not improve from 0.40529\n",
      "Epoch 866/1000\n",
      "25/25 - 0s - loss: 0.2242 - accuracy: 0.8898 - val_loss: 0.4664 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00866: val_loss did not improve from 0.40529\n",
      "Epoch 867/1000\n",
      "25/25 - 0s - loss: 0.2131 - accuracy: 0.8923 - val_loss: 0.4697 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00867: val_loss did not improve from 0.40529\n",
      "Epoch 868/1000\n",
      "25/25 - 0s - loss: 0.2071 - accuracy: 0.9014 - val_loss: 0.4764 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00868: val_loss did not improve from 0.40529\n",
      "Epoch 869/1000\n",
      "25/25 - 0s - loss: 0.2148 - accuracy: 0.8936 - val_loss: 0.4410 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00869: val_loss did not improve from 0.40529\n",
      "Epoch 870/1000\n",
      "25/25 - 0s - loss: 0.2067 - accuracy: 0.9027 - val_loss: 0.4515 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00870: val_loss did not improve from 0.40529\n",
      "Epoch 871/1000\n",
      "25/25 - 0s - loss: 0.2078 - accuracy: 0.8962 - val_loss: 0.4638 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00871: val_loss did not improve from 0.40529\n",
      "Epoch 872/1000\n",
      "25/25 - 0s - loss: 0.2113 - accuracy: 0.9027 - val_loss: 0.4700 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00872: val_loss did not improve from 0.40529\n",
      "Epoch 873/1000\n",
      "25/25 - 0s - loss: 0.2097 - accuracy: 0.8975 - val_loss: 0.4777 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00873: val_loss did not improve from 0.40529\n",
      "Epoch 874/1000\n",
      "25/25 - 0s - loss: 0.2109 - accuracy: 0.9001 - val_loss: 0.4779 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00874: val_loss did not improve from 0.40529\n",
      "Epoch 875/1000\n",
      "25/25 - 0s - loss: 0.2091 - accuracy: 0.9014 - val_loss: 0.4762 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00875: val_loss did not improve from 0.40529\n",
      "Epoch 876/1000\n",
      "25/25 - 0s - loss: 0.2067 - accuracy: 0.9040 - val_loss: 0.4770 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00876: val_loss did not improve from 0.40529\n",
      "Epoch 877/1000\n",
      "25/25 - 0s - loss: 0.2104 - accuracy: 0.8962 - val_loss: 0.5072 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00877: val_loss did not improve from 0.40529\n",
      "Epoch 878/1000\n",
      "25/25 - 0s - loss: 0.2125 - accuracy: 0.9001 - val_loss: 0.4643 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00878: val_loss did not improve from 0.40529\n",
      "Epoch 879/1000\n",
      "25/25 - 0s - loss: 0.2169 - accuracy: 0.8975 - val_loss: 0.4615 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00879: val_loss did not improve from 0.40529\n",
      "Epoch 880/1000\n",
      "25/25 - 0s - loss: 0.2099 - accuracy: 0.9040 - val_loss: 0.4743 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00880: val_loss did not improve from 0.40529\n",
      "Epoch 881/1000\n",
      "25/25 - 0s - loss: 0.2154 - accuracy: 0.9001 - val_loss: 0.4822 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00881: val_loss did not improve from 0.40529\n",
      "Epoch 882/1000\n",
      "25/25 - 0s - loss: 0.2175 - accuracy: 0.9001 - val_loss: 0.4694 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00882: val_loss did not improve from 0.40529\n",
      "Epoch 883/1000\n",
      "25/25 - 0s - loss: 0.2244 - accuracy: 0.8988 - val_loss: 0.4553 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00883: val_loss did not improve from 0.40529\n",
      "Epoch 884/1000\n",
      "25/25 - 0s - loss: 0.2188 - accuracy: 0.8975 - val_loss: 0.4602 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00884: val_loss did not improve from 0.40529\n",
      "Epoch 885/1000\n",
      "25/25 - 0s - loss: 0.2098 - accuracy: 0.9027 - val_loss: 0.4696 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00885: val_loss did not improve from 0.40529\n",
      "Epoch 886/1000\n",
      "25/25 - 0s - loss: 0.2070 - accuracy: 0.9001 - val_loss: 0.4756 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00886: val_loss did not improve from 0.40529\n",
      "Epoch 887/1000\n",
      "25/25 - 0s - loss: 0.2063 - accuracy: 0.8975 - val_loss: 0.4800 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00887: val_loss did not improve from 0.40529\n",
      "Epoch 888/1000\n",
      "25/25 - 0s - loss: 0.2086 - accuracy: 0.8975 - val_loss: 0.4978 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00888: val_loss did not improve from 0.40529\n",
      "Epoch 889/1000\n",
      "25/25 - 0s - loss: 0.2160 - accuracy: 0.8975 - val_loss: 0.4635 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00889: val_loss did not improve from 0.40529\n",
      "Epoch 890/1000\n",
      "25/25 - 0s - loss: 0.2089 - accuracy: 0.9014 - val_loss: 0.4785 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00890: val_loss did not improve from 0.40529\n",
      "Epoch 891/1000\n",
      "25/25 - 0s - loss: 0.2086 - accuracy: 0.9001 - val_loss: 0.4842 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00891: val_loss did not improve from 0.40529\n",
      "Epoch 892/1000\n",
      "25/25 - 0s - loss: 0.2074 - accuracy: 0.8949 - val_loss: 0.4846 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00892: val_loss did not improve from 0.40529\n",
      "Epoch 893/1000\n",
      "25/25 - 0s - loss: 0.2102 - accuracy: 0.9001 - val_loss: 0.4967 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00893: val_loss did not improve from 0.40529\n",
      "Epoch 894/1000\n",
      "25/25 - 0s - loss: 0.2079 - accuracy: 0.9027 - val_loss: 0.4813 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00894: val_loss did not improve from 0.40529\n",
      "Epoch 895/1000\n",
      "25/25 - 0s - loss: 0.2125 - accuracy: 0.8949 - val_loss: 0.4602 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00895: val_loss did not improve from 0.40529\n",
      "Epoch 896/1000\n",
      "25/25 - 0s - loss: 0.2176 - accuracy: 0.8846 - val_loss: 0.4722 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00896: val_loss did not improve from 0.40529\n",
      "Epoch 897/1000\n",
      "25/25 - 0s - loss: 0.2085 - accuracy: 0.9014 - val_loss: 0.4616 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00897: val_loss did not improve from 0.40529\n",
      "Epoch 898/1000\n",
      "25/25 - 0s - loss: 0.2091 - accuracy: 0.8988 - val_loss: 0.4842 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00898: val_loss did not improve from 0.40529\n",
      "Epoch 899/1000\n",
      "25/25 - 0s - loss: 0.2085 - accuracy: 0.9014 - val_loss: 0.4605 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00899: val_loss did not improve from 0.40529\n",
      "Epoch 900/1000\n",
      "25/25 - 0s - loss: 0.2127 - accuracy: 0.8975 - val_loss: 0.4942 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00900: val_loss did not improve from 0.40529\n",
      "Epoch 901/1000\n",
      "25/25 - 0s - loss: 0.2152 - accuracy: 0.8988 - val_loss: 0.4679 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00901: val_loss did not improve from 0.40529\n",
      "Epoch 902/1000\n",
      "25/25 - 0s - loss: 0.2114 - accuracy: 0.8962 - val_loss: 0.4657 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00902: val_loss did not improve from 0.40529\n",
      "Epoch 903/1000\n",
      "25/25 - 0s - loss: 0.2077 - accuracy: 0.9027 - val_loss: 0.4516 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00903: val_loss did not improve from 0.40529\n",
      "Epoch 904/1000\n",
      "25/25 - 0s - loss: 0.2080 - accuracy: 0.9001 - val_loss: 0.5039 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00904: val_loss did not improve from 0.40529\n",
      "Epoch 905/1000\n",
      "25/25 - 0s - loss: 0.2106 - accuracy: 0.8975 - val_loss: 0.4729 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00905: val_loss did not improve from 0.40529\n",
      "Epoch 906/1000\n",
      "25/25 - 0s - loss: 0.2129 - accuracy: 0.8988 - val_loss: 0.4828 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00906: val_loss did not improve from 0.40529\n",
      "Epoch 907/1000\n",
      "25/25 - 0s - loss: 0.2072 - accuracy: 0.9001 - val_loss: 0.4789 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00907: val_loss did not improve from 0.40529\n",
      "Epoch 908/1000\n",
      "25/25 - 0s - loss: 0.2063 - accuracy: 0.9014 - val_loss: 0.4840 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00908: val_loss did not improve from 0.40529\n",
      "Epoch 909/1000\n",
      "25/25 - 0s - loss: 0.2082 - accuracy: 0.9001 - val_loss: 0.4933 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00909: val_loss did not improve from 0.40529\n",
      "Epoch 910/1000\n",
      "25/25 - 0s - loss: 0.2070 - accuracy: 0.9001 - val_loss: 0.4967 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00910: val_loss did not improve from 0.40529\n",
      "Epoch 911/1000\n",
      "25/25 - 0s - loss: 0.2074 - accuracy: 0.9027 - val_loss: 0.4941 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00911: val_loss did not improve from 0.40529\n",
      "Epoch 912/1000\n",
      "25/25 - 0s - loss: 0.2063 - accuracy: 0.9001 - val_loss: 0.4842 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00912: val_loss did not improve from 0.40529\n",
      "Epoch 913/1000\n",
      "25/25 - 0s - loss: 0.2069 - accuracy: 0.8975 - val_loss: 0.4963 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00913: val_loss did not improve from 0.40529\n",
      "Epoch 914/1000\n",
      "25/25 - 0s - loss: 0.2059 - accuracy: 0.9014 - val_loss: 0.4825 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00914: val_loss did not improve from 0.40529\n",
      "Epoch 915/1000\n",
      "25/25 - 0s - loss: 0.2058 - accuracy: 0.9014 - val_loss: 0.4783 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00915: val_loss did not improve from 0.40529\n",
      "Epoch 916/1000\n",
      "25/25 - 0s - loss: 0.2056 - accuracy: 0.9040 - val_loss: 0.4657 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00916: val_loss did not improve from 0.40529\n",
      "Epoch 917/1000\n",
      "25/25 - 0s - loss: 0.2083 - accuracy: 0.8988 - val_loss: 0.4810 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00917: val_loss did not improve from 0.40529\n",
      "Epoch 918/1000\n",
      "25/25 - 0s - loss: 0.2064 - accuracy: 0.9001 - val_loss: 0.4778 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00918: val_loss did not improve from 0.40529\n",
      "Epoch 919/1000\n",
      "25/25 - 0s - loss: 0.2049 - accuracy: 0.9014 - val_loss: 0.4809 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00919: val_loss did not improve from 0.40529\n",
      "Epoch 920/1000\n",
      "25/25 - 0s - loss: 0.2063 - accuracy: 0.9027 - val_loss: 0.4619 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00920: val_loss did not improve from 0.40529\n",
      "Epoch 921/1000\n",
      "25/25 - 0s - loss: 0.2088 - accuracy: 0.9040 - val_loss: 0.4771 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00921: val_loss did not improve from 0.40529\n",
      "Epoch 922/1000\n",
      "25/25 - 0s - loss: 0.2060 - accuracy: 0.8988 - val_loss: 0.4772 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00922: val_loss did not improve from 0.40529\n",
      "Epoch 923/1000\n",
      "25/25 - 0s - loss: 0.2067 - accuracy: 0.8988 - val_loss: 0.4805 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00923: val_loss did not improve from 0.40529\n",
      "Epoch 924/1000\n",
      "25/25 - 0s - loss: 0.2160 - accuracy: 0.8962 - val_loss: 0.4761 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00924: val_loss did not improve from 0.40529\n",
      "Epoch 925/1000\n",
      "25/25 - 0s - loss: 0.2073 - accuracy: 0.9053 - val_loss: 0.4747 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00925: val_loss did not improve from 0.40529\n",
      "Epoch 926/1000\n",
      "25/25 - 0s - loss: 0.2068 - accuracy: 0.9001 - val_loss: 0.4786 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00926: val_loss did not improve from 0.40529\n",
      "Epoch 927/1000\n",
      "25/25 - 0s - loss: 0.2053 - accuracy: 0.9027 - val_loss: 0.4861 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00927: val_loss did not improve from 0.40529\n",
      "Epoch 928/1000\n",
      "25/25 - 0s - loss: 0.2061 - accuracy: 0.9014 - val_loss: 0.4748 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00928: val_loss did not improve from 0.40529\n",
      "Epoch 929/1000\n",
      "25/25 - 0s - loss: 0.2050 - accuracy: 0.9014 - val_loss: 0.4863 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00929: val_loss did not improve from 0.40529\n",
      "Epoch 930/1000\n",
      "25/25 - 0s - loss: 0.2067 - accuracy: 0.9014 - val_loss: 0.4862 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00930: val_loss did not improve from 0.40529\n",
      "Epoch 931/1000\n",
      "25/25 - 0s - loss: 0.2063 - accuracy: 0.9001 - val_loss: 0.4918 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00931: val_loss did not improve from 0.40529\n",
      "Epoch 932/1000\n",
      "25/25 - 0s - loss: 0.2072 - accuracy: 0.9001 - val_loss: 0.4771 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00932: val_loss did not improve from 0.40529\n",
      "Epoch 933/1000\n",
      "25/25 - 0s - loss: 0.2059 - accuracy: 0.9027 - val_loss: 0.4931 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00933: val_loss did not improve from 0.40529\n",
      "Epoch 934/1000\n",
      "25/25 - 0s - loss: 0.2045 - accuracy: 0.9040 - val_loss: 0.4875 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00934: val_loss did not improve from 0.40529\n",
      "Epoch 935/1000\n",
      "25/25 - 0s - loss: 0.2059 - accuracy: 0.9027 - val_loss: 0.4814 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00935: val_loss did not improve from 0.40529\n",
      "Epoch 936/1000\n",
      "25/25 - 0s - loss: 0.2080 - accuracy: 0.8988 - val_loss: 0.4835 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00936: val_loss did not improve from 0.40529\n",
      "Epoch 937/1000\n",
      "25/25 - 0s - loss: 0.2104 - accuracy: 0.8949 - val_loss: 0.5007 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00937: val_loss did not improve from 0.40529\n",
      "Epoch 938/1000\n",
      "25/25 - 0s - loss: 0.2073 - accuracy: 0.8962 - val_loss: 0.4940 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00938: val_loss did not improve from 0.40529\n",
      "Epoch 939/1000\n",
      "25/25 - 0s - loss: 0.2051 - accuracy: 0.9040 - val_loss: 0.4961 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00939: val_loss did not improve from 0.40529\n",
      "Epoch 940/1000\n",
      "25/25 - 0s - loss: 0.2057 - accuracy: 0.9014 - val_loss: 0.4925 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00940: val_loss did not improve from 0.40529\n",
      "Epoch 941/1000\n",
      "25/25 - 0s - loss: 0.2055 - accuracy: 0.9027 - val_loss: 0.4947 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00941: val_loss did not improve from 0.40529\n",
      "Epoch 942/1000\n",
      "25/25 - 0s - loss: 0.2119 - accuracy: 0.9001 - val_loss: 0.4819 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00942: val_loss did not improve from 0.40529\n",
      "Epoch 943/1000\n",
      "25/25 - 0s - loss: 0.2609 - accuracy: 0.8846 - val_loss: 0.4742 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00943: val_loss did not improve from 0.40529\n",
      "Epoch 944/1000\n",
      "25/25 - 0s - loss: 0.2487 - accuracy: 0.8859 - val_loss: 0.4521 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00944: val_loss did not improve from 0.40529\n",
      "Epoch 945/1000\n",
      "25/25 - 0s - loss: 0.2141 - accuracy: 0.8988 - val_loss: 0.4687 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00945: val_loss did not improve from 0.40529\n",
      "Epoch 946/1000\n",
      "25/25 - 0s - loss: 0.2071 - accuracy: 0.9040 - val_loss: 0.4773 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00946: val_loss did not improve from 0.40529\n",
      "Epoch 947/1000\n",
      "25/25 - 0s - loss: 0.2093 - accuracy: 0.8975 - val_loss: 0.4772 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00947: val_loss did not improve from 0.40529\n",
      "Epoch 948/1000\n",
      "25/25 - 0s - loss: 0.2077 - accuracy: 0.8988 - val_loss: 0.4849 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00948: val_loss did not improve from 0.40529\n",
      "Epoch 949/1000\n",
      "25/25 - 0s - loss: 0.2127 - accuracy: 0.9014 - val_loss: 0.4681 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00949: val_loss did not improve from 0.40529\n",
      "Epoch 950/1000\n",
      "25/25 - 0s - loss: 0.2063 - accuracy: 0.9027 - val_loss: 0.4822 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00950: val_loss did not improve from 0.40529\n",
      "Epoch 951/1000\n",
      "25/25 - 0s - loss: 0.2114 - accuracy: 0.9014 - val_loss: 0.4784 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00951: val_loss did not improve from 0.40529\n",
      "Epoch 952/1000\n",
      "25/25 - 0s - loss: 0.2080 - accuracy: 0.8988 - val_loss: 0.4675 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00952: val_loss did not improve from 0.40529\n",
      "Epoch 953/1000\n",
      "25/25 - 0s - loss: 0.2050 - accuracy: 0.9001 - val_loss: 0.4809 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00953: val_loss did not improve from 0.40529\n",
      "Epoch 954/1000\n",
      "25/25 - 0s - loss: 0.2082 - accuracy: 0.9001 - val_loss: 0.4735 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00954: val_loss did not improve from 0.40529\n",
      "Epoch 955/1000\n",
      "25/25 - 0s - loss: 0.2221 - accuracy: 0.8962 - val_loss: 0.4508 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00955: val_loss did not improve from 0.40529\n",
      "Epoch 956/1000\n",
      "25/25 - 0s - loss: 0.2197 - accuracy: 0.8949 - val_loss: 0.4911 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00956: val_loss did not improve from 0.40529\n",
      "Epoch 957/1000\n",
      "25/25 - 0s - loss: 0.2125 - accuracy: 0.8936 - val_loss: 0.4686 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00957: val_loss did not improve from 0.40529\n",
      "Epoch 958/1000\n",
      "25/25 - 0s - loss: 0.2099 - accuracy: 0.9001 - val_loss: 0.4662 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00958: val_loss did not improve from 0.40529\n",
      "Epoch 959/1000\n",
      "25/25 - 0s - loss: 0.2067 - accuracy: 0.9001 - val_loss: 0.4687 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00959: val_loss did not improve from 0.40529\n",
      "Epoch 960/1000\n",
      "25/25 - 0s - loss: 0.2087 - accuracy: 0.8975 - val_loss: 0.4725 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00960: val_loss did not improve from 0.40529\n",
      "Epoch 961/1000\n",
      "25/25 - 0s - loss: 0.2223 - accuracy: 0.8975 - val_loss: 0.4721 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00961: val_loss did not improve from 0.40529\n",
      "Epoch 962/1000\n",
      "25/25 - 0s - loss: 0.2092 - accuracy: 0.8975 - val_loss: 0.4499 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00962: val_loss did not improve from 0.40529\n",
      "Epoch 963/1000\n",
      "25/25 - 0s - loss: 0.2055 - accuracy: 0.8949 - val_loss: 0.4720 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00963: val_loss did not improve from 0.40529\n",
      "Epoch 964/1000\n",
      "25/25 - 0s - loss: 0.2070 - accuracy: 0.9027 - val_loss: 0.4705 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00964: val_loss did not improve from 0.40529\n",
      "Epoch 965/1000\n",
      "25/25 - 0s - loss: 0.2051 - accuracy: 0.9001 - val_loss: 0.4646 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00965: val_loss did not improve from 0.40529\n",
      "Epoch 966/1000\n",
      "25/25 - 0s - loss: 0.2096 - accuracy: 0.8975 - val_loss: 0.4549 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00966: val_loss did not improve from 0.40529\n",
      "Epoch 967/1000\n",
      "25/25 - 0s - loss: 0.2081 - accuracy: 0.9001 - val_loss: 0.4781 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00967: val_loss did not improve from 0.40529\n",
      "Epoch 968/1000\n",
      "25/25 - 0s - loss: 0.2060 - accuracy: 0.9001 - val_loss: 0.4781 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00968: val_loss did not improve from 0.40529\n",
      "Epoch 969/1000\n",
      "25/25 - 0s - loss: 0.2061 - accuracy: 0.9001 - val_loss: 0.4825 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00969: val_loss did not improve from 0.40529\n",
      "Epoch 970/1000\n",
      "25/25 - 0s - loss: 0.2056 - accuracy: 0.9014 - val_loss: 0.4801 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00970: val_loss did not improve from 0.40529\n",
      "Epoch 971/1000\n",
      "25/25 - 0s - loss: 0.2135 - accuracy: 0.8949 - val_loss: 0.4597 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00971: val_loss did not improve from 0.40529\n",
      "Epoch 972/1000\n",
      "25/25 - 0s - loss: 0.2058 - accuracy: 0.8988 - val_loss: 0.4795 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00972: val_loss did not improve from 0.40529\n",
      "Epoch 973/1000\n",
      "25/25 - 0s - loss: 0.2057 - accuracy: 0.9014 - val_loss: 0.4651 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00973: val_loss did not improve from 0.40529\n",
      "Epoch 974/1000\n",
      "25/25 - 0s - loss: 0.2089 - accuracy: 0.9001 - val_loss: 0.4767 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00974: val_loss did not improve from 0.40529\n",
      "Epoch 975/1000\n",
      "25/25 - 0s - loss: 0.2057 - accuracy: 0.9014 - val_loss: 0.4772 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00975: val_loss did not improve from 0.40529\n",
      "Epoch 976/1000\n",
      "25/25 - 0s - loss: 0.2053 - accuracy: 0.9014 - val_loss: 0.4887 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00976: val_loss did not improve from 0.40529\n",
      "Epoch 977/1000\n",
      "25/25 - 0s - loss: 0.2092 - accuracy: 0.8949 - val_loss: 0.4974 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00977: val_loss did not improve from 0.40529\n",
      "Epoch 978/1000\n",
      "25/25 - 0s - loss: 0.2078 - accuracy: 0.8975 - val_loss: 0.4757 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00978: val_loss did not improve from 0.40529\n",
      "Epoch 979/1000\n",
      "25/25 - 0s - loss: 0.2084 - accuracy: 0.9001 - val_loss: 0.4763 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00979: val_loss did not improve from 0.40529\n",
      "Epoch 980/1000\n",
      "25/25 - 0s - loss: 0.2123 - accuracy: 0.8988 - val_loss: 0.4831 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00980: val_loss did not improve from 0.40529\n",
      "Epoch 981/1000\n",
      "25/25 - 0s - loss: 0.2062 - accuracy: 0.9001 - val_loss: 0.4744 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00981: val_loss did not improve from 0.40529\n",
      "Epoch 982/1000\n",
      "25/25 - 0s - loss: 0.2076 - accuracy: 0.8936 - val_loss: 0.4806 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00982: val_loss did not improve from 0.40529\n",
      "Epoch 983/1000\n",
      "25/25 - 0s - loss: 0.2078 - accuracy: 0.9001 - val_loss: 0.4704 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00983: val_loss did not improve from 0.40529\n",
      "Epoch 984/1000\n",
      "25/25 - 0s - loss: 0.2063 - accuracy: 0.9053 - val_loss: 0.4867 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00984: val_loss did not improve from 0.40529\n",
      "Epoch 985/1000\n",
      "25/25 - 0s - loss: 0.2064 - accuracy: 0.9027 - val_loss: 0.4815 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00985: val_loss did not improve from 0.40529\n",
      "Epoch 986/1000\n",
      "25/25 - 0s - loss: 0.2050 - accuracy: 0.9001 - val_loss: 0.4834 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00986: val_loss did not improve from 0.40529\n",
      "Epoch 987/1000\n",
      "25/25 - 0s - loss: 0.2069 - accuracy: 0.8988 - val_loss: 0.4806 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00987: val_loss did not improve from 0.40529\n",
      "Epoch 988/1000\n",
      "25/25 - 0s - loss: 0.2049 - accuracy: 0.9040 - val_loss: 0.4876 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00988: val_loss did not improve from 0.40529\n",
      "Epoch 989/1000\n",
      "25/25 - 0s - loss: 0.2058 - accuracy: 0.8962 - val_loss: 0.4905 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00989: val_loss did not improve from 0.40529\n",
      "Epoch 990/1000\n",
      "25/25 - 0s - loss: 0.2138 - accuracy: 0.8988 - val_loss: 0.4853 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00990: val_loss did not improve from 0.40529\n",
      "Epoch 991/1000\n",
      "25/25 - 0s - loss: 0.2059 - accuracy: 0.9027 - val_loss: 0.4836 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00991: val_loss did not improve from 0.40529\n",
      "Epoch 992/1000\n",
      "25/25 - 0s - loss: 0.2146 - accuracy: 0.9027 - val_loss: 0.4965 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00992: val_loss did not improve from 0.40529\n",
      "Epoch 993/1000\n",
      "25/25 - 0s - loss: 0.2192 - accuracy: 0.9053 - val_loss: 0.4857 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00993: val_loss did not improve from 0.40529\n",
      "Epoch 994/1000\n",
      "25/25 - 0s - loss: 0.2094 - accuracy: 0.8962 - val_loss: 0.4853 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00994: val_loss did not improve from 0.40529\n",
      "Epoch 995/1000\n",
      "25/25 - 0s - loss: 0.2070 - accuracy: 0.9040 - val_loss: 0.4765 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00995: val_loss did not improve from 0.40529\n",
      "Epoch 996/1000\n",
      "25/25 - 0s - loss: 0.2122 - accuracy: 0.8949 - val_loss: 0.4703 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00996: val_loss did not improve from 0.40529\n",
      "Epoch 997/1000\n",
      "25/25 - 0s - loss: 0.2053 - accuracy: 0.9001 - val_loss: 0.4945 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00997: val_loss did not improve from 0.40529\n",
      "Epoch 998/1000\n",
      "25/25 - 0s - loss: 0.2100 - accuracy: 0.9001 - val_loss: 0.4895 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00998: val_loss did not improve from 0.40529\n",
      "Epoch 999/1000\n",
      "25/25 - 0s - loss: 0.2065 - accuracy: 0.8949 - val_loss: 0.4888 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00999: val_loss did not improve from 0.40529\n",
      "Epoch 1000/1000\n",
      "25/25 - 0s - loss: 0.2114 - accuracy: 0.9001 - val_loss: 0.4801 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 01000: val_loss did not improve from 0.40529\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 16)                512       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 2,483\n",
      "Trainable params: 2,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABOz0lEQVR4nO2dd5wURfbAv48lR0mKEgQEQSTKiooBDHeiGDGBGDChp4hizvrzzOcdimI8EfUMKIeIiqKihBMDWbIEQaIkWTKb3u+Pmmbi7szuzuzM7rzv59Of7qqurn493VOv6lXVK1FVDMMwjPSlQrIFMAzDMJKLKQLDMIw0xxSBYRhGmmOKwDAMI80xRWAYhpHmmCIwDMNIc0wRGIZhpDmmCAwjABEZKSKPxZh2pYiclmiZDCPRmCIwjFJCRCaKiIpIxYA4FZFWccq/uS+/nQHbg/HI2yjfVIyexDCMkiIi/YFKpXS7A1Q1t5TuZZQDrEVglEl8Zpk7ReQXEdklIm+IyEEi8oWI7BCRb0Skri/tOSKyQES2icgkETkiIJ8uIjLLd80ooGrIfc4SkTm+a6eJSMdiyFoHeBi4q4TPXMUnR/uAuIYiskdEDixJ3kZ6Y4rAKMtcAPwFOBw4G/gCuA9oiPu2B4vI4cD7wK2++PHApyJSWUQqA2OBd4B6wEe+PAGnJIARwPVAfeBVYJyIVCminE8ALwMbivOQHqq6DxgD9AuIvhiYrKobA+JWicgaEXlTRBqU5J5GemCKwCjLvKCqf6jqWmAq8JOqzlbVvcDHQBfgEuBzVf1aVXOAZ4FqQHfgWJy55jlVzVHV0cD0gPwHAq+q6k+qmqeqbwH7fNfFhIhkAscDL5T4aR3vAX0Dwpf64gA2A0cDhwJdgVrAu3G6r1GOsT4CoyzzR8DxngjhmsAhwCovUlXzRWQ10BjIA9ZqsAveVQHHhwJXisjNAXGVfXlGRUQqAC8Bt6hqrojEclk0vgOqi8gxuOftjFN6qOpOYIYv3R8iMghYLyK1VHVHPG5ulE9MERjlnXVABy8grjRuCqwFFGgsIhKgDJoBy33Hq4HHVfXxYt67NpAJjPIpgQxf/BoRuUhVpxY1Q1XNE5EPceahP4DPCinkvWeylr9RKPaBGOWdD4HeInKqiFQCbseZd6YBPwC5uL6ESiLSB+gWcO3rwA0icow4aohIbxGpFeO9s3Cth86+7UxffFfgp4B0lUWkasCWQeG8hzN59cdvFsInZxsRqSAi9YFhwCRVzYpRXiNNMUVglGtUdQlwGc5GvxnXqXy2qmarajbQBxgAbMUVrmMCrp0BXAe8CPwJLPOljfXeqqobvA3Y5Dv1h+/eHgtwpixvuypKvj8Bu3BK5ouAUy2BL4EdwHycwusXloFhhCC2QplhGEZ6Yy0CwzCMNMcUgWGUEN8ktp0RtvuKmd8rBeT3SrxlNwww05BhGEbak7DhoyIyAjgL2Kiq7SOcF+B53EiK3cAAVZ0VLd8GDRpo8+bN4yytYRhG+WbmzJmbVbVhpHOJnEcwEjfa4u0Czp8BtPZtx+Cm4B8TLdPmzZszY8aMaMkMw0gBVu/dC0DTqlWjpDQSjYisKuhcwvoIVHUKbkheQZwLvO0bYvcjcICIHJwoeQzDKH0uX7SIyxctSrYYRhSSObO4MW7mpscaX9z60IQiMhDn94VmzZqVinCGYZScBw49NNkiGDFQJlxMqOprwGsAmZmZ1rttGGWE0+rVS7YIRgwkUxGsxfl88WjiizPSjJycHNasWcNenz3ZSC5Vq1alSZMmVKpU8nV0VuzZA0DLatVKnJeROJKpCMYBg0TkA1wncZaqhpmFjPLPmjVrqFWrFs2bNydOHjqNYqKqbNmyhTVr1tCiRYsS53f14sUATOrSpcR5GYkjkcNH3wd6Ag1EZA1uhaZKAKr6Cm6BkDNx/lt2E8W/ilF+2bt3rymBFEFEqF+/Pps2bYqeOAb+Lw7KxEg8CVMEqlqosyuf29+bEnV/o2xhSiB1iOe76HHAAXHLy0gc5mLCMIyEsWT3bpbs3p1sMYwopI8i+OgjOP542Lkz2ZIYKcaWLVvo3LkznTt3plGjRjRu3Hh/ODs7u9BrZ8yYweDBg6Peo3v37nGRddKkSZx11llxyas0uH7JEq5fsiTZYhhRKBPDR+PCpk0wbRrs2gU1ayZbGiOFqF+/PnPmzAHgkUceoWbNmtxxxx37z+fm5lKxYuS/SmZmJpmZmVHvMW3atLjIWtZ4omXLZItgxED6tAiqV3d733A2wyiMAQMGcMMNN3DMMcdw11138fPPP3PcccfRpUsXunfvzhJfLTewhv7II49w9dVX07NnT1q2bMmwYcP251fTV/mYNGkSPXv25MILL6Rt27b0798fz/Hj+PHjadu2LV27dmXw4MFFqvm///77dOjQgfbt23P33XcDkJeXx4ABA2jfvj0dOnRg6NChAAwbNox27drRsWNH+vbtW/IfqxC616lD9zp1EnoPo+SkT4vAG8ds9srUp2fP8LiLL4Ybb3Tv78wzw88PGOC2zZvhwguDz02aVCwx1qxZw7Rp08jIyGD79u1MnTqVihUr8s0333Dffffx3//+N+yaxYsX891337Fjxw7atGnD3/72t7Dx+LNnz2bBggUccsghHH/88Xz//fdkZmZy/fXXM2XKFFq0aEG/frEvLLZu3TruvvtuZs6cSd26dfnrX//K2LFjadq0KWvXrmX+/PkAbNu2DYCnnnqK3377jSpVquyPSxTzfabY9tYKT2msRWAYBXDRRReRkeGWD87KyuKiiy6iffv2DBkyhAULFkS8pnfv3lSpUoUGDRpw4IEH8scff4Sl6datG02aNKFChQp07tyZlStXsnjxYlq2bLl/7H5RFMH06dPp2bMnDRs2pGLFivTv358pU6bQsmVLVqxYwc0338yXX35J7dq1AejYsSP9+/fnP//5T4Emr3gxaOlSBi1dmtB7GCUnfVoEDRvC0UdDHGZLGgmmsBp89eqFn2/QoNgtgFBq1Kix//jBBx/k5JNP5uOPP2blypX0jNRqAapUqbL/OCMjg9zc3GKliQd169Zl7ty5TJgwgVdeeYUPP/yQESNG8PnnnzNlyhQ+/fRTHn/8cebNm5cwhfCPww5LSL5GfEmfFsGxx8LPP0PHjsmWxCiDZGVl0bhxYwBGjhwZ9/zbtGnDihUrWLlyJQCjRo2K+dpu3boxefJkNm/eTF5eHu+//z49evRg8+bN5Ofnc8EFF/DYY48xa9Ys8vPzWb16NSeffDJPP/00WVlZ7EzgSLqja9fmaF9LxEhd0qdFYBgl4K677uLKK6/kscceo3fv3nHPv1q1arz00kv06tWLGjVqcPTRRxeYduLEiTRp0mR/+KOPPuKpp57i5JNPRlXp3bs35557LnPnzuWqq64iPz8fgCeffJK8vDwuu+wysrKyUFUGDx7MAQmc9DVnxw4AOteqlbB7GCWnzC1VmZmZqcVamGb1ajj7bHj0UTjnnPgLZhSbRYsWccQRRyRbjKSzc+dOatasiapy00030bp1a4YMGZIUWeL1TnrOng2Yr6FUQERmqmrEsc7p0yKoXRvmzgWb3GKkKK+//jpvvfUW2dnZdOnSheuvvz7ZIpWY51q1SrYIRgykjSJYu6M2t2aM4cmFC7FP00hFhgwZkrQWQKIwk1DZIG06ix/9uzA673ze+qltskUxjLRh+vbtTN++PdliGFFIG0Xwr3+5/WOLLkiuIIaRRty5fDl3Ll+ebDGMKKSNaShgSLhhGKXEi61bJ1sEIwbSRhEEkpcHvgmjhmEkEHMtUTZIG9MQQFPfCslRPAsbaUZJ3FCDcyRXkHfRkSNHMmjQoHiLXGaYlpXFtKysZIthRCGhikBEeonIEhFZJiL3RDh/qIhMFJFfRGSSiDSJlE+8GNL7VwD2zZiXyNsYZQzPDfWcOXO44YYbGDJkyP5w5cqVo15fmCJId+5bsYL7VqxIthhGFBKmCEQkAxgOnAG0A/qJSLuQZM8Cb6tqR+BR4MlEyQNQuap73Oz1WxJ5G6McMHPmTHr06EHXrl05/fTTWb9+PRDuwnnlypW88sorDB06lM6dOzN16tSY8v/Xv/5F+/btad++Pc899xwAu3btonfv3nTq1In27dvvdzNxzz337L9n4DoJZYFX27Th1TZtki2GEYVE9hF0A5ap6goAEfkAOBdYGJCmHXCb7/g7YGwC5aFKddcxsG9XYpx8GSXn1lvBt0ZM3OjcGXxlbUyoKjfffDOffPIJDRs2ZNSoUdx///2MGDEizIXzAQccwA033BC2mE1hzJw5kzfffJOffvoJVeWYY46hR48erFixgkMOOYTPP/8ccP6NtmzZwscff8zixYsRkYS7jY43bTyvv0ZKk0jTUGNgdUB4jS8ukLlAH9/x+UAtEakfmpGIDBSRGSIyY9OmTcUWyBSBEQv79u1j/vz5/OUvf6Fz58489thjrFmzBoiPC+f//e9/nH/++dSoUYOaNWvSp08fpk6dSocOHfj666+5++67mTp1KnXq1KFOnTpUrVqVa665hjFjxlC9jBWsk7dtY3IZU17pSLJHDd0BvCgiA4ApwFogLzSRqr4GvAbO11Bxb1a5hnvc7N2mCFKVotTcE4WqcuSRR/LDDz+EnYvkwjleHH744cyaNYvx48fzwAMPcOqpp/LQQw/x888/M3HiREaPHs2LL77It99+G7d7JpqHf/sNMF9DqU4iWwRrgaYB4Sa+uP2o6jpV7aOqXYD7fXHbEiVQlbpuMsG+BqENE8PwU6VKFTZt2rRfEeTk5LBgwYICXTjXqlWLHT4vm7Fw4oknMnbsWHbv3s2uXbv4+OOPOfHEE1m3bh3Vq1fnsssu484772TWrFns3LmTrKwszjzzTIYOHcrcuXMT9dgJYUTbtoxoa7P5U51EtgimA61FpAVOAfQFLg1MICINgK2qmg/cC4xIoDxUbujWTs0+0monRsFUqFCB0aNHM3jwYLKyssjNzeXWW2/l8MMPj+jC+eyzz+bCCy/kk08+4YUXXuDEE08Mym/kyJGMHTt2f/jHH39kwIABdOvWDYBrr72WLl26MGHCBO68804qVKhApUqVePnll9mxYwfnnnsue/fuRVX5lzdFvozQ0lsi1khpEuqGWkTOBJ4DMoARqvq4iDwKzFDVcSJyIW6kkOJMQzep6r7C8iy2G2pg4kQ47TSYPBlOOqlYWRgJwNxQpx7xeiffbN0KwGn16pU4L6NkJM0NtaqOB8aHxD0UcDwaGJ1IGQKpVmEfUIXdb38EJ11UWrc1jLTlsVWrAFMEqU6yO4tLldr13OMWwZxrGEYJeMdaemWCtFIEdeq54aNZO9PqscsEqoqIJFsMA/cu4kXTqlXjlpeRONLK15C3hvb2XeZxLpWoWrUqW7ZsiWsBZBQPVWXLli1UjVMB/uWWLXy5xWbypzppVTX2HCFm7a6UXEGMIJo0acKaNWsoyWRBI35UrVqVJk3i4/brqd9/B6BX/bB5okYKkVaKICMDalbax/YGLZMtihFApUqVaNGiRbLFMBLAB+1C3YsZqUhaKQKASjWrkNPSnGAZRmnQqEqVZItgxEBa9REAZGQo+blhXiwMw0gAn27ezKebNydbDCMKadciyNi2hbwvZwKnJ1sUwyj3/HO18zt5doMGSZbEKIz0UwSST16ejU4xjNJg9JFHJlsEIwbSTxFUUPLM+ahhlAoNYljhzUg+6ddHYC0Cwyg1xmzaxBgbFpzyWIvAMIyEMcy3oE+fhg2TLIlRGOmnCGrXIO/gw5IthmGkBZ906JBsEYwYSD9FULcOeYfVSbYYhpEW1Cnmcp5G6ZJ+fQQV8snbvTfZYhhGWjBq40ZGbdyYbDGMKKSfIti0gbwvvgZzcGYYCefltWt5ee3a6AmNpJJQRSAivURkiYgsE5F7IpxvJiLfichsEfnFt6JZQsmoVIE8Fdi1K9G3Moy0Z3zHjozv2DHZYhhRSJgiEJEMYDhwBtAO6CcioR6oHgA+9C1e3xd4KVHyeFSolEEeGfDqq9YqMIwEUz0jg+oZ5vY91Ulki6AbsExVV6hqNvABcG5IGgV8qwRQB1iXQHkAyKiUQT4V4I474P33E307w0hr/rNhA//ZsCHZYhhRSGSXfmNgdUB4DXBMSJpHgK9E5GagBnBaAuUBIKOKr0UAcPjhib6dYaQ1/16/HoDLGjVKsiRGYSS7s7gfMFJVmwBnAu+ISJhMIjJQRGaIyIySLl6SUaMqOVRiAwdBZmaJ8jIMo3C+7tSJrzt1SrYYRhQSqQjWAk0Dwk18cYFcA3wIoKo/AFWBMDeFqvqaqmaqambDEs5QzKhWhSn04GA2sOJnc49rGImkUoUKVKqQ7PqmEY1EvqHpQGsRaSEilXGdweNC0vwOnAogIkfgFEFCHZME9ltNvO3zRN7KMNKekevXM9JnHjJSl4QpAlXNBQYBE4BFuNFBC0TkURE5x5fsduA6EZkLvA8M0ASvYB6oCLK2SyJvZRhpz8gNGxhpncUpT0Lnf6vqeGB8SNxDAccLgeMTKUMogYpAdmwvzVsbRtoxqUuXZItgxEDaGe+CFMH6tTaXwDCMtCetFUH+vhyoWROyspInkGGUY15ft47X1yV8epBRQtJaEeS2OBx274Z3302eQIZRjjGnc2WD9FYEl/R3B9nZyRHGMMo533TuzDedOydbDCMKaacIAoc051auDgcdBD/+mDyBDMMwkkzaKYKgFkGewAknwKhRMH58wRcZhlEsXlq7lpfMDXXKk3aKoFIl/3FODnDbbS7Quzfk5SVFJsMor3y6ZQufbtmSbDGMKKSdIqhRw3+cmwt07w6vv+4ifAttG4YRH77o2JEvbD2ClCftFEHNmv7j3FzfQcuWbv/226Uuj2EYRrIxRQDQoYPbv/eejSAyjDjy/Jo1PG8t7ZQn7RRBmGkIoGFDePhhWLwYqlRJilyGUR6Z+OefTPzzz2SLYUQh7RRBaIsgOxvatIHPj37EbyIyDCMujOvQgXFei9tIWdJaEeTkwLp18OuvcOONwMUXQ8WK5n/IMIy0Iu0UQffu8Je/uOPc3JAyv3ZtF7ndvJIaRjx49vffefb335MthhGFtFMEzZvDV19B27awdSvcdFPASa9/oF+/ZIhmGOWOH7Zv5werWKU8CV2PIJWpVAkmTPCHRYDzzoPbb4eqVZMllmGUK/7bvn2yRTBiIO1aBB6BM4z307IldOliQ0gNw0grEqoIRKSXiCwRkWUick+E80NFZI5v+1VEtiVSnkBatw4Or1rlW5bgkEPA1lg1jLjw1KpVPLVqVbLFMKKQMEUgIhnAcOAMoB3QT0TaBaZR1SGq2llVOwMvAGMSJU8onTqFxw0ZAtSr5zoPDMMoMXN27mTOzp3JFsOIQiL7CLoBy1R1BYCIfACcCywsIH0/4OEEyhNEJBfp27YB1/aFY48tLTEMo1zzwZFHJlsEIwYSqQgaA6sDwmuAYyIlFJFDgRbAtwWcHwgMBGjWrFlchDv5ZDj99OAO448/BsacGZf8DcMwygqp0lncFxitqhH9QKvqa6qaqaqZDRs2jMsNq1aFL7+E444Ljv/w7b2wZIl1GBtGHPj7ypX8feXKZIthRCGRimAt0DQg3MQXF4m+wPsJlKVApk2DwCVVn/2/XW6SwW+/JUMcwyhXLNm9myW7dydbDCMKiTQNTQdai0gLnALoC1wamkhE2gJ1gR8SKEuhNGwIRx0Fs2bB9BX1yaYSla3D2DBKzH/atYueyEg6CWsRqGouMAiYACwCPlTVBSLyqIicE5C0L/CBanId/MycCXfe6Y5vYrjzRbFnTzJFMgzDKBUSOrNYVccD40PiHgoJP5JIGYpCz57wj3/ArxzuIvbsgWrVkiqTYZRlHvKZWB9t0SLJkhiFkbYuJiJx5plQrZpyxJ5FLmLv3uQKZBhlnNX79iVbBCMGTBGEcMghwo5aJ8EcTBEYRgl5s23bZItgxECqDB9NGWrVgu0VDnABUwSGYaQBpghCqF0bdlALrrgieBUbwzCKzL0rVnDvihXJFsOIgpmGQjjkEJg0qRZ5P79FRkaypTGMss2WnJxki2DEgCmCEE47DT74AL77DvLz4a9/TbZEhlF2ea1Nm2SLYMSAKYIQPFdG3nKWtnyxYRjlHesjCKFJk5AIm2FsGMXmjmXLuGPZsmSLYUTBFEEIjRoFh/Xn6ckRxDDKAXvy89mTn59sMYwomGkohDp1gsPZq/+gSnJEMYwyz/DDD0+2CEYMWIsghAohv8jeqgckRQ7DMIzSwhRBFGa9uwhsmrxhFItbly7l1qVLky2GEQVTBBF4/nn/8SkT7mbhB78kTxjDMIwEY4ogAoMHB4c3ZlkvgWEUh+dat+a51q2TLYYRBVMEBTBsmP/45Fs60q0bTJ6cPHkMwzASRUyKQERqiEgF3/HhInKOiFRKrGjJJbQSM326W6/AIzfXug4MIxo3/forN/36a7LFMKIQa4tgClBVRBoDXwGXAyMTJVQqcMQRhZ/v3h2qVg2OO+ss6N8/cTIZRlmjWoUKVAsdimekHLG+IVHV3UAf4CVVvQg4MupFIr1EZImILBORewpIc7GILBSRBSLyXuyiJ5ZDD4UHHwyP91xOTI8wz+zzz+G9lHkCw0g+z7ZqxbOtWiVbDCMKMSsCETkO6A987osr1DeniGQAw4EzgHZAPxFpF5KmNXAvcLyqHgncGrvoiefRR8PjbBljwzDKG7EqgltxBfbHvgXoWwLfRbmmG7BMVVeoajbwAXBuSJrrgOGq+ieAqm6MWfIk8d13wR5JReCjj5Inj2GkMgOXLGHgkiXJFsOIQkyKQFUnq+o5qvq0r9N4s6oOjnJZY2B1QHiNLy6Qw4HDReR7EflRRHpFykhEBorIDBGZsWnTplhEjhtjPw52P3rWWfD118Fphg8PDjdvXvz75eW5zTDKA/UrVaJ+pXI9rqRcEOuoofdEpLaI1ADmAwtF5M443L8i0BroCfQDXheRA0ITqeprqpqpqpkNGzaMw21j59zzhKUztxeaZvJkt6CNx6pVxb9f69bh/o4Mo6zyZMuWPNmyZbLFMKIQq2monapuB84DvgBa4EYOFcZaoGlAuIkvLpA1wDhVzVHV34BfcYohpWj19ctkU3itZv36+Nzrt99g16745GUYhhELsSqCSr55A+fhK7iBaEu2TAdai0gLEakM9AXGhaQZi2sNICINcKai1FvgdNAgKjU4gAmH3RjzJbm5CZTHMMoIVy1ezFWLFydbDCMKsSqCV4GVQA1giogcChRqL1HVXGAQMAFYBHzo62h+VETO8SWbAGwRkYW4zuc7VXVL0R8jwdSoAdddx19XvY7mxFbC22Qzw4CmVarQtIq5aEl1RIu5FqOIVPQV9qVKZmamzpgxo7RvCyNGwDXXwLx5TJlVkx5XNi80+ZYtUK9e0W8j4va2RKZhGPFERGaqamakczEtTCMidYCHgZN8UZOBR4GsuEhYFujUCc4+Gy68kJOWLOH5f+agGRW5+OLgjmIPaxEYhlFWiNU0NALYAVzs27YDbyZKqJSka1cYNw5WrgRg8BXbuOUWOPhg+Ne/wpPHqgjq1IHnnoublIaRUly2cCGXLVyYbDGMKMS6VOVhqnpBQPj/RGROAuRJbb76yl/Cb98ODRoAMGSIc0h31FH+pLEoAlWXzZAhkJEBLVrEX2TDSCZtqldPtghGDMSqCPaIyAmq+j8AETkeSD9nCxMnuv3550OtWkGnQhe9z86Onl3gyKLQNRAMozzwYElmVxqlRqymoRuA4SKyUkRWAi8C1ydMqlSla1e3b9MGQia2HXwwfPihPxypRZCbGzxHICcnATIahmEUkVhdTMxV1U5AR6CjqnYBTkmoZKnIxRe7/VNPwc6dYacvughef90dH3202+67z3/+kkugZk1/2BSBQ9XcapRX+i5YQN8FC5IthhGFIjkKV9XtvhnGALclQJ7Up0kTt3/nnYinjz7afzxjBjz5JCxf7sJjxrj9mjVub4rAcf/9ULFifH6PqVMhP7/k+YTyyy/QpYvr0zFip3PNmnQOrP0YKUlJVoyQuElRlvj9d6heHW68Ebp1cy2DvXv3n47ker1VK1i0yB/u2NHtC5t9PHx4+iyN+corbr9jR8nymTABTjopMaOw7rsP5sxJn3cSL+459FDuOfTQZIthRKEkiiA9pzyJwCk+q9j06a7TuEuX/adr1IC77w6/LNAX0Z9/un1hNeBBg9xIJK81kSi+/Rbq109uTdcbWBLB2lYkVvt83SbCEuFN8JP0rP4Y5ZxCFYGI7BCR7RG2HUCEaVRpwumnB4dDfKk89RQMHOiOa9Rw+0i13VhMId26FUO+IvDgg7B1K8ybl9j7FIanCIqijD76KNzLa0XfGLhE+HnyzE226mLRuGD+fC6YPz/ZYhhRKPSzVtVaqlo7wlZLVWMdelr+CF2sOAKvvgpz58LMmS4cWsjdfDN88030W23dWgz5ikGgS4sHHyzdmq+nCIpiGrr44uD+GHBzMSAxHc/WIigex9WuzXG1aydbDCMK6VuYl4SrroLateHWW53N5/rII2k7doSNvjXX7r03+NyLLyZWxFiJVLA99pjb5+eXTg24qC0Cr3YeukZRIlsERvG4o1mzZItgxIA1dItDRoarkrZvD+ec43o79+51Q1ZC8CpDa0NXYigDxKNmnZ/vlM3zzxecxmtgxdpHUFBB77UIEqEIrEVglGdMEZSEt9+Gjz92x/fe64ashBjbS+qBN1rB88UXMHt2ye4Bkb2dxqNA9QZUhbaIAvEK8FiHj0ZTUNZHkDqcM28e5ySzA8qICfusS0KjRvD0027GsTdluFq1oCQihReC0VB1ppNILiu2boUzz4TevYuff2GKJh4F6h6fI5KKhRghPRlivV9B6TxFUpKWzDPPuFXiQvEUZSzuwXNz3RwSA06tW5dT69ZNthhGFEwRlJRt22DWLP+U4gjrsx5wQMlusWcP/PFHePy6dW6/fr0bbup18hZnQlWiWgSxKAKPSC2C3bv9eUSTy1OWxZV7wwY39LdXr/Bz3u8Ti5IZONB1ZHsTB9OZW5o04RZvEqaRspgiKClXXRUc9nqHAwhcoOaKK/zHsRSOHs2ahZuAAv0WDR/u7+QNmN9WIgoqUFXdTNtYKGmLoFYt58cpkIIK45K0CAL9QGVFWGXDUwSBMo4ZA+PHh6d90+eg3Xv23FynHBI9J8QIJz9/v+d4oxASqghEpJeILBGRZSJyT4TzA0Rkk4jM8W3XJlKehNC2LfzjH/5w4LGP/v1df/Jbb8Edd/jjL7208KxDC89hw4LHzu/eHfm64iiCorQI3n7brdPzxRfR8y2KIojUIsjPDy+Yv/02cj4laRGcf75/VnikFpUXFyjjBRcUbpbz0i5e7BqM559fdLnKOmf88gtnxFprSABPP+3cuy9ZEvs1Y8b45wGlCwlTBCKSAQwHzgDaAf1EpF2EpKNUtbNv+3ei5Ekol14KJ5zgjhcvhgsvDJoAUK2aG2F6xRXQoYP/sscf9x+fcw4ce2xwtqHuKkaOBM+r7549wS2CQIqyOppXCEeqRRfUeev9ryPNE7r44uCFemJRBF4HbCwF+PjxznlfJAprEfz3v/D11wXn+9ln/uPCTGu5uW5w2O+/R5fVU0xeZ/iKFdGvKW+cXb8+Z9evH/d8ly+He+6J3mfjzdWJ5X15XHCB39IbiSlT3P9mw4boeZV0tnxpkcgWQTdgmaquUNVs4APg3ATeL3kccogrHTp3diXVf/8Lo0YVmPyoo+CII5z/ut273fj5Tz4JVhIA7SKpTVxNvHr1gmvGxWkRRCqECyqYK1Vy+0gd2B99BLff7o4vuADuvNMdF6QIPvvM37IoTBEsWQL/+1+43T1QBu84KwsqV3avwePCC+Gvfy04/0ACFYGqyyewtXHSSXDYYdHzyc52Hc/ff+/CgYr7t9+gbl1YujQ2mcoqNzZuzI2NG8c934sucrX9QB9e4CZwRrDORiV0ToqHqluPKifHX8HwhkJPnRrefxXIV1850+a0abHLsWhRcpxRJlIRNAZWB4TX+OJCuUBEfhGR0SLSNFJGIjJQRGaIyIxNBb2xVOCII/zHhfQQz5gB3up91ar517h5+ungwurIIyNf//nnbj9pUuTzniLIzy+4xpSX55yzeWmLoggqV3b7whbf6drVNbG9qRWRFEFenlsG2qOwP0DbtnDiiX4l5BE4G9m7fu5cd3zbbZGfPy/P9fEXRKAi+Oorp0R++MGFvd8kltZLTo4bO3DddcHxX3zh4rdtgxEjoudTHti7N7YadKx4315o6y8zM8j1V0zzP6ZMgQMPhLFjg+Pz82H0aOdRpnJl19e3erVLD25wRvXqYWtUAe778Co4xx8f7g4lEitWuMrfQw/54+65x8n+9tux5VFckt1Z/CnQXFU7Al8Db0VKpKqvqWqmqmY2DFkQJqXo3t1/HFjChVDQR1m3Lrz7rj9cUIvAq/EU9GF4pqHKlV3tNRLvvOOWyJw+3YUjmVO8wu7LL53nzZ073SJt3p8wsBCeNy+4z2LWrOC8PPPI3r3+P1yoCSuWwjXQhAPBs5FDFdPvv7tCPJS77nK/9Y4dcOWVrqURSKAiCHXx8cEHhcsXWEMMra2C+w0vu8wfHj3amfu8wiVZ/Pyzv5M7npw2Zw6nzZnDRReFd/qXBO97Cuyn8pT1unXhFYCsrHB/WqpOGXtuYEI9y2Znw7Jl/vD27c5bwObNLuz1O+zcGXy/XbtchSXQC+4TT/iP5893w5RD8QYT/Pyz22/Y4CqH4L7TgiqGcUFVE7IBxwETAsL3AvcWkj4DyIqWb9euXTVlWblS9f77VceNU337bdURI0qU3fLlqu4TC95OOSVyvLf98IO73gsHMmWK6rvvqg4bFnzNmDH+NF7c3LnB4WuuCb7msstUV61SPfBAFz755IJlOuool9dNN/ll3Lw5OM3DD4f/BoU9J6ieeaZqfr5Le+edkdPk5gb/Fg0buuN589y+Vq3wa3btiu3+oPrEE6qXXOKOb73VH3/RRZHTH3BAeNzJJ8f+XbzxhurMmbGnj4VI30o8eG3tWn1t7dr9+efkFJ5+/XrVjRuj59u5s1/m7GwXF/h73n23iwv9JlVd+sWLVV96ycXdfLPbDx4cnM+2baoPPhjbN7B9u7s2J0f1hBPCzw8e7P9O69Rxcfv2BT/Te++5+D59VEeNUq1ZMzyfP/+M/tsUBDBDCyhXE9kimA60FpEWIlIZ6AuMC0wgIoF1hHOACHWoMsShh7oxnD/+6HqGr766RNkVtJi9VyMpiL59/eYjD6/WctJJbhRTaKskFtNQqH1+0ybXgvFaKN99V7BM3jw7z1Hrjh3hfRnFGe0zfrz//gXZa194wX+8eLHfHuy5ra5TJ/yaHTuid0R63Hefv0vIW9YaXH9JJCKZpQKHGEfjmmv8q6bGG2+ifLy47pBDuO4Qv6PiwFbj6tXubxJY6z74YGemicSwYe673bPH3yIA9zuHvqvnn3emudBv8r33XEu5bVu3pAj4h5eGDhL4+uvC+wAC8eb5PPxweAuzVSv3jVao4PoBvTy9FvXq1a5l432PY8a4ARGROpojtTLjQcIUgarmAoOACbgC/kNVXSAij4rIOb5kg0VkgYjMBQYDAxIlT6ny9tv+4xtvjDy8JgZE3OpdoUQbjbdqFZx1lj+8aZOzY3rNzEjEoghCm/abNsVeWG7Z4tZ09vKsWDFcEQT2Eaxe7UZSxYJXsBbUST5kiP84sBvH66eJpAh27iy4A7EwiutNIZKdORn06ZPY/AMVwU03ORNl69bODBrpW3r3XbfgEDhFAPC3vwV/m/37w4ABwdfl5vr7sgLp3z88znMDk5cXXMm66CJ/R39BeGvutG7t/q+BJiBwJsiDDw4eaeeZMD2z5tFHOw8BkdYxCSVhI88Kaiqk6pbSpiGPzZtVW7cOb5MWk5yc2JqnBW0zZrh9YHP6+eeD07zzjrvX7t3+uO+/d3EF5duiheq11xZNllat3L5dO2feiJQmM1P1yCNjz3PECGfy6t+/eL/PUUeFx1WsWLLfvKjb1VfH/j3E4ZPSdev87zf0HW/ZUrK8A+kxa5b2mDVrf97LlvnPnX568H2vvz782QLDPXok5revUcN/3K5d0a7dsqXw81u3uncb6dzcuc6aXNC1TZq49+QVJVWrqn71VfHfBUkyDaUv9euXzMFQCEWZgRwJb0JWYA0p1OXz5Ze7Go3nEhpcrUo1cp5nneXy/XcRZ354ZoCFCws2b8yYUbRVxq6+2pm8ijujOrRjG0rflXVpjzfv0sWNZolEjx7hcX37wqefFv0+Axo1YkCjRvvnimzZ4swjQ4f6a/oer77qP4404i0Bo1CB4GG9XisxFjp0KNikd+WVrjO5bt3Iy9eCm5TpzQvyCFze+e67XWvC89AxZgz85S+xy1cUTBEkilAbwd69zmAZydaTYE491e0DFUFhwyc9Nm0qeP3fpk3DZ/zGsF5PQpk7N7KZpyzw4YfwxhvR3ZUXpJhD00RTip5Ne8MGeOml4HOhlsysLNcHEqupbt8+V2iJQMulBzPg4IP3V2YmT3b533Zb4XlkZAR3seXnFz58sqDRcQX1NxTGaafFli7SBMXp093vP3IkHH64iyuKz71//cvfT+NVlK680u0T6rKpoKZCqm5lwjSkqvrmm/423lFHBQ8n8YYPFIGCmo8DB8bejA0cbRQ6Aqio2+OPh8cdfXTJ8ozH1qVL6d9z/nzVu+7yhwNffaVKRc/v11/dO58/35m7AkeXZGf70xU0AscbEbZuXfTv6ZhjIsuwebMbebNvX3B8INu2qU6fHhx33XXB6avXztPlq/K0evWS/cY33hg5/scfVV9/3T/iJnTbt89vjox180YRRdsi/TdXrgz/rd99N/Z7f/yxuyZ0dNCmTQW/y1ihENNQxMhU3sqMIsjNdWPAIpVUxaCgD6dt2+DCobCtV6+S/Rm97b33VF95JTy+W7eCr6lfv3j36t69aOkzM+PzjNG24493+3PP9b8jr19hzRq3f/RR1R073PGzz8Zu437zTZefNwxxyhQXzs8PVsBVqkT+Vrz34A0jVnV9P7fc4i9gvDzq1Yssg1fwhhawa9b4Zena1cXNn+/s7BErAkNnac1/z9o/xDjem8e6dYWfv+8+Fz7sMPdeCstz/PjgcN26qgMGFJz3mjX+Pq0dO8Lfx7hx7typpxb+X4Zi1RFjxhRBssjOdgOMs7NVMzLcz927d7Gy8v5kL7+s+u9/+z+cZ591573w6NEFf2Rnnx2/P9+vv4bHF1S79Aqsyy8PP3fSSaqzZkW+zhtbv2iR6s8/q/7yi+tQ7NOnYNlCO36nTo3tmebNc4VEQQXD558Hxz36qOozz/gLRlXX+Xr77e54167wP3Uk5Rlpe+wxl/6ss1y4Wzd//qFp9+xx50aO9E9biaQI3njDxd18c/D3Eq1TvG3b8N9TteB3Hbadtl6r9F4fl+8udGvZMvj37djRxQeO4w98N95/QNX9Jbdti5zv9u2uU9YLZ2e71lfv3sGti0B27HCDMiLhfTunnx782wduLVqoPvdc5OvjhSmCVCBwdtGECUW+fO/e4NqGl5VX2AR+nIn4091wQ/gfwAv36+f23oSu3r3Dr1f1m0xatFBdvdqZH0LzCtzOPDPyb+GZw15+OTj9Tz+pLl0aHLdoUfRnW7zY5VuQ+cFr7nvhRx7xF8BFIT8/PO+lS/11hM2b3ciQO+906a+6KjjdDz9Elm/rVv/x//4X3DIbP97l9dZb/ncT+hsVZXv2Wfde4vVdLVyounZtbGnnzXPP9/jjkX/fTp38z7x2bbA5JS/PzfHcujX4Gm+k0iGHhH/ff/2rG2kXSmi6aHzyif+3D7w+cNu9O/b8iospglTAm1ILqu+/74/32pxFVA4vvaR6773+cJ8+riakWvQ/Y2h/QaAZJz/fmQd273abN+NW1f3RJk/226rffttd4+m8Jk3cRGvv0XbudPFnnBH+PF7hvmGDv6A5+ODIzz5/vpMxtADx+PBDf5xnMqhTx9/yeOEF//mOHf3XZWerPvCAi+/Txz2XpyQCf9eS8OmnrnbuFUCq/k8jN1f1oIPcb/HII+EtlHvuifz+brnFf9ytW7AiuOgid49AK6U3o7ZUtiq5bguJf/NN1VdfdbLt3euPnzNH9bbbIue1fHnhv23jxi7dtGmxv49XX3XXPPJI7O/3mmuCv5toZGU5i3DgTP1Gjfz3C/xPJRJTBKnAkiWuJwiccVXVVVO8r6FVq7jd6vDDC/9zigSHQ22mgYqgKGRnuyn527Y5m2xgIerxyy/Rp8l7CsMziRRGJEWgqvrHH04hqKoOHx48fj0nx5lIRo92yiSQvDzVv/89cufcs8+qPv10dJmKSm6ue2ZV1TZtCnZNUdzt4Yf9LYJS34bOcltA3FtvBT9/YEtJ1W/PD91C31UoQ4a4dJ7LiVjYt8+1NALNRIlm+3ZX+P/6a3hneyIxRZAqBM7WmjnTX+KBas+ecb1N5coF/zkvvTQ4/MwzweG6dV0H18KFcROpyMye7VoH0fBs1S1aJFykUqGwDveSbMOHJ7bAHzo08iRAOfUP5eQ/FJxpqyD3W7EogmgT3fLyim9iCRwdVV4pTBHYPILSJHCgfdeuMC7A9dJNN8XtNtWquTlt4MamB3o0BedvJZDevZ23xDffdBNWPv7YOU8NdMdQ2nTuDAcdFD3dV185NwVF8fmeyoT6l4rF7UAsxPHzisiBBwa7Y/AmpdX46UD4zg3mP/bY8JVdC+Ouu4InPkabp1Khgt+nVVGpVMn91p433rSjIA2RqluZbhGohtth2rRxYxGXLInrbbwRKpG8aIZ25ubmxvXWRgl4/XX/e2nSpOAO4tLeAru4mjULH0306afBtv7t212j94DGOUqNnKg17UMO8XeSe15hFyxwYS/PvLzE/vblHaxFkEI8+GBwuGpVV5X68EMXzskpmn+FArj+evf38VxGTJ/uFon55hs3SzRwun6gJ0cjuVxzjXNNsG2bc7zXsaOrXV9bwGreJ54Y7oJkzBj/bPJQiuLTftIk53oEnEO2CRPcbNpVq8JrznXqBM9cr1XLrcS385558Fh0T3xr1/p99Ldv777d0PU4KlhplTgK0hCpupX5FoGqc+L/978HV6kuvdSd86Y1rl+fUBHy811n1ddfJ/Q2RhzZsME/zPGSS/zxZ5wR/Cl5w4xDJ9edc47Lo7Caf+AEM1X/EN3rrguXZ+lSNxLrmWdca0A1+FpV1Rq9Nionbtw/hr44lHfbfWmBtQhSjGbN4IEHgp2HzJnj9t4KbAlY8DsQEec6N1a/KkbyOeggGDjQHbdu7Y8PrSnXqOH2kyYFL9r+xhsuj+HDgz2lewwa5JzCBZKZ6faRvpNWrZzzujvv9LtyDqXSjw1hakPuuKPAxzJSgBL6tTRKxCmn+P+RCxe60vnWW127OnRxXsPArwACTXvDh7t6w333Ob/33qJDNWq47euvnTfVBg1c/I03OlPPFVf485g82e+4bfZsv6O0zEy3XGesjtM++MCZdjzya2VDPlSOtDhAjCxfntj1eg0Q12IoO2RmZuqMGTOSLUZ8WLzYVbUCXU7WquWWLpo+3V8dMwwfqm6k1F/+UnKbuacwJk50dZJEUPml2eRkw4/HdeGYYxJzDyM2RGSmqkYsVBJqGhKRXiKyRESWicg9haS7QERURNKr5Gvb1q3/GOiw3Fu/LpKTfCPtEYHTT49Px+neva5jOVFKAKDR5KbwYVNr4KY4CVMEIpIBDAfOANoB/USkXYR0tYBbgJ8SJUvKEzqSCNw/1GP16nDjrWGUkCpV4PzzE3uPQ9c1gB8a7K/fGKlJIlsE3YBlqrpCVbOBD4BzI6T7O/A0UMz1pcoBRx7pX33CY8IEN8NL1XUue4ujGkYZ4vbH93FAy3107JhsSYzCSKQiaAysDgiv8cXtR0SOApqq6ucJlCP16drVLWmUm+t68Tyuvho++cQdB66nZxhlhOdqLaTT6IVFWqXLKH2SNnxURCoA/wJujyHtQBGZISIzNm3alHjhkkVGhjP+erN4wE0wA5tNY5RJ7mnWjHuaNUu2GEYUElm6rAWaBoSb+OI8agHtgUkishI4FhgXqcNYVV9T1UxVzWzojbMvz7z+uv943z63QvaTTyZPHsMoJr3q16dXgufEGCUnkYpgOtBaRFqISGWgL7Dfy5qqZqlqA1VtrqrNgR+Bc1S1nIwNLQGBs3Muv9wN5A5sJeTlOc9wZWzor5F+rN67l9V707f7r6yQMEWgqrnAIGACsAj4UFUXiMijInJOou5bbujePTh8yCH+4xdfhD594P33S1cmwygily9axOWLFiVbDCMKCZ1ZrKrjgfEhcQ8VkLZnImUpc3z/vfMO17evP27nTqhZ0w0nBdiwITmyGUaMPGCj3coE1gOZyoS2Cn77ze0vvdTtDzusdOUxjCJyWr16nFavXrLFMKJgiiCVaerra2/e3O07doQVK/yrb+zZE5z+44+d/wHDSBFW7NnDitDv1Eg5zOlcqvPaa87h/NVXu/CUKc4fUdeucNxx8M9/un337tC/v+to/vPP5MpsGD6uXrwYgElduiRZEqMwTBGkOtdd5/bLlsETT7i1/i65BGbOhEaN4N574bbbnCI4+WT444/kymsYAfxf6NqbRkpipqGywqOP+o9HjXL7d991Xsi8URm//w5z55a+bIZRAD0OOIAeBxyQbDGMKFiLoKwQaT3Ja65x+3HjnNfS+fNLVybDiMKS3bsBaOOtmWqkJNYiKEs8FHHkrePLL/3HNtHMSBGuX7KE65csSbYYRhSsRVCW6NDBLTO1ebM/7txz3QrmnnvHBg2cIvBWHTGMJPJEy5bJFsGIAVMEZYkLL4QLLnDLWHpeSg86CG73+e2rWdOtP2gO6owUoXudOskWwYgBKzHKGiLOZfURR7iwKsyY4dYu3LkT/vc/yMpKqoiG4TF/507m79yZbDGMKNiaxWWV3FzXSdy6NWGrfnz/ffisZMNIAj1nzwZsHkEqUNiaxWYaKqtUrOgcz4Fb1tI7Bti2LSkiGUYo/zA3KGUCUwTlgU6dgsOmCIwU4ejatZMtghED1kdQHghd+MPrI5g61b/CmWEkgTk7djDHVq5PeUwRlAdq14YePfzhbdtgwQI46SR4/PGkiWUYty5bxq3LliVbDCMKpgjKAyIwaZLzM/TOOzBvHpx6qjs3Zw7ceGMypTPSmOdateK5Vq2SLYYRBRs1VN5Ys8bvvjqQMvaeDcOIL4WNGkpoi0BEeonIEhFZJiL3RDh/g4jME5E5IvI/EWmXSHnSgsaNI8e//765pzZKnenbtzN9+/Zki2FEIWGKQEQygOHAGUA7oF+Egv49Ve2gqp2BZ4B/JUqetEEEfvkFzj47OP7SS+GWW5Ijk5G23Ll8OXcuX55sMYwoJHL4aDdgmaquABCRD4BzgYVeAlUNrCrUAMx+EQ86dHAL3C9dCr6FQQC/B9O8vMjeTA0jzrzYunWyRTBiIJGmocbA6oDwGl9cECJyk4gsx7UIBkfKSEQGisgMEZmxadOmhAhb7mjWDK69NjjulVfgqaegXj2/ryLDSCDta9akfc2ayRbDiELSRw2p6nBVPQy4G3iggDSvqWqmqmY2bNiwdAUsywwY4HwQHXkkdOnilrGsXx+2bwdrrhulwLSsLKaZ76uUJ5GKYC0QOHyliS+uID4AzkugPOlH/fpuMfvp010L4bbbYOBAd27SpKSKZqQH961YwX0rViRbDCMKiVQE04HWItJCRCoDfYFxgQlEJNCA2BtYmkB50pdq1WDvXhg61B/3229un5sLgwcH9yUYRpx4tU0bXm3TJtliGFFIWGexquaKyCBgApABjFDVBSLyKDBDVccBg0TkNCAH+BO4MlHypD316gWHN2xw+++/hxdegCVL4LXXYOtWZ0YqT4wdC7t3u5FTRqliS1SWDRLqdE5VxwPjQ+IeCji28YylRd26/uO773aO6mbPdq6swa1s1ry5O96wAQ48ML6rnC1YAB9/7Fofpe2IrF8/1yIyRVDqTPY5QLQF7FMb8z6aLlSp4j9+4gm3itlhh4Fnvw1UFI0auTT33hu/+3/yCTz4IJx3HrRvH798Y+GYY0r3fsZ+HvaZIG09gtQm6aOGjFJi4EB4+GFnIqlQARYt8iuBOnXCC/377oMhQ/zhzZtdS6K43ky9lse6dcW7viioBq/rvHSpa5EYpc6Itm0Z0bZtssUwomCKIF1o2xYeecR1HP/wA7QLmORdoYKbYBaqDJ57zn98xx3wzDPw+eeF36dbNxg0KDzeMwdt2VIc6YvG0KHQsKG/Q3zdumDFYJQaLatVo2W1askWw4iCKYJ05Oijg8N//gkHHwyTJ4cvcZmf7/YHHeT20SaiTZ8Ow4f7w6rQpAl8/bULx3tM+b59zoy1b58/7pNP3H7lyvjd55NPghWjERPfbN3KN1u3JluM5LJjB/z8c7KlKBRTBOlIxYpw7LHu+Oab/fHTprn5BoFUrgzz57vJaQAXXhjZrfVHH4X7N5oyBWbNgrUB00firQiGDYP773cjnzwuv9zta9Rw+8C1GorLhRcGm8oSxa+/wn/+E6zYyjCPrVrFY6tWJVuM5DJggOunKo3WcDExRZCufPGFq6UMG+Zq7V6hGeoOIC/P+S7atMmZkLy40aOdp1OvYJ83Dz77zH/dqae6AjgzwOtt7dqRC9PNm6FVK5dHUfHuv2ePP85zw+21Xk46ye1L4or79NPhqKOKf32sfPONU2TlZLnRd444gneOOCLZYiSX+fPd/o8/kitHIZgiSFcOOCDYRPT77zBzpjPrzJsX7pSuRw//rOTXXoOLLnK2919/dR2xoTOVv/3W7WvVghYt3EihMWNcCyOQzz939vzly50fpKJy4IF++Ty2boVDD3WT5QAmTHD7ktSyN24snT/y00+7/d69ib9XPNi717ksKYCmVavStGrVUhQoBTn8cLdP4TkVpggMR716rsZbubIrtO+7z8WfcII/ze+/h1/38ssu/dSpkfPdscN12tav7zqcReDHH/3nK1XyH3uFeiCzZ8Ptt4fX5r/4At56y8l3//3QubP/3M8/w6pVriWwbZsL160brNyqVYPTTosscySmTw82cSWK3bvdviSKYMEC99uUhnnpmGPgiisKPP3lli18mcImkVLhkkucadGbp5OKqGqZ2rp27apGKTFjhuqff6p+/rnqsGGq336r6opk1SVL/MexbA8+6D9+9lnV7GzV/HzVCy/0x597rmpenur337v0X36peuCB7tzmzcGyeddkZ6tOnKi6cqWLnzNH9cwz/ecXLVKtW1f15psjXx8rXvqcnJL8otFp0MDdZ86c4udx+ukuj+nTI5+fN0/1gQfc719SovyOPWbN0h6zZpXsHtu3q65eXbI8kk1+vvu2kwjOo0PEcjXpBXtRN1MESWb2bNVVq1Rzc1Uvvlj16qvDC/0WLQpXCrfconrwwa7AbtIk+NwTT/iPMzJU69d3xwsWBMtx/fUuft48v3JRDb+XF9epk+qGDf7ri6oI/u//XPrt20vw48WA97w//lj8PI491uUxbVrk882bu/N//FH8e3iE/o5jx6ouXrw/uH7vXl2/d2/J7uEptrLKhg2qIqrDhydVjMIUgZmGjKLRubMbWZSRAaNGwRtvuGGay5e70S7jxsHChW6ExNKl0KdPeB7PPw/r18P48cGdvOC3p4Lr7PXMCkce6cxK114Lu3Y50w7ADTe4/aOPRu4MXrTI7efOdaOYPM47z+UZypdfOrNTKPXru32ovKH8/e8wYkTx3Xx7HdIlmX3tuQYpaPKf9zuVdG5F4FBib5jxeee5OSs+GlWpQqPAWe3FoX37lLavR+Xuu91vnsL9PqYIjJJz6KHQsiX07++GkFat6vocWrVyyqFfP3/awHkKPXq4gv7SS+FKn7/BNWvCfRydeKL/+N133cgmb0y/NyJj+/bI8wb69vUfr1nj9qNGOUd0CxZAr17+QgzgjDPgzDPD8/E6ssePL9z2/tBDcM017tkjKSZwnfF33RX5/Jlnuol93iiuklCQ0rrkErffuLFk+Qf+DtOn+497995/+OnmzXzqKZzPP3eDC4pKrVqu78Tr/C9reAogWiUiiZgiMBJLtWrw3nvw0kuuAH79dRd/7LFuCCo4ZfDmm65zd+PG8AIyMBxYq2ra1D+ktVMnp4xC+eUX//Ftt7ktUDlMmOBGGWVluXMeK1e6ls0DDzhF4SmRq65yG7iJbNdc478mtAa+e7frYB871hWAq30L9g0ZAv/4hxuSG8oVV7gW17Jl4edixVOkBdVAH37YPd/xxxf/HoH5H3GEexfe8x933P4k/1y9mn96z33WWVAcl9SPPOL2O3cWX9Zk4n2/KawIkm7zL+pmfQTliJwc1X79VL/7Ljj+jTdUX39dddAgZxvu0kV12zbXYe3ZpAcNUn3sMXd8xhmqRx/tPzdhgmqFCgX3URx1VHifxVNP+cMXXRR8fu5c1WrVVOvVc+GDDlIdNSrYPp6fr7punepZZ/nzCMzT2z77TLVOHX948WJny7/tNtWZM1WnTPH3lag6m/v778f2e27dqrpzp+tfOPRQ1alTI6fbskX17bdV77or/Nzvv8feIT5zppP1P/9x4T//1P2d/j427dunm/btU92xo+j9Mh7edatWFf3aWDnlFNXnnguOu+EG1SuvLHne553n5L/tNheeP191+XLVSZPi008TI1hnsVFm2bjRFVyqroB6/nn3B1J1hXGdOq4AfvJJ1UqV3D4/3xVyDzzgCqvsbNU33/QXKNWrF6wkjjjCFaKBcaHh++8PDu/c6T++5hq3v/bagu8RuBWmsCZO9B+vXOkK+vfec8rzm2/8o4Ly810hVquWS7t3r1NeDz4YeWSQVzCB6p49/t/28stdXPPmTiEF8t//Bhf6qqpt27q4yZNV16xxyjpSYZ+d7TZvhFhRR894ea5d64/bvFn1nXeC0332mSu4o+U/YoT7LT3y8yPL3bOniyvp6CpvFNvYsS4Mqh07Biv8gti1y73HHTtKJoOaIjAMx4YNqiNHukJ12TI3rPSyy4ILX1WnRMANOQ08d999rrXhFbje9uyzql27uuOMjOBzp54am0II3IYMiT3t0qXhcd27B4e/+MK1Yr780j3f4Yf7z91yi+oLL4Tnccopqnfeqfq//wUPGwbVr79Wfeklp3i9uIce8iuGgw/e/5P/9/rr9b8nnqj6zDOqb72leswx/pFXa9eqvvKK6rhxbvTZ0Uer/u1vqllZTrl6tG+v2qaNG432yScuzhtJFDi6ymsxhioxj6wsN5wYXMtN1SmoG24IVjZ5eaq1a/srALfc4i/Es7JUH344csG8caNTshs3Bsc/+6zqI4/4ww0a+JXxsGH+fLOzw/N89FGXbujQyM9UBEwRGEZB5Oerrl/val7eXIRdu9wfd9s2V0DNn68aOBb+229V//lPN4QW3NDAxYt1f2tjzhxX6IGbg+EVMrffrnr22a7g8cxMnvI4/3xXc2zRwt3/jDNUq1RxJrBOnQpWBJ75LFJLxdt69Sq6Miqs1eRt3lDXSNu6daqjR2uPoUO1x9ChLq5ZM9cC2bNH9dNPVU84IfK1Z53lfpOXXlIdPTr8/ObNka/7+9+DZZs1y72XgQNVBw928SNGuH2LFu5dfvBBcB4dOrh5LKF5d+qk2qePf2j088+Hf0uPPOLOPfCAC+fkqH71lfvGcnJcK/GMM1wr8JxzXNo77nAt3l693PWhrZkBA1y6WrVUf/21RJ960hQB0AtYAiwD7olw/jZgIfALMBE4NFqepgiMlGLKFDe5Lj9f9d13VX/7zX9u9263z8115wNNDDNmqP7wQ/j8iILMELNnq1aurNqtm6udjh3rFMfOna4vwJtwN2KEm/OweLGrec+b5+4f2ArwCqAqVZxiCoyvWTPYdOQVgq1aucJvwgR/fKtW7pk9k1Lg1rmzKui2GjV0W40a/vgVK4qulAK3nj1dgRhL2mOPVT3ttOA4TxE880xwfPv2/uPQFlWkzevnOfpop4z79PG3IPv3d2Y7z7T0xBPR59YEbkcd5Qr+fv3Cz3mmvGKQFEWAW6d4OdASqAzMBdqFpDkZqO47/hswKlq+pggMo5jk5jrzWGDNctcuvzL66Se/7Twnx/XFPP98eIfmsmWu4Dv2WFeD3bvXdfDPmeMU4wknqB52mKv9gurLLztFtny5K4i9zviePf2F7pVXqv7jH6qXXqraqJHfzFOhgr914JmBdu1yNeipUwsvUJ96ys1IHj7cTVx84AGnIJs08Xd0g1Nmv/ziD8+a5eI2bFA9+WQnZ82a7tyAAc68OHZs+P2GD3f7JUvcbxF4rkuX4PBxxwWHY1UU69YV+/UXpgjEnY8/InIc8Iiqnu4L3+sbpfRkAem7AC+qaqFj2jIzM3XGjBnxFtcwjHiRm+uGsGZkMMo3V+GSSH6kPFascBPGGjUq2j0qVnTDjX/7LXw50pycYD9WHjt3uuuqVHHDeRs39vugUg2fw5Kd7a6pVy88L88J4bRp0Lq1m3RYubLbb9rk5p6ceKKTsW9f53130SL4/nu4+mqX9z//6YY+H3EEfPedu8/xx7u8H3/cDam+9FL46Sd3j8MOi/03CkFEZqpqZsRzCVQEFwK9VPVaX/hy4BhVjbB8FYjIi8AGVX0swrmBwECAZs2adV2V7v7NDaOM0HP2bMDWLE4FClMEKbF4vYhcBmQCPSKdV9XXgNfAtQhKUTTDMErA+I4dky2CEQOJVARrgaYB4Sa+uCBE5DTgfqCHqpaPZZkMwwCgeui6FkZKkkgXE9OB1iLSQkQqA32BcYEJfP0CrwLnqGoJHZ8YhpFq/GfDBv6zYUOyxTCikDBFoKq5wCBgArAI+FBVF4jIoyJyji/ZP4CawEciMkdExhWQnWEYZZB/r1/Pv9evT7YYRhQS1lmcKGzUkGGUHXJ8nl0rVTD/lskm5TuLDcMon5gCKBvYWzIMI2GMXL+ekWYaSnlMERiGkTBGbtjASOssTnnKXB+BiGwCijujrAFQwvX5yhz2zOmBPXN6UJJnPlRVG0Y6UeYUQUkQkRkFdZaUV+yZ0wN75vQgUc9spiHDMIw0xxSBYRhGmpNuiuC1ZAuQBOyZ0wN75vQgIc+cVn0EhmEYRjjp1iIwDMMwQjBFYBiGkeakhSIQkV4iskRElonIPcmWJ16ISFMR+U5EForIAhG5xRdfT0S+FpGlvn1dX7yIyDDf7/CLiByV3CcoPiKSISKzReQzX7iFiPzke7ZRPo+3iEgVX3iZ73zzpApeTETkABEZLSKLRWSRiBxX3t+ziAzxfdfzReR9Eala3t6ziIwQkY0iMj8grsjvVUSu9KVfKiJXFlWOcq8IRCQDGA6cAbQD+olIu+RKFTdygdtVtR1wLHCT79nuASaqamtgoi8M7jdo7dsGAi+Xvshx4xacV1uPp4GhqtoK+BO4xhd/DfCnL36oL11Z5HngS1VtC3TCPXu5fc8i0hgYDGSqanvcGuh9KX/veSTQKySuSO9VROoBDwPHAN2Ahz3lETMFLWZcXjbgOGBCQPhe4N5ky5WgZ/0E+AuwBDjYF3cwsMR3/CrQLyD9/nRlacMtcjQROAX4DBDcbMuKoe8c5wb9ON9xRV86SfYzFPF56wC/hcpdnt8z0BhYDdTzvbfPgNPL43sGmgPzi/tegX7AqwHxQeli2cp9iwD/B+WxxhdXrvA1hbsAPwEHqarn6WsDcJDvuLz8Fs8BdwH5vnB9YJu6NTAg+Ln2P7PvfJYvfVmiBbAJeNNnDvu3iNSgHL9nVV0LPAv8DqzHvbeZlO/37FHU91ri950OiqDcIyI1gf8Ct6rq9sBz6qoI5WaMsIicBWxU1ZnJlqUUqQgcBbysql2AXfjNBUC5fM91gXNxSvAQoAbhJpRyT2m913RQBDGtnVxWEZFKOCXwrqqO8UX/ISIH+84fDHjLgJaH3+J44BwRWQl8gDMPPQ8cICLe+hqBz7X/mX3n6wBbSlPgOLAGWKOqP/nCo3GKoTy/59OA31R1k6rmAGNw7748v2ePor7XEr/vdFAEUddOLquIiABvAItU9V8Bp8YB3siBK3F9B178Fb7RB8cCWQFN0DKBqt6rqk1UtTnuXX6rqv2B74ALfclCn9n7LS70pS9TNWdV3QCsFpE2vqhTgYWU4/eMMwkdKyLVfd+598zl9j0HUNT3OgH4q4jU9bWk/uqLi51kd5SUUmfMmcCvwHLg/mTLE8fnOgHXbPwFmOPbzsTZRicCS4FvgHq+9IIbQbUcmIcbkZH05yjB8/cEPvMdtwR+BpYBHwFVfPFVfeFlvvMtky13MZ+1MzDD967HAnXL+3sG/g9YDMwH3gGqlLf3DLyP6wPJwbX8rinOewWu9j37MuCqosphLiYMwzDSnHQwDRmGYRiFYIrAMAwjzTFFYBiGkeaYIjAMw0hzTBEYhmGkOaYIDCMEEckTkTkBW9w81opI80BPk4aRClSMnsQw0o49qto52UIYRmlhLQLDiBERWSkiz4jIPBH5WURa+eKbi8i3Ph/xE0WkmS/+IBH5WETm+rbuvqwyROR1n6/9r0SkWtIeyjAwRWAYkagWYhq6JOBclqp2AF7EeUEFeAF4S1U7Au8Cw3zxw4DJqtoJ5xtogS++NTBcVY8EtgEXJPRpDCMKNrPYMEIQkZ2qWjNC/ErgFFVd4XP2t0FV64vIZpz/+Bxf/HpVbSAim4AmqrovII/mwNfqFh1BRO4GKqnqY6XwaIYREWsRGEbR0AKOi8K+gOM8rK/OSDKmCAyjaFwSsP/BdzwN5wkVoD8w1Xc8Efgb7F9juU5pCWkYRcFqIoYRTjURmRMQ/lJVvSGkdUXkF1ytvp8v7mbc6mF34lYSu8oXfwvwmohcg6v5/w3nadIwUgrrIzCMGPH1EWSq6uZky2IY8cRMQ4ZhGGmOtQgMwzDSHGsRGIZhpDmmCAzDMNIcUwSGYRhpjikCwzCMNMcUgWEYRprz/6vuPaNZf7a4AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([      \n",
    "      tf.keras.layers.Dense(16, activation='sigmoid'),\n",
    "      tf.keras.layers.Dense(16, activation='sigmoid'),\n",
    "       tf.keras.layers.Dense(32, activation='sigmoid'),\n",
    "      tf.keras.layers.Dense(32, activation='sigmoid'),\n",
    "      tf.keras.layers.Dense(3)\n",
    "    ])\n",
    "learning_rate = 0.005\n",
    "batch_size = 32\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "metrics = ['accuracy']\n",
    "model_filename = 'models/model_4L_v5'\n",
    "model_l_v_e_filename = 'loss_vs_epochs_images/model_4L_v5_le.png'\n",
    "model_l_v_e_title = 'model_4L_v5'\n",
    "model_history_filename = 'history/history_model_4L_v5'\n",
    "\n",
    "model.compile(optimizer, loss_fn, metrics)\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(model_filename, monitor='val_loss', verbose=1,save_best_only=True, mode='min')\n",
    "model.fit(X_train, y_train, epochs = 1000,  validation_data=(X_test, y_test),batch_size = batch_size,callbacks=[checkpoint], verbose=2)\n",
    "model.summary()\n",
    "graph_loss_vs_epochs(model.history, model_l_v_e_filename, model_l_v_e_title)\n",
    "save_history(model_history_filename, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:\n",
      "7/7 [==============================] - 1s 2ms/step - loss: 0.4053 - accuracy: 0.8290\n",
      "\n",
      "Test accuracy: 82.9%, test loss: 0.405291\n"
     ]
    }
   ],
   "source": [
    "best_m4L_v5 = load_model(model_filename)\n",
    "evaluate_model(best_m4L_v5, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241\n"
     ]
    }
   ],
   "source": [
    "test_ds_filename = '../test-ds.csv'\n",
    "output_filename_test_ds_labeled = 'test-ds-m4L_v5.csv'\n",
    "fill_test_ds_labels(model, test_ds_filename, output_filename_test_ds_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_param(num_versions, param_name='val_accuracy'):\n",
    "    params = []\n",
    "    legend = []\n",
    "    for i in range(1,num_versions+1):\n",
    "        param = load_history(f'history/history_model_4L_v{i}.npy')[param_name][:200]\n",
    "        x = range(len(param))\n",
    "        params.append(param)\n",
    "        plt.plot(x,param)\n",
    "        legend.append(f\"m4v{i}\")\n",
    "    plt.legend(legend, loc=\"upper right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_param(5, param_name='val_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAB38UlEQVR4nO2dd3gc1dWH37u9q/diSe4V9wqm2BQbQu+EkpAQQkggpACBEAIBAh8kJEDohBK6aaY3G4yNe8O9SbJ6b6vt5X5/zGoluWAZXJB83+fRo92Z2Zmzs7O/PXPuOecKKSUKhUKh6P3oDrcBCoVCoTgwKEFXKBSKPoISdIVCoegjKEFXKBSKPoISdIVCoegjGA7XgVNTU2VBQcHhOrxCoVD0SlauXNkgpUzb07rDJugFBQWsWLHicB1eoVAoeiVCiJ17W6dCLgqFQtFHUIKuUCgUfQQl6AqFQtFHOGwxdIVCodgXoVCIiooK/H7/4TblkGOxWMjNzcVoNPb4NUrQFQrFD5aKigqcTicFBQUIIQ63OYcMKSWNjY1UVFRQWFjY49epkItCofjB4vf7SUlJOaLEHEAIQUpKyn7fmShBVygUP2iONDHv4Lu8byXoCoXiwNBSDhveOtxW9BwpwdMA0cjhtuSAoQRdoVAcGBb8H7x+BTRsO9yW9IxgO7SWQ3vdAdvl8uXLMRgMzJkz51u3a2xs5Pjjj8fhcHDttdcesOMrQVcovoU6bx1vb3/7cJvROyj5Uvu/6nlo3gnLn4ZodM/bbv0EShYcOttiyEiEcEMjMhyGQLu20Nuoeevfk0gkwo033shJJ520z20tFgt33nkn999///c+bleUoCsU38Kb297kz4v+TJ33wHlxfZLmndBcCnozrH0ZXjwX3r8Bvnpg922lhHd+BS+eDzXrD5mJUkpCVVWEaqoJVlQgA25AQDQEAfdeX1daWsqQIUO44oorGDRoEJdccgmfffYZ06ZNY+DAgSxbtgyAhx56iHPOOYf09PT4ay+88ELef//9+PMrrriCOXPmYLfbOfroo7FYLAf0Paq0xYNBJAxf/xvG/wSsSYfbGsX3oMZTA0BJawnptvR9bH0E0+GdH38zfHa75vX2mwbz74LmEtCbtPUjzwNbMnjqAAGv/hiuXghmBwCed54kUl+L62e3dt9/0MNf39vExvpQ57JoCIQexC5+aSQMQoBO322xDIeQgSBCr0dGahA6GJpm5fbjXdBWSaShHl1KBjqLHTz1YHaBwQyeBrZv387LD/+Tp596iomTJvHSSy+xcOFC5s6dy913380jjzzCW2+9xfz581m+fHn8mBdccAGvvfYaJ02cSNRu5/PPP+fRRx89ACd8zygP/WBQ8gV8/tfeNUCk2CM13k5BV3wLJQvAng5Tfg2DToFTH4BL5kD/E2Dbp7D5fc1zf/93UBwT/1Pv18S++AvteTRK/T//QdU//0ekoapz3+EgNO7QYt7RmKBHghAOQCTQ3Q4piQYCRP2B3cI9MhhC6PUIiwVh0CMlREMRwhE7UX+YUIuPYGkpsrUS2iqhaQe4a6C9loLcHIZk5hGtKmX48OHMmDEDIQQjR46ktLSU66+/nnvvvRedrrukzpo1i/nz5uEpL+f9OXOYPn06Vqv1AJ747igPfX9x18LSx+DYGyHkhUX/gul/iHsYQOcF27D90NkVCcOXf4cxl0JSv93XNxXDxndg2vWa96LoEbWeWuD7CfrS4kY217i5fGrBAbKqk/mb62gPhPnRUdk9fo2UkqcXljAqN5GJhcnd1r2zppJEfYBj617kk9RLCevMzB6Zta8daoJeOB30Brj41c51l77Z+Xjlc/Dub2DJf2itz0Pf1g+H0OH++H0CpUY+b6nmqIYoMqKj7b/3kfSHB0FGCZVvR2+C22ZkE27zo3c60IVbQeiJhqNEjBkYMjIRQhBuaCBUU4PQ60FvwJeVh86gxxH0EiwvJ5yZjdPggaAHwn6CoSQiHh/S6kLoPMhIlFBdE8ZkJyLYDu01BHQ2zEYTQicIt/kh6McXEYSamgh5ffiDIVasWMGFF14IkQgNTU188N57yNZWzr38cqZPncqnixYx57PPuOgnP6Flewmm1BRsia4ef2Y9RQn6/rL4Ifj6IUgbrKVpLXoQXDkw6arObTpuPxu2Hjq7tn2sZRm018Hp/959/dpX4Mt7YdiZkNzzyrMjnQMh6E8sKObzzXVYTXrOH593oExjVVkzV72wAr1OcOzgNFyWnpWIP/d1KX97fxNOs4G5vz6awlQ7AG5/iJveWMdZ5uUcG76ft4SFRXIUJwxJx2LU732H9ZuhvRaKjv32A484Gz66mUh9GdULcjCVPYTjlMHUvrAIr34jCeP1yLDm4ba8P4+kP0C0rZFwNBlhSULnSiNcux0pvZiSnODKIVyyjUhrIzqHE53dTri5GZ3ViiEjk2BpCeGqSmrsKRT4m0CnxxP04Aw2aCEgeyp6XQKRnTuJuN0YUlMh4ifc3I6OBAyJyUS9TTR6fQCIvHxEZRnSH4DWFsJVVYRqaglHonyxfB2ZbXVEfT6u+vOfmXXscZw2aRKR1lbOnT2bZ55/nlUbNvLAv/6Dub2ZcDihR5/V/qJCLvtDOAhrXtYer/gvbWue597kRLyrnu0cJfc2QfU32uMDIegrn4VvXgfgw/m38OH8P+22yddVX/PK8ge1J+vf6By970prpfa/em180YtLd7JwW8M+TQiGo/ztvY3UufdRtbbg/6Bq9bdusuTNh1n5yYv7PObeiEQlD3yyheWlTd95H/tic9Nmnlz7OJ7Pbscd0gbL1tVt4+oXVnLr2+sIR7rfyrfWlLDs4Z/gaWuiva2ZRf+6nJv/+yEvLtXaVu+o1z6PW99ezy9eWMG/Pts9re+Dzas5//Vb8IVClLaW8ocv/8Bv5/+WBRV7zgRp9Ya45n+rcFmM+ENR3llTpWWOvPpjmHMl1G7UrtePb9GWfXY7RMKsKG3ib+9v4ugBqej1gkufXsrVL6zk0421vLu2Gl8ogtOnXSvOYC1t/jAfb6ih/csvaXn77d3sWFu/lieX/4MosMkymn98soX6hx/Gt7bzOtvRsoM/Lvgjv/36Nj4pOpq2nVZkKEpg2zbWVqQSaglhbKxjdIV2XhKmD8NfE6Lm9hO00AkQlXpkWDvvkYiJWmMuUWEkEtQkLFhdjq9iKzIQIKIP4W+vImQ14Aj5yPU0YPB7aTPZSZBtRA1WWl2DaDKkoXM4wKD5tfqkJAzZ/dA7XYRqavHVufG2GXAFvEQRlPsExn4FANhCfiJChyESRi+imJobiHq9uBPTEE4n+qxMonoD7c1tTB83ga9WruT4KZNJ8rYgdXocyYkUFBRwww038Oyzz5Kbm8vGjRu/9brsCcpD3x+2fADeBu3WsmQBy21W/peRxvC6Ek6rWgU546B0ISCh6HgtNhjygfE7xswiYfjkNgi2I+s380Cpdvt6StYxiCGz4ps9uvJfbIxUc2bh0VhKFmqx+7GXdt9XW4X2v3otDD8TgPs+2sLInASOHpj6rWasq2zlqYUlZCVaufLovXj3LWUw729apsMZj+xxk1ZviKy1/6Zd5yQ84yIM+v33J/7x6RYemb+D5xfv5L1fH01esm2/97Ev3tn+Dv/b9D9GV9dCVgb9nfnscJfxxY5y/EEjl00pYFCGU9s4HCD00iVMbNvAN19NQgod05rfJqFpHT8vv5Nzx+VS1uTlkkn5lDf7WF/Zxscbajl1VBYD0rUwXZ3bz83z7ydq+4br3h5ORvYmPi/7HJPeRL2vnum503ez8fWV5dS0+Xnrmqn86a31vLpsJ5eKm7XBPAlULIOC6bDmf5A6CDa9iycY5prVx5GbZOWRS8aysaqNez7cxKqyZuZtriMjwcygDAeD2hpAwiCrm3yTjVeWlTP6q6cJVVeTeOaZ3ey4Z+k9bGjcgMjIZ/7XXuqWf82sLx/Bu3wF/Z57ltZAK7/6/Fe0BlqJyijLvGn8Z0cqepsZvddD88ImMmL7attuJaTXk/rn+3CffjrN71Ujj9GuERkMIkNBbcNQkMYWD05fBAHojIJoIIIIRUAHemMEohGsliBhYcUSloSMZhJTnVi9jbQbsqhq8SElJNlMtNoTkX4/KXojJiEIpmXg9wcx+wMIIC8vjyWLlrAzGMYtbdz/4IMkBdy0JqWTj2T5229gDLTjtjqpkSYeePgJANqrq3AEfASsKWxZW4Yp6EYXaEafYEHodJSWlh7Q6xaUh75vFtwPJV9pj1e/wI6kXP7SbwgBnZ42i/aFXGqzw7KntG22fwpGOxx1EfNtFq7++Gf8et6v2dS4Kb7LtfVr+deqfwGwpWkL9y67l6iMajH3926ASGzgp2Ytr5gifOB0sHPxg9QaDNQaDGx58yoaKndAoB3Pa5exrnEjQSFYPflKSB2Mf9Vz3L30btbUrYkf09+kCfrjVfNZsOFlAm//Bq/Px/qqVuSecnD9rfDOtdBeT1VdI3cbnqSytNOz/Hp7A498sg4+vIkNqxfz/juvaCu63AHsyturK8ikCauugl9/fCufvHoPq167J77eGwxz85vfUNXi6/Y6b9DHj176HWc9/SKPzN/BrBGZRKXkF/9bzj/fOI8vnz8J3vyFNki2F2rb/Pz65dVc9swyHvtyR3x5eyDMX95ZT3F9513NjvJVAMzLHQ7AxEZtYPS8ATu5x/Ak5XUtVLf6uPnNbwh99GdS2zYQkEZ0pV+hL11AQBoZIXZwZfgxrvv0VjDWMi4ryhD7X3nkjAgmnaT5jevjdzO/emUBUauWvreo7nXe3/Ehp/c/nYvt/Vlfv472YDuLXryLRx+6h2tfWkXL4hfwLHqC0XmJjMlP4sIJediql0Hjdjjl73Dpm0TbqmHN//jAeS6X2R5hnuNU7MseYrR/GY/+eBwJViNTEluYW/gWH/96MmlOM+VNPq7zrmdUnfZ+p6T4OH98LouLG6nevINAdQ2yY6Ax4Gbz2z9nQ+MG0iNRHrLBqsB9nNr4vPaZLV3KjS9dzqUfXoq5uJqffzgYQ8tRJDZWY2oO8+HYU/EarWTUN2OwRNBbI0QCena4slnqd3Hf9GuJerSxnoDeRDQQRAaD8c/IFvITjYVXWpNztYVSYCoowpwzHHP2cHSJuZgsPqxJUVypAlugmiiCSr+FUCRKWIYpd1fSaPbQ4NTT7NX23+gLUZNooNKZTKM9k5b0XJxpSRh0gubmVjxGK0ZHBKvOSLs9jbAhlbDZSFphHjaTgSZPkGZvkLDFStjoIGywohOSkNGOFDqapIPWlsa9XqvfByXo30Y4oKVdrdIuUnfFcn6T7ODNnR+xfcpVtAw6GYClrmTk2pfgoz/Bqhdg5DmQMZw5Tgermzezpm4Nv573axp92of4+pbXeWrdUzT4Gnh7+9v8b9P/2NK0BVb+F1Y8DWVLAJA7vuDRpATuzcxlUdGkuFmrTVG2ffBvWPcaK0s+JhIb41zYWoocPIu7/MW8vPllrpt/nZZ2JyW0VrDdaORh2cgNK+6hZONLjNdtocUbonIXAQW0rITVL8D6N9AVz+diw3wyKj6Mr370i+2kfXULLH0U5t1BaPt8bUXdpj0Kq5SSD5auI6oL88eMRBbWv8vmymcYu/Hv2mAt8PbqKl5eVs6nG2u7ve6PX9xOaegTdugeZvZoC/+8YDR3nDGc0uAcnmnfzO+iVWze/AZsenePH2MwHOWaF1fx6cYaqlt8/P3Dzby2vBwpJX94fS3PLd7Jvz/v/LGqa9oCwFtS+3ocHfsxHNv8GBcZ5hMsXcynG2t5eVk5wXVv8QmT+Tw6hqympWQ2LmW5cTwVI37J8qxNLKp7D2ve83y25Ze87C/jlVV3c22/MibUvk50/j20eIOsaf4MRJSjvT50ju2EZIDx5jFM2vQZEaI88sUcxm/9Bxc2PcqyTTswfvwHrvM/yu9zNSfhzDE5XGFZQDs2Wgtns0k/iN+Ff8mbupN5ynw5bb4Q/7FcRbU+i3szPmdoVmwwbsNbsPwpkhpW8sRl4zh7bA4DP3kdsVILZw20tnHhxHymFybidDeji4RpKK+J55G/WfYpJil5sbKaEaI/lqiX6VtbWdPPSlTAwEU7SfGZ+cOrRqYsX8rU7TBjnY+IwcBzrhGsSSkCwJYRwJGhXTM7EnL55f9W8ZWjgOgfbkU4HARMFmQoRDQQBL2BiNCR5m9BHw6hS0mlISTw2BMw5eait3W5Y7OlgiPm/0cjCJ2eNkMqgSgxz74Jd7ANKULoDG6aPEHCkSjucANC78ERFVijYNfr0AlBgk2PNWzCHrbSHk3F6xFEdQbCRhtNMa872W4iEI7gD0Ww2J0EzIkYQl6cZjdS6Gh3ZCGkGcFeCq6+Jyrk0pXSRbBpLsy6V3veVAwyiq++mL+99BUhp4GyqBeAlmE/orVmOdQuoDrqoyJnNHlLHoH04ZqXJHRUGgxMNmfwixn38+P3L+Xit6/n44teYFONNpfqplfOZ1XsAlxctQR96Tz+m5bCX4vnYSo8htqSeTTp9RBy84TFSKYxkzp3gPetJv5RORcZWcXCxGxkFKKBDL4sX4w5msbbTjuZobG06jbwu7fP4+8nvESe9POcIxuDlLgiEX6bnsqJvnWUG/Tc+/Y93HPeG3i99fzrk2v51UkPk91RxVfyJaZ6EzempTCkYQNtPj/3rLiT5OpGztd/ScCRyxD3EnJ0Vrw6B7ZoO4+8+g7t5pcZljCeBS2nkZr/OUurVlBmred8ZyY7jQYcISOfuEL8tNWM/a2rEUseJdgwBDgxHnMGeGPbG3xZ/QGhlnEkpG6mxfk0Ot0xJCYXo0/9ghM9XtYmZvKLLEHW0rvxrn+eokgLt578OK3kced7G6lq8bG1tp2HLx7DKcMzufy/y7j1nfU8v6SU9ZVt5CZZ+XB9DX/1hmir3EibLgAY8ETrEAhsOT9GF/6YxxyCL4xpnF65gB3RYdjx8pw1wBuJbqI6PfkITvT4sNom8U1RFl97rJzX6uFNF3wF5ETgU1nPm1HtB2zJyq/Z9skJOKb5GeEPcEPIykIgIeig/L33OBE/pqikfNN/eCbJRmIkwrv2F3nda+AjWw6m2vt58lktp9mQ4WZ73XjeeGI1nkAYmZhE2pRJvDllOqvrVvN+8fukhH6O6fM7oGEb9+yYw+ayd0lNS+G2HZ8y/MRj+b/ZA9l6Wy0RIOTVYfJUk+ow89Qpuez4p3YX9/mCddQb72BF62LWO12c4PGSGYlQseMiLnFXYg0+yf/yf8oVfMW4r7YyeGkYpzeATErmJxV1eLZJPFNHEbQ62JY7hKk1G/ClW5EGL5RCc34KnnAzY8fN435rgGvM1+By2sDXRrC9DWEw4ZMSRzBAq1VPU6ieqF6HMTMXvdXU/fssBLg6s38afA00+1rR4cOgh4gMoo8mE4pIhLEZWyhKSV0DwujBII2Yotogsz6kvXezPkw05gP7ogmEDX68Fjeu9jTCEQiGgoj2MClRbZuoN4pOhrGGWjBFAqCzQ1SPzh7GlbjHOZ6/N0rQu7L6BS1X9ujfgjMzPqgZbixlzc7VNA2yMt5ZyAp3Cc2BZlqDreiFnoiMsGTij8krGQHTfwcmO1JKKo1GpoVCDEsZRo7uNEqDb7KtqYwdHi3HdkOgnlKioNPx8bZ5bA7X8qHDzhmlnzM5fBOb6r+BtEQMOgNN/iamZpxCeVUdWxI2kFrfhKhpYl7+CEQgHentR1n7PJ6SW5nm86FrOoosYzWvZVRz+7w/8SjwqcvCCZ5Wzmr38MvMdIzO9RRaivlC18a7y/9FtbucuZFGtn9+Lc9X1WIGKF3IdmsCHyTYSfVX8vH2lbxXPJcrnW6+bBxFzYi/csGSs0gUHh4Pn8kvdG+zqu4RliU30b95E8HyKOXe19CFMknSSTIiEa5obQNh4vZUJxfqL+O5rHIS6lcwzVNGV0Ff37Ceu5fejVMOxxK+jFuOllz/xfX8aeGfWFy1mGwSuKu+nNUnPMbza+8n3FyMsXUbi8w6fv/+j6lqvIcat2RETgIXTsjntFHal/vfF47hL3M30OQJ8qvj+zNrRBanPbSQd9ZWUvjNEzSYOzM6jLj4Ku1KxmxcTTjPyjxPGSObl7Cj/lJSk+bxaFICdr+eJHsqVYEGnkx08evs6Xy480Gswf6MrveTEmwiUlTAicMv4fwlt7LIu56vDGNwrq1lYmUj13jMHDW+hYE/W8TPP/gZo5u3M1pUUWwYychAA0tdHr7UJQKwtW0Nc1KSyDLlkR9uhmhYu3StFvQj88httBLU72S7/n+8vDXEWYNm88+V/2R13Wqihadxm87AlqUP8VLDfAZF9Xxjt+Gr+JCH5R3Ub1kTf98rWpOY0qZdp8Hyivjy+Us+ZcmERWTqLZgYilkOZK6jlvykAk5euwx9agpjZk9n6bpkrIveRCcl8prrGRZsoP7Bf+EAVhyTw42FQ0gJ5pKQG6F4uJN/+T/ihPYG1k38hgH2MnZ6dzDYMpj2UDtu0Y4TMESitBvCtDkiENDR6jQhiCL0PoTOD+wi6F1oDbRS66nFbDBj0OswG3T4A1aCQStChDFGzFilDnPIRKvBTDKpRAFpgLAvQjQqCYUD6LHiMbViiBpwm5rJsGUQ8YBBGmhv9xH2C0wGHVKAyaDDaoiiM1kR+AhYPBDRk5uS+R0Fat8cuYIeDsArl9DWUMlWQxGvjcrhotpVjAEtDtxF0J2hBgr0pZTpdIxNO4oV7hJa/C20BlrJd+XjCXpY1rKV887sHAxs9DfiF5DjbQUg5B4ENnhs9XNE0H7xP0rvh9e9E2dEsrVtHdvsmre+pL0Mw8cvsMkgEAiG22ez1j2Xhvo8jMEk/GIVX5pTKIx4qNW3MTxpFm5dLmV8jgg7+Xt9GZHjnOyc14q9pY3/Jq7h7NwsPLowZ7o9DDT2IzUq+TqhjWJTENDxeuV8GiM++oVCbKSRe8x+bk85Bln6FZ+n2AAT9RYfDaVfA/CN2cYb+uuwbtKTFxnGVP1GHk/18rElm23mJvoFw+wwGRmX/TLl0oCv/Ke8P7WW3MV/geQifM0l3J/sYHtCHW8NvIfx7bdg9S+j35A32Vp/NDWtBfxq7o9xWRKo23Ee54xOZ0a/EfxkxE/47/r/4jQ5+ae5P57oTtbVFPL7cf+m8IVJRNDzJ8dkPk4v4wzD9dyUlIgjoqdhfZTLt3rwxcJTFgk3R62MLDHATgNnp1/Cgx/Dc/r3kPku8p35lLnLkOEEylqCbAvcysJzjuf4/05koaWVsuYVtGZ8zTFeH772P/Krk2azfs5kHki30JoaoHRDKQOsF/Gb0FEck5TKC2drIbNhX/+Fh5MSSY66+b9KEK4IR68PkN1/KKQO5DfnvgWPHwveMlyn/5Npm19ipWcLRzsKaQq2MscFYy2ZPHXeOxh1nWmKty68lU93fspbF97KFR/dRhqpNPoa+cfKf7C6bjUFrgJeL3mPkf0nsqXsE4wOG09X1/ORCe5KSeTxVf8mb1kV/YGIkKxrsrDGbyJ4/TEEcPOj2HFcfEp+KMSz+eeTcvId8eOfDhSfcQ+G4cP521mj4KxRwMXx9aHaWur//RBNiXoWZbQyyPIWHzcv4aVp4A66qYg2M+2mqyjb8CyRYBV3HX0XPyr6EYvXLKY56iE2BE3EmEDE4CUxI580vREpJVubt9ISaEGv01Prrd3jmFAgEsBmtNHP1Q9drLK0vMlLczCI2WDCHNUSF4QUJPrTkFIQ1PuwOo1Emw20tLoJhkJYsWK2GWgONeGSgmRLMs1GL4aIEY/Pi0nYSMgwYjaYOw9eXw3Sis/gxWaxHdR2wEduDL2pGLZ/inTXkN7yER+WfMhjNGvrOgb2unSNG+HQ4pUpjlHohI7mQDNtgTYSzYkMTx3O9pbuRUQVbs2ryW2r0SrgGlOREQvzK7U470hhY4dbS2u7qM1NWEQICUG6KYFlFhNHLb+JTfYERCiNRStHkaM7gZWbcrhk1CmkWdP4W242V2UNRo+FG6ZewIzCiQSbpiBrfkKCFKSEahhpruM3zS1c2BaiMBjigsLT2CIu4HHTT8kNj2a9xYRXp+OE9hDbIu00EeE3bsnPW1p5w+ngpQHHsNFkZIvZhEHq2GQy4a5+D4BvLE6K8vPZWtvOfeELKR93DaGEzUSNFi5udXNxRR4iamClVc+EsIl/nzudXF0z6IwwYCZWKTnVko0xYT1LSyvY3BRmkQuaxDK8SU9xzcfX0i7CTC3Oweu3MG1ACgC/GfMbrhxxJf8+/t8Maylmp2kA87bUs6bVzl/Dl7Hx6Ifw59zJuEAB7yTqWZiSAK4c5tjNrNJHSNdbydDbqNALrrf4aXBmQON2/pTwKVembyNk0MYTjss7DgCfz8nWWjd5yVaEEAwzTmCl1Yw7+b+kYOauhmYuOGk6Q7MT+Lr9VAA+rHoWgAkZmoj3T+ssOvvtUdcwzpnP7A0JRITAN6sfEbuetrpYaMCWrBXmTLsehpzGj6bdwnmWXP5+0mM8OOMRLrLk8sCJj3UTc4BzBp2DN+zl4vcvptHXyD+P+ycz+81kSfUSDMLAMyc/w6SsSfwtUsM7Fj0zE4eS6G/jguxj+ZHbw6Prn2Hz6s+J6sCcE2DqRjhuqeCYL5vIrfMS0UPEIBjscfDvunpSBndvQBX1+wls345l2LA9ft2MGRlk3PhHvrlkAl9XL+a/G/6L1WAlw5bBgMQB3DblNq4fdz13H303f5zwR07vfzpCCBLMCSTYteKnqM6ITthJJh2jXnv/QggSzYm4g27K3eWEI2GMOuNufwmmBHIduXExB+K59VajAVPESlgXpNXSgN4oMFsMBMwe6oI1REQEj9fbcTNEij2FFJ2Z7HAIARiMOozSgjFqJqwLUt5eTqSjJW/QCyEfUVsyoUgIk37vdxEHgr4v6J5GeP5MaKuOL3ppaRnPf7IUgJeNZ1Fi1G5UFlvMVBr0UL2Wp1d+zGX1S6kzaQNIOVZNfJeW2Eg0J9Lib6El0EKCOYHGFgelreVxz6DZE+SWd7Xioly/B19jGZO8Cxns0xOSPlyRKHkeLVVQRvVMzr8CISWDwiZm5J/BBrOJNqFjgyOJgDcHA042bziJY/rn8ocTx/DAcQ/QJD1UG5q579i7mJg3kGMGZhKoPYPZQyYiEnKhajXGQBMG4JbGah6qb+LWaXdSO+Jq/lfTj7KmE9FLSX4YEmqmY4lGSQ+H+bjpTC5riTDGG+HeHa/wy6wszFHJpIQZ7DQa2Cm0AcuAzktRpnbRFpuH0DblxwBcmzyam5uaeTc0E0dEE7RLmio4peVVrZzalQXZYwA4u/A0ECG+qPqE5rCRdx1GUszZCL2Pbb4t3NrYxLiQD72IcsLaG6B0IQadgevHXc/4lBFQvwl/6khWl7WworSJ13WzGTnjIh6+eCxPXvkmR6UdxW2ikW2z7uQtq5HJWZN5+LLFPHTZ1zz6o1do1es5x1DPWfl5VNZ/ya9M71Hj0H44js87HoBoKIENVW3kJWl3T8OzL0UvJVIX5I5wJkmJBZxyVD/sZgM7XGeii6SypXkTSeYkpheOBKB/mj1+7U0eexX/PutdjtngZXHWCC6K3sCmgcfgXbdd6wAIkDEMTvwrGEy4qiU/mV+APWwlK30Ef7rgQ1KT+xMoLmbnjy8lWFYGwOi00RQmFNLob+SWybcwPHU452Sews2vRrjYN4o0Wxr3Tb+PJEsS7TodZzdpn6MYeyl/bvUwSO8guc5HONlCamYAfUSiN0ew+qJM2iaxpLiwZOUyK2glcaudyofeQobDtMyZQ9UttxDYsgUikb0KOkDy5ZfjOuEEJJIZ+TN49pRneWjGQzw04yHOG3QeALOLZnNe/oW88+BqGivb0QkdmY4shNFIRKeJoS7SXbYSLYnad0lK+rn6ke/K3+0vx5lDqD2Kp7VzwN4aE3SLQYc+YiCo9xPS+0lKt5OQbsNiMSGR6IwSQ9SEXuoReoHZYCLT5EIvoxANozfqIAq6qJFNmzYwJHUIT734FFJK6tyV1OgNBE3aNWDWa577p59+yrhx4xg5ciTjxo1j3rx5ez1v+0PfF/TKlVA8H6rXABCKRPnHp1v4ZrOWyfCOexgbjZ1fuLdyhkD1Wl7f/BarLVGuScwgCtRH27TtV/gx4ojH0BNMCWyvMhGWARq8sSyWleVsa9J+ALLDERpK13OufgFnB8oBGBoM0tSkCbo+nM34M//C9LaB5IXPJM00mqgQXG45lfpgMxF/NrefPpyrj+3Pvy4cg14nGJM+hvuPvZ/bp9zOSQWapzQmL5FfHd+fa08YoJX+ly7U3pBNEygcmaA3MLV/KsFIlJ3Ndk5nIlcPuJIV4aO4tbGZWxubWRgdizj1QQo852MLTGGIYziFdUcxJud4pBCUmYz0i2gNx5wuTRRG5CRQFRsXyBlxIRx3MzNOOZtbp/2an474KdPTxsL6N7XiJlcuDDkVpv6GYWOvJMVYiDFxOU0JsN1k5Pz+l+CruJTs2nGc1e5hRpaPu491YNr2gVY63kHdRoiGSSgaRzCiFdYMy3ah12m3s0a9kQeOfQCrwcpPPv4JVZ4qzhl4Tvzlg5MH86/j/8WkzEmURnzMs5qgYjm1eWO1zyhlKD8ffh2hlgkA8Xz3QVlFnFPn5O5aNxPbK7Qc7xh/OHkIEzImAjAhcwITC1L55XH9mbVL6XyguBiDu5Wvs0bgD0UJHjWOaHs7/l0KS0K1dVT85jrav/iC1jc7S+gj7R4qrv013hUraPv4Y0DzVP8y5S/cMukWzh54NjIaJfP+VxhTLDm9RvP+ky3J/OfEx7guaGZiSayBVOZIrP1n8u/aekZ6kkhMteIankTyhWeTf5x2PQfdBkxJZoyZmYSqa2guTabt/Q+o+PVvqL7tL7S+8SbNL2kFd9ZvEXSAkwtO5vJhl3PntDv3GnrYvKSais3NbF3Wme0kjCaiMe82HIp2C6uY9Way7Fnku/K7hzp2we8N43N3NveymfWkOc3YY/1Xgno/VoMVfaypV4o1hTRbGnarDX3UgEXaMBhiktlxnEgQfWxZJBzmb3/7K8fNOA5vyEt5SzH1MkiTXocvGozbCpCamsq7777LunXreO6557j00l3qRr4jfV/Q27WcWkI+CLhx/2cmCZ4SkqUWXimPJLDckEJyJMK0YIS3jBHCreXUB9eQFg6zxR7geVciFQYDiegZlZ1BdZOez7eW0OBtwWF00dSi3VIv3LkFKSWvLC9HmJqxChcWKfFWbmKErpTJPq3SclggSIpNy3HOsg5A6HSYMv/CooYpSH8/ZNRAaboW9on6c5jaP5WbZg0h2d55uzaj3wzOGdQpUAa9jj+cPEQTnsR+nU2Lhp+l/U/IAWBiYTKGmOgNHPIXfnTs9djyjuK4dh1Z3nQmjhhEwvjzGDDtCqqLT8UauZHlzRczJe+o+LGunHglAkHIoP1AjchJ6Awx5U2F427iZ9MHMHvocH477rcY+58AteugfpOWdWBJgJPuBJOd47JPQ2+p4u30TVijUS4cOAN8gxnQopXIJ/qruKAwVqFaskArtnr2NPjf2QAUjZyGQSfwhSKMyO7eGyPDnsH9x95Pe7CdBHMCJ+Sf0G39tJxp3HfsfQxMGsgml5Z1UJOcj8PowG608+txV5KgzwcgPybo+ck2SlpmM9vfhKllB6QOjO/vlBGZnDtc8+wnZU3CZNBx4ylDSHV0F5kO4S5L0fbtnKLdyXiWLO22XfWttxL1ejH170/L63PiIlZ7z90ES0vRJyfjXbwkvn2/N5dx9H8WI4NBGh59FM+CBWA0Ym/wIKWk/JfXkLlkBz/LPxkd4G1JYPtZl7HtoR0Yv/bhrG7FYvOizywg48+3Y0mKYHJqAmh0RDGkJhJoDBGoDWBIS6N9/nxMBQXobDZa33kHfUIChuy995SZ98ImdnzWxu8n/B6nyUlzjYfX/76C9mY/7c0BXr9nOdU7Wtm4UHMOKrY0x18rTEYiHeEKKYmEOtP+ZFSic1vw1Uqaqj1Eo5JwMEJTtYdIl6reaCRKNBKNL9MJQVaClUhQy2MM6YPYuzh3VoOVdFs6ldXlTDthPL+5/homTButtc/9YiHTzvgJA4eNYtUaLWvtqWcf5+yzzyY3KxeLwYw74uePP/89X3zyJS2BFgB+8bNfMGfOHMaMGUN27FwNHz4cn89HILD3Ooqe0qNBUSHEKcC/AD3wlJTy77uszweeAxJj29wkpfzge1t3IHDHfuVDPmgqIblxJScYR5IebSEgLLRjpdRsoTDYwjnWfvw2UsuLLidBnYdrmlp5OmMEnyUIbCEvOUYnD146nsvfT6XGV0pY+olGrESC2kWwqHQrebahFNd7sOY3YZDpYEnEUrmQdNFCWggua5Cc53OTeMXpeNbYOGOIVgU4IjuBN1dVsrykDX/NGehtO7EbnOgCBeQl7WelaVKB9l9vhiGnwfKn4ulbdrOB0XmJrNjZHN/v+RP78cc3r8SNjV9N0IT07LG5PL2whHfWVGHUC4al55JictEYbGNc/vH02zaHKu92bj31VE4enslzW9/AZXLhNDl3t6foOJh3J/ia4z8sHVw36WI2NRQzQF/ClO0LSNbr6ZdsI6HZo23QWqF546D9OC99FEq/gsGzIXsMtoz+jMmvY3lpM8Nzdu+PMSFzAg8e/yA6odtr/HJYyjA+d5cjZz9ATfs6Mu1aFoIQghE5CXy1rYG8ZO1c5SZZ+TJ6FPUimTTZ1M1DBy1Uc81R1zC7cPZePx7/xo0IqxXnwP5Q2UbBgDzMgwbhXbIYrvo5oE3E4F22jKQLL8Q8ZAjVN9+Mb9UqTEVFtM59l6SLLwYhaHn9daLBIO2ffUb9v7QePuVXu/EsXkLCGWcQbm4iWFFBpLGR9vnzCVVU4Lz/V4jFD+NpSSdUXY1twgQalrYCEcyGBhj9e9AbwZGBLcNH0G3EaPUTdQiisVL77Afux7dqNa5TZ9P4xBO0vD4H87Che/W6o1HJ1mW1REJRkjJtDJqQybr5FdSVtlGytgGhE9TtdPPeQ2sI+iMkpFmp39mGjGo/pIaUFKzv3oKxeSNSSoRBB3odEk3cbVGJTieIRiUYdYgoOCJR6LKdK6CFCIVRDzGnRmaOIDDiVswWA+m2NBLNibvZbjDqKdlZzJP/eY5xE0dz3MyjeenVOSx8+xnmfvUN9913L3/909/58JP3+GrRl1x55ZWkoCctEuGKiy/lf3Ne5diTjkVGJPM+n8djjz7Wbf9vvPEGY8eOxWze+91FT9mnhy6E0AOPALOAYcBFQohd76tuBV6TUo4BLgT+870tO1B0eOhhH/XNLQCcnOMnW99KTTQBELRZghSFQiREhmKUDh5O0oRhks/Pyf2ns8Eg2WE0kmtNIzPBwpSCfKRBK75o8xiJhrQQxLraUp5YUIzDbMBqayUSTILUQeQ2aOEPAfzBXU5OOIozs4iHTruWmQNGAZqXC/DFljqGOmYSqjmXpvKTKUhx7X+JfIegpwyA7NHaY1dufPXU/loYpsPrPG1UFouMUylPnMCUIm2dw2zg0UvGYTHqyE60YtDrGJo2CofRQa4zl6HJQ1nfsJ6fHl1AXrKNivYKchzdxTpO1mitt/QudgAkWR28eu7fuavwTE7zeCHooSjNQYo+VuwkI7BjPhhiEwHMuwvsaXDec3DsH0EIpvTXwlcjsvfc8Oi4vOP2WD7fwdDkobSE2qkZdiq13loybBnxdcNj++wIudjNBpIcVpa6TtE22EXQzXozvxz9SxwmB3vDv3EjliFDGJ6bCEBRmgPb5El4Fi9hy6TJNL/yCqHqamQggHngAFwnn4TO4aDx6WdoffsdCIVIPP887FMmI/1+Wt94g6pb/4x1zBiSLrsUz9eLMQ8eTObtf8GUm0eoooJAcTEAgW3b8Le5QGcg4LFizM0l/6knsfbX7lBM42bC6Es0QxNysRdp799kasVg1WL8OrsN29ixpF79C0x5eZhmnc2KMb+jqd+Uvb7n9iY/kVAUg1nP/Bc2U1vaxpZYSKViczMVm5uw2I1EIxKjWc/R5w9ESgjFPG1f7IdEp48JcVQSCkYIBbSUQr1ep8Wy0brmRqPa3Uw0IpFI6JL4IqUkEo4SDkWIhCXRqMTiMJJmS4sPtnZFpxfk5/Vj2JDhGI0GrX3uzJkIvZGRgwoo3VnKbXfezF9uvRO9XgvX6IIe0g12fvSjs1n+9XKCgSCL5y3erX3uhg0buPHGG3n88cf3eu72h5546BOB7VLKYgAhxCvAGUDXgJ8EOu53E4Aqfii4O0MuCzeWcRYwzNKM1eym1p9IiitEAC8b/OP4sHICnvQoppQFuEJGLJNuZVK/KTy99VXqDAZynJr3mmRJQqL92m+ujIA0YSKB0rYytlTX8ruT+/NEWRMhzxhkgQV9xTKiCETB0YjSr4g6stAZunuLw2LhglBEMjTLSXsgTEmDp1uGRI9JjLXPTR2oTbBx1uOQNzG++vKpBSTbTfEuezaTgQcvGI3TYkCn6/SwhmW7eObyCfhC2nu9dsy11Hhq0Akdx+Qew4elH7KydiUTMidQ6a5kYFJn+KEbeoM22cHWD7sVenTDFKvwC3m5fuZAbCY7bImtK1sMeZOhtUzrGTPx59Dl/F0+pR9JNiNDs/Zwd9ADhqYMBWBj00ZqPDUMSR7Sue+p/eiXYiPd2TmzzD1njyLHMghqhmn9e/YDGY0S2LiJhLPO4qrpRYzJT8JhNmC67HKtkvGDD3B/8inG2O24qagInc1Gyi+uov6Bf+BZvBjrUUdhGTQIY1YW6HTU/PUO9Kmp5Dz4IIaUZEy5uThPPBGdVRPsqNuNb00sc8tgoGXuB1gveILg0icxFxYgjEZyn3iW1sfvwfqLf3a2V555O87pAdJdz+NgLh6hxdRtEyYiYg2tIpEoXy6K0pZQxHa9RUv73QPNNVpB3ozLhvLVq1t5+x+rCAc1b71yazNCCApGpTBsWjZBf4TcwUkYjDoCnjDhYIRwMAKTbseYacfT7CcU87atDhN6o8DoNCGEwFvrJRKOEglH0Rt1REJREjO0VMGWGu2uz2QxEApENE9fCHQ6gcm6dykUQsS9Z51BoNPptOe2FHShMsLBAGvXr+EXv/oJXAsNDQ188N5cDM4MzrzgEqYdM41F8xcxb+48rvjxFfH9VlRUcNZZZ/H888/Tv3///bqO9kZPXL8coLzL84rYsq7cDvxYCFEBfAD8ek87EkJcJYRYIYRYUV9f/x3M3T9ueWsdJaWaZxINelmyVYvzPhfcwSPJrdTJRLJTtcHOFf5pODP64QxNA6DFN5rkGb9lTPoYjLFUp9zkwQDdbss2VoTITrCQac9GZ2zmxGEZzBptBCQ+XwI+l/ZB1RpzEQVHA2CIlTx3xWE2UBQT2P5pjnhmRP90+27b7pMOD73DezzqQkjuPGaKw8wV0wq73R7PHJbBpJh33pWpA1KZMVTzWIenDGdG/gwATux3Ik6jkze2vUFURqlsryTXkbvb6+MUxjzkhL1sE8sCIOhlRE4CRY4Q2j0NWvFM6kAojLVnHXtZt5emOMz8ZJf3sz8MShqEXuiZVzaPRn9jNw89K8HKRRPzu21/4rAMhhX1g6m/3m1WnL0Rbm6m+MyzqP/3v4l6vViGDaNfip1zx2nnw5SbQ8ZNN2Kffgz+jRsJ7NCuW1Oh1gwt5corccyYgfT5SDzvXAD0TieWESNAryfnHw9gzEhHGAwkX3aZJvaAMVf7qrYvWMCyCX9i/tH/5MPyEYTyTyZYUYOpSLsuyuqcvOm+lMd+t5xHfzWfp25YQKtjPGLwTFLOORmdQWL0aP1mdubP5M3/W0koEGHxGzuo3tFK3tAk6ir9NFZ2VvkGfGFev2c5az8vpzkmpjmDEzn55yOIhiUJaVbGzSog4A3j94TIHZxE1oBE+o1IQW/UkTVAuztwpljinrnBqMNg0s65M9mCM8WCzWWOf/ZGi55IrCujI8mC0An87SGiHXFzvY6gP4yUEpPFgJSad76va6djfccAqGZAFhhtEA1RunUDpTtLKS0p4dzTTuI/f7+FM8+/CIALL7iQt15+i6VfL+WUU7Q7u5aWFk499VT+/ve/M23atH1fQD3kQA2KXgQ8K6XMBWYDLwix67xQIKV8Qko5Xko5Pi3t4JS+dlDd6uPlZWUYfdpckBV1TXjb3fiE4AWDn8UWSa1MwJXQAsCNM6bz359M5PyjxuKrvIgBxjPR6wQWg4XRqdqAYE7GaEDz0DsIh230T3cwPK2QlIR2/nH+UXy88yMEgohnALUmTQwaHEMgKzawuKcJKCAeA9YEXfPMOzry7ReONDjnac2TPUhYDBZOLTqVT0s/ZUfLDkLRELnObxH0sZfBaQ92noNd6RiMCsVi5/5WrW+7iAlm6iBtIpFznu42EHkgsBgsFCYUMnfHXOxGO6cWnXpA9w/QNncugc2baXxMu7W2DN9zNohl2DAiLS14vv5aa+eapF1rQqcj+957ybrrLhJOPz2+featt5D3n0ewT5y4x/2Z8rS7ytb122i35+Bw6PBZ0qiY8zEyEMBQUEhjVTufPbsRV6qF0SfmM3x6DgFvmMqt2qCkdGo/DmZ9OZlnDaTR0o/qHa289cAq1s4rZ9QJuZx45XB0BsGGhVVEIpqH/PmzG6nb6WbL0hqaa71Y7EasDhPZAxP50XWjOelnw8kd0vldyhncfbKNqecMwOrUXpOYbsOVakXoBDanCWeKBYtj9/CIyaJ52kIITGY9RrOecDBCNBIr34954gajjoR0a+wHYd+54Tq9wJVi7S7oQsQcFKHNvBQJgbtac0AsSfGp8X4060esWryKE2eeiMmkHevhhx9m+/bt3HHHHYwePZrRo0dTV/f9563tScilEujalT83tqwrVwKnAEgpFwshLEAqcNhm1p2zooKolGQIrVLzs29KSTYX8pndijuWplRssGIw12EOmfnZlLHohI7zx+fxny+OYsyIgvi+JucezfL61eS5YpkXXTx0GbHSP81BsjOH9sjHmI2St7a9xaiUiSzclMRyj41CwJc6ooug77kF7cgcF++urWJAuoOmWOe3AWnfLYzAyHO/2+v2g3MGncMrW17h/hXazOV7jaGDNqPT+J/sfX1HyCWo3Zrja9FSLmVUa8mbOkj7IdzLj+H3ZVjKMLa3bOeuaXeR78rf9wv2AyklLXPmYB4yhEhbK5GGRsx7ucXuSPvzfP011tGju63TO+wknnN29+1HjfrWYxtztR9Zn1ETziFH57L8owqqPlmCTB7G/C9SkPOXYXUaOfWaUTiSLMioZPPX1TSUuWkZ4OWN/+g43jSRIssykmYfS9snIYwWPfVlbrL6JzD1nAHo9TqKRqexbn4F6+Z3tgpIyrJTX+4mGtHCKx3kDu4U8uRsO9GIxJHUfVAwNddJvVv7QTeY9HHPXG/UYTXuWYQNJh1CJzCa9AidwGDU4fV3CrrJqsfXDhaHFqKxOvYt5gUFBaxf3zmZ9bPPPtu5rv9A1n+zRitCrNW2efaJhyGx8xoymUw0N3Vm7ADceuut3HrrLvOmHgB6IujLgYFCiEI0Ib+QrjW9GmXADOBZIcRQwAIc/JjKXohGJa+uKOfEQhPGai3tamKulePy0rmj3IE5GiWg09F/ZCaV5ioGGQfFK8gKUu08ddn4+CAlwMVDLibfmU9eRwzd3HkxyoiN/ml27M5cIjLCq1tepdZby2/G/I6FC6M8sDLCguCv+e2xv9CKai54EfL3PHh00cR8shOtFKTayUywYNLrGJFz4KepOlAMSR7CqUWn8n6xNqv5twr6voh76DFB97dogm60xQT9wHrlu3L1UVczM38mx+cf/63bdcRd9wf/2rUEtm0n8847sE+YQKC0FGHc8+xC5sGDQaeDSARz0b5nlpJSEvSF0el1GM27h3/0Tie6hAT8Zi2c1u+oTJZ/VEFrc5hw0lB0esH42YUUjU7DkaSNEwidIDXPQX25m9J1Dfi9UT73/YZkwx9xJQ+ivdHP6BPzSMl1kDc0GX1s0H7q2QNIzXUgY5mCzhQLzmQLbz2wisZKD0On7XkquxmXD2UP1frfCSEECWnWeIhGb9SBlIQCEUQsVu5MsWCx9Wx2px5hsmsJCMF2LQRn3T10eajYp6BLKcNCiGuBj9FSEp+RUm4QQtwBrJBSzgV+BzwphPgt2gDpFXKPTbYPDSvLmqlo9nHHFDvECkRHpJuosXtZabXwk5Y2/pvoghQDW6s3c0rBKd1eP3NYRrfnDpODUwo7t+moTNOhg6iZAelODHZN7O9bfh9J5iRmFc4kyTaf2rYAtQWz6Z8bu5iHnrZXu50WY7yBlMWo58wx30MgDxG3Tb6Nrc1bKW4pJtvR83ktdyPuocdisP5WSO4PFhdUrICEAzd1257Ic+bFf7D3xvaVdXzx4mYu+etkrE7Ns3v3obU4kswc/+Mhe3yNlJKGxx5H2Gy4Zs1G77BjKijY6zF0Vivm/kUEtm3HVLj7WMuufPG/zWxcVA0CTr9uNHlDknfbxpSTg69dE5mkLBs2YxCvLYOAPY3UPCfjZ+9uT1q+k40LqzBZDDiSzIRb3XzRdjUnmIqIRmtxpVoZNKF7kylnsoVxp3TfVyQcxWDSaQOgGXseD0rvd2Cdlo6wC3TGvEOBCDqD6LFXvt+YHd3nFT5M9CgPPZZT/sEuy27r8ngjcOAi+9+TTdXaQOeoRB8RtF8hQj7Kfdp0a1N9PuY67CxyF+MOuuNZDj2lw0NPMCdw74/HMbkomahM5K9T/4on5GFk6kiMeiP5yTaava1cMOHA3sL/kLAZbTw+83G2Nm/9fn0qjHsIuVgT4ZjfwagLNK/1EBKODdobuoz1fDOvnIA3TMXmZgZOyCDgDVG+sRGTzcBxFw9G6Hb33Ksfe4bGr1eT89vfoHd0FzQpJdGwjKfbdWAZNkwT9JiHHolE415wt9dHJcVrGsgakEBNcRuVW5r3KOjGvDx8JSlYbDpMFgOJ6VbcTZn47Jnk5u85pJeW7yQcjFK2qYnhx+Rg3PgZ6xom0epPBTRB7wl6g47sgYmUbWjqFnI5VBhi51ZKGU8p7Mv0yUrRHXXtOMwG7i5+hj+mpWg50CEf9UEtnp5mdFEYCrG8Scu8HJb87eXKu2I32jHoDCSYEzhlRBZCCPQ6PWcPPJtLh13K6PTRABSm2nGaDZy6r1nTezlptjSm5XzP33NTl5CLlJqHbknQ0hzzJ39/I/eDmjvuYNsx09l2zHSq//pXAJqqPFTv0K6f8nVaKmzVthakhIAnTEPF7vO4Vn20iLdX57No6t18tGMgPnew2/pVH+/kuVu+jqfgdWAZofWAMQ8YwPovK3jm9wvjWSJdaaxqx+8JMezobJKz7NSX7WEuWcBUUIDfloorTRPUlAEZuB25hIWJtL0Jel5sudTi3WlpISKYKN2knYOeCjpAbuxHJjn7O2RsfU90el08FbcjDNOX6ZuCXu9heAoscRezxGpBJvWDsJ/62IS/qa5cCsNRJBKDMDAgacB+7V8IQZI5aY9VZV25cdYQXv3FFKymvu8Z7AspJaHKSgIlJZ1NqLoQjUiiUSMEPVrYRUYgFto6ULQ3B2ip9Wo5zXuh/tU3aHrpZRLOPpuEs8+m5eVXaH79dTZ+XYWQERJad1CxSSsqK9/cjIi14Cvf1DmlmLesCt+6dax84nMQMOVH+Xhagnzy9IYuBS9R1n1Ria8tyPaVtd1sSDz/PPKf/S+NASdfvbqNoC/MhgWx3uT+znNXsVkbaMsdnERavoP6srZ4e4BoJBrfNuWnPyGUN5SEWApscrYjnoERF+5dSMq0xe8ccgYnkjb7CgCKV9cjBDiSe17VOPK4HE6/fvR+/QgcSDrehxL0Xoq5dhX/13Yx7miQNr2eKlsShLw0hDyYpMSVMphCgxbv6p/YP94wZ3/IsGWQZvv21MusBGu8YOhIp33+fLbPmEnxrNnsvOTHRLv0rYgGg5Rdehll85M1D93Xoq2wJh6w49cUt/LczYt48S9LeOXOZfg9od22qV5XwZzPbJQe82uy7ryDrDvvwD51KqX3PcLGL3aS2vAN6XUrcbslbQ0+KjbUk9iyDZunhrKVWmbHxndW8exdG/jq+keoThpNv8FOxp46gGMvHkTF5maWztXyy8s2NuFpCaA36Ni4sLqbHTqzGdvESXz23w04UizkD09m89Jq1n1RwVM3fMXW5dodQsXmZhIzbDiSLKTlO/G5Q3hbtbuApe+W8NLtS4mEogiHE49H4krRBj0TMzVh1+nFXr1mnV5Her6TtHynljbYvz9Gs5725gCOJMseQ0B7w2DU7zEUdKjoFPQ+KXfd6DPvUEajNDZuoz0QxuXZyRZT5yj2Jr3UQi4RL2lSIE76G4XTbwHY7/h5B/cdex83TbzpgNh+MPC2BZHRznHpaFTiaw9+yysOLu1ffEk4IZ20G27At3YttXfdHV9Xe9fd+NauxVevJ9zcomW4gBZy2QeR1tY9evy7smFBJUaLnukXDsLd5OfTZzbGz097c4CaklY+enIjUugp0Q9hy/I6hF5P+t/vY93wnyP9fgaUvU+ypwSA9Qsqaa4LkNy8haSWLdRU+Nm5oZEFHzeBlGwbeD4ho4MRJ2vZOUOnZjPsmGxWfbSTjYuqWPdFBVankQmnFVBT3ErpuoZurV3LNzfR1uBn8hlFHDUjj4AnzIJXtiIEzH9hMzvXN1K1rSWe/tfhadeXaXehJWsb8LQEKF5bT3tzABmVcQ+5I5adkuPonle9CzN/OoxTrhoBdGa+ALhSLXt9zQ8RwyH00JcvX47BYGDOnDnfut2yZcvi+edHHXUUb7311gE5fp8R9IUrH2Hmu2exYtNXpIg2NplNGKRED2wUIQj5aIgGSJV6cKQxoN90dELHqLRvz+PdG3nOPNJt6Qf2TRwggr4wL9z6NfNf3BxftmlRFS/csniPnumhoOSbBr4a82dMZ/+YlJ//jJbXXsO3Zg2+b76h5dVXsR+tVdF6t9Zo8XPYZ8glWFrK9hNPovzqXyIjew+jBHxhtq+sY+CEDEYel8sx5w+kbEMjyz8opXxjE8/f8jVv3LsSXwCmeD8gZ1AiX768lXAwwuZvPLgtWQzb9hIZx44jOduBRXpZ/YnWhzy5eROp4UoiUR3vPbQWQ8TPtKZXcaVqVYx5Qzs90+nnDyK9n5P5L2ymbEMTQ6ZkMXRqNjqD4P1HvuH5W76mensLAJsWVWO2Gyg6Ko28Icnx/Z1/ywRMFgPvPbyWUCBC3jBt/ym5DhBQX+7G0xqgudoT208VbQ1aX5wOIba5TFidRjIKv/3u0ZVi7RYm6fjROFyhk++KIdb3/Nt+vA4EkUiEG2+8kZNOOmmf244YMYIVK1awZs0aPvroI37xi18Q7oFjsi/6jKCvr15GWAhWln5Bqmhjo9lC/4T+9HcVskn6NQ9dBkkTmueeac/ktdNe46wBZx1myw88DRVuwsEomxZVs+ErrQasobydUCBC1daWPb7G7wl9a2y5p8hgEO/q1XhXrUIGtTuCUGUlNTITiY6mag8pV14JQtC+aBHtCxeCEGTf+3d0JoFnW1NnyKWLhx6ur0dGu7RC9Xqp+PVvkIEAnoULqX/oIe34UUlrva+bTduW1xIORRk2LdaudHoOA0c4WP5eCR89/g1JmTZOOMnGxOV3U3jWdEafmE84EKGmuJWyjU0kZ9uZ9L97ybrzDsxFRYzf+Tyzrh7J9NT1JNBC/2lFjN70OCdfPoAJK+4lc9xAzrt5Amf/fly33jh6o44zfjuG2deM4tRrRjHhtEJsLhPn3jieWVePxJFk4aMn11O6roHiNfUMmZSF3qgVypz9+3Gc/6cJpGQ7OP+WCcy6eiQ/+s1RFI7SGpOZLAaSMmzUl7mpjLWdLRiVSvmmZnas1jJ2OoRYCME5fxzH5DP3r39IxwBqb/PQjRY9SZn2Pebp94TS0lKGDBnCFVdcwaBBg7T2uZ99xrRp0xg4cCDLli0D4KGHHuKcc84hPb3T0bvwwgt5//3348+vuOIK5syZg81mwxDrh+P3+w/YtHR9Zk7RknZt0Gh721ZmCDcbzSaOTR+FlJKvij9Ehn3USzMTdZ3exeBYb5a+Rke2Q0ahi4Wvb2PI1Ky4l1axuYmiMd1j/1JK3npgFTIqOfem8d3yePeXhiefpOGhhwGwTZhA/jNP41mylOZE7Vy3NfjQj8zDMnSo1stbCCxDh2JIScGWZ8Fb4u4MucRi6J6lyyj76U9J+/W1pF59NQCNTz9DYPt28p58krYPP6DxscdJOu88yutMfPj4Omb+ZBiDJ2Xi94RY9dFOUnIdpPfTBKntvffJ/s+fqB7zO3yRNGZclo3vwb+hE+24TjkZm96MTifYuaGJ6m0tDDs6O15CbyoqxPT++xQMdlBRtYZIURGOaVNI/t8LWF79JyFPA7Ypk7HYjbCH8LTJYoiLcAdpeU7S8py4Uq28ce8K3n/kGxB0K8SxJ3aO89gTzBSN3n38Jr2fi+K19YSDEcw2g3Ynsr6R9V9WYjDru1ViJqTtfwphRqELRGxQ9TBw77J72dy0ed8b7gdDkodw48Qb97nd9u3bef3113nmmWeYMGECL730EgsXLmTu3LncfffdPPLII7z11lvMnz+f5cuXx193wQUX8Nprr3HqqacSDAb5/PPPefTRRwFYunQpP/3pT9m5cycvvPBCXOC/D31H0EMtAFSEqrBboVknGJo8FInknR3vUCGDuIUkTd+7bhd7gt8TIugP40rR3lt9mRt7gokRx+bw+bObcDf4aWvUJonoOmkAaGMPpV9spKlKu0X//NlNDBntJDnTSkJB9wKrUCBC0B/GnmAmHIrgbw/FqwtB6+Hd8vocbOPH4zj+eOr+7/+oufNvtFa34bdq0wy3NWh22KZMpun5FxBA0mXabC32IhftO2ppW7ACq0eHu9WM3VdD5Q03QCRCw6tvYDjrxySkWml54w3s06YRHToWZ3IarW+8iWfxYqqlFkKb//xGglu3sL04iqdFcswEA56Fi4i626j+859xjB3Fjy7Lo+Kvd9P082ak10vW3+9BZ7djAtILXGxYUEk4FO3Wb8RcVARSEty5k0BxCfZJk3Aceyz2Y6fj/ugj0OuxjZ/wnT7H1FwHF90+idY6HxaHkZSc/RPOCacVUrqugfJNzRSNTsOVauX8WybgbQviSDJ/70HBpEw7l9w+mYS0vvcd2heFhYWMHKmlkw4fPpwZM2YghGDkyJGUlpZy/fXXc++996LbpV5i1qxZXHfddQQCAT766KNu7XMnTZrEhg0b2LRpE5dffjmzZs3CYvl+dz99QtCjMkqpDIKAal0LNVbt1mp46nCisTrkeWbtrabpD31xw8FmwStbKV3XwPk3TyAxw0Z9uZu0fGe8Mq+p2kNbow+jWU9zjRdPSyDu8bk/+4yVj67ClDeJ0ScXsOzdEorX1JMSqebCJy/pdpxPn9lAxZZmzvnDOL54cTPNNV4uu3tq3KP3LFpEuKaGjJtvxnXySYSqqmh+8UWqsqbCYDCa9fE7BfvkKTQ9/QwSsE/W8sztg1Ph01oqH/2Y+oyTWefexEjvAjJ8PtKu+w3L3t7OF3cs49wz9IRrakj+/U28dtdyBk3MIDMtFc+SpVQbHdi8zYT1ZhYsSgRg8JaX8c9bGG8ZakhPJ/ef/8SQlobJrKf86l+SdPFFJJ55Zvy95g5Joqa4FSEge2BifHlH9aZv3TrCNVq3QqHTkXPffZScex7GrKzdCoj2B1eKNf7DvL8kpFmZ+ZNhvP+fb8gfHout5zhIOYAFx4kZh+/70xNP+mDRdfKJePvc2ONwOMyKFSu48MILgVj73A8+wGAwcOaZZ3Lcccfx8ccf8+qrr8a36crQoUNxOBysX7+e8ePHfy87e6+gN+4AeypYEqhxV+IXMNIfYJ3FzOuuMDnCxsjUkYSjYSxCzwcO7UJMNfbsyxYORWit8+23l3QgaK33YrIaditRbmv0UV/mRm/Q0W94CkInkFFJ+cYmQv4IHzy2jjN/O4bmag9FY9JIjGUzVGxpJhqWDJmcwcaFVaz9vJyiMWlkFiXg3rCV+rQx9BPlTDj1eApHpTDvd8/Q4ixCRiIIvR4pJY3L1lH6TQNSwuv3rIi3KN2+so6B4zNoa/The30OpKQTGKR5qBm33kLC2WdR+mETtjpI6+fq9NDHjQWjUdu3oz+1q+tISSyg6PxNNNhn8uX2kwFoboow+u67cJ5wAu0LniASgXWvLiUnKYla51AC3u3UlrTRf9Jk2pcsoXHY8WTJWo75xTG0NkcxmQWJSdcA18TPo7moCH2CFp93HHssA774AkN69xBG7uAkVnxQSlo/F+YufT9MBf1ACG2iCYhXc+oTEih8Yw4HrCnJd6RgZCqX3TW1W4hGcfApKSmJP77iiis47bTTODPmIFxwwQU89dRTrFixIt7Yq6SkhLy8PAwGAzt37mTz5s0UfEtLiJ7SewdFnz0NvvoHACU12px+sz1a2Xi5QcfZjqL4tGNjbTlsjP2ippn2nQoHsO6LSl67Z3m3Qo5DxbsPreWz/27abfknT23go8fX8/4j37B1uVaM0lCpVQsOmZpFS42Hdx9ag5RaXNZsNWBLMFG2Xit6KRqdhi3BxOpPy3jjvpVsWVLN6u12ojojaSteI9LejjNYT0LTVkJGB20bdwDQ/NJLLP/zM0gJx10yGBmVFHpWY/fVsmFBJe89vJZX71zGzpUVbJx0Pa/du5riNfVa34zhw6lr1JEzKAlXqpW2Rh9SSnQ2G/bJkwlNPpX3Ht/MR4+v550Vx2O0+VjVNh6DIYzVV09o4Fhcp5yCMJnwp2recWkwh4RzzmHTUq2ZZ2OlB+ukyXjaJWGdhcyReSRNHkfBrAlknzAe25gx3f46xLwDY0b6boNSGUUuLHYjhaO6N1rSmc2YBwzAt3KlFv8f0tnDRe9y7bbvw4Ez2dJtMFZxeDnppJP48ssvmTlzZrx97sKFCznqqKMYPXo0Z511Fv/5z39ITU3dx572Te/00KXUppZr177QJXXfADA9qOcBKYkCZ6R2zp0yyVnI1x4tzSy1h4LeWNFONCzxtAQwZR660xSNStoa/LTW+3A3+XEmazE1vydEbWkbI4/PpWx9IxsXVjF4UmY8o2GYeRuWwWbWbNYGRDsyEpIybVRuaQG0W/ILb52IpzXAwte2Me/5zUSj/ShsWoSjcQdt73+AzmbF7tV+LOpWbcPf3MaGpz6jqvA0Epu3kLbyG042VuFf/i763BPYbtXi7KaQm7Ujf4n06rG6THz+7EaSb56ALcFEe3OA5BwHBqOOkD9CwBPG4jCS+68HaVtcC6+XMH52ASs+KGVjy2TKWrIYn7eS1tSTqd6pxfYjkSieiBW7U4eHLIoLJ1LzaTnp/ZzU7XQT7D8at0MbuMyb/f1bBRiMei65YzImy+6ZEf3+9wKhmhr0DgfGnB9+AzXF9+Nb2+fusm7X9QBGo5GmpqZuyy699FIuvfTSA25r7/TQgx6tT3asM19J83YSIhHcxqGM9geY6fGSkdDZenRSojZzj15Kkru0vv02OnpndFTeHSq8rbGCIAmbvu6sIKza2gISBoxNZ9jR2VRta6Gl1kv5+jrswUZa/nIjSY9dT16qH2eKJZ7REO9wJzTPzeo0kZrr5KSfjcCWYCK5eTNjxpoxDxpEy5w5+DdsxB7SLr7GrTXMf24jmwZfit+URH9XPY2PPU7g43dxnXwymbXLMBklAxzVjF33EEaLkSFTszj3xnFICas/2UlLrXbXlJRpi6fNtcbi6DqbjZbmMHqjjnGz+mE1h1jYos1GNHRIgOS8RNqbAoQCEdrqfUSjknGn9sdsN7Dq03IMZj3TztMKd5r9NnwFoxFESRvcvQvgd8ViN+5xIFGfkIBl8GAl5oofHL3TQw9o1XAdgl7cXklhKMyqcBGP1yzWJi6zd96+DHEV4oxEscooOtO+B3WklDTHhMjT1lm9V7ezDavTFPeaDwbtzVqM2WjWs+nrKsbPLkCnE1RsacZg0pFR6CIh3cqSd4r5+s3tVG5uJLNxI3mPP0bl7//ABOMKUm+6BSEE4eZm7GFNnO0uI21vvwGRKI4TjseWns55P8+ldPbPsZ53B+bsLGrvvptwfT0JhRnoZJi67Q00JYxmQIaHqdediD3hWMKVVyBMJgwpKbSPHcepuavxffUFxpEFXPF/x2Aw6hBCkNk/gboyN9mxuSSTMuzxPiZtDT4yCrSilpYaL4kZNgxGPYP7t7BmYxp5pjW4+uWRpNM+q5ZaL+4m7byk93Nx6Z1T8HtCmK1GzDYDRrOe+nI3wfEnkuwOxQtJFIojjd7poccF3YM35GVjsJGBmFnvdmICjKDNDB9Db7RxotfL4GAIjPvOIPC2Bgn5I/HHoIn8e498w2f/3fhtL/3etDdrPyDDjsmmvamz4q9icxPZAxPRG3TYE8wMGJtGydoGIhgZMHM4jmOPxVRUSLCkJF5A0fDwI/ifeAAAa6iVmj/fRs3tt1N22eVE2tuJlpcikJiKikg4/UcIk4lwTQ3W4UNxGv1UO4YjdUYGzR6lxWX1ekz5+RgzMxFGI+bBg/Ev/JLg9h3Yp0zWZomJxaLT8pw0VXlorGhH6LRJBzoKUtyxFErQ7oSSY4O3w4f5MRBglO19SB0UH9RtrvXEPf3ETBtmm5GENJs2F2SsJL1kTT2V21rJHpB4UD8fheKHTC8V9LbY/3Y+Lv0YL1FmiDSqo13i410EHaONa6sd3Fae2Nl3G9ixqm6PpfBdW5V6YoLe3hzA1xaMhzoOBO758wnVds7SF3G7aVi8BoDs/omA1pOlvd5Nc42XnEGJ8W0nD2xm2tc3M9v5OcOvPQcAc2ERweLiTtu//hq7Wyu4snjrMBUWkvfkEwTLy6m++eZuExHrExNxnniitu2wYSQkGwkbbQii5By159BCR99uANuk7nHrtHwn0Yhkx+o6XKkW9EatF7fFboynLoaDEdoa/fFmUYmpJn6W8WMKLCs0QU+zIYQ2Y3xzjQdbgik+J2S3Y+U5Y02jzEw8fd+TQigUfZXeLejBdt7a/hYFEUm2Lps62SU+3iXk0tZu5J2mv/FF2y/jHnpbo4+PnljPR0+si88I3kFzLExgMOvxxhomdTQ9gu6x7e9K63vvU/HLa2h8+qnO4770MnUffoleFyUpS/vh8bmDlLzyCQCuGm3wRUpJw/3/hzM3lX533Br3ik1FRYTr6oi0txOqrSVYUoI50ILTGsZVvQ7LyBE4jjmG9D/8Hvenn9H41FPdJiJO+vEl6BwO7BMmkDpQi0OnZRr3Wjlqic1/qXO5sAzr3uQsLV9L92xr8JOU2Zkqmpxtp3pHqzbPZp0PZGezKEw29CKs9XCxp6I36nClWmmp8dJc493rBAl5Q5Mx2wycctVIrUJToThC6aWCronrjoiH1XWrOafdR1PEQT2J2nprEui1L3Y4GOGjN3wEpBNvNDnuoXtioY3KLS0seae42+6ba70YLXpSc+xxD72+3A1CKzjZtLg6nocNWmy9bmdbz83fvp3qP/8ZAP+GzhCOZ/FiAuYkzO31yC1a5o7PHaIx5rWH52k9IfzffENg2zaSr7gcnbUzhNQxB2WwpATvkiUACL2O471vkrnlo7gAJ19+Oc5ZpxBpasJU1OnR2saMYdDyZZgKCkgZopWd54/b+7RsHTPX2ydNROwyG4wr1Yop5k0ndSlGGTQxg6YqD7WlbfE7oU5Bjwl/6iBtRvXYuuodrTRVefY6hVnBqFSuvP+YvU7WoFAcKfROQfe3EQJudxqwGqz8qKWJhpAZqysNdIZ4uEVKyZevbKW+KkSmcTO+qJOoXovjdgh19sBEVn9Sxo5VnaGPlhoPSRk2bAnmuIfeUN5OUoaNMSfl42sLsvjtHfHt5/9vM/Ne6HmPiabnnkPodDhPPhn/pk3IaJRoIIBv1SrC2f2x6ALU3/x7hA7aiivxNGmz+ESWLSC4cyctc+Zoc1TOPrXbfjvEOVhcjGfxEvSJidgnT6b9q6+ATo9aCEH23/6GZeRI7FO7T1jd4e1nFiZgTzDRf8zeO0qaBw3CVFiI69RTd1snhCAt1m41sYtnPXBCBgaznk0Lq7TQlYCE9Nh6YxdBj5E7JBlPS4BwMEJ2l5DTbsdTedeKHwA9bZ/bQVlZGQ6Hg/vvv/+AHL/XZrn8IzmRNWYT94//IynbrqTabyIn2Q6ejLigb/q6ms1fVzN+Zjq2pU9QExqCP2zFBnhj2SszfzKMj55Yz+fPbyI5205ihi0Wr07CZNHH87zry9zkDEokf1gKI4/PZe1n5WQWJlAwKoWmyliudChKfYWboDdM/nCtIEVKycaFVRSNSYtXfnqWLMU2eTINg2YS/XIFwdKdhOtqkcEgfmMCOeOz4Rs/plA7zYu3ELEmY7Hr0Qmo+etf8a1Zi2vWKbuVmJvy8sBgILB9B54lS7BNmoSpoADPokUAWIZ2hkV0djuFr7+211PsSrVyxb1Hf+vHoDOb6f/hB3tdn5rvpHJrS7eQi8liYOC4dLauqCMhVZsV3tgxo1NHBlLqwPj2R83IY9TxuYASbcUPm/1pn9vBDTfcwKxZsw6YDb3TQw+4ecvpYHa7h5NdmjdX7jOSl2yDgSdC4bEAbPiqirR8JxNOzceq13ps+wJafranNYjQCRyJZk65agQGo44PH1vH6k/LaG8OkDUgAVuCmYA3TFujD09LIH5LP+2cAaTk2Fn9yU6aqjxEo5JoVNJY1c5Xr2zl46c2EIq1om2t8/HFi1tY8UEpAMGKSkLl5ejGTmXROhtleTPwb9yIZ/ESonojPj8k5KeRfd+9mAJt+NrDyIIh2JNtJJx1Jt6Vq8BgIPmS7n1WAITRiCkvj+aXXiJcU4Nz5sy4V27sl4/eeWhDEkVHpZKcbSclp/sPz8jjctHrBS11PvqN6FKJmdgP0oZA/+O7bS90Qom54rBxMNrnArz99tsUFhYyfPjwA2Zrr/TQQ/4WPDodhaEQtGlZHBU+I8OTbTDjX/Ht2pv89BuZgs5kw6rTBN0bMJACeFsD2FwmhE7gTLZw0pXDmfuvNSx+cwf9RqYwbFo2mxZrg58dpfMdgq436CgcncbKD0rZ8uyHgHZHULG5mboyN0gtg2bI5CxaazXvffP8EoZG1sRnT2lNGwY04Xb1w79xI94VK9CNmoiUWqtU5/SZJG1cg98bJiIldoeR7FvvIvuuu7713JiKigiWlOCaPRvXaacSqtT6oXcI+6Eke2ASF902abflaflOfvaP6bu/wJoIv1p68A1T9Epq7r6bwKYD2z7XPHQImX/60z63O9Dtc9vb27n33nv59NNPD1i4BXqph+72a8UyrkgU2jTBcmMjL7lzgDASjuJ1B3EkmkFvwKrXhNXn037DvK1B7Amdza9yhyRzzAWDyB6YyMwrhiF0AnuC5s1vWFiF3qjrNuiWOzABKWFLiQGTUWK2GVj3RQVIbcqrjQu1H5r6ZVpmSlAaWf/oXOoffgR9Wio1Ldq+2x05NM15E/8336CbrHmmHVWeVqcJnzuIpzWILaFnzZacJxyPbfJksu68AyEExpwc7EcfjevkU/bnFCsUii50tM/V6XT73T53/vz5BAIBPvzww3j73Ntvv53f/va3OBwHtvlfr/TQ3QHN23ZGo3EPvU3ayE/uHHzztARAgiNW1Wkza4OgPp92wj2tQZwp3Ss+Rx6Xy8jjcuPPbTHBbyhvZ9CkDEwWA6G6OhoefoRQRSU6/bkELEmkiWZMeYVUbmnBoIeB+m1s2t6f+nWlNK7aii5agD3VQe2QWWQs+Buu006jcmszeqOOSMhIe9iK5+izaI0OBVrilahWpxFvW5BoRGJ3de+8uDcSzzmHxHPOiT8XQpD/1JM9PrcKxQ+VnnjSB4sD3T536dKlzJkzhz/+8Y+0tLSg0+mwWCxce+2138vOXinobUEtRTChi6C7sZGX1Cno7S3aoKcj1kbUbJboCOON1QR52wJkFH37nIr2Ll5xx/RlTc89R8ucORgyM0gbHaDWa8Jet43E6aOo3NJCQut2Una8Ckfdwvq7nqY1nIQ9K8KAcRms/TyAZeIkdDPPoO1tPyOm52iTDY85jW2G0VgqPaQXuOITCFidJiIhLT2ypx66QqE49Oxv+9yvYplnALfffjsOh+N7izn00pBLW0gLn7iiUYhVQgb0DtKcnaLX0ROlY0YdYTJj0bXha48QiUTxuUP79HqtsdLyhDQr2QMTkcEgrW+/g3PGCQycN4+ik0cDYKtaT7JLGwRNrF1HwV9uxGKGZp8FvzmZhNwkkrPtRKOQ9H//odmhpReOODYHg1FHiW0sQsAFt0zkvJvGY4hlfVidnfZ1DQ8pFIrew57a5x4seqWH7g55QB8LubRqMfSEpNRuPa3bm2IeenJM5I02rHo3vvYQvjYt/LIvr1foBMOmZZEzOAkhBG1ffEGksZHEc88FYMD4dHaurCB50RaSmreQJnxkBXfgOuE40rdtpM0wHr9P0C8vubMvSY2HmpJWLHYjydl2UvMc1BS3UTAypducj6DNzh5/rDx0heKwcDDa53bl9ttvPxBmAr3VQw9rvUBcsZCLHzPZyd1T8tpbApgs+s6ydYMFm8ETH2SEnnm9x10yhIHjtZ7fLXPmYMjIwH60lp/tSrFy5k1TsDqMtD/5MCO/uovMU49HmEyk5Tlp9RoJRQ24Uq3xasnmGi/1ZW7S+jljxTea3UNjIZ2uWJ2dZezKQ1coFPuidwp6VBNkVzQKIQ9ubGQndu+i2N7kjw+IApqHbvTgbQvGqz/3x+uVUuJbsRLnjBndytyFTkfKz36GPjER61FHkXTxxYCWmtcxG5kr1YLZZsTmMtFQ0U5TlScu5IMmZTJoUgb9RqbsdsyuIRebEnSFQrEPehRyEUKcAvwL0ANPSSn/vsv6fwId1SA2IF1KmXgA7ewkGqUtGsSEDXNMMFujVtKd3TNWPC2B+IAoAEYLVpMfX9v+eegdhOvqiHq9mAcO2G1dypU/JeXKn3Zb1jXFsWNih6RMGzvXNRCNyPj6zKIEMov2PItSh4duthlUj2+FQrFP9umhCyH0wCPALGAYcJEQoluVipTyt1LK0VLK0cBDwJsHwVaNkIc2nQ6X3gymWEc/bKS7unvb7lg71TijL8FWMIxwMEprvQ8EWHuYCggQ3KH1bumY9X1fOFMsmG2G+GOAxEw7wVif9Y5uhN+GwajHZDV0i6UrFArF3uhJyGUisF1KWSylDAKvAGd8y/YXAS8fCOP2SMBNm16Hy2CNd+dzSxvpXTJcIuEovrZg95DLiLOxDpsGQG1JK1aHEf0ephfb62GLtbSkjlne94UQgtQ8J2abId7StSOObrIa4l77vrA6jWpAVKFQ9IiehFxygPIuzyuA3eu5ASFEP6AQmLeX9VcBVwHk5+fvl6FxAm7cOoHTYIt56LW4sdGvS8jFE8tBtyd2F8KOmHT19laGTs3ar8MGi4vRORwY0tL2vXGMMSfm01LXORlGR5vYtDzHbrPM742xJ/dTPb4VCkWPONCDohcCc6SUkT2tlFI+IaUcL6Ucn7YfwtgNf5sWcjE64x56m+wecunIQXcmdY+rd4QukrPtHHPBIPZFNBik6sabaPv4EwIlxZiKinosxAD9RqRw1Amd/cQ7UhdT96Nv97Bp2RSN/o7nSqFQHFJ62j63tLQUq9XK6NGjGT16NFdfffUBOX5PPPRKoOssB7mxZXviQuBX39eobyWgCXqh2QUmbaILNzZS7J1x5o45K+M56DFSchwcNSOPkcflxufd/DZq77mH1nfewbtmNdLnxz5lyj5f8204ky1MOK2QgeP33mNcoVD0Tva3fW7//v1Zs2bNAbWhJx76cmCgEKJQCGFCE+25u24khBgCJAGLD6iFuxJw49bpcJoTwawNLEZMTgxd4uGtDX4QWp54V/QGHUefNzBeWv9tuOfNp+XlV7AMG0ZoZxnhurpus/t8F4QQTDytsFt/cIVC8cPmYLXPPRjs00OXUoaFENcCH6OlLT4jpdwghLgDWCGl7BD3C4FXpOzIvj44RP2tuHU6XJYkMDVoC83d0/7cDT7sCWb0xu8eUfIsWYyw2ch//nm2H388Ube7xwOiCoXiwPPVa1tpKG8/oPtMzXNwzPn7Dr8e6Pa5tbW1lJSUMGbMGFwuF3/729845phjvvf76VEeupTyA+CDXZbdtsvz27+3NT3A42skKgQuawqYtH7lelt3QW9r9ONKtezp5T0mWFyCubAQvcNOwo9Oo/mllzEXKkFXKI5EOtrnAvvdPve6664jEAjw0UcfxdvnZmVlUVZWRkpKCitXruTMM89kw4YNuFzf3jBwX/S6Xi7upH4AuGxp8Tx0kz2p2zZtDT5yBift9tr9IVC8A9u48QCk/vKXGPPyMfXv/732qVAovjs98aQPFge6fa7ZbI7vY9y4cfTv35+tW7cyfvz472VnrxP0tixtuiaXOZGoyY4OsDg7xTsSitLeEsCV8t099KjXS7iqGvN5mkduSEsj5SdXfB+zFQpFH2Z/2+fW19eTnJyMXq+nuLiYbdu2UfQ9x+igF/ZyaQtovdBdZhdeNNG2JyTH17ub/CDB1YOBz70RLC0Fel4VqlAoFHtjT+1zFyxYwKhRoxg9ejTnnnsujz32GMnJyfvY077pdR66O6ilKjpNTlqlDQfgTOzM025riHViTPnugr6/VaEKhaLvcjDa555zzjmc02VmsQNF7/PQY7MVuUwudqSfwq+Cv8GVUdC5PpaD/l0HRWU0SrC4GHQ6TP36fW97FQqF4lDRqwW9OmDk/ejkbn1c2up96Ayi2/RxPaXugQfYPnMmnqVLMebmojOrHioKhaL30OtCLuMyxnHd2OuwGW1Ut2rTz2W4Or3xtkYfrhQrQtfzEn2A1vfep/HJpwAIV1XjOO64A2azQqH47kgp96vlRl/hu5T09DoPfUTqCH428mfohI6aVj+pDjMmQ+fbaGvw73eGS6TdQ/Vtt2EdN46cf/4DAPMAlaKoUBxuLBYLjY2N30ncejNSShobG7FY9k/Lep2H3pWqVj/Zid3fcFuDj4yC/UvO965YjvR6Sfv1tdgnT0aflIR50OHLeVUoFBq5ublUVFRQX19/uE055FgsFnJzc/frNb1a0KtbfBSmdvZFCXhDBLxhnPs5IOpdshRhMmEdPRoA++TJB9JMhULxHTEajRSqCu0e0+tCLl2pafWTnWgl6A8TCUVpa4hluOxnyqJnyRKsY8ei28/bG4VCofgh0WsF3e0P4Q6EyUqw8M4/V7Poje20NWo56D3ppthBuKmJwObN2Cfvcc4OhUKh6DX02pBLTavmjWcmWGhs8hMOReNzdzr3Y1DUu3QpoMIsCoWi99NrBb0qJujZiVZq/BH87R6aqj2YrIb9mrKt/Ysv0TkcWEaMOFimKhQKxSGh14Zcalq18EqGw0w4FEVK2LmuYb8qRCNuN22ffIJr1iyEodf+tikUCgXQiwW9qsWPEJBs6fTGfe4QrtSex8/b3v8A6fOReN65B8NEhUKhOKT0Wre0utVHqsOMiHQvOHClWJDRKIEtWzAPGRKvMAvV1eHfpYlO88svYx40CEuscb1CoVD0ZnqxoPvJTrAQ8ke6LXelWqn/54M0Pvkkab+7gdSf/xyAyut/i2/Vqt32k3Hbn4/IsmKFQtH36NWCPiDNQSigCXpiho2WWi+G8k00Pvkk+uRk6v/5INYRIzCkpeFbtYqUn/8c5yknx/chDEbMAwccrregUCgUB5ReK+h1bX6m9U8hFNQEvWBUKt/MKyf6xrNYBw8m/9n/svPHl1J5w++wT5kCRiPJV1yOISXlMFuuUCgUB4deOSgqpcQdCOOyGuMeev8xafz0/45GX7oR+5QpGJKSyH3o38hgkLYPPsB5wglKzBUKRZ+mVwq6NxhBSnCYDfEYutGsR+9pQfr9GGMNbcxFRWT9/R50NhvJP77kcJqsUCgUB51eGXJx+8MAOC2dHrrRrCdYXqE9zs2Jb+s68UScxx2HMPa82EihUCh6I73SQ28PhABwWAyEg52CHqrQBN2Ul9dteyXmCoXiSKBXCnrcQzcbunnoHYJuzMnZ62sVCoWir9K7Bd0SE3QBeqOOYEUF+rRU1QZXoVAckfRKQW8PaILusGiDokazHiEEoYpKTLl5+3i1QqFQ9E16p6DHPHSH2UAoqAk6QKi8PJ7holAoFEcaPRJ0IcQpQogtQojtQoib9rLN+UKIjUKIDUKIlw6smd1xBzpi6FqWi9GsR4ZChGpqumW4KBQKxZHEPtMWhRB64BHgRKACWC6EmCul3Nhlm4HAzcA0KWWzECL9YBkM2mxFEAu5xAQ9VFMD0agKuSgUiiOWnnjoE4HtUspiKWUQeAU4Y5dtfg48IqVsBpBS1h1YM7vT7g9jM+nR6wShQFgT9PJyABVyUSgURyw9EfQcoLzL84rYsq4MAgYJIRYJIZYIIU45UAbuifZAGIdZu7kIBaIYzXrCTc0AGNJSD+ahFQqF4gfLgaoUNQADgeOAXGCBEGKklLKl60ZCiKuAqwDy8/O/88HcgTBOS4egR3AmmyGixdXVzEMKheJIpSceeiXQNTCdG1vWlQpgrpQyJKUsAbaiCXw3pJRPSCnHSynHp6WlfVebcfvDOGIzFXWEXGRYKzASev133q9CoVD0Znoi6MuBgUKIQiGECbgQmLvLNm+jeecIIVLRQjDFB87M7rT7QzjNnR660aRHhjUPHeWhKxSKI5R9CrqUMgxcC3wMbAJek1JuEELcIYQ4PbbZx0CjEGIjMB/4g5Sy8WAZ3b5LyMVo0SM7Qi7KQ1coFEcoPXJnpZQfAB/ssuy2Lo8lcEPs76Dj9muDopFIlGhYaoVF7thUdErQFQrFEUqvrRR1WAyE4425DMhILIauOisqFIojlF4n6NGopD0Y7tZp0WDSdWa5KA9doVAcofQ6QfeGtNmKuk1uYVFZLgqFQtHrBH3Xsn+IhVxUlotCoTjC6XWC3q3TYpfJLWQkDEIgdL3uLSkUCsUBodepX7zTYlcP3aSHcER55wqF4oim1wl6+66zFdHhoUdU2b9CoTii6XUKWLm8jmtaLaz693qISEAbFA1FwmpAVKFQHNH0OkEP2/RsM0Y4c0QmdpMeW4IZR5IZTziiBF2hUBzR9DpBD6Sa+NQW4oGLBuGydBYRyXBYxdAVCsURTa+LoQ/LdnHF1ALspu7iLVXIRaFQHOH0Opd2av9UpvbfwyQW4QgYlKArFIojl17noe8NLctF9XFRKBRHLn1G0FEhF4VCcYTTZwRdhiMIFXJRKBRHMH1I0MOg73VDAgqFQnHA6DuCrkIuCoXiCKfPCLrKclEoFEc6fUbQVZaLQqE40ukzgk5YhVwUCsWRTZ8RdM1DV4KuUCiOXPqOoKssF4VCcYTTdwRdZbkoFIojnD4j6CrLRaFQHOn0GUFXWS4KheJIp88IuspyUSgURzp9RtBVlotCoTjS6TuCrrJcFArFEU7fEXSV5aJQKI5weiToQohThBBbhBDbhRA37WH9FUKIeiHEmtjfzw68qftAZbkoFIojnH3GKIQQeuAR4ESgAlguhJgrpdy4y6avSimvPQg29giV5aJQKI50euKhTwS2SymLpZRB4BXgjINr1ndAZbkoFIojnJ4Ieg5Q3uV5RWzZrpwjhPhGCDFHCJG3px0JIa4SQqwQQqyor6//DubuHRkOqywXhUJxRHOgBkXfBQqklKOAT4Hn9rSRlPIJKeV4KeX4tLS0A3To2L4jEZXlolAojmh6IuiVQFePOze2LI6UslFKGYg9fQoYd2DM6xlSSohEVMhFoVAc0fRE0JcDA4UQhUIIE3AhMLfrBkKIrC5PTwc2HTgTe0Akov1XIReFQnEEs88YhZQyLIS4FvgY0APPSCk3CCHuAFZIKecCvxFCnA6EgSbgioNo8+42xgRdZbkoFIojmR4FnaWUHwAf7LLsti6PbwZuPrCm7QfhMIAKuSgUiiOaPlEpKjsEXYVcFArFEUzfEPSOGLrKclEoFEcwfUPQlYeuUCgUfUPQ41kuKoauUCiOYPqEoKssF4VCoegjgo4KuSgUCkXfEHSp0hYVCoWijwi6ynJRKBSKPiLoKuSiUCgUfUPQVZaLQqFQ9BFBl2GV5aJQKBR9QtCJqJCLQqFQ9AlBV1kuCoVC0WcEXWW5KBQKRd8QdBVyUSgUir4h6CrLRaFQKPqIoKssF4VCoegjgq6yXBQKhaKPCLrKclEoFIo+I+ixGLpBZbkoFIojl74h6BHloSsUCkWfEHSV5aJQKBR9RNA7s1xUyEWhUBy59AlB78xyUYKuUCiOXPqEoKssF4VCoegzgq6yXBQKhaJvCLrKclEoFIq+IeiEVZaLQqFQ9AlBl5EI6PUIIQ63KQqFQnHY6JGgCyFOEUJsEUJsF0Lc9C3bnSOEkEKI8QfOxB4QCasMF4VCccSzT0EXQuiBR4BZwDDgIiHEsD1s5wSuA5YeaCP3hQyFVfxcoVAc8fTEQ58IbJdSFkspg8ArwBl72O5O4F7AfwDt6xEyElEZLgqF4oinJ4KeA5R3eV4RWxZHCDEWyJNSvv9tOxJCXCWEWCGEWFFfX7/fxu4NGVEeukKhUHzvQVEhhA74B/C7fW0rpXxCSjleSjk+LS3t+x66k3AEVC90hUJxhNMTQa8E8ro8z40t68AJjAC+EEKUApOBuYdyYFRGIgg1QbRCoTjC6YmgLwcGCiEKhRAm4EJgbsdKKWWrlDJVSlkgpSwAlgCnSylXHBSL94TKclEoFIp9C7qUMgxcC3wMbAJek1JuEELcIYQ4/WAb2BNUlotCoVBAj9xaKeUHwAe7LLttL9se9/3N2j9UlotCoVD0mUpR5aErFApFnxB0leWiUCgUfUTQVZaLQqFQ9BFBV1kuCoVC0UcEXWW5KBQKRV8RdJXlolAoFH1F0JWHrlAoFH1C0FWWi0KhUPQRQVdZLgqFQtFHBF1luSgUCkUfEXQZCiNUyEWhUBzh9A1Bj0RAhVwUCsURTq8X9FBtLaHKSow52YfbFIVCoTis9Fq3tv7hR7CMGE5g8xaIRkk866zDbZJCoVAcVnqloIebmmh4+GGE1Yre4cA2aRKmfv0Ot1kKhUJxWOmVIRfv0qXxx+H6ehLPPfcwWqNQKBQ/DHqlh+5ZshSdw0Hek0/QOncuzpNOPNwmKRQKxWGnlwr6YmwTJmAbMwbbmDGH2xyFQqH4QdDrQi6hqipCO8uwT5l8uE1RKBSKHxS9TtA9S7T4uW2SEnSFQqHoSq8TdH1iAo4ZMzAPGni4TVEoFIofFL0uhu484QScJ5xwuM1QKBSKHxy9zkNXKBQKxZ5Rgq5QKBR9BCXoCoVC0UdQgq5QKBR9BCXoCoVC0UdQgq5QKBR9BCXoCoVC0UdQgq5QKBR9BCGlPDwHFqIe2PkdX54KNBxAcw4kP1TblF37h7Jr//mh2tbX7OonpUzb04rDJujfByHECinl+MNtx574odqm7No/lF37zw/VtiPJLhVyUSgUij6CEnSFQqHoI/RWQX/icBvwLfxQbVN27R/Krv3nh2rbEWNXr4yhKxQKhWJ3equHrlAoFIpdUIKuUCgUfYReJ+hCiFOEEFuEENuFEDcdRjvyhBDzhRAbhRAbhBDXxZbfLoSoFEKsif3NPgy2lQoh1sWOvyK2LFkI8akQYlvsf9Ihtmlwl3OyRgjRJoS4/nCdLyHEM0KIOiHE+i7L9niOhMa/Y9fcN0KIsYfYrv8TQmyOHfstIURibHmBEMLX5dw9dojt2utnJ4S4OXa+tgghTj5Ydn2Lba92satUCLEmtvyQnLNv0YeDe41JKXvNH6AHdgBFgAlYCww7TLZkAWNjj53AVmAYcDvw+8N8nkqB1F2W3QfcFHt8E3DvYf4ca4B+h+t8AdOBscD6fZ0jYDbwISCAycDSQ2zXSYAh9vjeLnYVdN3uMJyvPX52se/BWsAMFMa+s/pDadsu6x8AbjuU5+xb9OGgXmO9zUOfCGyXUhZLKYPAK8AZh8MQKWW1lHJV7LEb2ATkHA5besgZwHOxx88BZx4+U5gB7JBSftdK4e+NlHIB0LTL4r2dozOA56XGEiBRCJF1qOySUn4ipQzHni4Bcg/GsffXrm/hDOAVKWVASlkCbEf77h5y24QQAjgfePlgHX8vNu1NHw7qNdbbBD0HKO/yvIIfgIgKIQqAMcDS2KJrY7dNzxzq0EYMCXwihFgphLgqtixDSlkde1wDZBwGuzq4kO5fsMN9vjrY2zn6IV13P0Xz5DooFEKsFkJ8KYQ45jDYs6fP7od0vo4BaqWU27osO6TnbBd9OKjXWG8T9B8cQggH8AZwvZSyDXgU6A+MBqrRbvcONUdLKccCs4BfCSGmd10ptXu8w5KvKoQwAacDr8cW/RDO124cznO0N4QQtwBh4MXYomogX0o5BrgBeEkI4TqEJv0gP7tduIjuzsMhPWd70Ic4B+Ma622CXgnkdXmeG1t2WBBCGNE+rBellG8CSClrpZQRKWUUeJKDeKu5N6SUlbH/dcBbMRtqO27hYv/rDrVdMWYBq6SUtTEbD/v56sLeztFhv+6EEFcApwGXxISAWEijMfZ4JVqsetChsulbPrvDfr4AhBAG4Gzg1Y5lh/Kc7UkfOMjXWG8T9OXAQCFEYczTuxCYezgMicXmngY2SSn/0WV517jXWcD6XV97kO2yCyGcHY/RBtTWo52ny2ObXQ68cyjt6kI3j+lwn69d2Ns5mgtcFstEmAy0drltPugIIU4B/gicLqX0dlmeJoTQxx4XAQOB4kNo194+u7nAhUIIsxCiMGbXskNlVxdmApullBUdCw7VOdubPnCwr7GDPdp7oP/QRoO3ov2y3nIY7Tga7XbpG2BN7G828AKwLrZ8LpB1iO0qQsswWAts6DhHQArwObAN+AxIPgznzA40Agldlh2W84X2o1INhNDilVfu7RyhZR48Ervm1gHjD7Fd29Hiqx3X2WOxbc+JfcZrgFXAjw6xXXv97IBbYudrCzDrUH+WseXPAlfvsu0hOWffog8H9RpTpf8KhULRR+htIReFQqFQ7AUl6AqFQtFHUIKuUCgUfQQl6AqFQtFHUIKuUCgUfQQl6AqFQtFHUIKuUCgUfYT/ByRG1Essp7j5AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_param(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions:\n",
    "\n",
    "With 4 hidden layers, we got a maximum test accuracy of 87% and minimum test loss of 0.328615. In most of the variations, accuracy was greater than 82%, the loss test was varied, it remained in a range of 0.32 to 0.42"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "66db04d85e2e99dede4bf4a0fc71476952aea13c01c61836cc5a63733bc91206"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
